<div id='glossarypanel' class='panel'><div class='glossarypanelcontent' id='glossarycontent'><h3> G L O S S A R Y </h3><ul id="glossaryindex" class="treeview-red"><li><span>$\RNr{}$   </span><a id='glossaryinfo-201' class='msm_infobutton' onmouseover='infoopen(201)'>i</a></li><div id="dialog-201" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>
                                       $\RNr{}$ denotes the set of all real numbers.</span>
                                 </p>
                              </info></div><li><span>$n$-tuple   </span><a id='glossaryinfo-256' class='msm_infobutton' onmouseover='infoopen(256)'>i</a></li><div id="dialog-256" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An expression of the form $(x_1,\dots ,x_n)$, where $x_1,\dots ,x_n$ are numbers.</span>
                                 </p>
                              </info></div><li><span>0-matrix   </span><a id='glossaryinfo-4820' class='msm_infobutton' onmouseover='infoopen(4820)'>i</a></li><div id="dialog-4820" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><li><span>0-transformation</span></li><li><span>addition</span><ul><li><span>of vectors</span></li><li><span>of matrices</span></li><li><span>matrices</span><ul><li><span>associativity property</span></li><li><span>commutativity</span></li></ul><li></ul><li><li><span>algebraic multiplicity   </span><a id='glossaryinfo-20112' class='msm_infobutton' onmouseover='infoopen(20112)'>i</a></li><div id="dialog-20112" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><li><span>alternating</span><ul><li><span>property of the determinant operation   </span><a id='glossaryinfo-10344' class='msm_infobutton' onmouseover='infoopen(10344)'>i</a></li><div id="dialog-10344" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><li><span>multilinear function</span></li></ul><li><li><span>angle between two vectors   </span><a id='glossaryinfo-1973' class='msm_infobutton' onmouseover='infoopen(1973)'>i</a></li><div id="dialog-1973" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The angle between two vectors $\Vect{x}$ and $\Vect{y}$ is denoted $\sphericalangle(\Vect{x},\Vect{y})$. Its cosine can be determined using the norm and dot product operations by</span>
                     </p>
                     $$\cos\sphericalangle(\Vect{x},\Vect{y}) = \frac{\DotPr{ \Vect{x} }{ \Vect{y} }}{| \Vect{x} | | \Vect{y} |}$$
                  </info></div><li><span>antisymmetric</span><ul><li><span>matrix   </span><a id='glossaryinfo-4956' class='msm_infobutton' onmouseover='infoopen(4956)'>i</a></li><div id="dialog-4956" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if Â  $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div></ul><li><li><span>arrow     </span><a id='glossaryinfo-640' class='msm_infobutton' onmouseover='infoopen(640)'>i</a><ul><li><span>length</span></li></ul><li><div id="dialog-640" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>in $\RNr{n}$, joining point $P$ to point $Q$.</span>
                                 </p>
                                 <p align="center">
                                    <span>Click to see the definition of arrow.</span>
                                 </p>
                              </info></div><li><span>associativity</span><ul><li><span>of matrix addition   </span><a id='glossaryinfo-5160' class='msm_infobutton' onmouseover='infoopen(5160)'>i</a></li><div id="dialog-5160" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><li><span>scalar multiplication of matrices</span></li><li><span>matrix multiplication</span></li></ul><li><li><span>augmented</span><ul><li><span>coefficient vector</span></li></ul><li><li><span>basic coordinate vector   </span><a id='glossaryinfo-709' class='msm_infobutton' onmouseover='infoopen(709)'>i</a></li><div id="dialog-709" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><li><span>basis</span><ul><li><span>ordered</span></li></ul><li><li><span>bilinearity</span><ul><li><span>of dot product   </span><a id='glossaryinfo-1866' class='msm_infobutton' onmouseover='infoopen(1866)'>i</a></li><div id="dialog-1866" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>The bilinearity property of the dot product asserts that</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div></ul><li><li><span>cartesian product   </span><a id='glossaryinfo-494' class='msm_infobutton' onmouseover='infoopen(494)'>i</a></li><div id="dialog-494" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>of $\RNr{m}$ and $\RNr{n}$ is $\RNr{m+n}$.</span>
                           </p>
                        </info></div><li><span>Cauchy-Schwarz inequality   </span><a id='glossaryinfo-1985' class='msm_infobutton' onmouseover='infoopen(1985)'>i</a></li><div id="dialog-1985" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The Cauchy-Schwarz inequality asserts that</span>
                     </p>
                     $$| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$$
                  </info></div><li><span>change of coordinates matrix</span><ul><li><span>of a composition of linear maps   </span><a id='glossaryinfo-14429' class='msm_infobutton' onmouseover='infoopen(14429)'>i</a></li><div id="dialog-14429" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><li><span>reversal of coordinate change   </span><a id='glossaryinfo-14445' class='msm_infobutton' onmouseover='infoopen(14445)'>i</a></li><div id="dialog-14445" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{B}\EuScript{C}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div></ul><li><li><span>characteristic</span><ul><li><span>polynomial of a matrix</span></li></ul><li><li><span>coefficient</span><ul><li><span>of a linear equation   </span><a id='glossaryinfo-3280' class='msm_infobutton' onmouseover='infoopen(3280)'>i</a></li><div id="dialog-3280" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Look up the definition</span>
                        </p>
                     </info></div><li><span>vector</span><ul><li><span>in a linear equation</span></li><li><span>augmented</span></li></ul><li></ul><li><li><span>cofactor   </span><a id='glossaryinfo-8939' class='msm_infobutton' onmouseover='infoopen(8939)'>i</a></li><div id="dialog-8939" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-cofactor of a matrix $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><li><span>colinear   </span><a id='glossaryinfo-2194' class='msm_infobutton' onmouseover='infoopen(2194)'>i</a></li><div id="dialog-2194" class="dialogs" title="What does âcolinearâ mean?"><info xmlns="Unit">
                     
                     <p>
                        <span>âColinearâ means âhas the same direction asâ.</span>
                     </p>
                  </info></div><li><span>column</span><ul><li><span>matrix   </span><a id='glossaryinfo-4802' class='msm_infobutton' onmouseover='infoopen(4802)'>i</a></li><div id="dialog-4802" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div></ul><li><li><span>commutativity</span><ul><li><span>of matrix addition   </span><a id='glossaryinfo-5175' class='msm_infobutton' onmouseover='infoopen(5175)'>i</a></li><div id="dialog-5175" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div></ul><li><li><span>component</span><ul><li><span>of a vector orthogonal to another   </span><a id='glossaryinfo-2247' class='msm_infobutton' onmouseover='infoopen(2247)'>i</a></li><div id="dialog-2247" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The component of a vector $\Vect{x}$ orthogonal to another vector $\Vect{y}$ is</span>
                           </p>
                           $$\Vect{u} = \Vect{x} - \pr_{\Vect{y}}(\Vect{x})$$
                        </info></div></ul><li><li><span>composite</span><ul><li><span>of linear transformations</span><ul><li><span>represented by matrix product</span></li></ul><li></ul><li><li><span>composition</span><ul><li><span>of linear transformations</span></li></ul><li><li><span>contraction</span><ul><li><span>matrix</span></li></ul><li><li><span>coordinate</span><ul><li><span>vector   </span><a id='glossaryinfo-13485' class='msm_infobutton' onmouseover='infoopen(13485)'>i</a></li><div id="dialog-13485" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of the term.</span>
                           </p>
                        </info></div><li><span>conversion matrix   </span><a id='glossaryinfo-14418' class='msm_infobutton' onmouseover='infoopen(14418)'>i</a></li><div id="dialog-14418" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div></ul><li><li><span>coordinate of an $n$-tuple   </span><a id='glossaryinfo-260' class='msm_infobutton' onmouseover='infoopen(260)'>i</a></li><div id="dialog-260" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Example for $n=3$: $(5,1,2)$ is a $3$-tuple; i.e. it has 3 positions, each of which is occupied by a number. These numbers are the coordinates of the $3$-tuple. Thus the first coordinate is $5$. The second coordinate is $1$. The third coordinate is $2$.</span>
                                       </p>
                                    </info></div><li><span>coordinate vector</span><ul><li><span>basic</span></li></ul><li><li><span>Cramerâs rule   </span><a id='glossaryinfo-10997' class='msm_infobutton' onmouseover='infoopen(10997)'>i</a></li><div id="dialog-10997" class="dialogs" title="Cramerâ rule"><info xmlns="Theorem">
               
               <p>
                  <span>is a formula for finding the solution of  a system of $n$ linear equations in $n$ variables.</span>
               </p>
            </info></div><li><span>cross product   </span><a id='glossaryinfo-10630' class='msm_infobutton' onmouseover='infoopen(10630)'>i</a></li><div id="dialog-10630" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of the operation</span>
                                 </p>
                              </info></div><li><span>determinant</span><ul><li><span>definition using cofactors</span></li><li><span>multilinear</span></li><li><span>alternating</span></li><li><span>norm property   </span><a id='glossaryinfo-10686' class='msm_infobutton' onmouseover='infoopen(10686)'>i</a></li><div id="dialog-10686" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here.</span>
                     </p>
                  </info></div><li><span>commutes with transposition</span></li><li><span>of Van der Monde</span></li><li><span>commutes with matrix multiplication</span></li></ul><li><li><span>diagonal</span><ul><li><span>matrix   </span><a id='glossaryinfo-4827' class='msm_infobutton' onmouseover='infoopen(4827)'>i</a></li><div id="dialog-4827" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div></ul><li><li><span>diagonalizable matrix   </span><a id='glossaryinfo-20319' class='msm_infobutton' onmouseover='infoopen(20319)'>i</a></li><div id="dialog-20319" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><li><span>dilation</span><ul><li><span>matrix</span></li></ul><li><li><span>dimension     </span><a id='glossaryinfo-12754' class='msm_infobutton' onmouseover='infoopen(12754)'>i</a><ul><li><span>formula for linear transformations   </span><a id='glossaryinfo-19004' class='msm_infobutton' onmouseover='infoopen(19004)'>i</a></li><div id="dialog-19004" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{ V }$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div></ul><li><div id="dialog-12754" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the dimension of a vector space $V$ as the number of basis vectors in $V$.</span>
                           </p>
                        </info></div><li><span>direction angle   </span><a id='glossaryinfo-2809' class='msm_infobutton' onmouseover='infoopen(2809)'>i</a></li><div id="dialog-2809" class="dialogs" title="Direction Angle"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>the angle between a given vector $\mathbf{x}$ in $\RNr{n}$ and one of the coordinate axes.</span>
                                 </p>
                              </info></div><li><span>distance</span><ul><li><span>preserving linear transformation   </span><a id='glossaryinfo-17064' class='msm_infobutton' onmouseover='infoopen(17064)'>i</a></li><div id="dialog-17064" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div></ul><li><li><span>distributivity</span><ul><li><span>scalar multiplication of matrices</span></li><li><span>matrix multiplication</span></li></ul><li><li><span>domain</span><ul><li><span>of a function</span></li></ul><li><li><span>dot product     </span><a id='glossaryinfo-1581' class='msm_infobutton' onmouseover='infoopen(1581)'>i</a><ul><li><span>relationship to norm</span></li><li><span>orthogonality criterion</span></li><li><span>is bilinear   </span><a id='glossaryinfo-1870' class='msm_infobutton' onmouseover='infoopen(1870)'>i</a></li><div id="dialog-1870" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>That the dot product is bilinear means</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{(\Vect{a} + \Vect{b})}{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{y} }\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{ \Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{ \Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><li><span>is symmetry   </span><a id='glossaryinfo-1878' class='msm_infobutton' onmouseover='infoopen(1878)'>i</a></li><div id="dialog-1878" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is symmetry means that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><li><span>algebraic properties   </span><a id='glossaryinfo-1880' class='msm_infobutton' onmouseover='infoopen(1880)'>i</a></li><div id="dialog-1880" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating the algebraic properties of the dot product operation</span>
               </p>
            </info></div><li><span>positive definite   </span><a id='glossaryinfo-1885' class='msm_infobutton' onmouseover='infoopen(1885)'>i</a></li><div id="dialog-1885" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is positive definite means that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><li><span>non-degenerate   </span><a id='glossaryinfo-1890' class='msm_infobutton' onmouseover='infoopen(1890)'>i</a></li><div id="dialog-1890" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is non-degenerate means that</span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><li><span>binomial identities   </span><a id='glossaryinfo-1937' class='msm_infobutton' onmouseover='infoopen(1937)'>i</a></li><div id="dialog-1937" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the dot product operation</span>
               </p>
            </info></div></ul><li><div id="dialog-1581" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The dot product of $\Vect{x} = (x_1,\dots ,x_n)$ and $\Vect{y} = (y_1,\dots ,y_n)$ is </span>
                           </p>
                           $$\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$$
                        </info></div><li><span>eigenvalue</span></li><li><span>eigenvector</span></li><li><span>elementary</span><ul><li><span>matrix   </span><a id='glossaryinfo-5572' class='msm_infobutton' onmouseover='infoopen(5572)'>i</a></li><div id="dialog-5572" class="dialogs" title="elementary matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form</span>
                                 </p>
                                 $$
									
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
								$$
                              </info></div></ul><li><li><span>epimorphic linear transformation   </span><a id='glossaryinfo-18903' class='msm_infobutton' onmouseover='infoopen(18903)'>i</a></li><div id="dialog-18903" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><li><span>epimorphism</span></li><li><span>equal $n$tuples   </span><a id='glossaryinfo-268' class='msm_infobutton' onmouseover='infoopen(268)'>i</a></li><div id="dialog-268" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.</span>
                                 </p>
                              </info></div><li><span>equation</span><ul><li><span>of hyperspace   </span><a id='glossaryinfo-2369' class='msm_infobutton' onmouseover='infoopen(2369)'>i</a></li><div id="dialog-2369" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The equation whose solutions form the hyperspace in $\RNr{n}$ perpendicular to the normal vector $\Vect{n} = (a_1,\dots ,a_n)$ is</span>
                                 </p>
                                 $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_1 + \cdots + a_nx_n$$
                              </info></div></ul><li><li><span>equivalent</span><ul><li><span>equations   </span><a id='glossaryinfo-2459' class='msm_infobutton' onmouseover='infoopen(2459)'>i</a></li><div id="dialog-2459" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept of equivalent equations.</span>
                                 </p>
                              </info></div><li><span>systems of equations   </span><a id='glossaryinfo-3872' class='msm_infobutton' onmouseover='infoopen(3872)'>i</a></li><div id="dialog-3872" class="dialogs" title="When are two systems of linear equations equivalent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Two systems of linear equations are equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.</span>
                                 </p>
                              </info></div></ul><li><li><span>function     </span><a id='glossaryinfo-15148' class='msm_infobutton' onmouseover='infoopen(15148)'>i</a><ul><li><span>domain</span></li><li><span>target</span></li><li><span>value</span></li></ul><li><div id="dialog-15148" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>âFunctionâ appears here in the introduction to the concept of a linear transformation.</span>
                  </p>
               </info></div><li><span>geometric multiplicity</span></li><li><span>Gram-Schmidt orthonormalization process</span></li><li><span>homogeneous</span><ul><li><span>linear equation   </span><a id='glossaryinfo-3282' class='msm_infobutton' onmouseover='infoopen(3282)'>i</a></li><div id="dialog-3282" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = 0$$
					                   <p>
                           <span>Look up the definition</span>
                        </p>
				                 </info></div></ul><li><li><span>homogeneous system of linear equations</span></li><li><span>homomorphism</span><ul><li><span>of vector spaces</span></li></ul><li><li><span>hyperspace   </span><a id='glossaryinfo-2351' class='msm_infobutton' onmouseover='infoopen(2351)'>i</a></li><div id="dialog-2351" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The hyperspace in $\RNr{n}$ perpendicular to a nonzero vector $\Vect{n}$  is the set</span>
                                 </p>
                                 <p align="center">
                                    <span>
                                       $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$
                                    </span>
                                 </p>
                              </info></div><li><span>identity</span><ul><li><span>matrix   </span><a id='glossaryinfo-4843' class='msm_infobutton' onmouseover='infoopen(4843)'>i</a></li><div id="dialog-4843" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><li><span>linear transformation of $\RNr{n}$   </span><a id='glossaryinfo-6887' class='msm_infobutton' onmouseover='infoopen(6887)'>i</a></li><div id="dialog-6887" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div></ul><li><li><span>image</span><ul><li><span>of element under a function</span></li></ul><li><li><span>image of a linear map</span></li><li><span>inconsistent</span><ul><li><span>system of linear equations   </span><a id='glossaryinfo-3671' class='msm_infobutton' onmouseover='infoopen(3671)'>i</a></li><div id="dialog-3671" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div></ul><li><li><span>inhomogeneous</span><ul><li><span>linear equation   </span><a id='glossaryinfo-3284' class='msm_infobutton' onmouseover='infoopen(3284)'>i</a></li><div id="dialog-3284" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = c$$
					                   <p>
                           <span>with $c \neq 0$. Look up the definition.</span>
                        </p>
				                 </info></div></ul><li><li><span>inhomogeneous system of linear equations</span></li><li><span>inverse</span><ul><li><span>of a linear transformation</span></li><li><span>of a $(2,2)$-matrix   </span><a id='glossaryinfo-11022' class='msm_infobutton' onmouseover='infoopen(11022)'>i</a></li><div id="dialog-11022" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div></ul><li><li><span>inversion   </span><a id='glossaryinfo-6959' class='msm_infobutton' onmouseover='infoopen(6959)'>i</a></li><div id="dialog-6959" class="dialogs" title="What is an inversion?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An inversion is a linear transformation $T$ of $\RNr{n}$ of the form $T(\Vect{x})= -\Vect{x}$.</span>
                                 </p>
                              </info></div><li><span>invertible</span><ul><li><span>matrix   </span><a id='glossaryinfo-5354' class='msm_infobutton' onmouseover='infoopen(5354)'>i</a></li><div id="dialog-5354" class="dialogs" title="Invertible Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>An analysis which motivates the concept of an invertible matrix.</span>
                     </p>
                  </info></div><li><span>linear transformation   </span><a id='glossaryinfo-7849' class='msm_infobutton' onmouseover='infoopen(7849)'>i</a></li><div id="dialog-7849" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div></ul><li><li><span>isomorphic linear transformation   </span><a id='glossaryinfo-18909' class='msm_infobutton' onmouseover='infoopen(18909)'>i</a></li><div id="dialog-18909" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><li><span>isomorphism</span></li><li><span>kernel   </span><a id='glossaryinfo-8371' class='msm_infobutton' onmouseover='infoopen(8371)'>i</a></li><div id="dialog-8371" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>`kernel' appears here in the context of linear transformations providing another view toward linear equations.</span>
                     </p>
                  </info></div><li><span>kernel of a linear map</span></li><li><span>kernel of a linear transformation   </span><a id='glossaryinfo-11570' class='msm_infobutton' onmouseover='infoopen(11570)'>i</a></li><div id="dialog-11570" class="dialogs" title="Kernel"><info xmlns="Unit">
                           
                           <p>
                              <span>The kernel of $L\from V\to W$ is the set of all $\Vect{x}\in V$ with $L(\Vect{x} )=\Vect{0}$. â Definition of the concept.</span>
                           </p>
                        </info></div><li><span>leading $1$   </span><a id='glossaryinfo-3865' class='msm_infobutton' onmouseover='infoopen(3865)'>i</a></li><div id="dialog-3865" class="dialogs" title="What is a leading $1$?"><info xmlns="Unit">
                                       
                                       <p>
                                          <span>The concept of âleading 1â occurs within the context of linear equations in row reduced echelon form.</span>
                                       </p>
                                    </info></div><li><span>left hand</span><ul><li><span>orientation</span></li><li><span>rule</span></li></ul><li><li><span>length</span><ul><li><span>of an arrow   </span><a id='glossaryinfo-662' class='msm_infobutton' onmouseover='infoopen(662)'>i</a></li><div id="dialog-662" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><li><span>of a vector   </span><a id='glossaryinfo-1672' class='msm_infobutton' onmouseover='infoopen(1672)'>i</a></li><div id="dialog-1672" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div></ul><li><li><span>level set</span><ul><li><span>of a linear transformation</span></li></ul><li><li><span>linear</span><ul><li><span>motion   </span><a id='glossaryinfo-1129' class='msm_infobutton' onmouseover='infoopen(1129)'>i</a></li><div id="dialog-1129" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>A motion of a particle whose location at time $t$ has position vector $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$. â Click to see to the definition.</span>
                           </p>
                        </info></div><li><span>equation   </span><a id='glossaryinfo-17300' class='msm_infobutton' onmouseover='infoopen(17300)'>i</a></li><div id="dialog-17300" class="dialogs" title="What is a linear equation?">
<info xmlns="Unit">
                  
				
				              <p>
                     <span>A linear equation is an expression which can be written as</span>
                  </p>
				
				              <p align="center">
                     <span>
                        <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
                     </span>
                  </p>
				
				              <p>
                     <span>Look up the definition.</span>
                  </p>
			            </info>
</div><li><span>function</span></li><li><span>transformation</span><ul><li><span>scaling</span></li><li><span>rotation</span></li></ul><li><li><span>map</span></li><li><span>transformation of $\RNr{n}$</span><ul><li><span>identity</span></li></ul><li><li><span>combination</span></li></ul><li><li><span>linear transformation     </span><a id='glossaryinfo-14982' class='msm_infobutton' onmouseover='infoopen(14982)'>i</a><ul><li><span>shear map of $\RNr{n}$ parallel to a hyperspace</span></li><li><span>scalar product</span></li><li><span>invertible</span></li><li><span>distance preserving</span></li><li><span>orthogonal</span></li><li><span>by specifying values on a basis   </span><a id='glossaryinfo-18207' class='msm_infobutton' onmouseover='infoopen(18207)'>i</a></li><div id="dialog-18207" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Look up the proposition which says that a linear map $f\from V\to W$ is given by specifying is values on a basis of $V$.</span>
               </p>
            </info></div><li><span>monomorphic</span></li><li><span>epimorphic</span></li><li><span>isomorphic</span></li></ul><li><div id="dialog-14982" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>Appears here in the introduction to the topic of linear transformations.</span>
                  </p>
               </info></div><li><span>linear transformations</span><ul><li><span>composition</span></li></ul><li><li><span>linearly dependent set</span></li><li><span>linearly independent set</span></li><li><span>Lo Shu-magic square   </span><a id='glossaryinfo-4663' class='msm_infobutton' onmouseover='infoopen(4663)'>i</a></li><div id="dialog-4663" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>appears here as an early example of organizing numbers in a rectangular shape.</span>
                        </p>
                     </info></div><li><span>matrix     </span><a id='glossaryinfo-4563' class='msm_infobutton' onmouseover='infoopen(4563)'>i</a><ul><li><span>square shaped   </span><a id='glossaryinfo-4790' class='msm_infobutton' onmouseover='infoopen(4790)'>i</a></li><div id="dialog-4790" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A square shaped matrix is one whose number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><li><span>of one row</span></li><li><span>of one column</span></li><li><span>0-</span></li><li><span>diagonal</span></li><li><span>identity</span></li><li><span>of upper triangular shape   </span><a id='glossaryinfo-4862' class='msm_infobutton' onmouseover='infoopen(4862)'>i</a></li><div id="dialog-4862" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is of upper triangular shape if it is square shaped and only entries on or above the diagonal are different from $0$.</span>
                                 </p>
                              </info></div><li><span>sum</span></li><li><span>addition</span></li><li><span>scalar product</span></li><li><span>multiplication     </span><a id='glossaryinfo-4927' class='msm_infobutton' onmouseover='infoopen(4927)'>i</a><ul><li><span>associative</span></li><li><span>distributive</span></li><li><span>neutral element</span></li></ul><li><div id="dialog-4927" class="dialogs" title="Matrix Multiplication"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><li><span>transpose</span></li><li><span>symmetric</span></li><li><span>antisymmetric</span></li><li><span>scalar multiplication</span><ul><li><span>distributes over matrix sums</span></li><li><span>is associative</span></li><li><span>commutes with matrix multiplication</span></li></ul><li><li><span>transposition</span><ul><li><span>commutes with addition</span></li><li><span>commutes with scalar multiplication</span></li><li><span>anticommutes with multiplication</span></li></ul><li><li><span>invertible</span></li><li><span>row rescaling   </span><a id='glossaryinfo-5546' class='msm_infobutton' onmouseover='infoopen(5546)'>i</a></li><div id="dialog-5546" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><li><span>equation   </span><a id='glossaryinfo-11004' class='msm_infobutton' onmouseover='infoopen(11004)'>i</a></li><div id="dialog-11004" class="dialogs" title="matrix equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><li><span>of a dilation   </span><a id='glossaryinfo-19501' class='msm_infobutton' onmouseover='infoopen(19501)'>i</a></li><div id="dialog-19501" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><li><span>representing a linear map</span></li><li><span>of a contraction   </span><a id='glossaryinfo-6922' class='msm_infobutton' onmouseover='infoopen(6922)'>i</a></li><div id="dialog-6922" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><li><span>orthogonal</span></li><li><span>inverse of a $(2,2)$-matrix</span></li><li><span>diagonalizable</span></li><li><span>power   </span><a id='glossaryinfo-20441' class='msm_infobutton' onmouseover='infoopen(20441)'>i</a></li><div id="dialog-20441" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>A method of computing powers $\Mtrx{A}^r$ of a diagonalizable matrix $\Mtrx{A}$
                  </span>
               </p>
            </info></div></ul><li><div id="dialog-4563" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>General description as a rectangular arrangement of objects</span>
                  </p>
               </info></div><li><span>matrix multiplication</span><ul><li><span>commutes with determinant</span></li></ul><li><li><span>minor   </span><a id='glossaryinfo-8930' class='msm_infobutton' onmouseover='infoopen(8930)'>i</a></li><div id="dialog-8930" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-minor of a matrix $\Mtrx{A}$ is the result of omitting the $i$-th row and the $j$-th column from $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><li><span>monomorphic linear transformation   </span><a id='glossaryinfo-18897' class='msm_infobutton' onmouseover='infoopen(18897)'>i</a></li><div id="dialog-18897" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><li><span>monomorphism</span></li><li><span>multilinear</span><ul><li><span>property of the determinant operation   </span><a id='glossaryinfo-9095' class='msm_infobutton' onmouseover='infoopen(9095)'>i</a></li><div id="dialog-9095" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div></ul><li><li><span>multiplication</span><ul><li><span>of a vector by a number   </span><a id='glossaryinfo-847' class='msm_infobutton' onmouseover='infoopen(847)'>i</a></li><div id="dialog-847" class="dialogs"><info xmlns="Unit">
                                 $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div></ul><li><li><span>multiplicity</span><ul><li><span>algebraic</span></li><li><span>geometric</span></li></ul><li><li><span>neutral element</span><ul><li><span>matrix multiplication</span></li></ul><li><li><span>non-degeneracy</span><ul><li><span>dot product   </span><a id='glossaryinfo-1888' class='msm_infobutton' onmouseover='infoopen(1888)'>i</a></li><div id="dialog-1888" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the dot product asserts that </span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div></ul><li><li><span>non-degenerate</span><ul><li><span>norm   </span><a id='glossaryinfo-1487' class='msm_infobutton' onmouseover='infoopen(1487)'>i</a></li><div id="dialog-1487" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. â Click to see why it is true.</span>
                     </p>
                  </info></div></ul><li><li><span>norm</span><ul><li><span>of a vector: properties   </span><a id='glossaryinfo-1691' class='msm_infobutton' onmouseover='infoopen(1691)'>i</a></li><div id="dialog-1691" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the norm operation</span>
               </p>
            </info></div><li><span>non-degeneracy</span></li><li><span>relationship to dot product   </span><a id='glossaryinfo-1962' class='msm_infobutton' onmouseover='infoopen(1962)'>i</a></li><div id="dialog-1962" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><li><span>of a vector   </span><a id='glossaryinfo-1676' class='msm_infobutton' onmouseover='infoopen(1676)'>i</a></li><div id="dialog-1676" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm or length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><li><span>property of the determinant operation   </span><a id='glossaryinfo-9488' class='msm_infobutton' onmouseover='infoopen(9488)'>i</a></li><div id="dialog-9488" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here</span>
                     </p>
                  </info></div></ul><li><li><span>normal</span><ul><li><span>vector   </span><a id='glossaryinfo-2353' class='msm_infobutton' onmouseover='infoopen(2353)'>i</a></li><div id="dialog-2353" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>to a hyperspace in $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div></ul><li><li><span>null space</span></li><li><span>of linear transformations</span><ul><li><span>sum</span></li></ul><li><li><span>ordered</span><ul><li><span>basis   </span><a id='glossaryinfo-13351' class='msm_infobutton' onmouseover='infoopen(13351)'>i</a></li><div id="dialog-13351" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div></ul><li><li><span>ordered pair   </span><a id='glossaryinfo-105' class='msm_infobutton' onmouseover='infoopen(105)'>i</a></li><div id="dialog-105" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>another word for $2$-tuple; i.e. an expression of the form $(x,y)$, where $x$ and $y$ are numbers.</span>
                     </p>
                  </info></div><li><span>orientation</span><ul><li><span>1-dimensional</span></li><li><span>2-dimensional</span></li><li><span>3-dimensional</span></li><li><span>right hand</span></li><li><span>left hand</span></li><li><span>of a subspace of $\RNr{k}$   </span><a id='glossaryinfo-14544' class='msm_infobutton' onmouseover='infoopen(14544)'>i</a></li><div id="dialog-14544" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is given by the choice of an ordered $n$-tuple $\EuScript{B} = (\Vect{b}_1, \dots , \Vect{b}_n)$ of $V$. â Definition of the concept.</span>
                           </p>
                        </info></div></ul><li><li><span>oriented</span><ul><li><span>volume</span></li></ul><li><li><span>orthogonal</span><ul><li><span>projection of a vector along a line   </span><a id='glossaryinfo-6998' class='msm_infobutton' onmouseover='infoopen(6998)'>i</a></li><div id="dialog-6998" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><li><span>projection of a vector along another   </span><a id='glossaryinfo-2243' class='msm_infobutton' onmouseover='infoopen(2243)'>i</a></li><div id="dialog-2243" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The orthogonal projection of a vector $\Vect{x}$ along $\Vect{y} \neq \Vect{0}$ is the vector </span>
                           </p>
                           $$\pr_{\Vect{y}}(\Vect{x}) := \dfrac{\Vect{x} \bullet \Vect{y} }{\Vect{y} \bullet \Vect{y} \cdot \Vect{y}$$
                        </info></div><li><span>projection</span><ul><li><span>$\RNr{n}$ onto a hyperspace   </span><a id='glossaryinfo-15985' class='msm_infobutton' onmouseover='infoopen(15985)'>i</a></li><div id="dialog-15985" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div></ul><li><li><span>reflection</span><ul><li><span>$\RNr{n}$ about a hyperspace   </span><a id='glossaryinfo-16049' class='msm_infobutton' onmouseover='infoopen(16049)'>i</a></li><div id="dialog-16049" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div></ul><li><li><span>linear transformation   </span><a id='glossaryinfo-8132' class='msm_infobutton' onmouseover='infoopen(8132)'>i</a></li><div id="dialog-8132" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for âdistance preserving linear transformationâ</span>
                           </p>
                        </info></div><li><span>matrix   </span><a id='glossaryinfo-17167' class='msm_infobutton' onmouseover='infoopen(17167)'>i</a></li><div id="dialog-17167" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><li><span>complement   </span><a id='glossaryinfo-11514' class='msm_infobutton' onmouseover='infoopen(11514)'>i</a></li><div id="dialog-11514" class="dialogs" title="Orthogonal complement"><info xmlns="Unit">
                           
                           <p>
                              <span>The orthogonal complement of a subset $S$ in a sub vector space $V$ of $\RNr{n}$ is the set of those $\Vect{x}$ in $V$ which are perpendicular to every $\Vect{s}$ in $S$. Â  Definition of the concept.</span>
                           </p>
                        </info></div><li><span>set of vectors   </span><a id='glossaryinfo-12456' class='msm_infobutton' onmouseover='infoopen(12456)'>i</a></li><div id="dialog-12456" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><li><span>splitting of a subspace</span></li><li><span>splitting   </span><a id='glossaryinfo-13898' class='msm_infobutton' onmouseover='infoopen(13898)'>i</a></li><div id="dialog-13898" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The construction of orthogonal splittings.</span>
               </p>
            </info></div></ul><li><li><span>orthonormal</span><ul><li><span>set of vectors</span></li></ul><li><li><span>overdetermined</span><ul><li><span>system of linear equations   </span><a id='glossaryinfo-3673' class='msm_infobutton' onmouseover='infoopen(3673)'>i</a></li><div id="dialog-3673" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div></ul><li><li><span>parallel</span><ul><li><span>vectors   </span><a id='glossaryinfo-874' class='msm_infobutton' onmouseover='infoopen(874)'>i</a></li><div id="dialog-874" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><li><span>hyperplanes   </span><a id='glossaryinfo-3484' class='msm_infobutton' onmouseover='infoopen(3484)'>i</a></li><div id="dialog-3484" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept.</span>
                                 </p>
                              </info></div></ul><li><li><span>point   </span><a id='glossaryinfo-281' class='msm_infobutton' onmouseover='infoopen(281)'>i</a></li><div id="dialog-281" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An $n$-tuple of $\RNr{n}$.</span>
                           </p>
                        </info></div><li><span>position vector   </span><a id='glossaryinfo-717' class='msm_infobutton' onmouseover='infoopen(717)'>i</a></li><div id="dialog-717" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The position vector of a $X$ point in $\RNr{n}$ is represented by the arrow $\Arrow{\Vect{0}}{X}$ joining the origin to $X$.</span>
                           </p>
                        </info></div><li><span>positive definite</span><ul><li><span>dot product   </span><a id='glossaryinfo-1883' class='msm_infobutton' onmouseover='infoopen(1883)'>i</a></li><div id="dialog-1883" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The positive definiteness property of the dot product asserts that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div></ul><li><li><span>preimage</span><ul><li><span>under a function   </span><a id='glossaryinfo-6245' class='msm_infobutton' onmouseover='infoopen(6245)'>i</a></li><div id="dialog-6245" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Given a function $f\from X\to Y$ and $y\in Y$, the preimage of $y$ under $f$ consists of all those $x\in X$ such that $f(x)=y$; notation $f^{-1}(y)$
                        </span>
                     </p>
                  </info></div><li><span>of a linear transformation   </span><a id='glossaryinfo-17288' class='msm_infobutton' onmouseover='infoopen(17288)'>i</a></li><div id="dialog-17288" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div></ul><li><li><span>product</span><ul><li><span>of subsets of $\RNr{n}$   </span><a id='glossaryinfo-511' class='msm_infobutton' onmouseover='infoopen(511)'>i</a></li><div id="dialog-511" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to jump to the definition of âproduct of subsets of $\RNr{n}$â.</span>
                           </p>
                        </info></div><li><span>of two matrices   </span><a id='glossaryinfo-4925' class='msm_infobutton' onmouseover='infoopen(4925)'>i</a></li><div id="dialog-4925" class="dialogs" title="product of two matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $B$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div></ul><li><li><span>projection</span><ul><li><span>of a vector along a line</span></li><li><span>$\RNr{n}$ onto a hyperspace</span></li></ul><li><li><span>rank</span><ul><li><span>of a system of linear equations     </span><a id='glossaryinfo-13127' class='msm_infobutton' onmouseover='infoopen(13127)'>i</a><div id="dialog-13127" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>the definition of the rank of a system of linear equations</span>
                                 </p>
                              </info></div><a id='glossaryinfo-13128' class='msm_infobutton' onmouseover='infoopen(13128)'>i</a><div id="dialog-13128" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Use of the concept while describing the general solution of such a system.</span>
               </p>
            </info></div><ul></ul><li><li><span>of a system of linear equations   </span><a id='glossaryinfo-13127' class='msm_infobutton' onmouseover='infoopen(13127)'>i</a></li><div id="dialog-13127" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>the definition of the rank of a system of linear equations</span>
                                 </p>
                              </info></div><li><span>formula for matrices   </span><a id='glossaryinfo-18769' class='msm_infobutton' onmouseover='infoopen(18769)'>i</a></li><div id="dialog-18769" class="dialogs" title="Rank formula for matrices"><info xmlns="Theorem">
               
               $$
							
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

						$$
            </info></div></ul><li><li><span>reflection</span><ul><li><span>$\RNr{n}$ about a hyperspace</span></li></ul><li><li><span>representing matrix</span><ul><li><span>of a linear map</span></li></ul><li><li><span>right hand</span><ul><li><span>orientation</span></li><li><span>rule</span></li></ul><li><li><span>rotation     </span><a id='glossaryinfo-19576' class='msm_infobutton' onmouseover='infoopen(19576)'>i</a><ul><li><span>of 3-space   </span><a id='glossaryinfo-19117' class='msm_infobutton' onmouseover='infoopen(19117)'>i</a></li><div id="dialog-19117" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>A section on arbitrary rotations in $\RNr{3}$
                        </span>
                     </p>
                  </info></div><li><span>finding axis of rotation   </span><a id='glossaryinfo-20287' class='msm_infobutton' onmouseover='infoopen(20287)'>i</a></li><div id="dialog-20287" class="dialogs"><info xmlns="Compositor">
						            <p>
                     <span>An application of the theory of eigenvectors and eigenvalues: given a rotation of $\RNr{3}$, find its axis of rotation.</span>
                  </p>
					          </info></div></ul><li><div id="dialog-19576" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><li><span>row</span><ul><li><span>reduced echelon form   </span><a id='glossaryinfo-3861' class='msm_infobutton' onmouseover='infoopen(3861)'>i</a></li><div id="dialog-3861" class="dialogs" title="What is row reduced echelon form?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>
                                       <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm is defined here.</span>
                                 </p>
                              </info></div><li><span>matrix   </span><a id='glossaryinfo-4795' class='msm_infobutton' onmouseover='infoopen(4795)'>i</a></li><div id="dialog-4795" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div></ul><li><li><span>row rescaling matrix</span></li><li><span>row space</span></li><li><span>RREF   </span><a id='glossaryinfo-3863' class='msm_infobutton' onmouseover='infoopen(3863)'>i</a></li><div id="dialog-3863" class="dialogs" title="What does RREF mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>RREF is the acronym for <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm. Its definition is given here.</span>
                                 </p>
                              </info></div><li><span>scalar product</span><ul><li><span>of a matrix   </span><a id='glossaryinfo-4907' class='msm_infobutton' onmouseover='infoopen(4907)'>i</a></li><div id="dialog-4907" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div><li><span>of a linear map by a number</span></li><li><span>of a linear transformation</span><ul><li><span>represented by scalar product of matrix</span></li></ul><li></ul><li><li><span>scaling</span><ul><li><span>transformation   </span><a id='glossaryinfo-6951' class='msm_infobutton' onmouseover='infoopen(6951)'>i</a></li><div id="dialog-6951" class="dialogs" title="What is a scaling transformation?"><info xmlns="Unit">
                           
                           <p>
                              <span>A scaling transformation is a linear transformation of $\RNr{n}$ of the form $S(\Vect{x}) = s\cdot \Vect{x}$, with $s\in\RNr{}$ fixed.</span>
                           </p>
                        </info></div><li><span>factor</span></li></ul><li><li><span>shear</span><ul><li><span>transformation of $\RNr{n}$ parallel to a hyperspace   </span><a id='glossaryinfo-7157' class='msm_infobutton' onmouseover='infoopen(7157)'>i</a></li><div id="dialog-7157" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div></ul><li><li><span>slanted box</span></li><li><span>span   </span><a id='glossaryinfo-11878' class='msm_infobutton' onmouseover='infoopen(11878)'>i</a></li><div id="dialog-11878" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors in $S$. â Definition of the concept.</span>
                                 </p>
                              </info></div><li><span>splitting</span><ul><li><span>of a subspace</span></li></ul><li><li><span>square</span><ul><li><span>matrix   </span><a id='glossaryinfo-4788' class='msm_infobutton' onmouseover='infoopen(4788)'>i</a></li><div id="dialog-4788" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div></ul><li><li><span>subspace   </span><a id='glossaryinfo-11474' class='msm_infobutton' onmouseover='infoopen(11474)'>i</a></li><div id="dialog-11474" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Subspace = subvector space; Â  Definition of the concept.</span>
                           </p>
                        </info></div><li><span>subvector space   </span><a id='glossaryinfo-11472' class='msm_infobutton' onmouseover='infoopen(11472)'>i</a></li><div id="dialog-11472" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><li><span>sum</span><ul><li><span>of matrices   </span><a id='glossaryinfo-4896' class='msm_infobutton' onmouseover='infoopen(4896)'>i</a></li><div id="dialog-4896" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><li><span>of linear transformations</span><ul><li><span>represented by sum of matrices</span></li></ul><li></ul><li><li><span>symmetric</span><ul><li><span>matrix   </span><a id='glossaryinfo-4952' class='msm_infobutton' onmouseover='infoopen(4952)'>i</a></li><div id="dialog-4952" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if Â  $A = A^T$.</span>
                           </p>
                        </info></div></ul><li><li><span>symmetry</span><ul><li><span>of dot product   </span><a id='glossaryinfo-1876' class='msm_infobutton' onmouseover='infoopen(1876)'>i</a></li><div id="dialog-1876" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The symmetry property of the dot product asserts that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div></ul><li><li><span>system of linear equations     </span><a id='glossaryinfo-3490' class='msm_infobutton' onmouseover='infoopen(3490)'>i</a><ul><li><span>inconsistent</span></li><li><span>overdetermined</span></li><li><span>homogeneous</span></li><li><span>inhomogeneous</span></li></ul><li><div id="dialog-3490" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>solutions discussed in geometrical terms</span>
               </p>
            </info></div><li><span>translation</span><ul><li><span>vector   </span><a id='glossaryinfo-3094' class='msm_infobutton' onmouseover='infoopen(3094)'>i</a></li><div id="dialog-3094" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div></ul><li><li><span>transposition</span><ul><li><span>of a matrix   </span><a id='glossaryinfo-4939' class='msm_infobutton' onmouseover='infoopen(4939)'>i</a></li><div id="dialog-4939" class="dialogs" title="Transpose of a Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><li><span>commutes with determinant</span></li></ul><li><li><span>triangle inequality   </span><a id='glossaryinfo-1979' class='msm_infobutton' onmouseover='infoopen(1979)'>i</a></li><div id="dialog-1979" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The triangle inequality asserts that, for any two vectors $\Vect{x}$ and $\Vect{y}$.</span>
                     </p>
                  </info></div><li><span>unit</span><ul><li><span>vector   </span><a id='glossaryinfo-1482' class='msm_infobutton' onmouseover='infoopen(1482)'>i</a></li><div id="dialog-1482" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>A vector of length $1$; click to see how to compute the unit vector in the direction of a given nonzero vector.</span>
                     </p>
                  </info></div><li><span>square of $\RNr{2}$</span></li><li><span>lattice of $\RNr{2}$</span></li></ul><li><li><span>unitary</span><ul><li><span>linear transformation</span></li></ul><li><li><span>upper triangular matrix   </span><a id='glossaryinfo-4860' class='msm_infobutton' onmouseover='infoopen(4860)'>i</a></li><div id="dialog-4860" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.</span>
                                 </p>
                              </info></div><li><span>value</span><ul><li><span>of element under a function</span></li></ul><li><li><span>Van der Monde determinant</span></li><li><span>vector     </span><a id='glossaryinfo-694' class='msm_infobutton' onmouseover='infoopen(694)'>i</a><ul><li><span>addition   </span><a id='glossaryinfo-810' class='msm_infobutton' onmouseover='infoopen(810)'>i</a></li><div id="dialog-810" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><li><span>sum</span></li><li><span>length</span></li><li><span>norm   </span><a id='glossaryinfo-1678' class='msm_infobutton' onmouseover='infoopen(1678)'>i</a></li><div id="dialog-1678" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ its length. It is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><li><span>translation</span></li><li><span>velocity</span></li><li><span>force</span></li></ul><li><div id="dialog-694" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of âvectorâ</span>
                                 </p>
                              </info></div><li><span>vectors</span><ul><li><span>parallel</span></li></ul><li><li><span>velocity</span><ul><li><span>vector</span></li></ul><li><li><span>velocity vector   </span><a id='glossaryinfo-1133' class='msm_infobutton' onmouseover='infoopen(1133)'>i</a></li><div id="dialog-1133" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to see the definition of the velocity vector of a linear motion.</span>
                           </p>
                        </info></div><li><span>volume</span><ul><li><span>of slanted box</span></li></ul><li></ul></div></div>