<div id='glossarypanel' class='panel'><div class='glossarypanelcontent' id='glossarycontent'><h3> G L O S S A R Y </h3><ul id="glossaryindex" class="treeview-red"><li><span>$\RNr{}$     </span><a id='glossaryinfo-201' class='msm_infobutton' onmouseover='infoopen(201)'>i</a><div id="dialog-201" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>
                                       $\RNr{}$ denotes the set of all real numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-201' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>We will use the symbol $\RNr{}$ to denote the set of all real numbers.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-199' onmouseover='infoopen(199)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-199' style='display:none;'><div class='title'>Real Numbers: Explanation</div><p xmlns="Unit">
               <span>We use the symbol $\RNr{}$ to denote the set of all real numbers. These include</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>all natural numbers $\NNr{}$: $0,1,2,3,\cdots$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>all integers $\ZNr{}$: $0,1,-1,2,-2,3,-3,\cdots$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>all rational numbers $\QNr{}$: a number is called rational if it can be expressed as a ratio $\frac{m}{n}$ in which $m$ and $n$ are integers, with $n\neq 0$. Examples of rational numbers are: $\frac{1}{2}$, $-\frac{7}{3}$, $101 = \frac{101}{1}$, etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>In general, a number is ‘real’ if it can be expressed in decimal form</span>
            </p>$$n.d_1d_2d_3\cdots$$<p xmlns="Unit">
               <span>where $n$ is an integer, and each of $d_1,d_2,d_3,\dots$ is one of $0,1,2,3,4,5,6,7,8,9$. This includes all roots of integers, but also numbers like $\pi$, $e$, $\ln 2$, etc.</span>
            </p></div><div id="dialog-199" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>What are real numbers? – An explanation by example.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>$n$-tuple     </span><a id='glossaryinfo-256' class='msm_infobutton' onmouseover='infoopen(256)'>i</a><div id="dialog-256" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An expression of the form $(x_1,\dots ,x_n)$, where $x_1,\dots ,x_n$ are numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-256' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-258" class="dialogs"><info xmlns="Unit">
                                    <p>
                                       <span>Read this expression as: ‘(n-tuple) x-one, x-two, to , x-n’.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<a id="hottag-258" class="hottag" onmouseover="popup(258)"> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </a>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-206' onmouseover='infoopen(206)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-206' style='display:none;'><div class='pack'><div class='title'>Examples of $n$-tuples.</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Here are some examples of $n$-tuples:</span>
         </p>
			
			      <ul>
				        <li>
					          <p>
                  <span>
                     $(5)$ is a 1-tuple. Its one and only coordinate is the number $5$. $(-3)$ is another 1-tuple, and an arbitrary 1-tuple is of the form $(s)$, with $s$ a number in the system of real numbers $\RNr{}$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(2,3)$ is a 2-tuple, or a pair of numbers. The first coordinate of this 2-tuple is 2. The second coordinate is 3. Another 2-tuple is $(-1,6)$. In this case the first coordinate of this 2-tuple is $-1$, the second coordinate is $6$.</span>
               </p>
					          <p>
                  <span>An arbitrary 2-tuple, or pair of numbers, is of the form $(s,t)$ with $s$ and $t$ numbers. In this case the first coordinate is $s$, while the second coordinate is $t$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(\tfrac{3}{2},0,-1)$ is a 3-tuple, or a triple of numbers. Its first coordinate is $\tfrac{3}{2}$. Its second coordinate is $0$. Its third coordinate is $-1$. Another 3-tuple is $(-16,3,4)$. In this case the first coordinate is $-16$, the second coordinate is $3$, the third coordinate is $4$.</span>
               </p>
					          <p>
                  <span>An arbitrary 3-tuple, or triple of numbers, is of the form $(x,y,z)$ with $x$, $y$, and $z$ numbers. In this case the first coordinate is $x$, the second coordinate is $y$, and the third coordinate is $z$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(4,1,0,3)$ is a 4-tuple. Its first coordinate is $4$. Its second coordinate is $1$. Its third coordinate is $0$. Its fourth coordinate is $3$; etc.</span>
               </p>
				        </li>
			      </ul>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-206" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of $n$-tuples</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>0-matrix     </span><a id='glossaryinfo-4810' class='msm_infobutton' onmouseover='infoopen(4810)'>i</a><div id="dialog-4810" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4810' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4808' onmouseover='popup(4808)'><span style='cursor:pointer'>Example</span></li><div id="dialog-4808" class="dialogs" title="Some Examples of 0-Matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The following are $0$-matrices</span>
                           </p>
                           $$
								
								\begin{bmatrix}
								0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0
								\end{bmatrix}\qquad
								\begin{bmatrix}
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0
								\end{bmatrix} \qquad
								\begin{bmatrix}
								0 &amp; 0 \\
								0 &amp; 0 \\
								0 &amp; 0 \\
								0 &amp; 0
								\end{bmatrix}
								
							$$
                        </info></div></ul></div><br /></div></li><li><span>0-transformation     </span><a id='glossaryinfo-19452' class='msm_infobutton' onmouseover='infoopen(19452)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-19452' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The $0$-transformation of $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\mathbf{0}\from \RNr{n} \longrightarrow \RNr{m},\quad \mathbf{0}(\Vect{x}) := \Vect{0}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-19454' onmouseover='popup(19454)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-19454" class="dialogs" title="Explanation of 0-Transformation"><info xmlns="Unit">
                     
                     <p>
                        <span>The 0-transformation turns the entire space $\RNr{n}$ into a single point, namely the origin of $\RNr{m}$. It is represented by the 0-matrix of size $(n,m)$.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>addition     </span><ul class='chilren'><li><span>of vectors     </span><a id='glossaryinfo-814' class='msm_infobutton' onmouseover='infoopen(814)'>i</a><div id="dialog-814" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-814' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-808' onmouseover='infoopen(808)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-808' style='display:none;'><div class='pack'><div class='title'>Geometric Interpretation of Vector Addition: Illustration</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>To form the sum of two vectors $\Vect{x}$ and $\Vect{y}$ we concatenate representing arrows. The picture below illustrates this in the case where  $\Vect{x}=(3,1)$, and where  $\Vect{y}=(1,5)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-793" class="hottag" onmouseover="popup(793)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn.gif" height="98.071979434447" width="350"/></a><div id="dialog-793" class="dialogs"><info xmlns="Compositor">
						                     <p>
                              <span>Remember that we can represent a vector as a &#x2018;free floating arrow&#x2019;; i.e. an arrow which we can shift freely in space without changing its length or its direction. Therefore, when given two vectors $\Vect{x}$ and $\Vect{y}$, we can always float them so that the tail of $\Vect{y}$ lies at the tip of $\Vect{x}$. Now the arrow joining the tail of $\Vect{x}$ to the tip of $\Vect{y}$ represents the sum to the two vectors. &#x2013; Why is this so?</span>
                           </p>
						                     <p>
                              <span>If we start from the tail of $\Vect{x}$, we first move $3$ units and then  $1$ unit in the first coordinate direction to get to the tip of $\Vect{y}$. So this is just adding first coordinates. Moreover this same trip has us move $1$ unit and then $-.5$ units in the second coordinate direction. Thus adding coordinates in matching positions corresponds to concatenating arrows as shown.</span>
                           </p>
					                   </info></div></div>	
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Similarly, we obtain the sum of several vectors by forming the concatenation circuit of representing arrows, as in the picture below. If you like, you can watch an animation of this process.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-798" class="hottag" onmouseover="popup(798)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn2.gif" height="244.65174129353" width="350"/></a><div id="dialog-798" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding three vectors, represented by the arrows $\overset{\longrightarrow}{AB}$, $\overset{\longrightarrow}{BC}$, and $\overset{\longrightarrow}{CD}$. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn2.gif" height="244.65174129353" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
				
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Let’s have another example, this time we form the sum of six vectors and obtain the $0$-vector as the final answer:</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-805" class="hottag" onmouseover="popup(805)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn3.gif" height="228.66666666667" width="350"/></a><div id="dialog-805" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding six vectors, and obtain the $0$-vector as the final answer. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn3.gif" height="228.66666666667" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-808" class="dialogs" title="Illustration of vector addition"><info xmlns="Unit">
                           
                           <p>
                              <span>The addition of vectors has a useful geometric interpretation: it corresponds to the concatenation of representing arrows.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of matrices     </span><a id='glossaryinfo-4890' class='msm_infobutton' onmouseover='infoopen(4890)'>i</a><div id="dialog-4890" class="dialogs" title="addition of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4890' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4879' onmouseover='popup(4879)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4879" class="dialogs" title="Comment on Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the sum of two matrices is only defined if both matrices have the same size.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4884' onmouseover='infoopen(4884)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4884' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Addition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The sum of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2} \\
					{\color{red}6} &amp; {\color{red}1}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined because both matrices are of the same size $(3,2)$. Their sum is</span>
         </p>
			
			      $$
					
					{\color{blue}A} + {\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} - {\color{red}3} &amp; {\color{blue}3} -{\color{red}3} \\
					{\color{blue}1} + {\color{red}1} &amp; {\color{blue}4} +{\color{red}2} \\
					{\color{blue}6} + {\color{red}6} &amp; {\color{blue}4} + {\color{red}1}
					\end{array}\right] \ =\ 
					\left[\begin{array}{cc}
					4 &amp; 0 \\
					2 &amp; 6 \\
					12 &amp; 5
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the sum of two matrices of size $(m,n)$
            </span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right]
					
				$$
			      <p>
            <span>is</span>
         </p>
			
			      $$
					
					\aligned
					{\color{blue}A}\ +\ {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\ +\
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right] \\
					&amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} + {\color{red}b_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} + {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} + {\color{red}b_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}} + {\color{red}b_{mn}}
					\end{array}\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4884" class="dialogs" title="Example of Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus, to add two matrices, we simply add their intries in matching positions. – Here are some examples.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>matrices     </span><ul class='chilren'><li><span>associativity property     </span><a id='glossaryinfo-5157' class='msm_infobutton' onmouseover='infoopen(5157)'>i</a><div id="dialog-5157" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5157' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5175' onmouseover='infoopen(5175)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5175' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>Addition of matrices is defined by adding the matrix entries in matching positions. Therefore the above identities for matrix sums follow directly from the corresponding identities for sums of real numbers. – The details follow.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose $A$, $B$, and $C$ are three matrices of size $(m,n)$. Let us work with the entries in position $(i,j)$ for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C$ has the number $c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Now let’s look at the entry in position $(i,j)$ of the two matrix sums in question:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $(A+B)+C$ has the number $(a_{ij}+b_{ij})+c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $A+(B+C)$ has the number $a_{ij}+(b_{ij}+c_{ij})$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the associativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Commutativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Again let's look at the entry in position $(i,j)$ of the two matrix sums in question.</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A+B$ has the number $a_{ij}+b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B+A$ has the number $b_{ij}+a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the commutativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p><p>
            <span>The remaining properties of matrix addition can be proved with the same method. – Try it!</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>commutativity     </span><a id='glossaryinfo-5172' class='msm_infobutton' onmouseover='infoopen(5172)'>i</a><div id="dialog-5172" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5172' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5175' onmouseover='infoopen(5175)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5175' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>Addition of matrices is defined by adding the matrix entries in matching positions. Therefore the above identities for matrix sums follow directly from the corresponding identities for sums of real numbers. – The details follow.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose $A$, $B$, and $C$ are three matrices of size $(m,n)$. Let us work with the entries in position $(i,j)$ for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C$ has the number $c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Now let’s look at the entry in position $(i,j)$ of the two matrix sums in question:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $(A+B)+C$ has the number $(a_{ij}+b_{ij})+c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $A+(B+C)$ has the number $a_{ij}+(b_{ij}+c_{ij})$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the associativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Commutativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Again let's look at the entry in position $(i,j)$ of the two matrix sums in question.</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A+B$ has the number $a_{ij}+b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B+A$ has the number $b_{ij}+a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the commutativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p><p>
            <span>The remaining properties of matrix addition can be proved with the same method. – Try it!</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li></ul></li><li><span>algebraic multiplicity     </span><a id='glossaryinfo-20076' class='msm_infobutton' onmouseover='infoopen(20076)'>i</a><div id="dialog-20076" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20076' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20074' onmouseover='infoopen(20074)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20074' style='display:none;'><div class='pack'><div class='title'>Algebraic Multiplicity: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Find the roots of the polynomial $q(\lambda)$ and their algebraic multiplicities if</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda^3 +4\lambda^2-3\lambda-18$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>First we need to find the roots of $q$, that is those number values for $\lambda$ with $q(\lambda)=0$.</span>
               </p>
			            <p>
                  <span>By trial and error we find</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(2)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2^3 + 4\cdot 2^2 - 3\cdot 2-18$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
			            <p>
                  <span>So $\lambda_1:=2$ is a root of $q$. So we know that $(\lambda-2)$ divides $q$. Via long division we find</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-2)(\lambda^2 +6\lambda +9)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-2)^1(\lambda+3)^2$</td></tr></table>
			            <p>
                  <span>We conclude that $q$ has</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>the root $\lambda_1=2$ with algebraic multiplicity $1$, and</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>the root $\lambda_2=3$ with algebraic multiplicity $2$.</span>
                     </p>
				              </li>
			            </ol>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Find the algebraic multiplicities of the roots of the polynomial</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-3)^5(\lambda+1)^2$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we get lucky: $p$ is given to us in a form from which we can read off its roots and their multiplicities right away.</span>
               </p>
			            <p>
                  <span>Indeed, the product $(\lambda-3)^5(\lambda+1)^2$ is $0$ exactly when at least one of its factors $(\lambda-3)$ or $(\lambda+1)$ is $0$.</span>
               </p>
			            <p>
                  <span>Now, $\lambda-3=0$ exactly when $\lambda=3$. So $p$ has the root $\lambda_1 = 3$ with algebraic multiplicity $5$.</span>
               </p>
			            <p>
                  <span>Similarly, $\lambda+1=0$ exactly when $\lambda=-1$. So $p$ has the root $\lambda_2=-1$ with algebraic multiplicity $2$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-20074" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>How to find the algebraic multiplicities of roots of a polynomial:</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>alternating     </span><ul class='chilren'><li><span>property of the determinant operation     </span><a id='glossaryinfo-10323' class='msm_infobutton' onmouseover='infoopen(10323)'>i</a><div id="dialog-10323" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10323' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>multilinear function     </span></li></ul></li><li><span>angle between two vectors     </span><a id='glossaryinfo-1969' class='msm_infobutton' onmouseover='infoopen(1969)'>i</a><div id="dialog-1969" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The angle between two vectors $\Vect{x}$ and $\Vect{y}$ is denoted $\sphericalangle(\Vect{x},\Vect{y})$. Its cosine can be determined using the norm and dot product operations by</span>
                     </p>
                     $$\cos\sphericalangle(\Vect{x},\Vect{y}) = \frac{\DotPr{ \Vect{x} }{ \Vect{y} }}{| \Vect{x} | | \Vect{y} |}$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1969' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>antisymmetric     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4946' class='msm_infobutton' onmouseover='infoopen(4946)'>i</a><div id="dialog-4946" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4946' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4935' onmouseover='popup(4935)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4935" class="dialogs" title="Comment on: Symmetric Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>The first thing to observe about a symmetric matrix $A$ is that its number of rows must be the same as its number of columns. Therefore $A$ is square shaped. Moreover, we have the identity of entries $a_{ij}=a_{ji}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4940' onmouseover='infoopen(4940)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4940' style='display:none;'><div class='pack'><div class='title'>Examples of (non-)Symmetric Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 5 &amp; 7 \\
					5 &amp; -1 &amp; 4 \\
					7 &amp; 4 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					4 &amp; a &amp; -2 &amp; 1 \\
					a &amp; 6 &amp; 3 &amp; b \\
					-2 &amp; 3 &amp; c &amp; 1 \\
					1 &amp; b &amp; 1 &amp; 0
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are not symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 0 &amp; 0 \\
					5 &amp; -1 &amp; 0 \\
					7 &amp; 6 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					0 &amp; 1 &amp; -2 &amp; 1 \\
					5 &amp; 6 &amp; 3 &amp; -2 \\
					b &amp; 3 &amp; 6 &amp; 1 \\
					1 &amp; b &amp; 5 &amp; 0
					\end{array}\right]
					
				$$
			      <p>
            <span>Note that, while the $(4,4)$-matrix on the right displays a different kind of symmetry, it is not equal to its transpose, and so it is not symmetric.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4940" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of (non-)symmetric matrices.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>arrow     </span><a id='glossaryinfo-640' class='msm_infobutton' onmouseover='infoopen(640)'>i</a><div id="dialog-640" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>in $\RNr{n}$, joining point $P$ to point $Q$.</span>
                                 </p>
                                 <p align="center">
                                    <span>Click to see the definition of arrow.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-640' style='display:none;'><br /><div class='def'><span class='deftitle'>Arrow</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An arrow 
					in $\RNr{n}$ is given by listing two points $P$ and $Q$ of $\RNr{n}$ in order. The first point $P$ is called the tail of the arrow. The second point $Q$ is called the tip of the arrow. We write $\Arrw{PQ}$
					to denote the arrow joining $P$ to $Q$.</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-636' onmouseover='infoopen(636)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-636' style='display:none;'><div class='title'>Arrows - Illustration</div><p xmlns="Unit">
               <span>We think of an arrow in $\RNr{n}$ as exactly what the word suggests: a perfectly straight object with a tail and a tip. Thus the location of an arrow in space is determined by two points, namely</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>a point, say $P$, which marks the tail of the arrow,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>a point, say $Q$, which marks the tip of the arrow</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We write $\Arrw{PQ}$ for the arrow which has its tail at $P$ and its tip at $Q$. – The picture below shows three such arrows.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/Arrows_illstrtn1.gif" height="170.05141388175" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>For example, the pink horizontal arrow on the right has its tail at a point named $R$, and it has its tip at a point named $S$. So we write $\Arrw{RS}$ for the arrow joining $R$ to $S$. Similarly,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\Arrw{PQ}$ denotes the arrow joining the point $P$ to the point $Q$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Arrw{TU}$ denotes the arrow joining the point $T$ to the point $U$.</span>
                  </p>
               </li>
            </ul></div><div id="dialog-636" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An illustration of arrows</span>
                           </p>
                        </info></div></ul></div><br /></div><ul class='chilren'><li><span>length     </span><a id='glossaryinfo-664' class='msm_infobutton' onmouseover='infoopen(664)'>i</a><div id="dialog-664" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-664' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-651' onmouseover='infoopen(651)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-651' style='display:none;'><div class='title'>Illustration: Length of an Arrow</div><p xmlns="Unit">
               <span>The length of the arrow joining $P(x_1,\dots ,x_n)$ to $Q(y_1,\dots ,y_n)$ is given by the formula</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/ArrowLength_Illstrtn.gif" height="142.87257019438" width="350"/></div>
               </span>
            </p>
$$\Abs{ \overset{\longrightarrow}{PQ} }\ :=\ \text{dist}(P,Q)\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$<p xmlns="Unit">
               <span>This means that the length of an arrow is defined to be the distance between its end points.</span>
            </p></div><div id="dialog-651" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Illustration of Length of an Arrow</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-658' onmouseover='infoopen(658)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-658' style='display:none;'><div class='pack'><div class='title'>Length of an Arrow: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the length of the arrow joining the point $P(4,-1,11)$ to the point $Q(-2,6,4)$ in $\RNr{3}$.  
			</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The length of the arrow $\Arrow{P}{Q}$ is the distance from $P$ to $Q$:</span>
               </p>
			            $$
					
					\aligned
\Length{\Arrow{P}{Q}}\ &amp;=\ \Dstnc{P}{Q} \\
					&amp; =\ \sqrt{(-2-4)^2+(6-(-1))^2+(4-11)^2} \\
					&amp; =\ \sqrt{36+49+49} \\
					&amp; =\ \sqrt{134}
					\endaligned
					
				$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the length of the arrow joining the point $A(1,3,0,5)$ to the point $B(2,1,-2,4)$ in $\RNr{4}$.  
			</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The length of the arrow $\Arrow{A}{B}$ is the distance from $A$ to $B$:</span>
               </p>
			            $$
					
					\aligned
\Length{\Arrow{A}{B}}\ &amp;=\ \Dstnc{A}{B} \\
					&amp; =\ \sqrt{(2-1)^2 + (1-3)^2 + ((-2)-0)^2 + (4-5)^2 } \\
					&amp; =\ \sqrt{1 + 4 + 4 + 1} \\
					&amp; =\ \sqrt{10}
					\endaligned
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-658" class="dialogs" title="Example"><info xmlns="Unit">
                           
                           <p>
                              <span>Examples of computing the length of an arrow</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>associativity     </span><ul class='chilren'><li><span>of matrix addition     </span><a id='glossaryinfo-5150' class='msm_infobutton' onmouseover='infoopen(5150)'>i</a><div id="dialog-5150" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5150' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5175' onmouseover='infoopen(5175)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5175' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>Addition of matrices is defined by adding the matrix entries in matching positions. Therefore the above identities for matrix sums follow directly from the corresponding identities for sums of real numbers. – The details follow.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose $A$, $B$, and $C$ are three matrices of size $(m,n)$. Let us work with the entries in position $(i,j)$ for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C$ has the number $c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Now let’s look at the entry in position $(i,j)$ of the two matrix sums in question:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $(A+B)+C$ has the number $(a_{ij}+b_{ij})+c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $A+(B+C)$ has the number $a_{ij}+(b_{ij}+c_{ij})$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the associativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Commutativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Again let's look at the entry in position $(i,j)$ of the two matrix sums in question.</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A+B$ has the number $a_{ij}+b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B+A$ has the number $b_{ij}+a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the commutativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p><p>
            <span>The remaining properties of matrix addition can be proved with the same method. – Try it!</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>scalar multiplication of matrices     </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5192' onmouseover='infoopen(5192)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5192' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>We verify the first distributivity property. The other two properties can be proved with the same method. So let $A$ and $B$ be two matrices of size $(m,n)$, and let $t\in\RNr{}$. We focus our attention on the matrix entries in position $(i,j)$, for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributes over a matrix sum
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Let us consider the entry in position $(i,j)$ of the relevant matrix expressions:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $t\cdot (A+B)$ has the number $t\cdot (a_{ij}+b_{ij})$ in position $(i,j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $tA +tB$ has the number $ta_{ij} + tb_{ij}$ in position $(i,j)$.</span>
               </p>
            </li>
         </ul><p>
            <span>These numbers are equal because of the distributivity law for multiplication and addition of real numbers.</span>
         </p><p>
            <span>Thus $t(A+B)$ and $tA+tB$ both have the same number in position $(i,j)$. This computation applies to each position. So the two matrices are equal and, therefore, the distributivity identity for scalar multiplication of matrices holds.</span>
         </p><p>
            <span>You should try proving the remaining properties of scalar multiplication by adapting the above method.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>matrix multiplication     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>augmented     </span><ul class='chilren'><li><span>coefficient vector     </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /></div></li></ul></li><li><span>basic coordinate vector     </span><a id='glossaryinfo-709' class='msm_infobutton' onmouseover='infoopen(709)'>i</a><div id="dialog-709" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-709' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-705' onmouseover='infoopen(705)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-705' style='display:none;'><div class='pack'><div class='title'>Examples of Basic Coordinate Vectors</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{3}$ has three basic coordinate vectors.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/BasicCoordinateVectorsR3.gif" height="242.72727272727" width="350"/></div>
			         </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <ul>
				              <li>
					                <p>
                        <span>The first basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_1:=(1,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_2:=(0,1,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The third basic basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_3:=(0,0,1)$
					                   </span>
                     </p>
				              </li>
			            </ul>
			            <p>
                  <span>In the physics literature these are often written as</span>
               </p>
			            <p align="center">
                  <span>
				                 $\mathbf{i}:=\mathbf{e}_1,\qquad \mathbf{j}:=\mathbf{e}_2,\quad \text{and}\quad \mathbf{k}:=\mathbf{e}_3$
			               </span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{4}$ has four basic coordinate vectors</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <ul>
				              <li>
					                <p>
                        <span>The first basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_1:=(1,0,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_2:=(0,1,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The third basic basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_3:=(0,0,1,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The fourth basic basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_4:=(0,0,0,1)$
					                   </span>
                     </p>
				              </li>
			            </ul>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-705" class="dialogs" title=""><info xmlns="Unit">
                           <p align="center">
                              <span>Examples of coordinate vectors.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>basis     </span><a id='glossaryinfo-12627' class='msm_infobutton' onmouseover='infoopen(12627)'>i</a><div id="dialog-12627" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12627' style='display:none;'><br /><div class='def'><span class='deftitle'>Basis</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-12629" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>The plural of ‘basis’ is ‘bases’.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A 
				<a id="hottag-12629" class="hottag" onmouseover="popup(12629)"> basis</a>  
				
				of a subvector space $V$ of $\RNr{n}$ is a collection of vectors $\EuScript{B}$ satisfying:
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ spans $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ is linearly independent.</span>
                        </p>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-12625' onmouseover='infoopen(12625)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-12625' style='display:none;'><div class='title'>Basis - Explanation</div><p xmlns="Unit">
               <span>Let’s examine a bit what the concept of a basis really means.</span>
            </p><p xmlns="Unit">
               <span>The first condition: $\EuScript{B}$ spans $V$ means that every vector $\Vect{x}$ in $V$ can be expressed in some way as a linear combination of vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1\Vect{b}_1 + \cdots + t_k\Vect{b}_k$</td></tr></table><p xmlns="Unit">
               <span>with $\Vect{b}_1, \dots ,\Vect{b}_k$ in $\EuScript{B}$ and $t_1, \dots ,t_k$ in $\RNr{}$. – Now, if there is one way of expressing $\Vect{x}$ as a linear combination of vectors in $\EuScript{B}$, there might be many ways of doing so. This is where the second requirement for a basis comes in:</span>
            </p><p xmlns="Unit">
               <span>
                  $\EuScript{B}$ is linearly independent. This means that if $\Vect{x}$ can be expressed as a linear combination of vectors in $\EuScript{B}$, then there is exactly one way of doing so.</span>
            </p><p xmlns="Unit">
               <span>The two conditions combined, then, tell us that every vector in $V$ can be expressed in exactly one way as a linear combination of vectors in $\EuScript{B}$.</span>
            </p></div><div id="dialog-12625" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Analyze what a basis really is.</span>
                     </p>
                  </info></div></ul></div><br /></div><ul class='chilren'><li><span>ordered     </span><a id='glossaryinfo-13463' class='msm_infobutton' onmouseover='infoopen(13463)'>i</a><div id="dialog-13463" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... when used to define a coordinate vector.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13463' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-13351' onmouseover='infoopen(13351)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-13351' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div><div id="dialog-13351" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>What does ‘ordered basis’ mean? – Explanation</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-13399' onmouseover='infoopen(13399)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-13399' style='display:none;'><div class='title'>Coordinate Vector - Illustration</div><p xmlns="Unit">
               <span>The picture below shows $\RNr{2}$ with an ordered basis $\EuScript{B} = (\Vect{a} , \Vect{b} )$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/CoordinateVector_1.gif' height='275.77962577963' width='350'/></div><p xmlns="Unit">
               <span>The basis vectors $\Vect{a}$ and $\Vect{b}$ set up a coordinate grid, and we use this grid to express arbitrary vectors as linear combinations of the basis vectors. For example</span>
            </p><table class='mathtable' border='1' cellpadding='3' style='width:100% !important;'><tr>
                  <td style='border-width:1px !important;'>
                     <p>
                        <span>
                           <b>Linear Combination</b>
                        </span>
                     </p>
                  </td>
                  <td style='border-width:1px !important;'>
                     <p>
                        <span>
                           <b>Coordinate vector with respect to</b>
                           $\EuScript{B}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1\cdot \Vect{a}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1)\cdot \Vect{a} + 5\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1,5)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3\cdot \Vect{a} + 2\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(3,2)$</td></tr></table>
                  </td>
               </tr></table></div><div id="dialog-13399" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An illustration of ‘coordinate vector’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-13455' onmouseover='infoopen(13455)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-13455' style='display:none;'><div class='pack'><div class='title'>Coordinate Vector: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>You are given the ordered basis $\EuScript{B} = (\Vect{a},\Vect{b})$ of $\RNr{2}$ with</span>
         </p>
			      <p align="center">
            <span>
               $\Vect{a} = (2,1)$ and $\Vect{b} = (-3,4)$.</span>
         </p>
			      <p>
            <span>Find $\Vect{x}_{\EuScript{S}}$ if $\Vect{x}_{\EuScript{B}} = (6,5)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We recall that $\Vect{x}_{\EuScript{B}} = (6,5)$ means that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot \Vect{a} + 5\cdot \Vect{b}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot (2,1) + 5\cdot (-3,4)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(12,6) + (-15,20)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-3,26)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Let $V$ be the subspace of $\RNr{3}$ spanned by the linearly independent vectors $\Vect{a} = (1,-1,2)$ and $\Vect{b}= (3,2,-3)$. You are given the information that $\Vect{x}= (0,-5,9)$ is in $V$. Find its coordinate vector with respect to the ordered basis $\EuScript{B}:= ( \Vect{a} , \Vect{b} )$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We have $\Vect{x}_{\EuScript{B}} = (s,t)$ for the two uniquely determined numbers $s$ and $t$ satisfying</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s \Vect{a} + t \Vect{b}$</td></tr></table>
			            <p>
                  <span>Therefore we need to solve the vector equation</span>
               </p>
							        $$
									
s
\left[
\begin{array}{r}
1 \\ -1 \\ 2
\end{array}
\right]\ +\ t
\left[
\begin{array}{r}
3 \\ 2 \\ -3
\end{array}
\right]\ =\ 
\left[
\begin{array}{r}
0 \\ -5 \\ 9
\end{array}
\right]
					
								$$
			            <p>
                  <span>This vector equation is equivalent to the system of linear equations</span>
               </p>
							        $$
									
\begin{array}{rcccr}
s &amp; + &amp; 3t &amp; = &amp; 0 \\
-s &amp; + &amp; 2t &amp; = &amp; -5 \\
2s &amp; - &amp; 3t &amp; = &amp; 9
\end{array}
					
								$$
			            <p>
                  <span>The row reduction method applied to the augmented coefficient matrix of this system yields</span>
               </p>
							        $$
									
\begin{array}{rr|r}
1 &amp; 3 &amp; 0 \\
-1 &amp; 2 &amp; -5 \\
2 &amp; -3 &amp; 9
\end{array} \qquad\qquad
\begin{array}{rr|r}
1 &amp; 0 &amp; 3 \\
0 &amp; 1 &amp; -1 \\
0 &amp; 0 &amp; 0
\end{array}
					
								$$
			            <p>
                  <span>Thus $s=3$ and $t=-1$ are the only solution of the given vector equation, and so we conclude:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3 \Vect{a} + (-1) \Vect{b}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(3,-1)$</td></tr></table>
			            <p>
                  <span>is the coordinate vector of $\Vect{x}$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose $\EuScript{B}=(\Vect{a},\Vect{b},\Vect{c})$ is an ordered basis of a subvector space $V$ of $\RNr{n}$. Find $\Vect{x}_{\EuScript{B}}$ if</span>
         </p>
			      <ol>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{a}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{b}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{c}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = 3\cdot\Vect{a}-\Vect{b} - 2\cdot \Vect{c}$
                  </span>
               </p>
            </li>
			      </ol>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The required coordinate vectors are</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 1},{\color{blue} 0},{\color{green} 0})$ as $\Vect{x} = {\color{red} 1}\cdot \Vect{a} + {\color{blue} 0}\cdot \Vect{b} + {\color{green} 0}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 0},{\color{blue} 1},{\color{green} 0})$ as $\Vect{x} = {\color{red} 0}\cdot \Vect{a} + {\color{blue} 1}\cdot \Vect{b} + {\color{green} 0}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 0},{\color{blue} 0},{\color{green} 1})$ as $\Vect{x} = {\color{red} 0}\cdot \Vect{a} + {\color{blue} 0}\cdot \Vect{b} + {\color{green} 1}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 3},{\color{blue} -1},{\color{green} -2})$ as $\Vect{x} = {\color{red} 3}\cdot \Vect{a} + {\color{blue} (-1)}\cdot \Vect{b} + {\color{green} (-2)}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
			            </ol>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose $\EuScript{B}=(\Vect{a},\Vect{b},\Vect{c})$ is an ordered basis of a subvector space $V$ of $\RNr{n}$. Then $\EuScript{C}=(\Vect{b},\Vect{c},\Vect{a})$ is another ordererd basis of $V$. If $\Vect{x}_{\EuScript{B}} = (-2,6,-5)$, find $\Vect{x}_{\EuScript{C}}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-2)\cdot \Vect{a} + 6\cdot \Vect{b} + (-5)\cdot \Vect{c}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot \Vect{b} + (-5)\cdot \Vect{c} + (-2)\cdot \Vect{a}$</td></tr></table>
			            <p>
                  <span>Therefore</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(6,-5,-2)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-13455" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of coordinate vectors</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>bilinearity     </span><ul class='chilren'><li><span>of dot product     </span><a id='glossaryinfo-1863' class='msm_infobutton' onmouseover='infoopen(1863)'>i</a><div id="dialog-1863" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>The bilinearity property of the dot product asserts that</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1863' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>cartesian product     </span><a id='glossaryinfo-494' class='msm_infobutton' onmouseover='infoopen(494)'>i</a><div id="dialog-494" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>of $\RNr{m}$ and $\RNr{n}$ is $\RNr{m+n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-494' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of   $\RNr{m}$ and $\RNr{n}$
               </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The cartesian product of $\RNr{m}$ and $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\RNr{m}\times \RNr{n}\ :=\ \RNr{m+n},$$
                  <p>
                     <span>i.e. the space of  all $(m+n)$-tuples.</span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-490' onmouseover='popup(490)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-490" class="dialogs" title="We think about this product operation as follows"><info xmlns="Unit">
                     
                     <p>
                        <span>If we form all possible combinations of concatenations using</span>
                     </p>
                     <ol>
                        <li>
                           <p>
                              <span>an $m$-tuple $(x_1,\dots ,x_m)$ from $\RNr{m}$
                              </span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>an $n$-tuple $(y_1,\dots ,y_n)$ from $\RNr{n}$,</span>
                           </p>
                        </li>
                     </ol>
                     <p>
                        <span>we obtain all possible $(m+n)$-tuples $(x_1,\dots ,x_m,y_1,\dots ,y_m)$ in $\RNr{m+n}$
                        </span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-492' onmouseover='popup(492)'><span style='cursor:pointer'>Example</span></li><div id="dialog-492" class="dialogs" title="Examples of Cartesian Products"><info xmlns="Unit">
                     
                     <ul>
                        <li>
                           <p>
                              <span>
                                 $\RNr{1}\times\RNr{1}=\RNr{2}$
                              </span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>
                                 $\RNr{2}\times\RNr{1}=\RNr{3}$
                              </span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>
                                 $\RNr{9}\times\RNr{6}=\RNr{15}$
                              </span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>
                                 $\RNr{4}\times\RNr{3}\times\RNr{2}=\RNr{9}$
                              </span>
                           </p>
                        </li>
                     </ul>
                     $$
							
\aligned
	\RNr{m}\times\RNr{n}\ &amp;=\ \underset{\leftarrow\hfill m\hfill\rightarrow}{(\RNr{}\times \RNr{}\times \dots \times \RNr)}\ \times\ \underset{\leftarrow\hfill n\hfill\rightarrow}{(\RNr{}\times\RNr{}\times \dots \times \RNr)} \\
	&amp;=\ \underset{\leftarrow\hfill m+n\hfill \rightarrow}{\RNr{}\times \RNr{}\times \dots \times \RNr} \\
	&amp;=\ \RNr{m+n}
\endaligned
								
						$$
                  </info></div></ul></div><br /></div></li><li><span>Cauchy-Schwarz inequality     </span><a id='glossaryinfo-1979' class='msm_infobutton' onmouseover='infoopen(1979)'>i</a><div id="dialog-1979" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The Cauchy-Schwarz inequality asserts that</span>
                     </p>
                     $$| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1979' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>change of coordinates matrix     </span><a id='glossaryinfo-14395' class='msm_infobutton' onmouseover='infoopen(14395)'>i</a><div id="dialog-14395" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14395' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$<div id="dialog-14342" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-14342' style='display:none;'><div class='title'>Change of Coordinates - Illustration</div><p xmlns="Unit">
               <span>To illustrate the essence of ‘change of coordinates’, consider two ordered bases $\EuScript{A} = (\Vect{a}_1,\Vect{a}_2)$ and $\EuScript{B}=(\Vect{b}_1,\Vect{b}_2)$ in $\RNr{2}$. Now, given a vector $\Vect{x}$ in $\RNr{2}$, we may</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{A}:$
                     </span>
                  </p>
                  $$\Vect{x} = u \Vect{a}_1 + v \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{A}} = (u,v)$$
                  <p>
                     <span>The $\EuScript{A}$-coordinates of $\Vect{x}$ are $(u,v)$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{B}:$
                     </span>
                  </p>
                  $$\Vect{x} = s \Vect{b}_1 + t \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{B}} = (s,t)$$
                  <p>
                     <span>The $\EuScript{B}$-coordinates of $\Vect{x}$ are $(s,t)$
                     </span>
                  </p>
               </li>
            </ol><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ChangeBases.png' height='197.4' width='350'/></div><p xmlns="Unit" align="center">
               <span>Here $\Vect{x}_{\EuScript{A}} = \left( \tfrac{3}{2} , \tfrac{5}{2} \right)$
               </span>
            </p><p xmlns="Unit">
               <span>So we arrive at the question: suppose we know the $\EuScript{A}$-coordinates of $\Vect{x}$, what are its $\EuScript{B}$-coordinates? and, vice versa, suppose we know the $\EuScript{B}$-coordinates of $\Vect{x}$, what are its $\EuScript{A}$-coordinates?</span>
            </p><p xmlns="Unit">
               <span>In the section on ‘Change of Coordinates’, we learn that there is a unique matrix $\Mtrx{C}_{\EuScript{B}\EuScript{A}}$, here of size $(2,2)$, with</span>
            </p>$$\Vect{x}_{\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}\cdot \Vect{x}_{\EuScript{A}}$$<p xmlns="Unit">
               <span>Moreover, the matrix which reverses the change from $\EuScript{A}$-coordinates to $\EuScript{B}$-coordinates is</span>
            </p>$$\Mtrx{C}_{\EuScript{A}\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}^{-1}$$</div>
<p xmlns="Unit">
               <span>What is the <a id="activehottag-14342" class="activehottag" onmouseover="infoopen(14342)"> relationship between the coordinate vectors</a>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14388' onmouseover='infoopen(14388)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14388' style='display:none;'><div class='pack'><div class='title'>Change Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Converting from general coordinates to standard coordinates:  Consider these two ordered bases of $\RNr{3}$:</span>
         </p>
			      $$
					
\begin{array}{ccclcclccl}
\EuScript{S} &amp; \StdBss{1} &amp; = &amp; (1,0,0) &amp; \StdBss{2} &amp; = &amp; (0,1,0) &amp; \StdBss{3} &amp; = &amp; (0,0,1) \\
\EuScript{B} &amp; \Vect{b}_1 &amp; = &amp; (2,-3,7) &amp; \Vect{b}_2 &amp; = &amp; (-1,9,2) &amp; \Vect{b}_3 &amp; = &amp; (4,2,-6)
\end{array}

				$$
			      <p>
            <span>Find the matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ which converts from $\EuScript{B}$-coordinates to $\EuScript{S}$-coordinates. Then find $\Vect{x}_{\EuScript{S}}$ if $\Vect{x}_{\EuScript{B}} = (2,0,3)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The column vectors of $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ consist of the coordinate vectors of $\Vect{b}_1$, $\Vect{b}_2$, and $\Vect{b}_3$ with respect to $\EuScript{S}$. As $\EuScript{S}$ is the standard basis of $\RNr{3}$, we have</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_1)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_1 = (2,-3,7)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_2)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_2 = (-1,9,2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_3)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_3 = (4,2,-6)$</td></tr></table>
			            <p>
                  <span>Using these coordinate vectors as the column vectors of the coordinate conversion matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$, we obtain</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{SB}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]

				$$
			            <p>
                  <span>Consequently,</span>
               </p>
			            $$
					
\Vect{x}_{\EuScript{S}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right] \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix}\ =\ 
\left[\begin{array}{r} 16 \\ 0 \\ -4 \end{array}\right]

				$$
			            <p>
                  <span>That is $\Vect{x}_{\EuScript{S}} = (16,0,-4)$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14388" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of a coordinate conversion</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14356' onmouseover='infoopen(14356)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14356' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Given $\Vect{x}\in W$, we need to express it as a linear combination of $\EuScript{C}$. So suppose</span>
         </p>$$
				
\begin{array}{rcclrcc}
\Vect{x}_{\EuScript{B}} &amp; = &amp; (x_1,\dots ,x_r) &amp; \quad \text{i.e.} &amp; \Vect{x} &amp; = &amp; x_1 \Vect{b}_1 + \cdots + x_r \Vect{b}_r \\
(\Vect{b}_1)_{\EuScript{C}} &amp; = &amp; (a_{11},\dots ,a_{r1}) &amp; \quad \text{i.e.} &amp; \Vect{b}_1 &amp; = &amp; a_{11}\Vect{c}_1 + \cdots + a_{r1}\Vect{c}_r \\
\vdots &amp; &amp; \vdots\quad\vdots &amp; &amp; \vdots &amp; &amp; \vdots \qquad \vdots \\
(\Vect{b}_r)_{\EuScript{C}} &amp; = &amp; (a_{1r},\dots ,a_{rr}) &amp; \quad \text{i.e.} &amp; \Vect{b}_r &amp; = &amp; a_{1r}\Vect{c}_1 + \cdots + a_{rr}\Vect{c}_r \\
\end{array}

			$$<p>
            <span>This implies</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1 \Vect{b}_1 + \cdots + x_r \Vect{b}_r$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1\left( a_{11}\Vect{c}_1 + \cdots + a_{r1}\Vect{c}_r\right)\ + \cdots +\ x_r\left( a_{1r}\Vect{c}_1 + \cdots + a_{rr}\Vect{c}_r\right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(a_{11}x_1 + \cdots + a_{1r}x_r\right)\Vect{c}_1\ + \cdots +\ \left( a_{r1}x_1+\cdots + a_{rr}x_r\right)\Vect{c}_r$</td></tr></table><p>
            <span>Writing $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$ as column vectors we find</span>
         </p>$$
				
\aligned
\Vect{x}_{\EuScript{C}}\ 
   &amp;=\ 
\begin{bmatrix}
a_{11}x_1\ +\ \dots\ +\ a_{1r}x_r \\
\vdots\qquad\qquad\qquad\quad\vdots \\
a_{r1}x_1\ +\ \dots\ +\ a_{rr}x_r
\end{bmatrix}\ =\ 
\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1r} \\
\vdots &amp;       &amp; \vdots \\
a_{r1} &amp; \dots &amp; a_{rr}
\end{bmatrix}
\begin{bmatrix}
x_1 \\ \vdots \\ x_r
\end{bmatrix} \\
   &amp;=\ \Mtrx{C}_{\EuScript{CB}}\, \Vect{x}_{\EuScript{B}}
\endaligned


			$$<p>
            <span>It remains to show that $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is the only matrix performing conversion from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates. So suppose</span>
         </p>$$
				
\Mtrx{D}\ =\ 
\begin{bmatrix}
d_{11} &amp; \dots &amp; d_{1r} \\
\vdots &amp;       &amp; \vdots \\
d_{r1} &amp; \dots &amp; d_{rr}
\end{bmatrix}

			$$<p>
            <span>also satisfies $\Vect{x}_{\EuScript{C}} = D \Vect{x}_{\EuScript{B}}$ for all vectors $\Vect{x}\in W$. Now, if $1\leq j\leq r$, we find</span>
         </p>$$
				
\begin{bmatrix}a_{1j} \\ \vdots \\ a_{rj} \end{bmatrix}\ =\ 
(\mathbf{b}_j)_{\EuScript{C}}\ =\ 
\begin{bmatrix}
d_{11} &amp; \dots &amp; d_{1r} \\
\vdots &amp;       &amp; \vdots \\
d_{r1} &amp; \dots &amp; d_{rr}
\end{bmatrix} \begin{bmatrix}0 \\ \vdots \\ 1 \\ \vdots \\ 0 \end{bmatrix}\ =\ 
\begin{bmatrix}d_{1j} \\ \vdots \\ d_{rj} \end{bmatrix}

			$$<p>
            <span>This means exactly that $\Mtrx{D}=\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ as required. &#x2013; The proof is complete.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-14413' onmouseover='infoopen(14413)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14413' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{D}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\left( \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}\right)$$<p>
            <span>Therefore the product matrix $\left( \Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)$ converts from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates. But we know that there is only one matrix with this property, namely $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$. Therefore these two matrices are equal, and this proves the corollary.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14448' onmouseover='infoopen(14448)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14448' style='display:none;'><div class='pack'><div class='title'>Reversal of Change Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Converting from standard coordinates to general coordinates:  Consider these two ordered bases of $\RNr{3}$:</span>
         </p>
			      $$
					
\begin{array}{ccclcclccl}
\EuScript{S} &amp; \StdBss{1} &amp; = &amp; (1,0,0) &amp; \StdBss{2} &amp; = &amp; (0,1,0) &amp; \StdBss{3} &amp; = &amp; (0,0,1) \\
\EuScript{B} &amp; \Vect{b}_1 &amp; = &amp; (2,-3,7) &amp; \Vect{b}_2 &amp; = &amp; (-1,9,2) &amp; \Vect{b}_3 &amp; = &amp; (4,2,-6)
\end{array}

				$$
			      <p>
            <span>Find the matrix $\Mtrx{C}_{\EuScript{B}\EuScript{S}}$ which converts from $\EuScript{S}$-coordinates to $\EuScript{B}$-coordinates. Then find $\Vect{x}_{\EuScript{B}}$ if $\Vect{x}_{\EuScript{S}} = (4,-1,2)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>From the information given, we know immediately that the column vectors of $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ consist of the coordinate vectors of $\Vect{b}_1$, $\Vect{b}_2$, and $\Vect{b}_3$ with respect to $\EuScript{S}$. As $\EuScript{S}$ is the standard basis of $\RNr{3}$, we have</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_1)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_1 = (2,-3,7)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_2)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_2 = (-1,9,2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_3)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_3 = (4,2,-6)$</td></tr></table>
			            <p>
                  <span>Using these coordinate vectors as the column vectors of the coordinate conversion matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$, we obtain</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{SB}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]

				$$
			            <p>
                  <span>Consequently,</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{BS}} = \left( \Mtrx{A}_{\EuScript{SB}}\right)^{-1}\ =\ \left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]^{-1}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]

				$$
			            <p>
                  <span>To find the $\EuScript{B}$-coordinates of $\Vect{x}_{\EuScript{S}}$, we compute</span>
               </p>
			            $$
					
\Vect{x}_{\EuScript{B}}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]
\left[\begin{array}{r} 4 \\ -1 \\ 2 \end{array}\right]\ =\ 
\frac{1}{388}
\left[\begin{array}{r} 310 \\ 8 \\ 235 \end{array}\right]

				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14448" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of reversing coordinate inversion.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14429' onmouseover='infoopen(14429)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14429' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{C}}$$<p>
            <span>Now, if $\dim(W)=r$, we also have that</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \IdMtrx{r} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \IdMtrx{r} \Vect{x}_{\EuScript{C}}$$<p>
            <span>As coordinate conversion matrices are unique, this gives</span>
         </p>$$\Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} = \IdMtrx{n} \quad\text{and}\quad \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{B}\EuScript{C}} = \IdMtrx{n}$$<p>
            <span>This implies the corollary on reversing coordinate conversion.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div><ul class='chilren'><li><span>of a composition of linear maps     </span><a id='glossaryinfo-14402' class='msm_infobutton' onmouseover='infoopen(14402)'>i</a><div id="dialog-14402" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14402' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-14413' onmouseover='infoopen(14413)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14413' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{D}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\left( \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}\right)$$<p>
            <span>Therefore the product matrix $\left( \Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)$ converts from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates. But we know that there is only one matrix with this property, namely $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$. Therefore these two matrices are equal, and this proves the corollary.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li><li><span>reversal of coordinate change     </span><a id='glossaryinfo-14418' class='msm_infobutton' onmouseover='infoopen(14418)'>i</a><div id="dialog-14418" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{B}\EuScript{C}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14418' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14448' onmouseover='infoopen(14448)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14448' style='display:none;'><div class='pack'><div class='title'>Reversal of Change Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Converting from standard coordinates to general coordinates:  Consider these two ordered bases of $\RNr{3}$:</span>
         </p>
			      $$
					
\begin{array}{ccclcclccl}
\EuScript{S} &amp; \StdBss{1} &amp; = &amp; (1,0,0) &amp; \StdBss{2} &amp; = &amp; (0,1,0) &amp; \StdBss{3} &amp; = &amp; (0,0,1) \\
\EuScript{B} &amp; \Vect{b}_1 &amp; = &amp; (2,-3,7) &amp; \Vect{b}_2 &amp; = &amp; (-1,9,2) &amp; \Vect{b}_3 &amp; = &amp; (4,2,-6)
\end{array}

				$$
			      <p>
            <span>Find the matrix $\Mtrx{C}_{\EuScript{B}\EuScript{S}}$ which converts from $\EuScript{S}$-coordinates to $\EuScript{B}$-coordinates. Then find $\Vect{x}_{\EuScript{B}}$ if $\Vect{x}_{\EuScript{S}} = (4,-1,2)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>From the information given, we know immediately that the column vectors of $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ consist of the coordinate vectors of $\Vect{b}_1$, $\Vect{b}_2$, and $\Vect{b}_3$ with respect to $\EuScript{S}$. As $\EuScript{S}$ is the standard basis of $\RNr{3}$, we have</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_1)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_1 = (2,-3,7)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_2)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_2 = (-1,9,2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_3)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_3 = (4,2,-6)$</td></tr></table>
			            <p>
                  <span>Using these coordinate vectors as the column vectors of the coordinate conversion matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$, we obtain</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{SB}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]

				$$
			            <p>
                  <span>Consequently,</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{BS}} = \left( \Mtrx{A}_{\EuScript{SB}}\right)^{-1}\ =\ \left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]^{-1}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]

				$$
			            <p>
                  <span>To find the $\EuScript{B}$-coordinates of $\Vect{x}_{\EuScript{S}}$, we compute</span>
               </p>
			            $$
					
\Vect{x}_{\EuScript{B}}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]
\left[\begin{array}{r} 4 \\ -1 \\ 2 \end{array}\right]\ =\ 
\frac{1}{388}
\left[\begin{array}{r} 310 \\ 8 \\ 235 \end{array}\right]

				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14448" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of reversing coordinate inversion.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14429' onmouseover='infoopen(14429)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14429' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{C}}$$<p>
            <span>Now, if $\dim(W)=r$, we also have that</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \IdMtrx{r} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \IdMtrx{r} \Vect{x}_{\EuScript{C}}$$<p>
            <span>As coordinate conversion matrices are unique, this gives</span>
         </p>$$\Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} = \IdMtrx{n} \quad\text{and}\quad \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{B}\EuScript{C}} = \IdMtrx{n}$$<p>
            <span>This implies the corollary on reversing coordinate conversion.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li></ul></li><li><span>characteristic     </span><ul class='chilren'><li><span>polynomial of a matrix     </span><a id='glossaryinfo-20016' class='msm_infobutton' onmouseover='infoopen(20016)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-20016' style='display:none;'><br /><div class='def'><span class='deftitle'>Characteristic polynomial</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The determinant of the $(n,n)$-matrix $(\Mtrx{A}-\lambda \IdMtrx{n})$ is a polynomial of degree $n$ in the variable $\lambda$, called the characteristic polynomial of $\Mtrx{A}$.
				
				It is of the form
			</span>
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_n \lambda^n + \cdots a_1\lambda + a_0$</td></tr></table>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20031' onmouseover='infoopen(20031)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20031' style='display:none;'><div class='pack'><div class='title'>Characteristic Polynomial: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Here are some examples of polynomials:</span>
         </p>
			      <ul>
				        <li>
               <p>
                  <span>
                     $p(t) = 3t^2 + t -1$ is a polynomial of degree $2$ in the variable $t$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $p(x) = 5x^3 + x^2 + 3x + 4$ is a polynomial of degree $3$ in the variable $x$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $q(s) = -2s^5 + s^4 - 2s^3 + s^2 - 5s + 1$ is a polynomial of degree $5$ in the variable $s$.</span>
               </p>
            </li>
			      </ul>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the characteristic polynomial of the matrix</span>
         </p>
			      $$
					
\Mtrx{A} =
\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>As $\Mtrx{A}$ is a $(2,2)$-matrix, its characteristic polynomial has degree $2$. To find it, we compute:</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ 
	\det\left(
	\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]\ -\ 
\lambda\cdot \left[
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right] \right) \\
	&amp;=\ \det
\left[
\begin{array}{cc}
3 - \lambda &amp; 1 \\
1 &amp; 3 - \lambda
\end{array}
\right] \\
	&amp;=\ (3-\lambda)^2 - 1 \\
	&amp;=\ (\lambda-4)(\lambda -2)
\endaligned

				$$
			            <p>
                  <span>So the characteristic polynomial of $\Mtrx{A}$ vanishes at two places, namely:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$4$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-20031" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of characteristic polynomials</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>coefficient     </span><ul class='chilren'><li><span>of a linear equation     </span><a id='glossaryinfo-3273' class='msm_infobutton' onmouseover='infoopen(3273)'>i</a><div id="dialog-3273" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Look up the definition</span>
                        </p>
                     </info></div></li><li><span>vector     </span><ul class='chilren'><li><span>in a linear equation     </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /></div></li><li><span>augmented     </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /></div></li></ul></li></ul></li><li><span>cofactor     </span><a id='glossaryinfo-8918' class='msm_infobutton' onmouseover='infoopen(8918)'>i</a><div id="dialog-8918" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-cofactor of a matrix $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8918' style='display:none;'><br /><div class='def'><span class='deftitle'>Cofactor of a matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-cofactor of $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                        </p>
                        $$c_{ij}(\Mtrx{A}) := (-1)^{i+j}\cdot \det(A_{ij})$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-8912' onmouseover='popup(8912)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-8912" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Here we assume that you know how to compute determinants of matrices of size $(r-1,r-1)$.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-8916' onmouseover='infoopen(8916)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-8916' style='display:none;'><div class='pack'><div class='title'>Cofactors of a Matrix: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rrrr}
4 &amp; 1 &amp; 6 &amp; 5 \\
3 &amp; -2 &amp; -3 &amp; 2 \\
9 &amp; 2 &amp; 4 &amp; 7 \\
1 &amp; -9 &amp; -3 &amp; 1
\end{array}
\right]

				$$
			
			      <p>
            <span>has as its $(4,2)$-minor the $(3,3)$-matrix</span>
         </p>
			
			      $$
					
\Mtrx{A}_{42} = 
\left[
\begin{array}{rrrr}
4 &amp; 6 &amp; 5 \\
3 &amp; -3 &amp; 2 \\
9 &amp; 4 &amp; 7 
\end{array}
\right]

				$$
			
			      <p>
            <span>Therefore the $(4,2)$-cofactor of $\Mtrx{A}$ is</span>
         </p>
			
			      $$
					
\aligned
c_{42}(\Mtrx{A})\ &amp;=\ (-1)^{4+2}\cdot \det(\Mtrx{A}_{42}) \\
	&amp;=\ (-1)^6\cdot \det\, 
\left[
\begin{array}{rrrr}
4 &amp; 6 &amp; 5 \\
3 &amp; -3 &amp; 2 \\
9 &amp; 4 &amp; 7 
\end{array}
\right] \\
	&amp;=\ 4\cdot (-21-8) - 3\cdot (42-20) + 9\cdot (12-(-15)) \\
	&amp;=\ 61
\endaligned

				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-8916" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An example of a cofactor</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>colinear     </span><a id='glossaryinfo-2187' class='msm_infobutton' onmouseover='infoopen(2187)'>i</a><div id="dialog-2187" class="dialogs" title="What does ‘colinear’ mean?"><info xmlns="Unit">
                     
                     <p>
                        <span>‘Colinear’ means ‘has the same direction as’.</span>
                     </p>
                  </info></div></li><li><span>column     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4792' class='msm_infobutton' onmouseover='infoopen(4792)'>i</a><div id="dialog-4792" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4792' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4790' onmouseover='popup(4790)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4790" class="dialogs" title="On column matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>A column matrix is one which has exactly one column, i.e. is of size $(m,1)$. Thus the matrices below are column matrices.</span>
                           </p>
                           $$
								\left[
								\begin{array}{r}
								15 \\ 4 \\ -7
								\end{array}
								\right]\qquad
								\left[
								\begin{array}{r}
								3 \\ 1 \\ 1 \\ 0\\ 1
								\end{array}
								\right]
							$$
                        </info></div></ul></div><br /></div></li></ul></li><li><span>commutativity     </span><ul class='chilren'><li><span>of matrix addition     </span><a id='glossaryinfo-5165' class='msm_infobutton' onmouseover='infoopen(5165)'>i</a><div id="dialog-5165" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5165' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5175' onmouseover='infoopen(5175)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5175' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>Addition of matrices is defined by adding the matrix entries in matching positions. Therefore the above identities for matrix sums follow directly from the corresponding identities for sums of real numbers. – The details follow.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose $A$, $B$, and $C$ are three matrices of size $(m,n)$. Let us work with the entries in position $(i,j)$ for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C$ has the number $c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Now let’s look at the entry in position $(i,j)$ of the two matrix sums in question:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $(A+B)+C$ has the number $(a_{ij}+b_{ij})+c_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $A+(B+C)$ has the number $a_{ij}+(b_{ij}+c_{ij})$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the associativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Commutativity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Again let's look at the entry in position $(i,j)$ of the two matrix sums in question.</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A+B$ has the number $a_{ij}+b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B+A$ has the number $b_{ij}+a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>These two numbers are equal because of the commutativity law for the addition of real numbers. – This result applies to each position. Therefore the two matrix sums are equal, and the associativity property of matrix addition is proven.</span>
         </p><p>
            <span>The remaining properties of matrix addition can be proved with the same method. – Try it!</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>component     </span><ul class='chilren'><li><span>of a vector orthogonal to another     </span><a id='glossaryinfo-2240' class='msm_infobutton' onmouseover='infoopen(2240)'>i</a><div id="dialog-2240" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The component of a vector $\Vect{x}$ orthogonal to another vector $\Vect{y}$ is</span>
                           </p>
                           $$\Vect{u} = \Vect{x} - \pr_{\Vect{y}}(\Vect{x})$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2240' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li></ul></li><li><span>composite     </span><ul class='chilren'><li><span>of linear transformations     </span><ul class='chilren'><li><span>represented by matrix product     </span><a id='glossaryinfo-17835' class='msm_infobutton' onmouseover='infoopen(17835)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17835' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Composite of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $S\from \RNr{p} \to \RNr{n}$ and $T\from \RNr{n} \to \RNr{m}$ are linear transformations, then their composite 
			</span>
         
      </p>$$(T\Comp S)\from \RNr{p} \longrightarrow \RNr{m},\quad (T\Comp S)(\Vect{x}) = T(S(\Vect{x}))$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(n,p)$-matrix representing $S$, and if $\Mtrx{B}$ is the $(m,n)$-matrix representing $T$, then $\Mtrx{B}\Mtrx{A}$ is the $(m,p)$-matrix which represents $T\Comp S$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-17837' onmouseover='popup(17837)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-17837" class="dialogs" title="Comment: What does this proposition tell us?"><info xmlns="Theorem">
         
         <p>
            <span>This proposition gives us two strong pieces of information:</span>
         </p>
         <ol>
            <li>
               <p>
                  <span>The composite of two linear transformations is again linear</span>
               </p>
            </li>
            <li>
               <p>
                  <span>How is the composite of $T$ and $S$ represented?</span>
               </p>
            </li>
         </ol>
         <p>
            <span>In short: the composite of linear maps corresponds to the product of representing matrices.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-17889' onmouseover='infoopen(17889)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-17889' style='display:none;'><div class='pack'><div class='title'>Example: Composition of Linear Transformations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Form the composite $R\Comp S$ of the two linear transformations $S$ and $R$ below. Then describe the transformation properties of the composite.</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $S\from \RNr{2} \to \RNr{2}$ is the shear map given by</span>
               </p>
					          $$
							
S(x,y) =
\left[
\begin{array}{rr}
1 &amp; 2 \\
0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{r}
x \\ y
\end{array}
\right]
							
						$$
				        </li>
				        <li>
               <p>
                  <span>
                     $R\from \RNr{2}\to \RNr{2}$ is the counterclockwise rotation about the origin through the angle $2\pi/3$ given by.</span>
               </p>
					          $$
							
R(x,y) =
\dfrac{1}{2}\cdot \left[
\begin{array}{rr}
-1 &amp; -\sqrt{3} \\
\sqrt{3} &amp; -1
\end{array}
\right]
\left[
\begin{array}{r}
x \\ y
\end{array}
\right]
							
						$$
				        </li>
			      </ul>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The matrix representing $R\Comp S\from \RNr{2} \to \RNr{2}$ is</span>
               </p>
			            $$
					
\dfrac{1}{2}\left[
\begin{array}{rr}
-1 &amp; -\sqrt{3} \\
\sqrt{3} &amp; -1
\end{array}
\right]
\left[
\begin{array}{rr}
1 &amp; 2 \\
0 &amp; 1
\end{array}
\right] = 
\dfrac{1}{2}\cdot \left[
\begin{array}{rr}
-1 &amp; -2 - \sqrt{3} \\
\sqrt{3} &amp; 2\sqrt{3} -1
\end{array}
\right]
							
				$$
			
			            <p>
                  <span>The transformation effect of $R\Comp S$ on $\RNr{2}$ is given by first performing the shear map, then performing the rotation on the result; as in the picture below.</span>
               </p>
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearRotate.png" height="124.25" width="350"/></div>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-17889" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of composition of linear maps</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-17840' onmouseover='infoopen(17840)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-17840' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><div class='proofblocktitle'>Linearity of $T\Comp S$
         </div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We need to show that $T\Comp S$ satisfies the properties of a linear transformation. To see that it commutes with vector addition, let $\Vect{x},\Vect{y}\in \RNr{n}$. We find</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(T\Comp S)(\Vect{x}+\Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T(S(\Vect{x}+\Vect{y}))$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17850" class="hottag" onmouseover="popup(17850)">$=	$</a><div id="dialog-17850" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>As $S$ is linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T(S(\Vect{x}) + T(S(\Vect{y}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17855" class="hottag" onmouseover="popup(17855)">$=	$</a><div id="dialog-17855" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>As $T$ is linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T(S(\Vect{x})) + T(S(\Vect{y}))$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T\Comp S(\Vect{x}) + T\Comp S(\Vect{y})$</td></tr></table><p>
            <span>So $T\Comp S$ commutes with vector addition.</span>
         </p><p>
            <span>To see that $T\Comp S$ commutes with scalar multiplication, let $\Vect{x}\in\RNr{n}$ and $t\in\RNr{}$. We find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T\Comp S(t\Vect{x})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17865" class="hottag" onmouseover="popup(17865)">$=	$</a><div id="dialog-17865" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $T\Comp S$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T(S(t \Vect{x}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17870" class="hottag" onmouseover="popup(17870)">$=	$</a><div id="dialog-17870" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>... because $S$ is linear</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$T(tS(\Vect{x}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17875" class="hottag" onmouseover="popup(17875)">$=	$</a><div id="dialog-17875" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>as $T$ is linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot T(S(\Vect{x}))$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \left( T\Comp S\right)(\Vect{x})$</td></tr></table><p>
            <span>This means that $T\Comp S$ commutes with scalar multiplication. &#x2013; The proof that $T\Comp S$ is linear is complete.</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><div class='proofblocktitle'>The matrix which represents $T\Comp S$
         </div><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We know now that $T\Comp S$ is linear. Therefore there is a unique $(m,p)$-matrix  which represents it. On the other hand, if $\Mtrx{A}$ represents $S$, and $\Mtrx{B}$ represents $T$, we find for arbitrary $\Vect{x}\in\RNr{p}$
            </span>
         </p>$$BA\Vect{x} = B S(\Vect{x}) = T(S(\Vect{x}) ) = T\Comp S(\Vect{x})$$<p>
            <span>Therefore $\Mtrx{C}:=\Mtrx{B}\Mtrx{A}$ is the unique matrix representing $T\Comp S$.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li></ul></li></ul></li><li><span>composition     </span><ul class='chilren'><li><span>of linear transformations     </span><a id='glossaryinfo-16571' class='msm_infobutton' onmouseover='infoopen(16571)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16571' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-16573' onmouseover='popup(16573)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-16573" class="dialogs" title="How to read this"><info xmlns="Unit">
                           
                           $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                           <p>
                              <span>is read: ‘T following S from R p to Rm, T following S of x is defined to be T of S of x’.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-16575' onmouseover='popup(16575)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-16575" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the functions $S$ and $T$, we define a new function here, namely their composite $T\Comp S$. The effect of the function $T\Comp S$ on a vector $\Vect{x}$ is defined by successive evaluation: first evaluate $S$ on $\Vect{x}$ so as to obtain the vector $S(\Vect{x})$ in $\RNr{n}$. To this vector we apply $T$ so as to obtain the vector $T(S(\Vect{x}))$ in $\RNr{m}$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with two linear functions $S$ and $T$, we do not know if their composite $(T\Comp S)$ is linear. Therefore we must check that $(T\Comp S)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>contraction     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-17566' class='msm_infobutton' onmouseover='infoopen(17566)'>i</a><div id="dialog-17566" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17566' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>     </span></li></ul></li><li><span>coordinate     </span><ul class='chilren'><li><span>vector     </span><a id='glossaryinfo-13459' class='msm_infobutton' onmouseover='infoopen(13459)'>i</a><div id="dialog-13459" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of the term.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13459' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-13351' onmouseover='infoopen(13351)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-13351' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div><div id="dialog-13351" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>What does ‘ordered basis’ mean? – Explanation</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-13399' onmouseover='infoopen(13399)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-13399' style='display:none;'><div class='title'>Coordinate Vector - Illustration</div><p xmlns="Unit">
               <span>The picture below shows $\RNr{2}$ with an ordered basis $\EuScript{B} = (\Vect{a} , \Vect{b} )$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/CoordinateVector_1.gif' height='275.77962577963' width='350'/></div><p xmlns="Unit">
               <span>The basis vectors $\Vect{a}$ and $\Vect{b}$ set up a coordinate grid, and we use this grid to express arbitrary vectors as linear combinations of the basis vectors. For example</span>
            </p><table class='mathtable' border='1' cellpadding='3' style='width:100% !important;'><tr>
                  <td style='border-width:1px !important;'>
                     <p>
                        <span>
                           <b>Linear Combination</b>
                        </span>
                     </p>
                  </td>
                  <td style='border-width:1px !important;'>
                     <p>
                        <span>
                           <b>Coordinate vector with respect to</b>
                           $\EuScript{B}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1\cdot \Vect{a}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1)\cdot \Vect{a} + 5\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1,5)$</td></tr></table>
                  </td>
               </tr><tr>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3\cdot \Vect{a} + 2\cdot \Vect{b}$</td></tr></table>
                  </td>
                  <td style='border-width:1px !important;'>
                     <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(3,2)$</td></tr></table>
                  </td>
               </tr></table></div><div id="dialog-13399" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An illustration of ‘coordinate vector’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-13455' onmouseover='infoopen(13455)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-13455' style='display:none;'><div class='pack'><div class='title'>Coordinate Vector: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>You are given the ordered basis $\EuScript{B} = (\Vect{a},\Vect{b})$ of $\RNr{2}$ with</span>
         </p>
			      <p align="center">
            <span>
               $\Vect{a} = (2,1)$ and $\Vect{b} = (-3,4)$.</span>
         </p>
			      <p>
            <span>Find $\Vect{x}_{\EuScript{S}}$ if $\Vect{x}_{\EuScript{B}} = (6,5)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We recall that $\Vect{x}_{\EuScript{B}} = (6,5)$ means that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot \Vect{a} + 5\cdot \Vect{b}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot (2,1) + 5\cdot (-3,4)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(12,6) + (-15,20)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-3,26)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Let $V$ be the subspace of $\RNr{3}$ spanned by the linearly independent vectors $\Vect{a} = (1,-1,2)$ and $\Vect{b}= (3,2,-3)$. You are given the information that $\Vect{x}= (0,-5,9)$ is in $V$. Find its coordinate vector with respect to the ordered basis $\EuScript{B}:= ( \Vect{a} , \Vect{b} )$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We have $\Vect{x}_{\EuScript{B}} = (s,t)$ for the two uniquely determined numbers $s$ and $t$ satisfying</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s \Vect{a} + t \Vect{b}$</td></tr></table>
			            <p>
                  <span>Therefore we need to solve the vector equation</span>
               </p>
							        $$
									
s
\left[
\begin{array}{r}
1 \\ -1 \\ 2
\end{array}
\right]\ +\ t
\left[
\begin{array}{r}
3 \\ 2 \\ -3
\end{array}
\right]\ =\ 
\left[
\begin{array}{r}
0 \\ -5 \\ 9
\end{array}
\right]
					
								$$
			            <p>
                  <span>This vector equation is equivalent to the system of linear equations</span>
               </p>
							        $$
									
\begin{array}{rcccr}
s &amp; + &amp; 3t &amp; = &amp; 0 \\
-s &amp; + &amp; 2t &amp; = &amp; -5 \\
2s &amp; - &amp; 3t &amp; = &amp; 9
\end{array}
					
								$$
			            <p>
                  <span>The row reduction method applied to the augmented coefficient matrix of this system yields</span>
               </p>
							        $$
									
\begin{array}{rr|r}
1 &amp; 3 &amp; 0 \\
-1 &amp; 2 &amp; -5 \\
2 &amp; -3 &amp; 9
\end{array} \qquad\qquad
\begin{array}{rr|r}
1 &amp; 0 &amp; 3 \\
0 &amp; 1 &amp; -1 \\
0 &amp; 0 &amp; 0
\end{array}
					
								$$
			            <p>
                  <span>Thus $s=3$ and $t=-1$ are the only solution of the given vector equation, and so we conclude:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3 \Vect{a} + (-1) \Vect{b}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(3,-1)$</td></tr></table>
			            <p>
                  <span>is the coordinate vector of $\Vect{x}$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose $\EuScript{B}=(\Vect{a},\Vect{b},\Vect{c})$ is an ordered basis of a subvector space $V$ of $\RNr{n}$. Find $\Vect{x}_{\EuScript{B}}$ if</span>
         </p>
			      <ol>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{a}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{b}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = \Vect{c}$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $\Vect{x} = 3\cdot\Vect{a}-\Vect{b} - 2\cdot \Vect{c}$
                  </span>
               </p>
            </li>
			      </ol>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The required coordinate vectors are</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 1},{\color{blue} 0},{\color{green} 0})$ as $\Vect{x} = {\color{red} 1}\cdot \Vect{a} + {\color{blue} 0}\cdot \Vect{b} + {\color{green} 0}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 0},{\color{blue} 1},{\color{green} 0})$ as $\Vect{x} = {\color{red} 0}\cdot \Vect{a} + {\color{blue} 1}\cdot \Vect{b} + {\color{green} 0}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 0},{\color{blue} 0},{\color{green} 1})$ as $\Vect{x} = {\color{red} 0}\cdot \Vect{a} + {\color{blue} 0}\cdot \Vect{b} + {\color{green} 1}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\Vect{x}_{\EuScript{B}}=({\color{red} 3},{\color{blue} -1},{\color{green} -2})$ as $\Vect{x} = {\color{red} 3}\cdot \Vect{a} + {\color{blue} (-1)}\cdot \Vect{b} + {\color{green} (-2)}\cdot \Vect{c}$
                        </span>
                     </p>
                  </li>
			            </ol>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose $\EuScript{B}=(\Vect{a},\Vect{b},\Vect{c})$ is an ordered basis of a subvector space $V$ of $\RNr{n}$. Then $\EuScript{C}=(\Vect{b},\Vect{c},\Vect{a})$ is another ordererd basis of $V$. If $\Vect{x}_{\EuScript{B}} = (-2,6,-5)$, find $\Vect{x}_{\EuScript{C}}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-2)\cdot \Vect{a} + 6\cdot \Vect{b} + (-5)\cdot \Vect{c}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$6\cdot \Vect{b} + (-5)\cdot \Vect{c} + (-2)\cdot \Vect{a}$</td></tr></table>
			            <p>
                  <span>Therefore</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(6,-5,-2)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-13455" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of coordinate vectors</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>conversion matrix     </span><a id='glossaryinfo-14391' class='msm_infobutton' onmouseover='infoopen(14391)'>i</a><div id="dialog-14391" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14391' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$<div id="dialog-14342" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-14342' style='display:none;'><div class='title'>Change of Coordinates - Illustration</div><p xmlns="Unit">
               <span>To illustrate the essence of ‘change of coordinates’, consider two ordered bases $\EuScript{A} = (\Vect{a}_1,\Vect{a}_2)$ and $\EuScript{B}=(\Vect{b}_1,\Vect{b}_2)$ in $\RNr{2}$. Now, given a vector $\Vect{x}$ in $\RNr{2}$, we may</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{A}:$
                     </span>
                  </p>
                  $$\Vect{x} = u \Vect{a}_1 + v \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{A}} = (u,v)$$
                  <p>
                     <span>The $\EuScript{A}$-coordinates of $\Vect{x}$ are $(u,v)$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{B}:$
                     </span>
                  </p>
                  $$\Vect{x} = s \Vect{b}_1 + t \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{B}} = (s,t)$$
                  <p>
                     <span>The $\EuScript{B}$-coordinates of $\Vect{x}$ are $(s,t)$
                     </span>
                  </p>
               </li>
            </ol><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ChangeBases.png' height='197.4' width='350'/></div><p xmlns="Unit" align="center">
               <span>Here $\Vect{x}_{\EuScript{A}} = \left( \tfrac{3}{2} , \tfrac{5}{2} \right)$
               </span>
            </p><p xmlns="Unit">
               <span>So we arrive at the question: suppose we know the $\EuScript{A}$-coordinates of $\Vect{x}$, what are its $\EuScript{B}$-coordinates? and, vice versa, suppose we know the $\EuScript{B}$-coordinates of $\Vect{x}$, what are its $\EuScript{A}$-coordinates?</span>
            </p><p xmlns="Unit">
               <span>In the section on ‘Change of Coordinates’, we learn that there is a unique matrix $\Mtrx{C}_{\EuScript{B}\EuScript{A}}$, here of size $(2,2)$, with</span>
            </p>$$\Vect{x}_{\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}\cdot \Vect{x}_{\EuScript{A}}$$<p xmlns="Unit">
               <span>Moreover, the matrix which reverses the change from $\EuScript{A}$-coordinates to $\EuScript{B}$-coordinates is</span>
            </p>$$\Mtrx{C}_{\EuScript{A}\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}^{-1}$$</div>
<p xmlns="Unit">
               <span>What is the <a id="activehottag-14342" class="activehottag" onmouseover="infoopen(14342)"> relationship between the coordinate vectors</a>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14388' onmouseover='infoopen(14388)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14388' style='display:none;'><div class='pack'><div class='title'>Change Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Converting from general coordinates to standard coordinates:  Consider these two ordered bases of $\RNr{3}$:</span>
         </p>
			      $$
					
\begin{array}{ccclcclccl}
\EuScript{S} &amp; \StdBss{1} &amp; = &amp; (1,0,0) &amp; \StdBss{2} &amp; = &amp; (0,1,0) &amp; \StdBss{3} &amp; = &amp; (0,0,1) \\
\EuScript{B} &amp; \Vect{b}_1 &amp; = &amp; (2,-3,7) &amp; \Vect{b}_2 &amp; = &amp; (-1,9,2) &amp; \Vect{b}_3 &amp; = &amp; (4,2,-6)
\end{array}

				$$
			      <p>
            <span>Find the matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ which converts from $\EuScript{B}$-coordinates to $\EuScript{S}$-coordinates. Then find $\Vect{x}_{\EuScript{S}}$ if $\Vect{x}_{\EuScript{B}} = (2,0,3)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The column vectors of $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ consist of the coordinate vectors of $\Vect{b}_1$, $\Vect{b}_2$, and $\Vect{b}_3$ with respect to $\EuScript{S}$. As $\EuScript{S}$ is the standard basis of $\RNr{3}$, we have</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_1)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_1 = (2,-3,7)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_2)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_2 = (-1,9,2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_3)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_3 = (4,2,-6)$</td></tr></table>
			            <p>
                  <span>Using these coordinate vectors as the column vectors of the coordinate conversion matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$, we obtain</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{SB}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]

				$$
			            <p>
                  <span>Consequently,</span>
               </p>
			            $$
					
\Vect{x}_{\EuScript{S}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right] \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix}\ =\ 
\left[\begin{array}{r} 16 \\ 0 \\ -4 \end{array}\right]

				$$
			            <p>
                  <span>That is $\Vect{x}_{\EuScript{S}} = (16,0,-4)$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14388" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of a coordinate conversion</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14356' onmouseover='infoopen(14356)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14356' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Given $\Vect{x}\in W$, we need to express it as a linear combination of $\EuScript{C}$. So suppose</span>
         </p>$$
				
\begin{array}{rcclrcc}
\Vect{x}_{\EuScript{B}} &amp; = &amp; (x_1,\dots ,x_r) &amp; \quad \text{i.e.} &amp; \Vect{x} &amp; = &amp; x_1 \Vect{b}_1 + \cdots + x_r \Vect{b}_r \\
(\Vect{b}_1)_{\EuScript{C}} &amp; = &amp; (a_{11},\dots ,a_{r1}) &amp; \quad \text{i.e.} &amp; \Vect{b}_1 &amp; = &amp; a_{11}\Vect{c}_1 + \cdots + a_{r1}\Vect{c}_r \\
\vdots &amp; &amp; \vdots\quad\vdots &amp; &amp; \vdots &amp; &amp; \vdots \qquad \vdots \\
(\Vect{b}_r)_{\EuScript{C}} &amp; = &amp; (a_{1r},\dots ,a_{rr}) &amp; \quad \text{i.e.} &amp; \Vect{b}_r &amp; = &amp; a_{1r}\Vect{c}_1 + \cdots + a_{rr}\Vect{c}_r \\
\end{array}

			$$<p>
            <span>This implies</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1 \Vect{b}_1 + \cdots + x_r \Vect{b}_r$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1\left( a_{11}\Vect{c}_1 + \cdots + a_{r1}\Vect{c}_r\right)\ + \cdots +\ x_r\left( a_{1r}\Vect{c}_1 + \cdots + a_{rr}\Vect{c}_r\right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(a_{11}x_1 + \cdots + a_{1r}x_r\right)\Vect{c}_1\ + \cdots +\ \left( a_{r1}x_1+\cdots + a_{rr}x_r\right)\Vect{c}_r$</td></tr></table><p>
            <span>Writing $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$ as column vectors we find</span>
         </p>$$
				
\aligned
\Vect{x}_{\EuScript{C}}\ 
   &amp;=\ 
\begin{bmatrix}
a_{11}x_1\ +\ \dots\ +\ a_{1r}x_r \\
\vdots\qquad\qquad\qquad\quad\vdots \\
a_{r1}x_1\ +\ \dots\ +\ a_{rr}x_r
\end{bmatrix}\ =\ 
\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1r} \\
\vdots &amp;       &amp; \vdots \\
a_{r1} &amp; \dots &amp; a_{rr}
\end{bmatrix}
\begin{bmatrix}
x_1 \\ \vdots \\ x_r
\end{bmatrix} \\
   &amp;=\ \Mtrx{C}_{\EuScript{CB}}\, \Vect{x}_{\EuScript{B}}
\endaligned


			$$<p>
            <span>It remains to show that $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is the only matrix performing conversion from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates. So suppose</span>
         </p>$$
				
\Mtrx{D}\ =\ 
\begin{bmatrix}
d_{11} &amp; \dots &amp; d_{1r} \\
\vdots &amp;       &amp; \vdots \\
d_{r1} &amp; \dots &amp; d_{rr}
\end{bmatrix}

			$$<p>
            <span>also satisfies $\Vect{x}_{\EuScript{C}} = D \Vect{x}_{\EuScript{B}}$ for all vectors $\Vect{x}\in W$. Now, if $1\leq j\leq r$, we find</span>
         </p>$$
				
\begin{bmatrix}a_{1j} \\ \vdots \\ a_{rj} \end{bmatrix}\ =\ 
(\mathbf{b}_j)_{\EuScript{C}}\ =\ 
\begin{bmatrix}
d_{11} &amp; \dots &amp; d_{1r} \\
\vdots &amp;       &amp; \vdots \\
d_{r1} &amp; \dots &amp; d_{rr}
\end{bmatrix} \begin{bmatrix}0 \\ \vdots \\ 1 \\ \vdots \\ 0 \end{bmatrix}\ =\ 
\begin{bmatrix}d_{1j} \\ \vdots \\ d_{rj} \end{bmatrix}

			$$<p>
            <span>This means exactly that $\Mtrx{D}=\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ as required. &#x2013; The proof is complete.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-14413' onmouseover='infoopen(14413)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14413' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{D}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{D}\EuScript{C}}\left( \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}\right)$$<p>
            <span>Therefore the product matrix $\left( \Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)$ converts from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates. But we know that there is only one matrix with this property, namely $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$. Therefore these two matrices are equal, and this proves the corollary.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14448' onmouseover='infoopen(14448)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14448' style='display:none;'><div class='pack'><div class='title'>Reversal of Change Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Converting from standard coordinates to general coordinates:  Consider these two ordered bases of $\RNr{3}$:</span>
         </p>
			      $$
					
\begin{array}{ccclcclccl}
\EuScript{S} &amp; \StdBss{1} &amp; = &amp; (1,0,0) &amp; \StdBss{2} &amp; = &amp; (0,1,0) &amp; \StdBss{3} &amp; = &amp; (0,0,1) \\
\EuScript{B} &amp; \Vect{b}_1 &amp; = &amp; (2,-3,7) &amp; \Vect{b}_2 &amp; = &amp; (-1,9,2) &amp; \Vect{b}_3 &amp; = &amp; (4,2,-6)
\end{array}

				$$
			      <p>
            <span>Find the matrix $\Mtrx{C}_{\EuScript{B}\EuScript{S}}$ which converts from $\EuScript{S}$-coordinates to $\EuScript{B}$-coordinates. Then find $\Vect{x}_{\EuScript{B}}$ if $\Vect{x}_{\EuScript{S}} = (4,-1,2)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>From the information given, we know immediately that the column vectors of $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ consist of the coordinate vectors of $\Vect{b}_1$, $\Vect{b}_2$, and $\Vect{b}_3$ with respect to $\EuScript{S}$. As $\EuScript{S}$ is the standard basis of $\RNr{3}$, we have</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_1)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_1 = (2,-3,7)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_2)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_2 = (-1,9,2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{b}_3)_{\EuScript{S}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}_3 = (4,2,-6)$</td></tr></table>
			            <p>
                  <span>Using these coordinate vectors as the column vectors of the coordinate conversion matrix $\Mtrx{C}_{\EuScript{S}\EuScript{B}}$, we obtain</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{SB}}\ =\ 
\left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]

				$$
			            <p>
                  <span>Consequently,</span>
               </p>
			            $$
					
\Mtrx{C}_{\EuScript{BS}} = \left( \Mtrx{A}_{\EuScript{SB}}\right)^{-1}\ =\ \left[\begin{array}{rrr}
2 &amp; -1 &amp; 4 \\
-3 &amp; 9 &amp; 2 \\
7 &amp; 2 &amp; -6
\end{array}\right]^{-1}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]

				$$
			            <p>
                  <span>To find the $\EuScript{B}$-coordinates of $\Vect{x}_{\EuScript{S}}$, we compute</span>
               </p>
			            $$
					
\Vect{x}_{\EuScript{B}}\ =\ \frac{1}{388}
\left[\begin{array}{rrr}
58 &amp; -2 &amp; 38 \\
4 &amp; 40 &amp; 16 \\
69 &amp; 11 &amp; -15
\end{array}\right]
\left[\begin{array}{r} 4 \\ -1 \\ 2 \end{array}\right]\ =\ 
\frac{1}{388}
\left[\begin{array}{r} 310 \\ 8 \\ 235 \end{array}\right]

				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14448" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of reversing coordinate inversion.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14429' onmouseover='infoopen(14429)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14429' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>For an arbitrary vector $\Vect{x}$ in $W$ we find</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{C}}$$<p>
            <span>Now, if $\dim(W)=r$, we also have that</span>
         </p>$$\Vect{x}_{\EuScript{B}} = \IdMtrx{r} \Vect{x}_{\EuScript{B}} \quad\text{and}\quad \Vect{x}_{\EuScript{C}} = \IdMtrx{r} \Vect{x}_{\EuScript{C}}$$<p>
            <span>As coordinate conversion matrices are unique, this gives</span>
         </p>$$\Mtrx{C}_{\EuScript{B}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}} = \IdMtrx{n} \quad\text{and}\quad \Mtrx{C}_{\EuScript{C}\EuScript{B}} \Mtrx{C}_{\EuScript{B}\EuScript{C}} = \IdMtrx{n}$$<p>
            <span>This implies the corollary on reversing coordinate conversion.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li></ul></li><li><span>coordinate of an $n$-tuple     </span><a id='glossaryinfo-260' class='msm_infobutton' onmouseover='infoopen(260)'>i</a><div id="dialog-260" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Example for $n=3$: $(5,1,2)$ is a $3$-tuple; i.e. it has 3 positions, each of which is occupied by a number. These numbers are the coordinates of the $3$-tuple. Thus the first coordinate is $5$. The second coordinate is $1$. The third coordinate is $2$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-260' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-258" class="dialogs"><info xmlns="Unit">
                                    <p>
                                       <span>Read this expression as: ‘(n-tuple) x-one, x-two, to , x-n’.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<a id="hottag-258" class="hottag" onmouseover="popup(258)"> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </a>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-206' onmouseover='infoopen(206)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-206' style='display:none;'><div class='pack'><div class='title'>Examples of $n$-tuples.</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Here are some examples of $n$-tuples:</span>
         </p>
			
			      <ul>
				        <li>
					          <p>
                  <span>
                     $(5)$ is a 1-tuple. Its one and only coordinate is the number $5$. $(-3)$ is another 1-tuple, and an arbitrary 1-tuple is of the form $(s)$, with $s$ a number in the system of real numbers $\RNr{}$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(2,3)$ is a 2-tuple, or a pair of numbers. The first coordinate of this 2-tuple is 2. The second coordinate is 3. Another 2-tuple is $(-1,6)$. In this case the first coordinate of this 2-tuple is $-1$, the second coordinate is $6$.</span>
               </p>
					          <p>
                  <span>An arbitrary 2-tuple, or pair of numbers, is of the form $(s,t)$ with $s$ and $t$ numbers. In this case the first coordinate is $s$, while the second coordinate is $t$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(\tfrac{3}{2},0,-1)$ is a 3-tuple, or a triple of numbers. Its first coordinate is $\tfrac{3}{2}$. Its second coordinate is $0$. Its third coordinate is $-1$. Another 3-tuple is $(-16,3,4)$. In this case the first coordinate is $-16$, the second coordinate is $3$, the third coordinate is $4$.</span>
               </p>
					          <p>
                  <span>An arbitrary 3-tuple, or triple of numbers, is of the form $(x,y,z)$ with $x$, $y$, and $z$ numbers. In this case the first coordinate is $x$, the second coordinate is $y$, and the third coordinate is $z$.</span>
               </p>
				        </li>
				        <li>
					          <p>
                  <span>
                     $(4,1,0,3)$ is a 4-tuple. Its first coordinate is $4$. Its second coordinate is $1$. Its third coordinate is $0$. Its fourth coordinate is $3$; etc.</span>
               </p>
				        </li>
			      </ul>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-206" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of $n$-tuples</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>coordinate vector     </span><ul class='chilren'><li><span>basic     </span><a id='glossaryinfo-711' class='msm_infobutton' onmouseover='infoopen(711)'>i</a><div id="dialog-711" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-711' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-705' onmouseover='infoopen(705)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-705' style='display:none;'><div class='pack'><div class='title'>Examples of Basic Coordinate Vectors</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{3}$ has three basic coordinate vectors.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/BasicCoordinateVectorsR3.gif" height="242.72727272727" width="350"/></div>
			         </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <ul>
				              <li>
					                <p>
                        <span>The first basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_1:=(1,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_2:=(0,1,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The third basic basic coordinate vector of $\RNr{3}$ is $\mathbf{e}_3:=(0,0,1)$
					                   </span>
                     </p>
				              </li>
			            </ul>
			            <p>
                  <span>In the physics literature these are often written as</span>
               </p>
			            <p align="center">
                  <span>
				                 $\mathbf{i}:=\mathbf{e}_1,\qquad \mathbf{j}:=\mathbf{e}_2,\quad \text{and}\quad \mathbf{k}:=\mathbf{e}_3$
			               </span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{4}$ has four basic coordinate vectors</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <ul>
				              <li>
					                <p>
                        <span>The first basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_1:=(1,0,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_2:=(0,1,0,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The third basic basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_3:=(0,0,1,0)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The fourth basic basic coordinate vector of $\RNr{4}$ is $\mathbf{e}_4:=(0,0,0,1)$
					                   </span>
                     </p>
				              </li>
			            </ul>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-705" class="dialogs" title=""><info xmlns="Unit">
                           <p align="center">
                              <span>Examples of coordinate vectors.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>Cramer’s rule     </span><a id='glossaryinfo-10976' class='msm_infobutton' onmouseover='infoopen(10976)'>i</a><div id="dialog-10976" class="dialogs" title="Cramer’ rule"><info xmlns="Theorem">
               
               <p>
                  <span>is a formula for finding the solution of  a system of $n$ linear equations in $n$ variables.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10976' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Cramer’ rule</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given the system of $n$ linear equations in $n$ variables below,</span>
      </p>$$
				
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{n1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{n2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$}{\color{red}x_n} &amp; = &amp; c_n \\
\end{array}

			$$<p xmlns="Theorem">
         <span>assume that its coefficient matrix $\Mtrx{A} = [a_{ij}]$ satisfies $\det(\Mtrx{A})\neq 0$. Then, for $1\leq j\leq n$,
			</span>
         
      </p>$$
				
{\color{red} x_j}\ =\ \frac{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$c_1$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$c_n$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; a_{1j} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \vdots &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; a_{nj} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}

			$$<p xmlns="Theorem">
         <span>The matrix in the denominator matrix is $\Mtrx{A}$, and the matrix in the numerator is formed from $\Mtrx{A}$ by replacing its $j$-th column by the augmentation column of the system, $[c_1\ \dots\ c_n]^T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-10977' onmouseover='infoopen(10977)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-10977' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><div id="dialog-10986" class="dialogs"><info>
                        <p>
                           <span>Look this theorem up</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-10986' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body><p>
            <span>We 
			<a id="activehottag-10986" class="activehottag" onmouseover="infoopen(10986)"> know</a>  
			that the given system has exactly one solution $(x_1,\dots ,x_n)$. With this solution we compute</span>
         </p>$$
				
\aligned
&amp;\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$c_1$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$c_n$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix} \\
    &amp;\quad=\ \begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$a_{11}x_1+\dots +a_{n1}x_n$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$a_{n1}x_1+\dots +a_{nn}x_n$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix} \\
    &amp;\quad=\ \sum_{t=1}^{n}x_t\cdot\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$a_{1t}$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$a_{nt}$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix} \\
    &amp;\quad=\ x_j\cdot\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$a_{1j}$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$a_{nj}$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix} \\
    &amp;\quad=\ x_j\cdot\text{det}(A)
\endaligned

			$$<p>
            <span>By hypothesis, $\det(\Mtrx{A})\neq 0$. So we can divide both sides of this identity by $\det(\Mtrx{A})$ to establish the claim.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li><li><span>cross product     </span><a id='glossaryinfo-10609' class='msm_infobutton' onmouseover='infoopen(10609)'>i</a><div id="dialog-10609" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of the operation</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10609' style='display:none;'><br /><div class='def'><span class='deftitle'>Cross product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The cross product of two vectors in $\RNr{3}$
                           </span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x}=(x_1,x_2,x_3)$   and   $\Vect{y}=(y_1,y_2,y_3)$
                           </span>
                        </p>
                        <p>
                           <span>is the following vector of $\RNr{3}$:
					</span>
                           
                           
                        </p>
                        $$
						
\aligned
\CrssPr{ \Vect{x} }{ \Vect{y} }\ &amp;:=\ \left(
\det
\left[
\begin{array}{cc}
x_2 &amp; y_2 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
- \det \left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_2 &amp; y_2
\end{array}
\right]
\right) \\
	&amp;=\ \left( x_2y_3 - x_3y_2 , -(x_1y_3 - x_3y_1) , x_1y_2 - x_2y_1 \right)
\endaligned

					$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-10568' onmouseover='infoopen(10568)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-10568' style='display:none;'><div class='pack'><div class='title'>Examples: Computing Cross Products</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the cross product of the vectors</span>
         </p>
			      <p align="center">
            <span>
               $\Vect{a}=(1,0,0)$   and   $\Vect{b}=(0,1,0)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>According to the general formula for the cross product we obtain for $\Vect{a}=(1,0,0)$ and $\Vect{b}=(0,1,0)$
                  </span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\CrssPr{ \Vect{a} }{ \Vect{b} }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
					
\left( \det
\left[
\begin{array}{rr}
0 &amp; 1 \\
0 &amp; 0
\end{array}
\right]\, ,\, 
-\det
\left[
\begin{array}{rr}
1 &amp; 0 \\
0 &amp; 0
\end{array}
\right]\, ,\, 
\det
\left[
\begin{array}{rr}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right] \right)
					
				$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0 - 0, - (0-0) , 1-0)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the cross product of the vectors</span>
         </p>
			      <p align="center">
            <span>
               $\Vect{x}=(2,1,1)$   and   $\Vect{y}=(3,0,-1)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>According to the general formula for the cross product we obtain for $\Vect{x}=(2,1,1)$ and $\Vect{y}=(3,0,-1)$
                  </span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\CrssPr{ \Vect{x} }{ \Vect{y} }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
					
\left( \det
\left[
\begin{array}{rr}
1 &amp; 0 \\
1 &amp; -1
\end{array}
\right]\, ,\, 
-\det
\left[
\begin{array}{rr}
2 &amp; 3 \\
1 &amp; -1
\end{array}
\right]\, ,\, 
\det
\left[
\begin{array}{rr}
2 &amp; 3 \\
1 &amp; 0
\end{array}
\right] \right)
					
				$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1 - 0, - (-2-3) , 0-3)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1,5,-3)$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-10568" class="dialogs" title="Example"><info xmlns="Unit">
                           
                           <p>
                              <span>Example of computing the cross product of two vectors.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-10588' onmouseover='infoopen(10588)'><span style='cursor:pointer'>Comment</span></li><div class='refcontent' id='refcontent-10588' style='display:none;'><div class='title'>Cross Product and Quaternion Number System</div><p xmlns="Unit">
               <span>There is a notational convention, used by engineers and physicists, which may make the formula for the cross product a little easier to remember. Let us name the standard coordinate vectors of $\RNr{3}$ as.</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\Vect{i}:=(1,0,0)$,   $\Vect{j}:= (0,1,0)$,   $\Vect{k}:=(0,0,1)$
               </span>
            </p><div id="dialog-10575" class="dialogs" title="Comment on ‘symbolically’"><info xmlns="Unit">
                        
                        <p>
                           <span>Let us be clear: Strictly speaking, the proposed determinant does not exist, as the entries in the first column are not numbers. However, nothing can stop us from applying the formula for evaluating $(3,3)$-determinants to the symbols appearing in the proposed matrix. Magically the formula for the cross product results. Only now we remember that $\Vect{i}$, $\Vect{j}$, and $\Vect{k}$ are vectors in $\RNr{3}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Now a vector $\Vect{z}=(a,b,c)$ can be written as $\Vect{z} = a \Vect{i} + b \Vect{j} + c \Vect{k}$. The formula for the cross product results from 
				<a id="hottag-10575" class="hottag" onmouseover="popup(10575)"> symbolically</a>  
				evaluating the determinant below along the first column. Here $\Vect{x} = (x_1,y_1,z_1)$ and $\Vect{y} = (y_1,y_2,y_3)$.</span>
            </p>
$$
					
\aligned
\CrssPr{ \Vect{x} }{ \Vect{y} }\ &amp;=\ \det
\left[
\begin{array}{ccc}
\Vect{i} &amp; x_1 &amp; y_1 \\
\Vect{j} &amp; x_2 &amp; y_2 \\
\Vect{k} &amp; x_3 &amp; y_3
\end{array}
\right] \\
	&amp;=\ \det
\left[
\begin{array}{cc}
x_2 &amp; y_2 \\
x_3 &amp; y_3
\end{array}
\right]\Vect{i}\ +\ 
(-1)\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_3 &amp; y_3
\end{array}
\right] \Vect{j}\ +\ 
\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_2 &amp; y_2
\end{array}
\right] \Vect{k} \\
	&amp;=\ (x_2y_3-x_3y_2 , -(x_1y_3-x_3y_1) , x_1y_2 - x_2y_1)
\endaligned

				$$<p xmlns="Unit">
               <span>Recalling that, for a square matrix $\Mtrx{A}$, $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$, we can alternatively express the above formula as follows:</span>
            </p>$$
					
\aligned
\CrssPr{ \Vect{x} }{ \Vect{y} }\ &amp;=\ \det
\left[
\begin{array}{ccc}
\Vect{i} &amp; \Vect{j} &amp; \Vect{k} \\
x_1 &amp; x_2 &amp; x_3 \\
y_1 &amp; y_2 &amp;  y_3
\end{array}
\right] \\
	&amp;=\ \det
\left[
\begin{array}{cc}
x_2 &amp; y_2 \\
x_3 &amp; y_3
\end{array}
\right]\Vect{i}\ +\ 
(-1)\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_3 &amp; y_3
\end{array}
\right] \Vect{j}\ +\ 
\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_2 &amp; y_2
\end{array}
\right] \Vect{k} \\
	&amp;=\ (x_2y_3-x_3y_2 , -(x_1y_3-x_3y_1) , x_1y_2 - x_2y_1)
\endaligned

				$$<p xmlns="Unit">
               <span>The $(3,3)$-determinant above has been evaluated along its first row.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Advanced Information</b>   We sketch how the cross product can be defined using multiplication of quaternion numbers.</span>
            </p>
<ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>Write an element $(a,b,c,d)$ of $\RNr{4}$ as $a + b \Vect{i} +c \Vect{j} + d \Vect{k}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Define addition of quaternion numbers by</span>
                  </p>
                  $$
							
\aligned
&amp;(a + b \Vect{i} + c \Vect{j} + d \Vect{k})\ +\ (w + x \Vect{i} + y \Vect{j} + z \Vect{k})\ = \\
&amp;\qquad (a+w) + (b+x) \Vect{i} + (c+y)\Vect{j} + (d+z)\Vect{k}
\endaligned

						$$
               </li>
               <li>
                  <p>
                     <span>Define multiplication of quaternion numbers by</span>
                  </p>
                  $$
							
\aligned
&amp;(a + b \Vect{i} + c \Vect{j} + d \Vect{k})\cdot (w + x \Vect{i} + y \Vect{j} + z \Vect{k})\ = \\
&amp;\qquad (aw-bx-cy-dz) + (ax+bw+cz-dy) \Vect{i} + (ay+cw-bz+dx)\Vect{j} + (az+dw+by-cx)\Vect{k}
\endaligned

						$$
               </li>
               <li>
                  <p>
                     <span>Define the imaginary part of $\Vect{u}=a+b \Vect{i} +c \Vect{j} + d \Vect{k}$ by</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\Im(\Vect{u})$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $:=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $b \Vect{i} +c \Vect{j} + d \Vect{k}$
                        </td>
                     </tr>
                  </math.array>
               </li>
               <li>
                  <p>
                     <span>Identify $\Vect{x} = (x,y,z)$ in $\RNr{3}$ with the purely imaginary quaternion number $x \Vect{i} + y \Vect{j} + z \Vect{k}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $\Vect{x},\Vect{y}\in \RNr{3}$, a computation gives $\CrssPr{ \Vect{x} }{ \Vect{y} } = \Im (\Vect{x}\cdot \Vect{y})$.</span>
                  </p>
               </li>
            </ol>
<p xmlns="Unit">
               <span>In other words, the cross product of $\Vect{x}$ and $\Vect{y}$ results from interpreting $\Vect{x}$ and $\Vect{y}$ as quaternion numbers (as in 4.), multiplying them (as in 2.), and taking the imaginary part of the resulting quaternion number (as in 3.).</span>
            </p></div><div id="dialog-10588" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An alternate description of the cross product formula, and the relationship between the cross product and the quaternion number system.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-10605' onmouseover='infoopen(10605)'><span style='cursor:pointer'>Comment</span></li><div class='refcontent' id='refcontent-10605' style='display:none;'><div class='title'>Cross Products in Arbitrary Dimensions?</div><p xmlns="Unit">
               <span>The operations ‘dot product’ and ‘determinant’ are defined for all dimensions $n\geq 1$. Analogously we would expect a definition of the cross product in dimensions $n\geq 1$. There are two interpretations</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>We look for an alternating and multilinear operation which assigns to an ordered $(n-1)$-tuple of vectors $(\Vect{b}_1,\dots ,\Vect{b}_{n-1})$ in $\RNr{n}$ a vector $\text{Cross}(\Vect{b}_1,\dots ,\Vect{b}_{n-1})$ in $\RNr{n}$ such that</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\det[\Vect{b}_1\ \ \cdots\ \ \Vect{b}_{n-1}\ \ \text{Cross}(\Vect{b}_1,\dots ,\Vect{b}_{n-1})]$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $ &gt; $
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $0$
                        </td>
                     </tr>
                  </math.array>
                  <p>
                     <span>
                        $(\Vect{b}_1,\dots ,\Vect{b}_{n-1})$ is linearly independent. Such an operation exists, but is usually not referred to as a &#x2018;cross product&#x2019;.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>We look for an alternating bilinear operation on ordered pairs of vectors $(\Vect{u},\Vect{v})$ such that $\CrssPr{ \Vect{u} }{ \Vect{v} }\neq \Vect{0}$ whenever $\Vect{u}$ and $\Vect{v}$ are not parallel, and such that $\CrssPr{ \Vect{u} }{ \Vect{v} }$ is perpendicular to both $\Vect{u}$ and $\Vect{v}$.</span>
                  </p>
                  <p>
                     <span>For deeper reasons, such an operation is only possible if $n=3$ or $n=7$.</span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Advanced information</b>   We mention two results on the (non-)existence of cross products of pairs. First a now classical result from algebraic topology:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Theorem</b>   Suppose $\RNr{n}$ admits a cross product operation satisfying</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, then $\CrssPr{ \Vect{x} }{ \Vect{y} }\neq 0$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>For all $\Vect{x},\Vect{y}\in \RNr{n}$, $\DotPr{ (\CrssPr{ \Vect{x} }{ \Vect{y} }) }{ \Vect{x} }\neq 0$ and $\DotPr{ (\CrssPr{ \Vect{x} }{ \Vect{y} }) }{ \Vect{y} }\neq 0$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\CrssPr{-}{-}\from \RNr{n}\times \RNr{n} \longrightarrow \RNr{n}$ is a continuous function</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Then $n=3$ or $n=7$.</span>
            </p><p xmlns="Unit">
               <span>If we add to the list of assumptions above the requirement that the cross product be bilinear, then the conclusion of the theorem can be proven by elementary algebraic means. This is a classical theorem of Frobenius.
				</span>
               
            </p></div><div id="dialog-10605" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Advanced information on the (non-)existence of cross products in dimensions other than 3 and 7.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>determinant     </span><ul class='chilren'><li><span>definition using cofactors     </span><a id='glossaryinfo-8919' class='msm_infobutton' onmouseover='infoopen(8919)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-8919' style='display:none;'><br /><div class='def'><span class='deftitle'>Determinant</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Let $n\geq 1$ be an integer for which determinants of matrices of size $(n,n)$ and smaller have been defined. Then the determinant of a matrix
					</span>
                           
                        </p>
                        $$
						
\Mtrx{A} =
\left[
\begin{array}{cccc}
{\color{red} a_{1,1}} &amp; a_{1,2} &amp; \cdots &amp; a_{1,n+1} \\
{\color{red} a_{2,1}} &amp; a_{2,2} &amp; \cdots &amp; a_{2,n+1} \\
{\color{red} \vdots} &amp; \vdots &amp; \ddots &amp; \vdots \\
{\color{red} a_{n+1,1}} &amp; a_{n+1,2} &amp; \cdots &amp; a_{n+1,n+1}
\end{array}
\right]

					$$
                        <p>
                           <span>of size $(n+1,n+1)$ is given by</span>
                        </p>
                        $$\det(A) := {\color{red} a_{1,1}}\cdot c_{1,1}(\Mtrx{A}) + {\color{red} a_{2,1}}\cdot c_{2,1}(\Mtrx{A}) + \cdots + {\color{red} a_{n+1,1}}\cdot c_{n+1,1}(\Mtrx{A}),$$
                        <p>
                           <span>where $c_{i,1}(\Mtrx{A})$ is the $(i,1)$-cofactor of $\Mtrx{A}$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-8921' onmouseover='popup(8921)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-8921" class="dialogs" title="Determinants of arbitrary size: How?"><info xmlns="Unit">
                           
                           <p>
                              <span>We have here what is called a recursive definition, and it works as follows:</span>
                           </p>
                           <ol>
                              <li>
                                 <p>
                                    <span>We know already how to compute the determinants of matrices of sizes $(1,1)$, $(2,2)$, and $(3,3)$.</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>So this definition tells us how to compute determinants of $(4,4)$-matrices.</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>Once we have determinants of $(4,4)$-matrices, the definition tells us how to compute determinants of $(5,5)$-matrices.</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>Now the definition comes in again and tells us how to compute determinants of matrices of $(6,6)$-matrices.</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>... and so on.</span>
                                 </p>
                              </li>
                           </ol>
                        </info></div><li class='defminibutton' id='defminibutton-8926' onmouseover='infoopen(8926)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-8926' style='display:none;'><div class='pack'><div class='title'>Determinant of a (4,4)-Matrix: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the determinant of the $(4,4)$-matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rrrr}
4 &amp; 1 &amp; 6 &amp; 5 \\
3 &amp; -2 &amp; -3 &amp; 2 \\
9 &amp; 2 &amp; 4 &amp; 7 \\
1 &amp; -9 &amp; -3 &amp; 1
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We first compute the cofactors of the entries in the first column of $\Mtrx{A}$.</span>
               </p>
			
			            $$
					
\aligned
c_{11}(\Mtrx{A})\ &amp;=\ (-1)^{1+1}\cdot \det(\Mtrx{A}_{11}) \\
	&amp;=\ 1\cdot \det\, 
\left[
\begin{array}{rrr}
-2 &amp; -3 &amp; 2 \\
2 &amp; 4 &amp; 7 \\
-9 &amp; -3 &amp; 1
\end{array}
\right] \\
	&amp;=\ (-2)\cdot (4+21) - 2\cdot (-3+6) + (-9)\cdot (-21 -8) \\
	&amp;=\ 205
\endaligned

				$$
			
			            $$
					
\aligned
c_{21}(\Mtrx{A})\ &amp;=\ (-1)^{2+1}\cdot \det(\Mtrx{A}_{21}) \\
	&amp;=\ (-1)\cdot \det\, 
\left[
\begin{array}{rrr}
1 &amp; 6 &amp; 5 \\
2 &amp; 4 &amp; 7 \\
-9 &amp; -3 &amp; 1
\end{array}
\right] \\
	&amp;=\ (-1)\cdot \left( (4 + 21) - (12-30) + (-9)\cdot (42- 20)  \right) \\
	&amp;=\ 215
\endaligned

				$$
			
			            $$
					
\aligned
c_{31}(\Mtrx{A})\ &amp;=\ (-1)^{3+1}\cdot \det(\Mtrx{A}_{31}) \\
	&amp;=\ 1\cdot \det\, 
\left[
\begin{array}{rrr}
1 &amp; 6 &amp; 5 \\
-2 &amp; -3 &amp; 2 \\
-9 &amp; -3 &amp; 1
\end{array}
\right] \\
	&amp;=\ (-3+6) -(-12-30) + (-9)(12+15) \\
	&amp;=\ -198
\endaligned

				$$
			
			            $$
					
\aligned
c_{41}(\Mtrx{A})\ &amp;=\ (-1)^{4+1}\cdot \det(\Mtrx{A}_{41}) \\
	&amp;=\ (-1)\cdot \det\, 
\left[
\begin{array}{rrr}
1 &amp; 6 &amp; 5 \\
-2 &amp; -3 &amp; 2 \\
2 &amp; 4 &amp; 7
\end{array}
\right] \\
	&amp;=\ (-1)\cdot \left( (-21-8) - (-2)\cdot (42 - 20) + 2\cdot (12-(-15)) \right) \\
	&amp;=\ -69
\endaligned

				$$
			
			            <p>
                  <span>Therefore</span>
               </p>
			
			            $$
					
\aligned
\det(\Mtrx{A})\ &amp;=\  
\det\, \left[
\begin{array}{rrrr}
{\color{red} 4} &amp; 1 &amp; 6 &amp; 5 \\
{\color{red} 3} &amp; -2 &amp; -3 &amp; 2 \\
{\color{red} 9} &amp; 2 &amp; 4 &amp; 7 \\
{\color{red} 1} &amp; -9 &amp; -3 &amp; 1
\end{array}
\right] \\
	&amp;=\ {\color{red} 4}\cdot c_{11}(\Mtrx{A}) + {\color{red} 3}\cdot c_{21}(\Mtrx{A}) + {\color{red} 9}\cdot c_{31}(\Mtrx{A}) + {\color{red} 1}\cdot c_{41}(\Mtrx{A}) \\
	&amp;=\ {\color{red} 4}\cdot 205 + {\color{red} 3}\cdot 215 + {\color{red} 9}\cdot (-198) + {\color{red} 1}\cdot (-69) \\
	&amp;=\ -386
\endaligned

				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-8926" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of computing a determinant.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>multilinear     </span><a id='glossaryinfo-9077' class='msm_infobutton' onmouseover='infoopen(9077)'>i</a><div id="dialog-9077" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9077' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9201' onmouseover='infoopen(9201)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-9201' style='display:none;'><div class='title'>The Multilinearity Property of Determinants</div><p xmlns="Unit">
               <span>The determinant operation is linear in each column. What exactly does this mean? Let $1\leq j\leq n$ be an integer. Let's build an $(n,n)$-matrix by placing a fixed column vector in each column position, except for one, say in position $j$. The result is an $(n,n)$-matrix which looks like this:</span>
            </p>$$[A_1\ \dots\ A_{j-1}\ \ -\ \ A_{j+1}\ \dots\ A_n]$$<p xmlns="Unit">
               <span>Allowing the still vacant $j$-th column to be filled by vectors from $\RNr{n}$ yields a function $L\from \RNr{n}\longrightarrow \RNr{}$:</span>
            </p>$$L(X) := \det[A_1\ \dots A_{j-1}\ X\ A_{j+1}\ \dots\ A_n]$$<div id="dialog-9191" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>So $L$ commutes with vector addition and scalar multiplicaiton. Look up the definition of ‘linear transformation’.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-9191' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>To say that the determinant operation is linear in the $j$-th column means that the function $L$ above is 
				<a id="activehottag-9191" class="activehottag" onmouseover="infoopen(9191)"> linear</a>  . To say the determinant operation is multilinear means that this happens for each column $1\leq j\leq n$. In other words, these two identities hold:</span>
            </p>
$$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$$$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$<p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the determinant operation as a whole is linear and, consequently, to assert that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(\Mtrx{A} + \Mtrx{B})$   and   $(\det(\Mtrx{A}) + \det(\Mtrx{B}))$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(t\cdot \Mtrx{A})$ and $t\cdot \det(\Mtrx{A})$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>. Instead, if $\Mtrx{A}$ has size $(n,n)$, we have the identity</span>
            </p>$$\det(t\cdot \Mtrx{A}) = t^n\cdot \det(\Mtrx{A})$$</div><div id="dialog-9201" class="dialogs" title="Explanation: Multilinear"><info xmlns="Theorem">
         
         <p>
            <span>What exactly does it mean: ‘the determinant operation is linear in each column’? Here you can find a detailed explanation.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-9219' onmouseover='infoopen(9219)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9219' style='display:none;'><div class='pack'><div class='title'>Multilinearity Property of the Determinant: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid:</span>
         </p>
			
			      $$
					
\det\, 
\left[
\begin{array}{cc}
a &amp; 1 \\
b &amp; 3
\end{array}
\right] = 
\det\, 
\left[
\begin{array}{cc}
a &amp; 1 \\
0 &amp; 3
\end{array}
\right]\ +\ 
\det\, 
\left[
\begin{array}{cc}
0 &amp; 1 \\
b &amp; 3
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here $j=1$, and we have fixed the one and only remaining column, namely the second. To say that the  $(2,2)$-determinant is linear in the first column means, in particular, that the function</span>
               </p>
			
			            $$
					
L\from \RNr{2} \longrightarrow \RNr,\quad L(x,y):=
\det\, 
\left[
\begin{array}{cc}
x &amp; 1 \\
y &amp; 3
\end{array}
\right]

				$$
			
			            <p>
                  <span>satisfies</span>
               </p>
			
			            $$L(a,b) = L\left( (a,0) + (0,b)\right) = L(a,0) + L(0,b)$$
			
			            <p>
                  <span>and this is exactly the identity of determinants above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid.</span>
         </p>
			
			      $$
					
\det\, 
\left[
\begin{array}{cc}
10 &amp; 27 \\
25 &amp; 18
\end{array}
\right]\ =\ 
5\cdot \det\, 
\left[
\begin{array}{cc}
2 &amp; 27 \\
5 &amp; 18
\end{array}
\right]\ =\ 5\cdot 9\cdot \det\, 
\left[
\begin{array}{cc}
2 &amp; 3 \\
5 &amp; 2
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we have first applied linearity of the $(2,2)$-determinant in the first column and then linearity in the second column. In detail: First choose $j=1$, and fix the second column as $C_2:= [ 27\ \ 18]^T$. Then we obtain a linear function $L_1\from \RNr{2} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            $$L_1(10,25) = L_1(5\cdot (2,5)) = 5\cdot L_1(2,5)$$
			
			            <p>
                  <span>and this is the first equation of determinants above. Next choose $j=2$, and fix the first column as $C_2:= [2\ \ 5]^T$. Then we obtain a linear function $L_2\from \RNr{2} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            $$L_2(27,18) = L_2(9\cdot (3,2)) = 9\cdot L_2(3,2)$$
			
			            <p>
                  <span>and this is exactly the second equation of determinants above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid.</span>
         </p>
			
			      $$
					
\aligned
\det\, 
\left[
\begin{array}{ccc}
4 &amp; 1+a &amp; 3 \\
1 &amp; 2+a &amp; 1 \\
5 &amp; 3+a &amp; 2
\end{array}
\right]\ &amp;=\ 
\det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 2 &amp; 1 \\
5 &amp; 3 &amp; 2
\end{array}
\right]\ +\ \det\, 
\left[
\begin{array}{ccc}
4 &amp; a &amp; 3 \\
1 &amp; a &amp; 1 \\
5 &amp; a &amp; 2
\end{array}
\right] \\
	&amp;=\ \det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 2 &amp; 1 \\
5 &amp; 3 &amp; 2
\end{array}
\right]\ +\ a\cdot \det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 1 &amp; 1 \\
5 &amp; 1 &amp; 2
\end{array}
\right] 
\endaligned

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we have applied linearity in the second column twice; first in the additive sense, then in the multiplicative sense. In detail: choose $j=2$, and fix the remaining columns as</span>
               </p>
			
			            <p align="center">
                  <span>
                     $C_1:=[4\ 1\ 5]^T$ and $C_3:=[3\ 1\ 2]^T$.</span>
               </p>
			
			            <p>
                  <span>Then we obtain a linear function $L\from \RNr{3} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1+a,2+a,3+a)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,2,3) + L(a,a,a)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,2,3) + a\cdot L(1,1,1)$</td></tr></table>
			
			            <p>
                  <span>and this is exactly the computation above.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-9219" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>Examples of how to use the multilinearity property of the determinant.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9078' onmouseover='infoopen(9078)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9078' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>For $1\leq j\leq n$ and column vectors $A_1,\dots, A_{j-1},X,Y,A_{j+1},\dots ,A_n$ in $\RNr{n}$, set</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{R}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ X+Y\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{U}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ X\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{V}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ Y\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{W}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ t\cdot X\ \ A_{j+1}\ \dots\ A_n]$</td></tr></table><p>
            <span>Then we need to verify the following two identities</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{U}) + \det(\Mtrx{V})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(\Mtrx{V})$</td></tr></table><p>
            <span>For both statements we argue by induction on $n$.</span>
         </p><p>
            <span>
               <b>Anchoring the induction</b> &#xA0; If $n=1$, $\Mtrx{A}$ consists just of a single number. Necessarily, $j=1$, and</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[x+y]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x+y = \det[x] + \det[y]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[t\cdot x]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot x = t\cdot \det[x]$</td></tr></table><p>
            <span>So the claim holds for $n=1$.</span>
         </p><p>
            <span>
               <b>Induction hypothesis</b> &#xA0; Now let $n\geq 1$, and suppose that the determinant operation has the stated properties for matrices of size $(n,n)$.</span>
         </p><p>
            <span>
               <b>The induction step</b> &#xA0; We need to infer that the determinant operation has the stated properties for matrices of size  $(n+1,n+1)$. We begin with the additivity property in the first column; i.e. $j=1$. So</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{R}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[X+Y\ \ A_2\ \dots \ A_{n+1}]$</td></tr></table><p>
            <span>with $\Mtrx{X}=[x_1\ \dots\ x_{n+1}]^T$ and $\Mtrx{Y}= [y_1\ \dots\ y_{n+1}]^T$. Now the cofactor expansion of $\det(\Mtrx{R})$ along the first column yields</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}(x_i+y_i)\det(\Mtrx{R}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}x_i\det(\Mtrx{R}_{i1})\ +\ \sum_{i=1}^{n+1} (-1)^{i+1}y_i\det(\Mtrx{R}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[X\ \ A_2\ \dots\ A_{n+1}]\ +\ \det[Y\ \ A_2\ \dots\ A_{n+1}]$</td></tr></table><p>
            <span>This shows that the determinant operation commutes with addition in the first column. To see that it commutes with scalar multiplication as well, consider $\Mtrx{W}= [tX\ \ A_2\ \dots\ A_{n+1}]$, for some  in $t\in\RNr{}$. We find</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}(tx_i)\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \sum_{i=1}^{n+1} (-1)^{i+1} x_i\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(U)$</td></tr></table><p>
            <span>This shows that the determinant operation commutes with scalar multiplication in the first column. We have shown that the determinant operation on  $(n+1,n+1)$-matrices is linear in the first column. Now consider columns $j$ with $j\geq 2$. We find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(R_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9153" class="hottag" onmouseover="popup(9153)">$=	$</a><div id="dialog-9153" class="dialogs" title=""><info>
                        <p>
                           <span>Here we apply the induction hypothesis to the $(n,n)$-matrix $R_{i1}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}\cdot (-1)^{i+1}( \det(U_{i1}) + \det(V_{i1}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1}\left( a_{i1}\cdot (-1)^{i+1} \det(U_{i1})\right)\ +\ \sum_{i=1}^{n+1}\left( a_{i1}\cdot (-1)^{i+1} \det(V_{i1}) \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{U}) + \det(\Mtrx{V})$</td></tr></table><p>
            <span>This completes the induction which establishes that the determinant operation commutes with addition in each column. To see that it commutes with scalar multiplication in each column as well, we compute:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9171" class="hottag" onmouseover="popup(9171)">$=	$</a><div id="dialog-9171" class="dialogs" title=""><info>
                        <p>
                           <span>Here we use the induction hypothesis</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}t\cdot \det(\Mtrx{U}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(\Mtrx{U}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(U)$</td></tr></table><p>
            <span>This completes the induction step which shows that the determinant operation commutes with scalar multiplication in each column. &#x2013; The proof of the multilinearity property of the determinant operation is complete.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li><li><span>alternating     </span><a id='glossaryinfo-9464' class='msm_infobutton' onmouseover='infoopen(9464)'>i</a><div id="dialog-9464" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9464' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>norm property     </span><a id='glossaryinfo-10665' class='msm_infobutton' onmouseover='infoopen(10665)'>i</a><div id="dialog-10665" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10665' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>commutes with transposition     </span><a id='glossaryinfo-9441' class='msm_infobutton' onmouseover='infoopen(9441)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9441' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9503' onmouseover='infoopen(9503)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9503' style='display:none;'><div class='pack'><div class='title'>Examples: Computing with Determinants</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the determinant of the matrix</span>
         </p>
			      $$
					
\Mtrx{A}\ :=\  
\left[
\begin{array}{rrrrr}
-1 &amp; 4 &amp; 3 &amp; 4 &amp; 5 \\
5 &amp; -2 &amp; 3 &amp; -2 &amp; 1 \\
0 &amp; 6 &amp; 0 &amp; 6 &amp; 2 \\
-1 &amp; -1 &amp; 2 &amp; -1 &amp; 4 \\
9 &amp; 3 &amp; 3 &amp; 3 &amp; -1
\end{array}
\right] = 0

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The 2nd and 4th columns of matrix $\Mtrx{A}$ are equal:</span>
               </p>
			            $$
					
\left[
\begin{array}{rrrrr}
-1 &amp; {\color{red} 4} &amp; 3 &amp; {\color{red} 4} &amp; 5 \\
5 &amp; {\color{red} -2} &amp; 3 &amp; {\color{red} -2} &amp; 1 \\
0 &amp; {\color{red} 6} &amp; 0 &amp; {\color{red} 6} &amp; 2 \\
-1 &amp; {\color{red} -1} &amp; 2 &amp; {\color{red} -1} &amp; 4 \\
9 &amp; {\color{red} 3} &amp; 3 &amp; {\color{red} 3} &amp; -1
\end{array}
\right] = 0

				$$
			            <p>
                  <span>Therefore</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, \Mtrx{A}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Compute the determinant of the $(3,3)$-matrix</span>
         </p>
			      $$
					
\Mtrx{B}\ :=  
\left[
\begin{array}{rrr}
2 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Of course we can always compute $\det\, \Mtrx{B}$ using the cofactor method. However, here is an opportunity which makes our live a lot easier: we may turn $\Mtrx{B}$ into an upper triangular matrix by subtracting the third column from the first. This process does not change the determinant, and the result is</span>
               </p>
			            $$
					
\det\, 
\left[
\begin{array}{rrr}
2 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right] = \det
\left[
\begin{array}{rrr}
1 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right] = 5

				$$
			            <p>
                  <span>Recall that the determinant of an upper triangular matrix is just the product of its diagonal entries, hence the final answer.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the determinant of the matrix</span>
         </p>
			      $$
					
\Mtrx{C}\ :=  
\left[
\begin{array}{rrrr}
4 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; -1 &amp; 0 &amp; 0 \\
1 &amp; 7 &amp; 3 &amp; 0 \\
5 &amp; 0 &amp; 1 &amp; 2
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We notice that $\Mtrx{C}$ is a lower triangular matrix, and we recall that the determinant of an upper triangular matrix is just the product of its diagonal entries. How can we make use of this fact?</span>
               </p>
			            <p>
                  <span>We also just learned that $\det(\Mtrx{C}) = \det(\Mtrx{C}^T)$. Now transposition turns a lower triangular matrix into an upper triangular matrix, and so:</span>
               </p>
			            $$
					
\det(\Mtrx{C}) = \det(\Mtrx{C}^T)\ =  
\left[
\begin{array}{rrrr}
4 &amp; 3 &amp; 1 &amp; 5 \\
0 &amp; -1 &amp; 7 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 2
\end{array}
\right] = -24
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-9503" class="dialogs" title="Example"><info xmlns="Theorem">
         
         <p>
            <span>See some examples which explain how to use these rules</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9448' onmouseover='infoopen(9448)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9448' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'> Equal columns gives 0-determinant</div></li><div id="dialog-9470" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Look up the alternating property of the determinant operation</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9470' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If two columns in a square matrix $\Mtrx{A}$ are equal, then $\Mtrx{A}$ is of the form</span>
         </p>$$A = [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$$<p>
            <span>But then the 
			<a id="activehottag-9470" class="activehottag" onmouseover="infoopen(9470)"> alternating property</a>  
			of the determinant operation gives</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9454" class="hottag" onmouseover="popup(9454)">$=	$</a><div id="dialog-9454" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Interchange the two columns containing the vector $X$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-\det [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$</td></tr></table><p>
            <span>Therefore $\det(\Mtrx{A}) = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><i><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></i></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If the square matrix $\Mtrx{A} = [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]$, we need to show</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9475" class="hottag" onmouseover="popup(9475)">$=	$</a><div id="dialog-9475" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Add $t\cdot Y$ to the $X$-column</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, [A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$</td></tr></table><p>
            <span>We invoke the multilinearity property of the determinant operation in the $X$-column:</span>
         </p>$$
				
\aligned
&amp;\det\, [A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n] \\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]\ +\ \det\, [A_1\ \dots\ (tY)\ \dots\ Y\ \dots\ A_n] \\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]\ +\ t\cdot \det\, [A_1\ \dots\ Y\ \dots\ Y\ \dots\ A_n]\\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]
\endaligned

			$$<p>
            <span>Because $[A_1\ \dots\ Y\ \dots\ Y\ \dots\ A_n]$ has two equal columns and, hence, vanishing determinant.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'> Determinant commutes with transposition</div></li><div id="dialog-9489" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Look up this result.</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9489' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Properties of alternating multilinear functions</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $F\from M_{nn}\to \RNr{}$ be any function which is linear in each column and alternating. Then $F$ has the following properties:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}=[A_1\ \dots\ X\ \dots\ X\ \dots\ A_n]$, then $F(\Mtrx{A}) =0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $F[A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n] = F[A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-9486" class="dialogs" title="Explanation of the symbols in this formula"><info xmlns="Theorem">
                        
                        <p>
                           <span>
                              $\SymGrp{n}$ denotes the group of all invertible functions from $\Set{ 1,\dots ,n}$ to itself. $E_{j}$ denotes the $(n,1)$-column matrix which has a ‘$1$’ in position $j$ and $0$’s everywhere else.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}= [a_{ij}]$, 
				<a id="hottag-9486" class="hottag" onmouseover="popup(9486)"> then</a>  
               </span>
            </p>
            $$F(\Mtrx{A}) = \sum_{r\in \SymGrp{n}} a_{r(1)1}\cdots a_{r(n)n} F[E_{r(1)}\ \dots\ E_{r(n)}]$$
         </part.body>
</li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>There exists a unique number $c$ in $\RNr{}$ such that, for each invertible  $r\from \Set{1,\dots ,n} \to \Set{1,\dots ,n}$,</span>
            </p>
            $$F[E(r(1))\dots E(r(n))] = c\cdot \det [E(r(1))\dots E(r(n))] = c\cdot \sign(r)$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>For each $(n,n)$-matrix $\Mtrx{A}$, $F(\Mtrx{A}) = F(\Mtrx{A}^T)$.</span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>This is a special case of a 
			<a id="activehottag-9489" class="activehottag" onmouseover="infoopen(9489)"> more general result about alternating multilinear functions</a>  
			which will be proved in the next section.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>of Van der Monde     </span></li><li><span>commutes with matrix multiplication     </span><a id='glossaryinfo-9650' class='msm_infobutton' onmouseover='infoopen(9650)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9650' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9669' onmouseover='popup(9669)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-9669" class="dialogs" title="Comment"><info xmlns="Theorem">
         
         <p>
            <span>This corollary says that the determinant of a product of two matrices is the product of the two determinants.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-9686' onmouseover='infoopen(9686)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9686' style='display:none;'><div class='pack'><div class='title'>Examples: Determinant of a Product</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Given an $(n,n)$-matrix $\Mtrx{A}$ with $\det(\Mtrx{A}) = 5$, find $\det(\Mtrx{A}^3)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We apply the fact that matrix multiplication commutes with the determinant operation:</span>
               </p>
			            $$\det(\Mtrx{A}\Mtrx{B})=\det(\Mtrx{A})\det(\Mtrx{B})$$
			            <p>
                  <span>In the case at hand we obtain</span>
               </p>
			            $$\det( \Mtrx{A}^3 ) = \left( \det(\Mtrx{A}) \right)^3 = 5^3 = 125$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>For an $(n,n)$-matrix $\Mtrx{C}$ and an integer $n\geq 1$ prove the formula</span>
         </p>
			      $$\det(\Mtrx{C}^n) = \left( \det(\Mtrx{C}) \right)^n$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We apply the fact that matrix multiplication commutes with the determinant operation:</span>
               </p>
			            $$\det(\Mtrx{A}\Mtrx{B})=\det(\Mtrx{A})\det(\Mtrx{B})$$
			            <p>
                  <span>In the case at hand we obtain</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{C}^n)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9679" class="hottag" onmouseover="popup(9679)">$=	$</a><div id="dialog-9679" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>on the right: $n$ copies of $\Mtrx{C}$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\left( \underset{\leftarrow\hfill \text{$n$ copies of $C$}\hfill\rightarrow}{\Mtrx{C} \cdots \cdots \Mtrx{C}}\right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\underset{\leftarrow\hfill \text{$n$ copies of $\det(C)$}\hfill\rightarrow}{\det(\Mtrx{C}) \cdots \cdots \det(\Mtrx{C})}$</td></tr></table>
			            <p>
                  <span>Notice: on the left hand side we first go through the labor intensive process of multiplying the matrix $\Mtrx{C}$ 
                     $n$ times by itself; then we compute the determinant of the resulting matrix. On the right hand side, we first evaluate the determinant, and then raise the resulting number to its $n$-th power - a much less labor intensive process.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-9686" class="dialogs" title="Example"><info xmlns="Theorem">
         
         <p>
            <span>A nice way of computing $\det(\Mtrx{A}^n)$
            </span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9654' onmouseover='infoopen(9654)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9654' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><div id="dialog-9657" class="dialogs" title="Why is this so?"><info>
                     
                     <p>
                        <span>Consider a non invertible $\Mtrx{A}$, and assume there is a matrix $\Mtrx{B}$ such that $\Mtrx{A}\Mtrx{B}$ is invertible. We know there is an invertible matrix $\Mtrx{R}$ such that $\Mtrx{R}\Mtrx{A}$ is in RREF. Given that $\Mtrx{A}$ is not invertible this means that $\Mtrx{R}\Mtrx{A}$ has at least one bottom row consisting of $0$’s only.</span>
                     </p>
                     <p>
                        <span>Now $\Mtrx{R}(\Mtrx{A}\Mtrx{B})$ is 
						<subordinate>
                              <a href="">invertible</a>  
                              <info>
                                 <p>
                                    <span>because it is a product of invertible matrices</span>
                                 </p>
                              </info>
                           </subordinate>
						and is equal to $(\Mtrx{R} \Mtrx{A})\Mtrx{B}$, which has at least one bottom row consisting of $0$’s only. So it is not invertible. This contradiction is a consequence of the assumption that $\Mtrx{A}\Mtrx{B}$ is invertible. So this assumption is false, and $\Mtrx{A}\Mtrx{B}$ is not invertible. 
					</span>
                     </p>
                  </info></div><div id="dialog-9659" class="dialogs"><info>
                                 <p>
                                    <span>because it is a product of invertible matrices</span>
                                 </p>
                              </info></div><div id="dialog-9663" class="dialogs"><info>
                        <p>
                           <span>Look up the determinant test for the invertibility of a matrix.</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9663' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div><div id="dialog-9665" class="dialogs" title="Why is $F$ linear in each column?"><info>
                     
                     <p>
                        <span>Given a matrix $\Mtrx{} = [B_1\ \dots\ B_n]$, expressed in terms of its column vectors. Then</span>
                     </p>
                     $$\Mtrx{A}\Mtrx{B} = [\Mtrx{A}B_1\ \dots\ \Mtrx{A}B_n]$$
                     <p>
                        <span>So each column $j$ of the matrix $\Mtrx{A}\Mtrx{B}$ is a linear function of the $j$-th column of $\Mtrx{B}$. The determinant operation is linear in the $j$-th column as well, and this implies that $F$ is linear in each column.</span>
                     </p>
                  </info></div><div id="dialog-9667" class="dialogs" title="Why is $F$ alternating?"><info>
                     
                     <p>
                        <span>To see why $F$ is alternating observe first that the following two processes have the same result:</span>
                     </p>
                     <ul>
                        <li>
                           <p>
                              <span>Interchange two columns $j$ and $k$ of $\Mtrx{B}$, then multiply on the left by $\Mtrx{A}$.</span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>Multiply $\Mtrx{B}$ on the left by $\Mtrx{A}$, then interchange columns $j$ and $k$.</span>
                           </p>
                        </li>
                     </ul>
                     <p>
                        <span>Following the second process with the determinant operation gives the required change of sign.</span>
                     </p>
                  </info></div>
<proof.block.body><proof.block.body><p>
            <span>We distinguish two cases. If $\Mtrx{A}$ is not invertible, then $\Mtrx{A}\Mtrx{B}$ is 
			<a id="hottag-9657" class="hottag" onmouseover="popup(9657)"> not invertible</a>  
			either. 
			<a id="hottag-9659" class="hottag" onmouseover="popup(9659)"> invertible</a>  
			both sides of the claimed identity above are $0$.</span>
         </p><p>
            <span>So let us turn to the case where $\Mtrx{A}$ is invertible; i.e. $\det(\Mtrx{A}) \neq 0$. We have the function</span>
         </p>$$F\from M_{nn} \longrightarrow \RNr,\quad F(\Mtrx{B}) := \dfrac{\det(\Mtrx{A}\Mtrx{B})}{\det(\Mtrx{A})}$$<p>
            <span>where $M_{nn}$ denotes the set of all $(n,n)$-matrices. Then $F$ is 
			<a id="activehottag-9663" class="activehottag" onmouseover="infoopen(9663)"> Therefore</a>  
			and is
			<a id="hottag-9665" class="hottag" onmouseover="popup(9665)"> linear in each column</a>  . 
			Moreover,
		</span>
         </p>$$F(\IdMtrx{n}) = \dfrac{\det(\Mtrx{A} \IdMtrx{n})}{\det(\Mtrx{A})} = \dfrac{\det(\Mtrx{A})}{\det(\Mtrx{A})} = 1$$<p>
            <span>
               <a id="hottag-9667" class="hottag" onmouseover="popup(9667)"> alternating</a>  
               $F=\det$; i.e. $\det(\Mtrx{B}) = \det(\Mtrx{A}\Mtrx{B})/\det(\Mtrx{A})$, and so
		</span>
         </p>$$\det(\Mtrx{A})\det(\Mtrx{B}) = \det(\Mtrx{A}\Mtrx{B})$$<p>
            <span>as claimed.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li></ul></li><li><span>diagonal     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4817' class='msm_infobutton' onmouseover='infoopen(4817)'>i</a><div id="dialog-4817" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4817' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4815' onmouseover='popup(4815)'><span style='cursor:pointer'>Example</span></li><div id="dialog-4815" class="dialogs" title="Some Examples of Diagonal Matrices"><info xmlns="Unit">
                           
                           $$
								
								\begin{bmatrix}
								2 &amp; 0 \\
								0 &amp; 1
								\end{bmatrix}\qquad
								\begin{bmatrix}
								\pi &amp; 0 &amp; 0 \\
								0 &amp; x &amp; 0 \\
								0 &amp; 0 &amp; 1
								\end{bmatrix}\qquad
								\begin{bmatrix}
								2 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 3 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 5 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 7
								\end{bmatrix}
								
							$$
                        </info></div></ul></div><br /></div></li></ul></li><li><span>diagonalizable matrix     </span><a id='glossaryinfo-20283' class='msm_infobutton' onmouseover='infoopen(20283)'>i</a><div id="dialog-20283" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20283' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20276' onmouseover='infoopen(20276)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-20276' style='display:none;'><div class='title'>Diagonalizable Matrix - Explanation</div><p xmlns="Unit">
               <span>To see the meaning of the concept of ‘diagonalizable matrix’, let's do the following:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>use the column vectors of $\Mtrx{C}$ to form an ordered basis $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_n)$ of $\RNr{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then $\Mtrx{C}=\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ converts from $\EuScript{B}$-coordinates to standard coordinates.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Both matrices $\Mtrx{A}$ and $\Mtrx{D}$ represent the same linear transformation of $\RNr{n}$. The difference is: $\Mtrx{A}$ describes it in standard coordinates, while $\Mtrx{D}$ describes it in $\EuScript{B}$-coordinates.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>Now, denote the diagonal entries of $\Mtrx{D}$ by $d_1,\dots ,d_n$:</span>
            </p>$$
					
\Mtrx{D} = 
\left[
\begin{array}{cccc}
d_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; d_2 &amp; &amp; \vdots \\
\vdots &amp; &amp; \ddots &amp; 0 \\
0 &amp; \cdots &amp; 0 &amp; d_n
\end{array}
\right]

				$$<p xmlns="Unit">
               <span>Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{D}\cdot (\Vect{b}_i)_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$d_i\cdot \Vect{b}_i$</td></tr></table><p xmlns="Unit">
               <span>In other words, $\Vect{b}_i$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $d_i$.</span>
            </p><p xmlns="Unit">
               <span>Conclusion: Given $\Mtrx{A}$ we may try to diagonalize it by looking for a basis of $\RNr{n}$ consisting of eigenvectors of $\Mtrx{A}$.</span>
            </p></div><div id="dialog-20276" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concept of a diagonalizable matrix.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>dilation     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-6891' class='msm_infobutton' onmouseover='infoopen(6891)'>i</a><div id="dialog-6891" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6891' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>     </span></li></ul></li><li><span>dimension     </span><a id='glossaryinfo-12730' class='msm_infobutton' onmouseover='infoopen(12730)'>i</a><div id="dialog-12730" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the dimension of a vector space $V$ as the number of basis vectors in $V$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12730' style='display:none;'><br /><div class='def'><span class='deftitle'>Dimension</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dimension of a subvector space $V$ of $\RNr{n}$ is</span>
                  </p>
                  $$\dim(V):= k\quad \text{if $V$ has a basis of $k$ vectors}$$
                  <p>
                     <span>If $V=\Set{ \Vect{0} }$, we set $\dim(V):=0$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-12726' onmouseover='infoopen(12726)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-12726' style='display:none;'><div class='title'>Basis and Dimension - Illustration</div><p xmlns="Unit">
               <span>The dimension of a sub vector space $V$ of $\RNr{n}$ is defined to be the number of vectors in any basis of $V$. In the series of pictures below, we illustrate the definition in the case where $V=\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>A single nonzero vector in $\RNr{3}$ determines one coordinate axis.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/BasisDimension_1.gif' height='326.02739726027' width='350'/></div><p xmlns="Unit">
               <span>A second vector, not parallel to the first, determines a second coordinate axis. These two vectors span a plane, and every vector in this plane can be expressed in exactly one way as a linear combination of the chosen vectors.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/BasisDimension_2.gif" height="350" width="259.86622073579"/></div> &#xA0; <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/BasisDimension_3.gif" height="350" width="242.72445820433"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>A third vector pointing outside the plane spanned by the first two vectors determines a third coordinate axis. Every vector in $\RNr{3}$ can be expressed in exactly one way as a linear combination of the chosen vectors. These three vectors form a basis of $\RNr{3}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/BasisDimension_4.gif' height='350' width='318.18181818182'/></div><p xmlns="Unit">
               <span>In $V=\RNr{3}$ the process of selecting basis vectors stops after three selections, because there is no more room for independent vectors.</span>
            </p><p xmlns="Unit">
               <span>In an arbitrary vector space $V$, we keep adding independent vectors until we cannot find any more. The vectors we have thus chosen form a basis of $V$, and the number of them is the dimension of $V$.</span>
            </p></div><div id="dialog-12726" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An illustration of the role of a basis in the case where $V=\RNr{3}$.</span>
                     </p>
                  </info></div></ul></div><br /></div><ul class='chilren'><li><span>formula for linear transformations     </span><a id='glossaryinfo-18969' class='msm_infobutton' onmouseover='infoopen(18969)'>i</a><div id="dialog-18969" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{ V }$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-18969' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Dimension formula for linear transformations</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>A linear transformation $L\from V\to W$ satisfies
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{ V }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li></ul></li><li><span>direction angle     </span><a id='glossaryinfo-2802' class='msm_infobutton' onmouseover='infoopen(2802)'>i</a><div id="dialog-2802" class="dialogs" title="Direction Angle"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>the angle between a given vector $\mathbf{x}$ in $\RNr{n}$ and one of the coordinate axes.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2802' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-2804" class="dialogs" title="Read this as ..."><info xmlns="Unit">
                                    
                                    <p>
                                       <span>‘omega i is defined to be the angle from $\mathbf{e}_i$ and $\mathbf{x}$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given a vector $\mathbf{x}$ in $\RNr{n}$, and a number $i$, $1 \leq i \leq n$, the $i$-th direction angle of $\mathbf{x}$ is
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              <a id="hottag-2804" class="hottag" onmouseover="popup(2804)"> 
                                    $\omega_i\ :=\ \sphericalangle(\mathbf{e}_i,\mathbf{x})$
                                 </a>  
                           </span>
                        </p>
                     </def.body>
<br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>distance     </span><ul class='chilren'><li><span>preserving linear transformation     </span><a id='glossaryinfo-17035' class='msm_infobutton' onmouseover='infoopen(17035)'>i</a><div id="dialog-17035" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17035' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17003' onmouseover='popup(17003)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17003" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>The identity $\abs{ L(\Vect{x}) } = \abs{ \Vect{x} }$ says exactly that the length of $\Vect{x}$ equals the length of ($\Vect{x}$ transformed by $L$). If this happens for all $\Vect{x}$ in $\RNr{n}$, then $L$ preserves the length of all vectors and, hence, the distance between any pair of points in $\RNr{n}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-17009' onmouseover='infoopen(17009)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-17009' style='display:none;'><div class='pack'><div class='title'>Rotations are Distance Preserving</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a linear transformation $L$ preserves the distance between two points $\Vect{a}$  and $\Vect{b}$ if the distance from $\Vect{a}$ to $\Vect{b}$ is equal to the distance from $L(\Vect{a})$ to $L(\Vect{b})$. For example, a rotation of the plane about the origin preserves the distance between any two points.</span>
         </p>
			
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/RotationOrthogonal.png" height="349.125" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-17009" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>A rotation is an example of a distance preserving linear transformation.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>distributivity     </span><ul class='chilren'><li><span>scalar multiplication of matrices     </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5192' onmouseover='infoopen(5192)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5192' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>We verify the first distributivity property. The other two properties can be proved with the same method. So let $A$ and $B$ be two matrices of size $(m,n)$, and let $t\in\RNr{}$. We focus our attention on the matrix entries in position $(i,j)$, for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributes over a matrix sum
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Let us consider the entry in position $(i,j)$ of the relevant matrix expressions:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $t\cdot (A+B)$ has the number $t\cdot (a_{ij}+b_{ij})$ in position $(i,j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $tA +tB$ has the number $ta_{ij} + tb_{ij}$ in position $(i,j)$.</span>
               </p>
            </li>
         </ul><p>
            <span>These numbers are equal because of the distributivity law for multiplication and addition of real numbers.</span>
         </p><p>
            <span>Thus $t(A+B)$ and $tA+tB$ both have the same number in position $(i,j)$. This computation applies to each position. So the two matrices are equal and, therefore, the distributivity identity for scalar multiplication of matrices holds.</span>
         </p><p>
            <span>You should try proving the remaining properties of scalar multiplication by adapting the above method.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>matrix multiplication     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>domain     </span><ul class='chilren'><li><span>of a function     </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>dot product     </span><a id='glossaryinfo-1581' class='msm_infobutton' onmouseover='infoopen(1581)'>i</a><div id="dialog-1581" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The dot product of $\Vect{x} = (x_1,\dots ,x_n)$ and $\Vect{y} = (y_1,\dots ,y_n)$ is </span>
                           </p>
                           $$\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1581' style='display:none;'><br /><div class='def'><span class='deftitle'>Dot Product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dot product of two vectors in $\RNr{n}$,</span>
                     
                     
                  </p>
                  <p align="center">
                     <span>
                        $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{y} = (y_1,\dots ,y_n)$
                     </span>
                  </p>
                  <p>
                     <span>is the number   $\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$
                     </span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-1575' onmouseover='infoopen(1575)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-1575' style='display:none;'><div class='pack'><div class='title'>Computing Dot Products - Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
         <p>
            <span>Find the dot product of the vectors $\Vect{x} = (-2)$ and $\Vect{y}=(5)$ in $\RNr{}$.</span>
         </p>
      </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The dot product of $\Vect{x}$ and $\Vect{y}$ is</span>
               </p>
			
			            $$\DotPr{\Vect{x}}{ \Vect{y} }\ =\ \DotPr{ (-2) }{ (5) }\ =\ (-2)\cdot 5\ =\ -10$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
         <p>
            <span>Find the dot product of the vectors $\Vect{x} = (-1,-3)$ and $\Vect{y}=(4,-6)$ in $\RNr{2}$.</span>
         </p>
      </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The dot product of $\Vect{x}$ and $\Vect{y}$ is</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{ (-1,-3) }{ (4,-6) }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-1552" class="hottag" onmouseover="popup(1552)">$=$</a><div id="dialog-1552" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>By definition of the dot product</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1)\cdot 4\ +\ (-3)\cdot (-6)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$14$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
         <p>
            <span>Find the dot product of the vectors $\Vect{x} = (7,0,-3)$ and $\Vect{y}=(3,-5,7)$ in $\RNr{3}$.</span>
         </p>
      </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The dot product of $\Vect{x}$ and $\Vect{y}$ is</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{(7,0,-3)}{(3,-5,7)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-1568" class="hottag" onmouseover="popup(1568)">$=$</a><div id="dialog-1568" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>By definition of the dot product</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$7\cdot 3\ +\ 0\cdot (-5)\ +\ (-3)\cdot 7$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-1575" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>How do I compute a dot product? – Here are some examples.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-1577' onmouseover='popup(1577)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1577" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the dot product of $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ is the sum of the products of components in matching positions.</span>
                     </p>
                     <p>
                        <span>Notice that this is only possible if both vectors have the same number of components.</span>
                     </p>
                  </info></div></ul></div><br /></div><ul class='chilren'><li><span>relationship to norm     </span><a id='glossaryinfo-1961' class='msm_infobutton' onmouseover='infoopen(1961)'>i</a><div id="dialog-1961" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1961' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>orthogonality criterion     </span><a id='glossaryinfo-1955' class='msm_infobutton' onmouseover='infoopen(1955)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-1955' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>is bilinear     </span><a id='glossaryinfo-1867' class='msm_infobutton' onmouseover='infoopen(1867)'>i</a><div id="dialog-1867" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>That the dot product is bilinear means</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{(\Vect{a} + \Vect{b})}{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{y} }\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{ \Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{ \Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1867' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>is symmetry     </span><a id='glossaryinfo-1875' class='msm_infobutton' onmouseover='infoopen(1875)'>i</a><div id="dialog-1875" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is symmetry means that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1875' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>algebraic properties     </span><a id='glossaryinfo-1877' class='msm_infobutton' onmouseover='infoopen(1877)'>i</a><div id="dialog-1877" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating the algebraic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1877' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>positive definite     </span><a id='glossaryinfo-1882' class='msm_infobutton' onmouseover='infoopen(1882)'>i</a><div id="dialog-1882" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is positive definite means that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1882' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>non-degenerate     </span><a id='glossaryinfo-1887' class='msm_infobutton' onmouseover='infoopen(1887)'>i</a><div id="dialog-1887" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is non-degenerate means that</span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1887' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>binomial identities     </span><a id='glossaryinfo-1934' class='msm_infobutton' onmouseover='infoopen(1934)'>i</a><div id="dialog-1934" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1934' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Binomial Identities of the Dot Product Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$ the following binomial identities hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            $$
					
					\aligned
					\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} + \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } + 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} } \\
					\DotPr{ (\Vect{x} - \Vect{y}) }{ (\Vect{x} - \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } - 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} }
					\endaligned

				$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            $$\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} - \Vect{y}) } = \DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{y} }{ \Vect{y} }$$
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1936' onmouseover='infoopen(1936)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1936' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. Here we rely on the basic algebraic properties of the dot product.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			This binomial identity holds because
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} + \Vect{y}) }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1941" class="hottag" onmouseover="popup(1941)"> 
                              $=$
                           </a>  
                     <div id="dialog-1941" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the distributivity property of the dot product operation.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ (\Vect{x} + \Vect{y}) } + \DotPr{ \Vect{y} }{ (\Vect{x} + \Vect{y}) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1943" class="hottag" onmouseover="popup(1943)"> 
                              $=$
                           </a>  
                     <div id="dialog-1943" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the distributivity property of the dot product operation.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } + \DotPr{ \Vect{x} }{ \Vect{y} } + \DotPr{ \Vect{y} }{ \Vect{x} } + \DotPr{\Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1945" class="hottag" onmouseover="popup(1945)"> 
                              $=$
                           </a>  
                     <div id="dialog-1945" class="dialogs" title="This computational step holds because of"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... the commutativity property of the dot product operation</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } + \DotPr{ \Vect{x} }{ \Vect{y} } + \DotPr{ \Vect{x} }{ \Vect{y} } + \DotPr{ \Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } + 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>This proves the first binomial identity. The second follows with a similar argument.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			This binomial identity holds because
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} - \Vect{y}) }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1949" class="hottag" onmouseover="popup(1949)"> 
                              $=$
                           </a>  
                     <div id="dialog-1949" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the distributivity property of the dot product operation.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ (\Vect{x} - \Vect{y}) } + \DotPr{ \Vect{y} }{ (\Vect{x} - \Vect{y}) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1951" class="hottag" onmouseover="popup(1951)"> 
                              $=$
                           </a>  
                     <div id="dialog-1951" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the distributivity property of the dot product operation.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{x} }{ \Vect{y} } + \DotPr{ \Vect{y} }{ \Vect{x} } - \DotPr{ \Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1953" class="hottag" onmouseover="popup(1953)"> 
                              $=$
                           </a>  
                     <div id="dialog-1953" class="dialogs" title="This computational step holds because of"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... the commutativity property of the dot product operation</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{x} }{ \Vect{y} } + \DotPr{ \Vect{x} }{ \Vect{y} } - \DotPr{\Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{y} }{ \Vect{y} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li></ul></li><li><span>eigenvalue     </span><a id='glossaryinfo-19995' class='msm_infobutton' onmouseover='infoopen(19995)'>i</a><div id="dialog-19995" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19995' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19989" class="hottag" onmouseover="popup(19989)">$=	$</a><div id="dialog-19989" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-19978' onmouseover='infoopen(19978)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-19978' style='display:none;'><div class='title'>Eigenvector - Illustration</div><p xmlns="Unit">
               <span>In the picture below $\Vect{v}$ is an eigenvector of the linear transformation $L$ (the transformation described by an $(n,n)$-matrix $\Mtrx{A}$) because</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\Vect{v} \neq \Vect{0}$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(\Vect{v})$ is a scalar multiple of $\Vect{v}$.</span>
                  </p>
               </li>
            </ul><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Eigentheory/ims/EigenLine.png' height='114.625' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, $\Vect{w}$ is not an eigenvector of $L$: $L(\Vect{w})$ is linearly independent of $\Vect{w}$, hence cannot be a scalar multiple of $\Vect{w}$.</span>
            </p></div><div id="dialog-19978" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An illustration of the concept ‘eigenvector’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19983' onmouseover='infoopen(19983)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-19983' style='display:none;'><div class='pack'><div class='title'>Eigenvector / Eigenvalue: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>With respect to standard coordinates of $\RNr{3}$, the $(3,3)$-matrix $\Mtrx{A}$ below describes the orthogonal projection of $\RNr{3}$ onto the $xy$-plane.</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\quad \text{gives projection}\quad
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right]

				$$
			      <p>
            <span>Relate its transformation properties to its eigenvectors and eigenvalues.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Discussion</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To visualize this projection, imagine light shining vertically onto the $xy$-plane. Then the projection sends each object in $\RNr{3}$ to its shadow in the $xy$-planae.</span>
               </p>
			            <p>
                  <span>Therefore every vector in the $xy$-plane gets transformed into itself, that is a vector of the form $\Vect{v} = (x,y,0)$ gets transformed into</span>
               </p>
			            $$
					
\Mtrx{A}\cdot \Vect{v} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\, 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right] = 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right] = 1\cdot \Vect{v}

				$$
			
			            <p>
                  <span>This means that every nonzero vector of the form $\Vect{v}=(x,y,0)$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $\lambda_1 = 1$.</span>
               </p>
			
			            <p>
                  <span>On the other hand, this projection sends the entire $z$-axis to the $\Vect{0}$-vector, that is a vector of the form $\Vect{w}=(0,0,z)$ gets transformed into</span>
               </p>
			
			            $$
					
\Mtrx{A}\cdot \Vect{w} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\, 
\left[
\begin{array}{c}
0 \\ 0 \\ z
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right] = 0\cdot \Vect{w}

				$$
			
			            <p>
                  <span>This means that every nonzero vector of the form $\Vect{w} = (0,0,z)$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $\lambda_2=0$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-19983" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of eigenvectors and eigenvalues.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19985' onmouseover='popup(19985)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-19985" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>The symbol $\lambda$ is a Greek letter. It is pronounced `lambda'</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>eigenvector     </span><a id='glossaryinfo-19993' class='msm_infobutton' onmouseover='infoopen(19993)'>i</a><div id="dialog-19993" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19993' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19989" class="hottag" onmouseover="popup(19989)">$=	$</a><div id="dialog-19989" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-19978' onmouseover='infoopen(19978)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-19978' style='display:none;'><div class='title'>Eigenvector - Illustration</div><p xmlns="Unit">
               <span>In the picture below $\Vect{v}$ is an eigenvector of the linear transformation $L$ (the transformation described by an $(n,n)$-matrix $\Mtrx{A}$) because</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\Vect{v} \neq \Vect{0}$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(\Vect{v})$ is a scalar multiple of $\Vect{v}$.</span>
                  </p>
               </li>
            </ul><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Eigentheory/ims/EigenLine.png' height='114.625' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, $\Vect{w}$ is not an eigenvector of $L$: $L(\Vect{w})$ is linearly independent of $\Vect{w}$, hence cannot be a scalar multiple of $\Vect{w}$.</span>
            </p></div><div id="dialog-19978" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An illustration of the concept ‘eigenvector’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19983' onmouseover='infoopen(19983)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-19983' style='display:none;'><div class='pack'><div class='title'>Eigenvector / Eigenvalue: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>With respect to standard coordinates of $\RNr{3}$, the $(3,3)$-matrix $\Mtrx{A}$ below describes the orthogonal projection of $\RNr{3}$ onto the $xy$-plane.</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\quad \text{gives projection}\quad
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right]

				$$
			      <p>
            <span>Relate its transformation properties to its eigenvectors and eigenvalues.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Discussion</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To visualize this projection, imagine light shining vertically onto the $xy$-plane. Then the projection sends each object in $\RNr{3}$ to its shadow in the $xy$-planae.</span>
               </p>
			            <p>
                  <span>Therefore every vector in the $xy$-plane gets transformed into itself, that is a vector of the form $\Vect{v} = (x,y,0)$ gets transformed into</span>
               </p>
			            $$
					
\Mtrx{A}\cdot \Vect{v} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\, 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right] = 
\left[
\begin{array}{c}
x \\ y \\ 0
\end{array}
\right] = 1\cdot \Vect{v}

				$$
			
			            <p>
                  <span>This means that every nonzero vector of the form $\Vect{v}=(x,y,0)$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $\lambda_1 = 1$.</span>
               </p>
			
			            <p>
                  <span>On the other hand, this projection sends the entire $z$-axis to the $\Vect{0}$-vector, that is a vector of the form $\Vect{w}=(0,0,z)$ gets transformed into</span>
               </p>
			
			            $$
					
\Mtrx{A}\cdot \Vect{w} = 
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]\, 
\left[
\begin{array}{c}
0 \\ 0 \\ z
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right] = 0\cdot \Vect{w}

				$$
			
			            <p>
                  <span>This means that every nonzero vector of the form $\Vect{w} = (0,0,z)$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $\lambda_2=0$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-19983" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of eigenvectors and eigenvalues.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19985' onmouseover='popup(19985)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-19985" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>The symbol $\lambda$ is a Greek letter. It is pronounced `lambda'</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>elementary     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-5561' class='msm_infobutton' onmouseover='infoopen(5561)'>i</a><div id="dialog-5561" class="dialogs" title="elementary matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form</span>
                                 </p>
                                 $$
									
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5561' style='display:none;'><br /><div class='def'><span class='deftitle'>Elementary Matrix</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form
					</span>
                           
                           
                        </p>
                        $$
						
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is a matrix of size $(n,p)$, then forming the matrix product $E_{ij}(t)\cdot \Mtrx{B}$ has the effect of adding $t$ times the $j$-th row of $\Mtrx{B}$ to the $i$-th row of $\Mtrx{B}$. Moreover, for each $t$ in $\RNr{}$, $E_{ij}(t)$ is invertible and   $E_{ij}(t)^{-1} = E_{ij}(-t)$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-5552' onmouseover='infoopen(5552)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-5552' style='display:none;'><div class='pack'><div class='title'>Examples of Elementary Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(3,3)$-matrices an elementary matrix of type $(1,3)$ is</span>
         </p>
			
			      $$
					
					E_{1,3}(5)\ :=\ \begin{bmatrix}
						1 &amp; 0 &amp; 5 \\
						0 &amp; 1 &amp; 0 \\
						0 &amp; 0 &amp; 1
						\end{bmatrix}
					
				$$
			
			      <p>
            <span>This matrix is invertible with inverse   $E_{1,3}(-5)$ because</span>
         </p>
			
			      $$
					
\begin{bmatrix}
1 &amp; 0 &amp; 5 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\left[\begin{array}{rrr}
1 &amp; 0 &amp; -5 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}\right]\ =\
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix} \ =\
\left[\begin{array}{rrr}
1 &amp; 0 &amp; -5 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}\right]
\begin{bmatrix}
1 &amp; 0 &amp; 5 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(4,4)$-matrices an elementary matrix of type $(3,2)$ is</span>
         </p>
			
			      $$
					
					E_{3,2}(4)\ :=\ \begin{bmatrix}
						1 &amp; 0 &amp; 0 &amp; 0 \\
						0 &amp; 1 &amp; 0 &amp; 0 \\
						0 &amp; 4 &amp; 1 &amp; 0 \\
						0 &amp; 0 &amp; 0 &amp; 1
						\end{bmatrix}
					
				$$
			
			      <p>
            <span>This matrix is invertible with inverse &#xA0; $E_{3,2}(-4)$ because</span>
         </p>
			
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
					
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 4 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\left[\begin{array}{rrrr}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; -4 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right]
					
				$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
					
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
					
				$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
					
\left[\begin{array}{rrrr}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; -4 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right]
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 4 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
					
				$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-5552" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of elementary matrices</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-5557' onmouseover='infoopen(5557)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-5557' style='display:none;'><div class='pack'><div class='title'>Explanation for Elementary Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The elementary matrix $E_{ij}(s)$ allows us to perform the row operation ‘add $t$ times the $j$-th row of an $(n,p)$-matrix $\Mtrx{B}$ to the $i$-th row of $\Mtrx{B}$’. In symbols:</span>
         </p>
			
			      $$
					
\begin{bmatrix}
1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
\end{bmatrix}
\begin{bmatrix}
* &amp; \cdots &amp; * \\
\vdots &amp; &amp; \vdots \\
a_{i1} &amp; \cdots &amp; a_{ip} \\
\vdots &amp; &amp; \vdots \\
a_{j1} &amp; \cdots &amp; a_{jp} \\
\vdots &amp; &amp; \vdots \\
{*} &amp; \cdots &amp; *
\end{bmatrix}\ =\
\begin{bmatrix}
* &amp; \cdots &amp; * \\
\vdots &amp; &amp; \vdots \\
a_{i1}+ta_{j1} &amp; \cdots &amp; a_{ip}+ta_{jp} \\
\vdots &amp; &amp; \vdots \\
a_{j1} &amp; \cdots &amp; a_{jp} \\
\vdots &amp; &amp; \vdots \\
{*} &amp; \cdots &amp; *
\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The matrix which, in the set of $(5,5)$-matrices adds $5$ times the $3$-rd to the $4$-th row is</span>
         </p>
			
			      $$
					
E_{3,4}(5)\ =\ 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 5 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $E_{3,4}(5)$ is</span>
         </p>
			
			      $$
					
E_{3,4}(-5)\ =\ 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -5 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
					
				$$
			
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-5557" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation for the role of elementary matrices in the context of elementary row operations.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>epimorphic linear transformation     </span><a id='glossaryinfo-18868' class='msm_infobutton' onmouseover='infoopen(18868)'>i</a><div id="dialog-18868" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18868' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>epimorphism     </span><a id='glossaryinfo-18872' class='msm_infobutton' onmouseover='infoopen(18872)'>i</a><div id="dialog-18872" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18872' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>equal $n$tuples     </span><a id='glossaryinfo-268' class='msm_infobutton' onmouseover='infoopen(268)'>i</a><div id="dialog-268" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-268' style='display:none;'><br /><div class='def'><span class='deftitle'>Equal $n$-tuples</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-266' onmouseover='infoopen(266)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-266' style='display:none;'><div class='pack'><div class='title'>Equality of $n$-tuples.</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine which of the following pairs of tuples are equal.</span>
         </p>
			      <ol>
				        <li>
               <p>
                  <span>
                     $(4,1,-6,3)$ and $(4,1,-6,3)$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $(1,0,3)$ and $(1,0,0,3)$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $(1,3,2)$ and $(6-5,2+1,3-1)$
                  </span>
               </p>
            </li>
				        <li>
               <p>
                  <span>
                     $(1,2,1,2)$ and $(2,1,2,1)$
                  </span>
               </p>
            </li>
			      </ol>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To tell if two tuples are equal, we need to check if the numbers in matching positions are the same. Let’s begin with the first pair:</span>
               </p>
			            <p>
                  <span>1. These two 4-tuples are equal: the numbers in matching positions are the same.</span>
               </p>
			            <p>
                  <span>2. The first tuple is a 3-tuple, while the second tuple is a 4-tuple. Tuples of distinct size are never equal.</span>
               </p>
			            <p>
                  <span>3. These two 3-tuples are equal as the entries in matching positions are the same.</span>
               </p>
			            <p>
                  <span>4. The $4$-tuple $(1,2,1,2)$ has a $1$ as its first coordinate, whereas the $4$-tuple $(2,1,2,1)$ has a $2$ as its first coordinate. So the first coordinates are distinct, and this is enough to render the 4-tuples distinct. In this case we could alternatively have observed that the second, or the third, or the fourth coordinates are distinct.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-266" class="dialogs" title="Examples"><info xmlns="Unit">
                           
                           <p>
                              <span>Examples of (un-)equal $n$-tuples</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>equation     </span><ul class='chilren'><li><span>of hyperspace     </span><a id='glossaryinfo-2362' class='msm_infobutton' onmouseover='infoopen(2362)'>i</a><div id="dialog-2362" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The equation whose solutions form the hyperspace in $\RNr{n}$ perpendicular to the normal vector $\Vect{n} = (a_1,\dots ,a_n)$ is</span>
                                 </p>
                                 $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_1 + \cdots + a_nx_n$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2362' style='display:none;'><div class='title'>Hyperspaces</div><p xmlns="Unit">
                     <span>Let us begin by saying in mathematical terms what a hyperspace is.</span>
                  </p><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-2328' onmouseover='popup(2328)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-2328" class="dialogs" title="Explanation: How to read this expression"><info xmlns="Unit">
                           
                           <p>
                              <span>Read $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$ as:</span>
                           </p>
                           <p>
                              <span>‘Perp of $\Vect{n}$ is defined to be the set of all those $\Vect{x}$ in $\RNr{}\ \ n$ such that the dot product of $\Vect{x}$ and $\Vect{n}$ is $0$’.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-2342' onmouseover='infoopen(2342)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2342' style='display:none;'><div class='title'>Hyperspace – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate the concept of a hyperspace in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{2}$ is just a line through the origin. Thus the red line in the picture below is a hyperspace. We characterize it as the collection of all those vectors which are perpendicular to the green vector $\Vect{n}$, called a normal vector to the hyperspace.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace2D.png' height='274.4' width='350'/></div><p xmlns="Unit">
               <span>Notice that a hyperspace has many normal vectors: if $\Vect{n}$ is a normal  vector, so are $2\cdot \Vect{n}$, $3\cdot \Vect{n}$, $(-1)\cdot \Vect{n}$ and, in general, $t\cdot \Vect{n}$ for any $t\neq 0$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{3}$ is just a plane, in the usual sense of the word, which passes through the origin.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace3D.gif" height="328.43942505133" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, if we call the hyperspace $H$, then the blue arrow $\Vect{n}$, is called a normal vector of $H$ because it is perpendicular to all those vectors which belong to $H$. The second plane in this picture (horizontal) is only there to provide visual reference points. Note that any non-zero multiple of $\Vect{n}$ is also a normal vector of $H$: if $n\geq 1$, there are always many normal vectors to a given hyperspace.</span>
            </p><p xmlns="Unit">
               <span>If $n \geq 4$, we cannot visualize a hyperspace in $\RNr{n}$. Still we can characterize it as the collection of all those vectors in $\RNr{n}$ which are perpendicular to a given nonzero vector $\Vect{n}$.</span>
            </p></div><div id="dialog-2342" class="dialogs" title="Illustration"><info xmlns="Unit">
                           
                           <p>
                              <span>For this definition to make sense we need to recall that the word ‘normal’ here means ‘perpendicular’. So $\text{Perp}(\Vect{n})$ consists of all those $\Vect{x}$ which are perpendicular to the given vector $\Vect{n}$. The mathematical test for being perpendicular is: $\DotPr{\Vect{x}}{\Vect{n}} = 0$.</span>
                           </p>
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div></ul></div><br /><br /><div class='comment'><span class='commenttitle'>Coordinate version of the Hyperspace Equation</span><br/><div class='mathcontent'><comment.body xmlns="Unit">
                        <p>
                           <span>Let us express the dot product equation $\DotPr{\Vect{x}}{\Vect{n}} = 0$ in terms of the coordinates of $\Vect{x}$ and $\Vect{n}$: if</span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{n} = (a_1,\dots ,a_n)$,
				</span>
                        </p>
                        <p>
                           <span>then</span>
                        </p>
                        $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_n + \cdots + a_n x_n$$
                        <p>
                           <span>This means that $\text{Perp}(\Vect{n})$ consists of the solutions of the linear equation</span>
                        </p>
                        $$a_1x_n + \cdots + a_n x_n = 0$$
                        <p>
                           <span>in the variables $x_1,\dots ,x_n$ with coefficients $a_1,\dots ,a_n$. Conversely, given an equation</span>
                        </p>
                        <p align="center">
                           <span>
                              $a_1x_1+ \cdots + a_nx_n = 0$,   with   $\Vect{n} = (a_1,\dots ,a_n) \neq \Vect{0}$, </span>
                        </p>
                        <p>
                           <span>we know that its solutions form the hyperspace $\text{Perp}(\Vect{n})$.
					</span>
                           
                        </p>
                     </comment.body><br /></div><br /><ul class='commentminibuttons'><li class='commentminibutton' id='commentminibutton-2358' onmouseover='infoopen(2358)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-2358' style='display:none;'><div class='pack'><div class='title'>Examples of Hyperspaces</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><div id="dialog-2354" class="dialogs" title="Why is this line perpendicular to c?"><info xmlns="Compositor">
                     
					
					                <p>
                        <span>Because ${\color{red} 2}x+{\color{blue} 3}y = \DotPr{ ({\color{red} 2},{\color{blue} 3}) }{ (x,y) }$
					                   </span>
                     </p>
				              </info></div>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The set of solutions of the equation</span>
         </p>
			      $${\color{red} 2}x + {\color{blue} 3}y = 0$$
			      <p>
            <span>forms the line through the origin of $\RNr{2}$ which is <a id="hottag-2354" class="hottag" onmouseover="popup(2354)"> perpendicular</a>   to the vector $\Vect{c} = ({\color{red} 2},{\color{blue} 3})$. This line is an example of a hyperspace in $\RNr{2}$.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace2D_Exmpl.gif" height="256.52818991098" width="350"/></div>
			         </span>
         </p>
			      <p>
            <span>Notice that a linear equation of the form</span>
         </p>
			      $${\color{red} 2}x + {\color{blue} 3}y = 0$$
			      <p>
            <span>always reveals a normal vector to the hyperspace of its solutions, namely the vector $({\color{red} 2},{\color{blue} 3})$ of its coefficients.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><div id="dialog-2357" class="dialogs" title="Why is this plane perpendicular to n?"><info xmlns="Compositor">
                     
					
					                <p>
                        <span>A point $(x,y,z)$ belongs to the given plane exactly when its position vector $\Vect{x} = (x,y,z)$ is perpendicular to $\Vect{n} = ({\color{red} 2},{\color{red} 9},{\color{red} -3})$. This happens exactly when</span>
                     </p>
					                $$0 = \DotPr{ \Vect{n} }{ \Vect{x} } =  \DotPr{ ({\color{red} 2},{\color{red} 9},{\color{red} -3}) }{ (x,y,z) } = {\color{red} 2}x + {\color{red} 9}y {\color{red} -3}z$$
				              </info></div>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The set of solutions of the equation</span>
         </p>
			      $${\color{red} 2}x + {\color{red} 9}y {\color{red} - 3}z = 0$$
			      <p>
            <span>forms the plane through the origin of $\RNr{3}$ which is <a id="hottag-2357" class="hottag" onmouseover="popup(2357)"> perpendicular</a>   to the vector $\Vect{n} = ({\color{red} 2},{\color{red} 9},{\color{red} -3})$. This plane is an example of a hyperspace in $\RNr{3}$.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-2358" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Some examples of hyperspaces</span>
                           </p>
                        </info></div><li class='commentminibutton' id='commentminibutton-2360' onmouseover='popup(2360)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-2360" class="dialogs" title="Comment"><info xmlns="Unit">
                           
                           <p>
                              <span>Thus a linear equation of the form</span>
                           </p>
                           $${\color{red} a_1}x_1 + {\color{red} a_2}x_2 + \cdots + {\color{red} a_n}x_n = 0$$
                           <p>
                              <span>always reveals a normal vector to the hyperspace of its solutions, namely</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Vect{n}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $({\color{red} a_1},{\color{red} a_2},\cdots ,{\color{red} a_n})$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>So the components of the normal vector are the coefficients of the linear equation.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>     </span></li></ul></li><li><span>equivalent     </span><ul class='chilren'><li><span>equations     </span><a id='glossaryinfo-2452' class='msm_infobutton' onmouseover='infoopen(2452)'>i</a><div id="dialog-2452" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept of equivalent equations.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2452' style='display:none;'><div class='title'>Hyperplanes</div><div id="dialog-2378" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Pictures which assist you with such an inspection.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-2378' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div>
<p xmlns="Unit">
                     <span>Recall: a hyperplane results from shifting a hyperspace off of the origin. Visual <a id="activehottag-2378" class="activehottag" onmouseover="infoopen(2378)"> inspection</a>   suggests: The location of a hyperplane $H$ is completely determined by a nonzero vector $\Vect{n}$ which is perpendicular to $H$, and a point $P$ on $H$. Accordingly, we have</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Equation of a Hyperplane</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$ and a point $P$ with position vector $\Vect{p}$, the hyperplane perpendicular to $\Vect{n}$ through $P$ is the set of  all those $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ with</span>
      </p>$$\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2386' onmouseover='popup(2386)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-2386" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words: the hyperplane in $\RNr{n}$ perpendicular to $\Vect{n}$ and passing through $\Vect{p}$ consists of all those $\Vect{p}$ such that $(\Vect{x}-\Vect{p})$ dot $\Vect{n}$ is zero.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2400' onmouseover='infoopen(2400)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2400' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div><div id="dialog-2400" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of a hyperplane</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-2381' onmouseover='infoopen(2381)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-2381' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>We use the picture below to guide our argument.</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlaneEquation.gif" height="159.95807127883" width="350"/></div><p>
            <span>If $\Vect{x}$ is the position vector of an arbitrary point in $\RNr{n}$, let $\Vect{y}:= \Vect{x} - \Vect{p}$ be as shown in the picture above. Then $\Vect{x}$ belongs to the hyperplane perpendicular to $\Vect{n}$ through $P$ if and only if $\Vect{y}$ is perpendicular to $\Vect{n}$; i.e. if and only if</span>
         </p>$$\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$$<p>
            <span>This is what we wanted to show.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /><div id="dialog-2403" class="dialogs" title="Why ‘a’ normal vector and not ‘the’ normal vector"><info xmlns="Unit">
                              
                              <p>
                                 <span>If $\Vect{n}$ is a normal vector of the given hyperplane, then $2\Vect{n}$, $3\Vect{n}$, etc. are also normal vectors of the hyperplane. Therefore, a given hyperplane has many normal vectors (which are all parallel to one another). For this reason we need to speak of a normal vector of a given hyperplane, rather than of the normal vector.</span>
                              </p>
                           </info></div>
<p xmlns="Unit">
                     <span>The vector $\Vect{n}$ is called <a id="hottag-2403" class="hottag" onmouseover="popup(2403)"> a normal vector</a>   of the specified hyperplane. An equation for one and the same hyperplane can present itself in various guises:</span>
                  </p>
<br /><div class='comment'><span class='commenttitle'>Alternate appearances of hyperplane equation</span><br/><div class='mathcontent'><div id="dialog-2415" class="dialogs" title="Why is this so?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>The symbols $a_1,\dots ,a_n$ and $p_1,\dots ,p_n$ represent fixed numbers. So we obtain a constant</span>
                                    </p>
                                    $$c := a_1p_1 + \cdots + a_n p_n$$
                                    <p>
                                       <span>Therefore the equation $\DotPr{(\Vect{x} - \Vect{p})}{ \Vect{n} } = 0$ is equivalent to</span>
                                    </p>
                                    <p align="center">
                                       <span>
                                          $\DotPr{\Vect{x}}{\Vect{n}} = \DotPr{ \Vect{p} }{\Vect{n} } = c$   or   $a_1x_1 + \cdots + a_n x_n = c$
                                       </span>
                                    </p>
                                 </info></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>The dot product equation $\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$
                              <a id="hottag-2415" class="hottag" onmouseover="popup(2415)"> just differs in appearance</a>   from either one of the two equations below</span>
                        </p>
                        <p align="center">
                           <span>
                              $\DotPr{\Vect{x}}{\Vect{n}} = c$ &#xA0; and &#xA0; $a_1x_1 + \cdots + a_n x_n = c$,</span>
                        </p>
                        <p>
                           <span>where $c:=a_1p_1+\cdots + a_np_n$, $\Vect{x} = (x_1,\dots ,x_n)$, $\Vect{n} = (a_1,\dots ,a_n)$, and $\Vect{p}=(p_1,\dots ,p_n)$. Therefore the solutions of each of these equations forms the same hyperplane as the solutions of any of the other equations.</span>
                        </p>
                        <p>
                           <span>Conversely, if we are given such an equation we can read off a normal vector $\Vect{n} := (a_1,\dots ,a_n)$ to the hyperplane in question. If $a_k\neq 0$, we conclude that the point $P$ with position vector $\Vect{p} := (0,\dots ,0,c/a_k,0,\dots , 0)$ belongs to the hyperplane.</span>
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'><li class='commentminibutton' id='commentminibutton-2413' onmouseover='infoopen(2413)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-2413' style='display:none;'><div class='pack'><div class='title'>Examples of Hyperplanes</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Describe the object in $\RNr{2}$ formed by the set of solutions of the equation</span>
         </p>
			      $$2x + 3y = 3$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>This is an equation in two variables. So each solution $\Vect{x} = (x,y)$ gives a point in $\RNr{2}$. Further, the equation is of the type</span>
               </p>
			            <p align="center">
                  <span>
				                 $ax + by = c$ &#xA0; or, equivalently, &#xA0; $\DotPr{ \Vect{x} }{ \Vect{n} } = c$,</span>
               </p>
			            <p>
                  <span>with $\Vect{n} := (2,3) \neq (0,0)$. Therefore all solutions together form a hyperplane in $\RNr{2}$, i.e. the line $L$ which is perpendicular to $\Vect{n} = (2,3)$ and passes through the point $(0,1)$.</span>
               </p>
			            <p align="center">
                  <span>
				                 <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D_Exmpl.gif" height="212.56097560976" width="350"/></div>
			               </span>
               </p>
			            <p>
                  <span>Note that, in the description of $L$ above, we are free to replace the point $(0,1)$ by any point on $L$. Here are some examples:</span>
               </p>
			            <ul>
				              <li>
					                <p>
                        <span>
                           $L$ is the line in $\RNr{2}$ which is perpendicular to $\Vect{n}$ and passes through the point $(3/2,0)$; or </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $L$ is the line in $\RNr{2}$ which is perpendicular to $\Vect{n}$ and passes through the point $(3,-1)$; or </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $L$ is the line in $\RNr{2}$ which is perpendicular to $\Vect{n}$ and passes through the point $(-3,3)$; etc. </span>
                     </p>
				              </li>
			            </ul>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Describe the object in $\RNr{3}$ formed by the set of solutions of the equation.</span>
         </p>
			      $$2x + y + z = -2$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>This is an equation in three variables. So each solution gives the coordinates of a point in $\RNr{3}$. Further, the equation is of the type</span>
               </p>
			            <p align="center">
                  <span>
				                 $ax + by + cz = k$ or, equivalently, $\DotPr{ \Vect{x} }{ \Vect{n} } = k$.</span>
               </p>
			            <p>
                  <span>with $\Vect{n} = (2,1,1)$. Therefore all solutions together form a hyperplane $H$ in $\RNr{3}$, namely the plane, which is perpendicular to $\Vect{n}$, and passes through the point  $(-1,0,0)$.</span>
               </p>
			            <p>
                  <span>Note that, in the description of $H$ above, we are free to replace the point $(-1,0,0)$ by any point on $H$. Here are some examples:</span>
               </p>
			            <ul>
				              <li>
					                <p>
                        <span>
                           $H$ is the hyperplane in $\RNr{3}$ which is perpendicular to $\Vect{n}$ and passes through the point $(0,-2,0)$; or</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $H$ is the hyperplane in $\RNr{3}$ which is perpendicular to $\Vect{n}$ and passes through the point $(0,0,-2)$; or</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $H$ is the hyperplane in $\RNr{3}$ which is perpendicular to $\Vect{n}$ and passes through the point $(0,-1,-1)$; or</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $H$ is the hyperplane in $\RNr{3}$ which is perpendicular to $\Vect{n}$ and passes through the point $(-2,1,1)$; etc.</span>
                     </p>
				              </li>
			            </ul>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-2413" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of hyperplanes</span>
                           </p>
                        </info></div></ul></div><br /><br /><div class='comment'><span class='commenttitle'>Equivalent hyperplane equations</span><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>Let $u$ be any nonzero number, and consider the two equations below:</span>
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_1 x_1 + \cdots + a_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$c$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$ua_1x_1 + \cdots ua_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$uc$</td></tr></table>
                        <p>
                           <span>These two equations are not the same. Still, a vector $\Vect{x} = (x_1, \dots ,x_n)$ satisfies one of them exactly when it satisfies the other. Therefore both equations describe the same hyperplane in $\RNr{n}$. In this situation we call the equations equivalent.
					</span>
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'><li class='commentminibutton' id='commentminibutton-2441' onmouseover='infoopen(2441)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-2441' style='display:none;'><div class='pack'><div class='title'>Equivalent Hyperplanes - Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the equations below are equivalent.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2x + 3y - z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$4x + 6y - 2z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We notice that multiplying the first equation by $2$ yields the second equation. So each solution of one of these equations is also a solution of the other. Therefore their solution sets form the same hyperplane in $\RNr{3}$: the hyperplane perpendicular to $\Vect{n}:=(2,3,-1)$ passing through $(0,0,-1)$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the equations below are equivalent.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3s + 4t -u+v$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$9s + 12t - 3u + 3v$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$5$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We notice that multiplying the left hand side of the first equation by $3$ yields the left hand side of the second equation. However, multiplying the right hand side of the first equation by $3$ yields $3\neq 5$. Therefore it is not the case that one equation is a nonzero multiple of the other: the equations are not equivalent.</span>
               </p>
			            <p>
                  <span>So </span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-2441" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of equivalent hyperplanes</span>
                           </p>
                        </info></div></ul></div><br /><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-2497' onmouseover='infoopen(2497)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-2497' style='display:none;'><div class='pack'><div class='title'>Parallel Hyperplanes - Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the solution hyperplanes of the equations below are parallel.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x + 4y - 1z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2x - 8y - 2z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to determine if the normal vectors of the two hyperplanes are parallel.</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>The first hyperplane has $\Vect{u}:=(1,4,-1)$ as a normal vector.</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second hyperplane has $\Vect{v}:=(2,-8,-2)$ as a normal vector.</span>
                     </p>
				              </li>
			            </ol>
			            <p>
                  <span>These vectors are parallel exactly when there exists a number $t$ with</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \Vect{u}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[ \begin{array}{r} 2 \\ -8 \\ -2 \end{array} \right]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \left[ \begin{array}{r} 1 \\ 4 \\ -1 \end{array} \right]$</td></tr></table>
			            <p>
                  <span>Comparing the first coordinates requires $t=2$, while comparing the second coordinates requires $t=-2$. This means that there is no number $t$ with</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \Vect{u}$</td></tr></table>
			            <p>
                  <span>So the normal vectors to the two hyperplanes are  not parallel and, therefore, the hyperplanes themselves are not parallel.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the solution hyperplanes of the equations below are parallel.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3u + v - w + 2x$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2w - 6u - 2v - 4x$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\pi$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to determine if the normal vectors of the two hyperplanes are parallel.</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>The first hyperplane has $\Vect{v}:=(3,1,-1,2))$ as a normal vector.</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second hyperplane has $\Vect{w}:=(-6,-2,2,-4)$ as a normal vector.</span>
                     </p>
				              </li>
			            </ol>
			            <p>
                  <span>We note that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{w}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-2)\cdot \Vect{v}$</td></tr></table>
			            <p>
                  <span>So the normal vectors to the two hyperplanes are  parallel and, therefore, the hyperplanes themselves are parallel.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-2497" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of parallel hyperplanes</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>systems of equations     </span><a id='glossaryinfo-3864' class='msm_infobutton' onmouseover='infoopen(3864)'>i</a><div id="dialog-3864" class="dialogs" title="When are two systems of linear equations equivalent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Two systems of linear equations are equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3864' style='display:none;'><br /><div class='def'><span class='deftitle'>Equivalent systems of linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two systems of equations are called equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li></ul></li><li><span>function     </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div><ul class='chilren'><li><span>domain     </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>target     </span><a id='glossaryinfo-6181' class='msm_infobutton' onmouseover='infoopen(6181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6181' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>value     </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>geometric multiplicity     </span><a id='glossaryinfo-20130' class='msm_infobutton' onmouseover='infoopen(20130)'>i</a><div id="dialog-20130" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20130' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20091' onmouseover='infoopen(20091)'><span style='cursor:pointer'>Comment</span></li><div class='refcontent' id='refcontent-20091' style='display:none;'><div class='title'>Eigenspace - Comments</div><p xmlns="Unit">
               <span>
                  <b>Subspace property of an eigenspace</b>   Given an $(n,n)$-matrix $\Mtrx{A}$, the eigenspace $E_k$ of $\Mtrx{A}$ with eigenvalue $\lambda_k$ is a subvector space of $\RNr{n}$. This is so because $E_k$ is the null space of the matrix $(\Mtrx{A} - \IdMtrx{n})$, hence is the orthogonal complement of the row vectors of $(\Mtrx{A} - \IdMtrx{n})$, and this is a subspace of $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Algebraic vs. geometric multiplicity</b>   One can show that the algebraic and geometric multiplicity of an eigenvalue are related by the inequality</span>
            </p>$$1 \leq \text{geometric multiplicity} \leq \text{algebraic multiplicity}$$</div><div id="dialog-20091" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Some comments on the concept of  on ‘Eigenspace’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-20128' onmouseover='infoopen(20128)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20128' style='display:none;'><div class='pack'><div class='title'>Eigenvectors and Eigenvalues: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the eigenvalues and eigenspaces of the matrix</span>
         </p>
			      $$
					
\Mtrx{A} =
\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-20102" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>because the exponent of the factor $(\lambda - 2)$ of $p(\lambda)$ is $1$
                                    </span>
                                 </p>
                              </info></div><div id="dialog-20104" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>because the exponent of the factor $(\lambda - 4)$ of $p(\lambda)$ is $1$
                                    </span>
                                 </p>
                              </info></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by looking for the eigenvalues of $\Mtrx{A}$. First we find its characteristic polynomial:</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ 
	\det\left(
	\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]\ -\ 
\lambda\cdot \left[
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right] \right) \\
	&amp;=\ \det
\left[
\begin{array}{cc}
3 - \lambda &amp; 1 \\
1 &amp; 3 - \lambda
\end{array}
\right] \\
	&amp;=\ (3-\lambda)^2 - 1 \\
	&amp;=\ \lambda^2 -6\lambda + 8 \\
	&amp;=\ (\lambda - 4)(\lambda - 2)
\endaligned

				$$
			            <p>
                  <span>So $\Mtrx{A}$ has two distinct eigenvalues:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\lambda_1 = 2$ with 
					<a id="hottag-20102" class="hottag" onmouseover="popup(20102)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\lambda_2 = 4$ with 
					<a id="hottag-20104" class="hottag" onmouseover="popup(20104)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_1$ consists of the solutions of the matrix equation $(\Mtrx{A} - \lambda_1 \IdMtrx{2})\Vect{x} = \Vect{0}$:</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
1 &amp; 1 \\
1 &amp; 1
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>The solutions of the corresponding system of linear equations are of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x,y)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s(-1,1)$</td></tr></table>
			            <p>
                  <span>where $s$ in $\RNr{}$ is arbitrary. Therefore the eigenspace of $\lambda_1$ is</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$E_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\span(-1,1)$</td></tr></table>
			            <p>
                  <span>and $\EuScript{B}_1 := (-1,1)$ is a basis of $E_1$. Thus $\Mtrx{A}$ transforms $E_1$ by scaling it by the factor of $2$.</span>
               </p>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_2$ consists of the solutions of the matrix equation $(\Mtrx{A} - \lambda_2 \IdMtrx{2})\Vect{x} = \Vect{0}$:</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
-1 &amp; 1 \\
1 &amp; -1
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>The solutions of the corresponding system of linear equations are of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x,y)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t(1,1)$</td></tr></table>
			            <p>
                  <span>where $t$ in $\RNr{}$ is arbitrary. Therefore the eigenspace of $\lambda_2$ is</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$E_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\span(1,1)$</td></tr></table>
			            <p>
                  <span>and $\EuScript{B}_ {2} := (1,1)$ is a basis of $E_2$. Thus $\Mtrx{A}$ transforms $E_2$ by scaling it by the factor of $4$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the eigenvalues and eigenspaces of the matrix</span>
         </p>
			      $$
					
\Mtrx{A}\ =\ \dfrac{1}{6}\left[
\begin{array}{rrr}
5 &amp; -1 &amp; -2 \\
-3 &amp; 3 &amp; -6 \\
-1 &amp; -1 &amp; 4
\end{array}\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-20123" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>Because the exponent of $(\lambda - 0)$ in $p(\lambda)$ is $1$.</span>
                                 </p>
                              </info></div><div id="dialog-20125" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>Because the exponent of $(\lambda - 1)$ in $p(\lambda)$ is $2$.</span>
                                 </p>
                              </info></div><div id="dialog-20127" class="dialogs" title="Why do these vectors form a basis of $E_2$?"><info xmlns="Compositor">
                           
						
						                     <p>
                              <span>Visibly the vectors span $E_2$. Their linear independence can be seen with the determinant test applied to rows $1$ and $3$. So they form a basis of $E_2$.</span>
                           </p>
					                   </info></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by looking for the eigenvalues of  ; i.e. all those values of $\lambda$ for which the characteristic polynomial below vanishes.</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ \text{det}
\begin{bmatrix}
\tfrac{5}{6} - \lambda &amp; -\tfrac{1}{6} &amp; -\tfrac{1}{3} \\
-\tfrac{1}{2} &amp; \tfrac{1}{2} - \lambda &amp; -1 \\
-\tfrac{1}{6} &amp; -\tfrac{1}{6} &amp; \tfrac{2}{3} - \lambda
\end{bmatrix} \\
6^3\cdot p(\lambda)\ &amp;=\ \text{det}
\begin{bmatrix}
5 - 6\lambda &amp; -1 &amp; -2 \\
-3 &amp; 3 - 6\lambda &amp; -6 \\
-1 &amp; -1 &amp; 4 - 6\lambda
\end{bmatrix} \\
   &amp;=\ \lambda^3\ -\ 2 \lambda^2\ +\ \lambda \\
   &amp;=\ (\lambda - 0)^1(\lambda-1)^2
\endaligned

				$$
			            <p>
                  <span>Thus $\Mtrx{A}$ has two distinct eigenvalues:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\lambda_1=0$ with <a id="hottag-20123" class="hottag" onmouseover="popup(20123)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\lambda_2=1$ with <a id="hottag-20125" class="hottag" onmouseover="popup(20125)"> algebraic multiplicity $2$
                              </a>  
                        </span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_1$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\dfrac{1}{6}
\left[\begin{array}{rrr}
5 &amp; -1 &amp; -2 \\
-3 &amp; 3 &amp; -6 \\
-1 &amp; -1 &amp; 4
\end{array}\right]\,
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}\ =\
\begin{bmatrix}
0 \\ 0 \\ 0
\end{bmatrix}

				$$
			            <p>
                  <span>The solutions of the corresponding system of homogeneous linear equations are of the form</span>
               </p>
			            $$
					
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = s
\left[
\begin{array}{c}
1 \\ 3 \\ 1
\end{array}
\right]

				$$
			            <p>
                  <span>with $s$ an arbitrary number in $\RNr{}$. Thus $\EuScript{B}_1=(\Vect{b}_1)$ with $\Vect{b}_1=(1,3,1)$ is a basis for $E_1$, the eigenspace of $\Mtrx{A}$ associated to $\lambda_1$. Therefore the geometric multiplicity of $\lambda_1$ is 1, and every nonzero vector in $E_1$ is an eigenvector of $\Mtrx{A}$ with eigenvalue    $0$. This means that $\Mtrx{A}$ transforms all of $E_1$ into the zerovector.</span>
               </p>
			
			
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_2$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\dfrac{1}{6}
\left[\begin{array}{rrr}
-1 &amp; -1 &amp; -2 \\
-3 &amp; -3 &amp; -6 \\
-1 &amp; -1 &amp; -2
\end{array}\right]\,
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}\ =\
\begin{bmatrix}
0 \\ 0 \\ 0
\end{bmatrix}

				$$
			            <p>
                  <span>The solutions of the corresponding system of homogeneous linear equations are of the form</span>
               </p>
			            $$
					
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = s_1
\left[
\begin{array}{r}
1 \\ -1 \\ 0
\end{array}
\right] + s_2
\left[
\begin{array}{r}
0 \\ -2 \\ 1
\end{array}
\right]

				$$
			            <p>
                  <span>with $s_1$ and $s_2$ arbitrary numbers in $\RNr{}$. Thus $\EuScript{B}_2=(\Vect{b}_2,\Vect{b}_3)$ with</span>
               </p>
			            $$\Vect{b}_2 = (1,-1,0) \quad\text{and}\quad \Vect{b}_3=(0,-2,1)$$
			            <p>
                  <span>form a 
				<a id="hottag-20127" class="hottag" onmouseover="popup(20127)"> basis</a>  
				of $E_2$, the eigenspace associated to $\lambda_2$. Thus the geometric multiplicity of $\lambda_2$ is 2, and every nonzero vector in $E_2$ is an eigenvector of $\lambda_2$ with eigenvalue   $1$. This means that $\Mtrx{A}$ transforms each such vector into itself; i.e. $\Mtrx{A}$ acts as the identity transformation on $E_2$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-20128" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of finding eigenvalues and associated eigenspaces</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>Gram-Schmidt orthonormalization process     </span><a id='glossaryinfo-14098' class='msm_infobutton' onmouseover='infoopen(14098)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-14098' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Gram-Schmidt orthonormalization</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given an ordered linearly independent set $\EuScript{A}:=(\Vect{a}_1,\dots ,\Vect{a}_r)$ of vectors in $\RNr{n}$, the ordered set of vectors $\EuScript{B}:=(\Vect{v}_1,\dots ,\Vect{v}_r)$ defined below is an ordered ONB of $\span(\EuScript{A})$.
			</span>
         
      </p><table xmlns:default="Theorem" border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14104" class="hottag" onmouseover="popup(14104)">$:=	$</a><div id="dialog-14104" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_1$ is the normalization of $\Vect{a}_1$; i.e. $\Vect{v}_1$ has the same direction as $\Vect{a}_1$, but has length $1$.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_1 }{ \abs{ \Vect{a}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14109" class="hottag" onmouseover="popup(14109)">$:=	$</a><div id="dialog-14109" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_2$ is the component of $\Vect{a}_2$ which is perpendicular to $\Vect{v}_1$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1 }{ \abs{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\vdots$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\qquad \vdots \qquad\qquad \vdots$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14118" class="hottag" onmouseover="popup(14118)">$:=	$</a><div id="dialog-14118" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_r$ is the component of $\Vect{a}_r$ which is perpendicular to each of $\Vect{v}_1$, ... , $\Vect{v}_{r-1}$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} }{ \abs{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} } }$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, $\span\Set{ \Vect{a}_1,\dots ,\Vect{a}_j } = \span\Set{ \Vect{v}_1,\dots ,\Vect{v}_j }$ for each $1\leq j\leq r$ and, if $\Vect{a}_1,\dots ,\Vect{a}_j$ are already orthonormal, then $\Vect{a}_k=\Vect{v}_k$ for each $1\leq k\leq j$.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-14195' onmouseover='infoopen(14195)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-14195' style='display:none;'><div class='title'>Gram-Schmidt Orthonormalization: the Idea</div><div id="dialog-14171" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the projection of a vector on a line.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-14171' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal vector decomposition</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given subspaces $V\subseteq W$ of $\RNr{n}$, every $\Vect{x}$ in $W$ has a unique sum expression</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_V + \Vect{x}_{\bot}$</td></tr></table><p xmlns="Theorem">
         <span>where $\Vect{x}_V=\pr_V(\Vect{x})$ is in $V$ and $\Vect{x}_{\bot}:= \Vect{x}- \pr_V(\Vect{x})$ is in $V^{\bot}$.
			</span>
         
         
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>The Gram-Schmidt orthonormalization procedure might look a bit intimidating at first. However, there is just one simple beautiful idea underlying: the <a id="activehottag-14171" class="activehottag" onmouseover="infoopen(14171)"> orthogonal vector decomposition</a>  , $\Vect{x} = \Vect{x}_V + \Vect{x}_{\bot}$, of a vector $\Vect{x}$ into the sum of a vector $\Vect{x}_V$ in a subspace $V$, and a vector $\Vect{x}_{\bot}$ in the orthogonal complement of $V$.</span>
            </p>
<p xmlns="Unit">
               <span>So, how does this orthogonal vector decomposition help in orthonormalizing an ordered set of vectors $(\Vect{a}_1,\dots ,\Vect{a}_n)$?</span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>We begin by turning $\Vect{a}_1$ into a vector of length $1$ and in the direction of $\Vect{a}_1$. This is accomplished by setting</span>
                  </p>
                  $$\Vect{v}_1 := \frac{ \Vect{a}_1 }{ \Abs{ \Vect{a}_1 } }$$
                  <p>
                     <span>Then $\span\Set{\Vect{a}_1} = \span\Set{\Vect{v}_1} =:V_1$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Next we split $\Vect{a}_2$ as</span>
                  </p>
                  $$\Vect{a}_2 = (\Vect{a}_2)_{V_1} + (\Vect{a}_2)_{\bot} = \pr_{V_1}(\Vect{a}_2) + \left( \Vect{a}_2 - \pr_{V_1}(\Vect{a}_2)\right)$$
                  <p>
                     <span>Thus $(\Vect{a}_2)_{V_1}$ is in $V_1$, and $(\Vect{a}_2)_{\bot}$ is in the orthogonal complement of $V_1$. So</span>
                  </p>
                  $$(\Vect{a}_2)_{\bot} = \Vect{a}_2 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1$$
                  <p>
                     <span>is perpendicular to $V_1$. This vector need not have length $1$. So we normalize it</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\Vect{v}_2$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $:=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $\dfrac{ \Vect{a}_2 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1 }{ \Abs{ \Vect{a}_2 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1 } }$
                        </td>
                     </tr>
                  </math.array>
                  <p>
                     <span>We then check that $\span\Set{ \Vect{a}_1,\Vect{a}_2 } = \span\Set{ \Vect{v}_1,\Vect{v}_2 } =: V_2$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Next we split $\Vect{a}_3$ as</span>
                  </p>
                  $$\Vect{a}_3 = (\Vect{a}_3)_{V_2} + (\Vect{a}_3)_{\bot} = \pr_{V_2}(\Vect{a}_3) + \left( \Vect{a}_3 - \pr_{V_2}(\Vect{a}_3)\right)$$
                  <p>
                     <span>Thus $(\Vect{a}_3)_{V_2}$ is in $V_2$, and $(\Vect{a}_3)_{\bot}$ is in the orthogonal complement of $V_2$. So</span>
                  </p>
                  $$(\Vect{a}_3)_{\bot} = \Vect{a}_3 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1 - (\DotPr{\Vect{a}_3}{\Vect{v}_2})\cdot \Vect{v}_2$$
                  <p>
                     <span>is perpendicular to $V_2$. This vector need not have length $1$. So we normalize it</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\Vect{v}_3$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $:=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $\dfrac{ \Vect{a}_3 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1 - (\DotPr{\Vect{a}_3}{\Vect{v}_2})\cdot \Vect{v}_2 }{ \Abs{ \Vect{a}_3 -  (\DotPr{\Vect{a}_2}{\Vect{v}_1})\cdot \Vect{v}_1 - (\DotPr{\Vect{a}_3}{\Vect{v}_2})\cdot \Vect{v}_2 } }$
                        </td>
                     </tr>
                  </math.array>
                  <p>
                     <span>We then check that $\span\Set{ \Vect{a}_1,\Vect{a}_2,\Vect{a}_3 } = \span\Set{ \Vect{v}_1,\Vect{v}_2,\Vect{v}_3 } =: V_3$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In general, suppose $1\leq k-1\leq r-1$, and vectors $\Vect{a}_1, \dots ,\Vect{a}_{k-1}$ have been orthonormalized into vectors $\Vect{v}_1,\dots ,\Vect{v}_{k-1}$, and</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\span\Set{\Vect{a}_1,\dots ,\Vect{a}_{k-1}}$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $\span\Set{\Vect{v}_1,\dots ,\Vect{v}_{k-1}} =: V_{k-1}$
                        </td>
                     </tr>
                  </math.array>
                  <p>
                     <span>Then we orthonormalize $\Vect{a}_k$ by splitting it as</span>
                  </p>
                  $$\Vect{a}_k = (\Vect{a}_k)_{V_{k-1}} + (\Vect{a}_k)_{\bot} = \pr_{V_{k-1}}(\Vect{a}_k) + \left( \Vect{a}_k - \pr_{V_{k-1}}(\Vect{a}_k)\right)$$
                  <p>
                     <span>Thus $(\Vect{a}_k)_{V_{k-1}}$ is in $V_{k-1}$, and $(\Vect{a}_k)_{\bot}$ is in the orthogonal complement of $V_{k-1}$. So</span>
                  </p>
                  $$(\Vect{a}_k)_{\bot} = \Vect{a}_k -  (\DotPr{\Vect{a}_k}{\Vect{v}_1}) \cdot \Vect{v}_1 - \cdots - (\DotPr{\Vect{a}_k}{\Vect{v}_{k-1}})\cdot \Vect{v}_{k-1}$$
                  <p>
                     <span>is perpendicular to $V_{k-1}$. This vector need not have length $1$. So we normalize it</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\Vect{v}_k$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $:=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $\dfrac{ \Vect{a}_k -  (\DotPr{\Vect{a}_k}{\Vect{v}_1}) \cdot \Vect{v}_1 - \cdots - (\DotPr{\Vect{a}_k}{\Vect{v}_{k-1}})\cdot \Vect{v}_{k-1} }{ \Abs{ \Vect{a}_k -  (\DotPr{\Vect{a}_k}{\Vect{v}_1}) \cdot \Vect{v}_1 - \cdots - (\DotPr{\Vect{a}_k}{\Vect{v}_{k-1}})\cdot \Vect{v}_{k-1} } }$
                        </td>
                     </tr>
                  </math.array>
                  <p>
                     <span>We then check that $\span\Set{ \Vect{a}_1,\cdots ,\Vect{a}_k } = \span\Set{ \Vect{v}_1,\cdots ,\Vect{v}_k } =: V_k$.</span>
                  </p>
               </li>
            </ol>
<p xmlns="Unit">
               <span>Thus we orthonormalize inductively the entire set of vectors $\Vect{a}_1$, ... , $\Vect{a}_r$.</span>
            </p></div><div id="dialog-14195" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>An explanation of the idea underlying the Gram-Schmidt orthonormalization procedure.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-14258' onmouseover='infoopen(14258)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14258' style='display:none;'><div class='pack'><div class='title'>Gram-Schmidt Orthonormalization: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>You are given the vectors $\Vect{a}$, $\Vect{b}$, and $\Vect{c}$ in $\RNr{3}$ with</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,1,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,-1,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{c}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,1,0)$</td></tr></table>
			      <p>
            <span>Verify that these vectors form a basis of $\RNr{3}$, then orthonormalize them.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by checking that the given vectors are linearly independent. we use the determinant.</span>
               </p>
			            $$
					
\det \left[
\begin{array}{rrr}
1 &amp; 0 &amp; 1 \\
1 &amp; -1&amp; 1 \\
1 &amp; 1 &amp; 0
\end{array}
\right] = \det \left[
\begin{array}{rrr}
1 &amp; 0 &amp; 0 \\
1 &amp;-1 &amp; 0 \\
1 &amp; 1 &amp;-1
\end{array}
\right] = 1 \neq 0

				$$
			            <p>
                  <span>So the vectors are linearly independent. Then we know that three linearly independent vectors in the 3-dimensional space $\RNr{3}$ always form a basis. This answers the first part of the problem.</span>
               </p>
			
			            <p>
                  <span>We use the Gram-Schmidt orthonormalization method to turn the given basis of $\RNr{3}$ into an orthonormal basis of $\RNr{3}$.</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{u}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{\Vect{a}}{ \Abs{ \Vect{a} } }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{1}{\sqrt{3}}\cdot (1,1,1)$</td></tr></table>
			
			            <p>
                  <span>To orthonormalize $\Vect{b}$ with respect to $\Vect{u}$, we encounter the expression</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[ \DotPr{ (0,-1,1) }{ \left( \tfrac{1}{\sqrt{3}}\cdot (1,1,1) \right) }\right]\cdot \tfrac{1}{\sqrt{3}}\cdot (1,1,1)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
			            <p>
                  <span>So we find</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{ \Vect{b} }{ \Abs{ \Vect{b} } }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{1}{ \sqrt{2} }\cdot (0,-1,1)$</td></tr></table>
			
			            <p>
                  <span>To orthonormalize $\Vect{c}$ with respect to $\Vect{u}$ and $\Vect{v}$ we encounter the expressions</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[ \DotPr{ (1,1,0) }{ \left( \tfrac{1}{\sqrt{3}}\cdot (1,1,1) \right) }\right]\cdot \tfrac{1}{\sqrt{3}}\cdot (1,1,1)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{2}{3}\cdot (1,1,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[ \DotPr{ (1,1,0) }{ \left( \tfrac{1}{\sqrt{2}}\cdot (0,-1,1) \right) }\right]\cdot \tfrac{1}{\sqrt{2}}\cdot (0,-1,1)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-\frac{1}{2}\cdot (0,-1,1)$</td></tr></table>
			            <p>
                  <span>Therefore the orthonormalization of $\Vect{c}$ with respect to $\Vect{u}$ and $\Vect{v}$ is</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{w}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{ (1,1,0) - \tfrac{2}{3}\cdot (1,1,1) + \tfrac{1}{2}\cdot (0,-1,1) }{ \Abs{ (1,1,0) - \tfrac{2}{3}\cdot (1,1,1) + \tfrac{1}{2}\cdot (0,-1,1) } }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{ \tfrac{1}{6}\cdot (2,-1,-1) }{ \Abs{ \tfrac{1}{6}\cdot (2,-1,-1) } }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\frac{1}{\sqrt{6}}\cdot (2,-1,-1)$</td></tr></table>
			            <p>
                  <span>Thus $\Vect{u}$, $\Vect{v}$, and $\Vect{w}$ as found above form the Gram-Schmidt orthonormalization of $\Vect{a}$, $\Vect{b}$, and $\Vect{c}$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-14258" class="dialogs" title="Example"><info xmlns="Theorem">
         
         <p>
            <span>An example of orthonormalizing a set of vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-14121' onmouseover='infoopen(14121)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-14121' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><div id="dialog-14129" class="dialogs"><info>
                           <p>
                              <span>Else $\EuScript{A}$ would not be linearly independent.</span>
                           </p>
                        </info></div><div id="dialog-14148" class="dialogs" title="Why is the vector distinct from 0?"><info>
                           
                           <p>
                              <span>If this vector were $\Vect{0}$, then $\Vect{a}_j$ would be a linear combination of $\Vect{v}_1$, ... ,$\Vect{v}_{j-1}$ and, hence, of $\Vect{a}_1$, ... , $\Vect{a}_{j-1}$, a contradiction to the assumption that $\EuScript{A}$ is linearly independent.</span>
                           </p>
                        </info></div><div id="dialog-14155" class="dialogs" title="Why is this so?"><info>
                           
                           <p>
                              <span>From the induction hypothesis we already know that $\span(\EuScript{A}_{j-1})=\span(\EuScript{B}_{j-1})$. Further, $\span(\EuScript{B}_{j-1}) \subseteq \span(\EuScript{B}_j)$ because $\EuScript{B}_{j-1}\subseteq \EuScript{B}_j$.</span>
                           </p>
                        </info></div>
<proof.block.body><proof.block.body><p>
            <span>We prove the theorem by induction on $r$. If $r=1$, $\EuScript{B}_1 := ( \Vect{v}_1 )$ is an ordered ONB of $\span\Set{ \Vect{a}_1 }$  for the following reasons:</span>
         </p><ol>
            <li>
               <p>
                  <span>the definition of $\Vect{v}_1$ is valid 
					<a id="hottag-14129" class="hottag" onmouseover="popup(14129)"> since</a>  
                     $\Vect{a}_1\neq \Vect{0}$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\span\Set{ \Vect{v}_1 } = \span\Set{ \Vect{a}_1 }$ because $t \Vect{a}_1 = (t \abs{ \Vect{a}_1 }) \Vect{v}_1$ for all $t\in \RNr{}$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\EuScript{B}_1$ is linearly independent since $\abs{ \Vect{v}_1 } = 1$.</span>
               </p>
            </li>
         </ol><p>
            <span>So suppose the theorem is true for $ 1\leq (j-1) &lt; r $. We need to deduce that the theorem is true for $j$. The induction hypothesis tells us that, $\EuScript{B}_{j-1} := (\Vect{v}_1,\dots ,\Vect{v}_{j-1})$ is an ordered ONB of $\EuScript{A}_{j-1}:=\span\Set{ \Vect{a}_1,\dots ,\Vect{a}_{j-1} }$. Therefore the following hold</span>
         </p><ol>
            <li>
               <p>
                  <span>
                     <a id="hottag-14148" class="hottag" onmouseover="popup(14148)"> 
                           $\Vect{a}_j - (\DotPr{ \Vect{a}_j }{ \Vect{v}_1 })\Vect{v}_1 - \cdots - (\DotPr{ \Vect{a}_j }{ \Vect{v}_{j-1} })\Vect{v}_{j-1}\neq \Vect{0}$
                        </a>  ,
				and so the definition of $\Vect{v}_j$ is valid</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\EuScript{A}_{j}:=\span\Set{ \Vect{a}_1,\dots ,\Vect{a}_j} \subseteq \span\Set{ \Vect{v}_1,\dots ,\Vect{v}_{j-1} }=:\EuScript{B}_j$. To see this, it only 
					<a id="hottag-14155" class="hottag" onmouseover="popup(14155)"> remains</a>  
					to show that $\Vect{a}_j\in \span(\EuScript{B}_j)$. Indeed, the defining equation for $\Vect{v}_j$ yields</span>
               </p>
               <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_j$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\DotPr{ \Vect{a}_j }{ \Vect{v}_1 })\Vect{v}_1 + \cdots + (\DotPr{ \Vect{a}_j }{ \Vect{v}_{j-1} })\Vect{v}_{j-1} + s \Vect{v}_j$</td></tr></table>
               <p>
                  <span>where $s=\abs{ \Vect{a}_j - (\DotPr{ \Vect{a}_j }{ \Vect{v}_1 })\Vect{v}_1 - \cdots -  (\DotPr{ \Vect{a}_j }{ \Vect{v}_{j-1} })\Vect{v}_{j-1}}$. Therefore, $\span(\EuScript{A}_j) \subseteq \span( \EuScript{B}_j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>Conversely, $\span(\EuScript{B}_j)\subseteq \span(\EuScript{A}_j)$: Indeed, $\span(\EuScript{B}_{j-1})=\span(\EuScript{A}_{j-})$ by induction hypothesis, and $\span(\EuScript{A}_{j-1})\subset \span(\EuScript{A}_j)$. So, $\Vect{v}_r$ is a linear combination of vectors in $\span(\EuScript{A}_j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>So $\span(\EuScript{A}_j)=\span(\EuScript{B}_j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\EuScript{B}_j$ is an orthonormal set of vectors: In view of the induction hypothesis it only remains to show that $\abs{ \Vect{v}_j } = 1$, which holds by design, and that $\DotPr{ \Vect{v}_j }{ \Vect{v}_k } = 0$ for $1\leq k\leq j-1$. We find</span>
               </p>
               <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{ \Vect{v}_j }{ \Vect{v}_k }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1/s)\left( \DotPr{ \Vect{a}_j }{ \Vect{v}_k } - (\DotPr{ \Vect{a}_j }{ \Vect{v}_1 }(\DotPr{ \Vect{v}_1 }{ \Vect{v}_k }) - \cdots - (\DotPr{ \Vect{a}_j }{ \Vect{v}_k }(\DotPr{ \Vect{v}_k }{ \Vect{v}_k })\right.$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left.\qquad  - \cdots - (\DotPr{ \Vect{a}_j }{ \Vect{v}_{j-1} }(\DotPr{ \Vect{v}_{j-1} }{ \Vect{v}_k })\right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1/s)(\DotPr{ \Vect{a}_j }{ \Vect{v}_k } - \DotPr{ \Vect{a}_j }{ \Vect{v}_k })$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
            </li>
         </ol><p>
            <span>It only remains to consider the situation where $\EuScript{A}_j$ is already orthonormal. By induction hypothesis, $\Vect{a}_1=\Vect{v}_1$, $\Vect{a}_{j-1}=\Vect{v}_{j-1}$. In the defining formula for $\Vect{v}_j$, we find $\DotPr{ \Vect{a}_j }{ \Vect{v}_k }=0$, for $1\leq k\leq j-1$. Therefore</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_j$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_j/\abs{ \Vect{a}_j } = \Vect{a}_j$</td></tr></table><p>
            <span>This completes the induction and, with it, the proof of the validity of the Gram-Schmidt orthonormalization procedure.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li><li><span>homogeneous     </span><ul class='chilren'><li><span>linear equation     </span><a id='glossaryinfo-3275' class='msm_infobutton' onmouseover='infoopen(3275)'>i</a><div id="dialog-3275" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = 0$$
					                   <p>
                           <span>Look up the definition</span>
                        </p>
				                 </info></div></li></ul></li><li><span>homogeneous system of linear equations     </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4225' onmouseover='infoopen(4225)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4225' style='display:none;'><div class='pack'><div class='title'>Homogeneous and Inhomogeneous Systems of Linear Equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called homogeneous if all of the augmented constants are $0$.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$3$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{-1}{\color{red}x_1}\ +\ \colorbox{lightgreen}{2}{\color{red}x_2}\ -\ \colorbox{lightgreen}{1}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$4$}{\color{red}x_5} \ -\ \colorbox{lightgreen}{$6$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$5$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$4$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$5$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			      <p>
            <span>This means that choosing all unknowns equal to $0$ is a solution. Therefore a homogeneous system of linear equations always has at least one solution, namely $x_1=\cdots =x_n=0$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called inhomogeneous if at least one of its augmented constants is different from $0$. This implies that setting all variables equal to $0$ can never be a solution of an inhomogeneous system.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$1$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$3$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$9$}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 11 \\
%
\colorbox{lightgreen}{20}{\color{red}x_1}\ +\ \colorbox{lightgreen}{0}{\color{red}x_2}\ +\ \colorbox{lightgreen}{3}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5} \ +\ \colorbox{lightgreen}{$0$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 2 \\
%
\colorbox{lightgreen}{$10$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_5}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$9$}{\color{red}x_7} &amp; = &amp; -3 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4225" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a homogeneous system of linear equations and an inhomogeneous system of linear equations.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>homomorphism     </span><ul class='chilren'><li><span>of vector spaces     </span><a id='glossaryinfo-6359' class='msm_infobutton' onmouseover='infoopen(6359)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6359' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6379' onmouseover='infoopen(6379)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6379' style='display:none;'><div class='title'>Explanation: Meaning of the Linear Transformation Properties</div><p xmlns="Unit">
               <span>A linear transformation $L\from \RNr{n} \to \RNr{m}$ satisfies the identities</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>What do these identities mean? – The short answer is that a linear $L$ commutes with the operations ‘vector addition’ and ‘scalar multiplication’. For a more detailed description, read on:</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the sum in $\RNr{n}$: $\Vect{x} + \Vect{y}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $(\Vect{x} +\Vect{y})$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result is the vector $L(\Vect{x}+\Vect{y})$ of $\RNr{m}$. It must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{y}$ into the vector $L(\Vect{y})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the sum $L(\Vect{x}) + L(\Vect{y})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First add $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, then transform the sum vector $\Vect{x}+\Vect{y}$ using $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ and $\Vect{y}$ individually, and then add the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$ in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first add and then transform or if we first transform and then add. This is what it means when we say: $L$ commutes with vector addition.</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with a number $t$ and a vector $\Vect{x}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the scalar product in $\RNr{n}$: $t\cdot \Vect{x}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $t\cdot \Vect{x}$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the scalar product $t\cdot L(\Vect{x})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First scalar multiply $\Vect{x}$ by the scalar $t$, then transform the resulting vector $t\cdot \Vect{x}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ using $L$, and then scalar multiply the transformed vector by $t$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first scalar multiply and then transform or if we first transform and then scalar multiply. This is what it means when we say: $L$ commutes with scalar multiplication.</span>
            </p><p xmlns="Unit">
               <span>Examples of two processes which do not commute include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Putting socks and shoes on.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Washing the salad and eating it (a cynical recommendation offered by a computing scientist to a fellow worker who just refused to pay attention to the order in which he invoked certain functions in his code).</span>
                  </p>
               </li>
            </ul></div><div id="dialog-6379" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation of the meaning of the requirements we place here on a linear transformation.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>hyperspace     </span><a id='glossaryinfo-2344' class='msm_infobutton' onmouseover='infoopen(2344)'>i</a><div id="dialog-2344" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The hyperspace in $\RNr{n}$ perpendicular to a nonzero vector $\Vect{n}$  is the set</span>
                                 </p>
                                 <p align="center">
                                    <span>
                                       $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2344' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-2328' onmouseover='popup(2328)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-2328" class="dialogs" title="Explanation: How to read this expression"><info xmlns="Unit">
                           
                           <p>
                              <span>Read $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$ as:</span>
                           </p>
                           <p>
                              <span>‘Perp of $\Vect{n}$ is defined to be the set of all those $\Vect{x}$ in $\RNr{}\ \ n$ such that the dot product of $\Vect{x}$ and $\Vect{n}$ is $0$’.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-2342' onmouseover='infoopen(2342)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2342' style='display:none;'><div class='title'>Hyperspace – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate the concept of a hyperspace in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{2}$ is just a line through the origin. Thus the red line in the picture below is a hyperspace. We characterize it as the collection of all those vectors which are perpendicular to the green vector $\Vect{n}$, called a normal vector to the hyperspace.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace2D.png' height='274.4' width='350'/></div><p xmlns="Unit">
               <span>Notice that a hyperspace has many normal vectors: if $\Vect{n}$ is a normal  vector, so are $2\cdot \Vect{n}$, $3\cdot \Vect{n}$, $(-1)\cdot \Vect{n}$ and, in general, $t\cdot \Vect{n}$ for any $t\neq 0$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{3}$ is just a plane, in the usual sense of the word, which passes through the origin.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace3D.gif" height="328.43942505133" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, if we call the hyperspace $H$, then the blue arrow $\Vect{n}$, is called a normal vector of $H$ because it is perpendicular to all those vectors which belong to $H$. The second plane in this picture (horizontal) is only there to provide visual reference points. Note that any non-zero multiple of $\Vect{n}$ is also a normal vector of $H$: if $n\geq 1$, there are always many normal vectors to a given hyperspace.</span>
            </p><p xmlns="Unit">
               <span>If $n \geq 4$, we cannot visualize a hyperspace in $\RNr{n}$. Still we can characterize it as the collection of all those vectors in $\RNr{n}$ which are perpendicular to a given nonzero vector $\Vect{n}$.</span>
            </p></div><div id="dialog-2342" class="dialogs" title="Illustration"><info xmlns="Unit">
                           
                           <p>
                              <span>For this definition to make sense we need to recall that the word ‘normal’ here means ‘perpendicular’. So $\text{Perp}(\Vect{n})$ consists of all those $\Vect{x}$ which are perpendicular to the given vector $\Vect{n}$. The mathematical test for being perpendicular is: $\DotPr{\Vect{x}}{\Vect{n}} = 0$.</span>
                           </p>
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>identity     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4833' class='msm_infobutton' onmouseover='infoopen(4833)'>i</a><div id="dialog-4833" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4833' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4831' onmouseover='infoopen(4831)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-4831' style='display:none;'><div class='title'>Illustration of Identity Matrices</div><p xmlns="Unit">
               <span>The $(1,1)$-identity matrix is</span>
            </p>$$\IdMtrx{1}\ =\ [1]$$<p xmlns="Unit">
               <span>The $(2,2)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{2}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 \\
					0 &amp; 1
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>The $(3,3)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{3}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>The $(4,4)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{4}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0  \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$</div><div id="dialog-4831" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>A display of the identity matrices $\IdMtrx{1}$, $\IdMtrx{2}$, $\IdMtrx{3}$, $\IdMtrx{4}$.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>linear transformation of $\RNr{n}$     </span><a id='glossaryinfo-6872' class='msm_infobutton' onmouseover='infoopen(6872)'>i</a><div id="dialog-6872" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6872' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6868' onmouseover='infoopen(6868)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6868' style='display:none;'><div class='title'>The Identity Transformation</div><p xmlns="Unit">
               <span>The identity transformation on $\RNr{n}$ is given by</span>
            </p>$$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$<p xmlns="Unit">
               <span>Why is it called the ‘identity transformation’? In general a linear transformation of $\RNr{n}$ changes location, size or shape of objects contained in it. However, there is one transformation which does not cause any change at all. This is the identity transformation. It sends every $\Vect{x}$ in $\RNr{n}$ to itself: </span>
            </p><p xmlns="Unit">
               <span>To find the matrix representing $\IdTrafo{n}$, we note that each basic vector $\StdBss{j}$ gets transformed into itself. </span>
            </p>$$\IdTrafo{n}(\StdBss{j}) = 1\cdot \StdBss{j} = (0,\dots ,0,1,0,\dots ,0)$$<p xmlns="Unit">
               <span>the ‘$1$’ appearing in position $j$. Therefore $\IdTrafo{n}$ is represented by the identity matrix of size $(n,n)$.</span>
            </p>$$
					
\IdMtrx{n}= 
\left[
\begin{array}{cccc}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1
\end{array}
\right]
					
				$$</div><div id="dialog-6868" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Details on the identity transformation</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>image     </span><ul class='chilren'><li><span>of element under a function     </span><a id='glossaryinfo-6181' class='msm_infobutton' onmouseover='infoopen(6181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6181' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>image of a linear map     </span><a id='glossaryinfo-18618' class='msm_infobutton' onmouseover='infoopen(18618)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18618' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18647' onmouseover='infoopen(18647)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18647' style='display:none;'><div class='title'>Kernel / Image - Explanation</div><p xmlns="Unit">
               <span>
                  <b>On the definition of ‘kernel’:</b>
               </span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Ker{L}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$:=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$</td></tr></table><p xmlns="Unit">
               <span>Read this as: ‘kernel of L is, by definition, equal to the set of all those x in V such that L of x equals 0.’</span>
            </p><p xmlns="Unit">
               <span>Thus the kernel of $L$ consists of all those $\Vect{x}$ in $V$ with $L(\Vect{x}) = \Vect{0}$; that is the kernel of $L$ consists of those vectors of $V$ which get transformed into the $\Vect{0}$-vector by $L$.</span>
            </p><p xmlns="Unit">
               <span>If several vectors of $V$ get transformed into one, then this means that the distinction that previously existed between these vectors has been destroyed. Accordingly, a large kernel corresponds to a highly destructive map. A small kernel corresponds to a map which preserves most of the distinctions between various vectors of $V$. So such a map is less destructive or more faithful.</span>
            </p><p xmlns="Unit">
               <span>We will see soon that the kernel of $L$ is a subvector space of $V$. So it has a dimension, and this dimension provides a measure for the destructiveness of $L$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>On the definition of ‘image’:</b>
               </span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\im(L)$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$:=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table><p xmlns="Unit">
               <span>Read this as: ‘image of L is, by definition, equal to the set of all those y in W such that L of x equals y, for some x in V.’</span>
            </p><p xmlns="Unit">
               <span>In other words, a vector $\Vect{w}$ in $W$ belongs to the image of $L$ if the equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{x})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{y}$</td></tr></table><p xmlns="Unit">
               <span>has a solution or, in equivalently, if there is a vector in $V$ which gets transformed in $\Vect{y}$ by $L$.</span>
            </p><p xmlns="Unit">
               <span>Thus $\im(L)$ consists of all those $\Vect{y}$ in $W$ into which $L$ transforms some $\Vect{x}$ in $V$. Therefore $L$ transforms $V$ into its image $\im(L)$.</span>
            </p><p xmlns="Unit">
               <span>We will soon see that $\im(L)$ is a subspace of $W$.</span>
            </p></div><div id="dialog-18647" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Details on the definition of ‘kernel’ and ‘image’.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>inconsistent     </span><ul class='chilren'><li><span>system of linear equations     </span><a id='glossaryinfo-3664' class='msm_infobutton' onmouseover='infoopen(3664)'>i</a><div id="dialog-3664" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3664' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3485' onmouseover='popup(3485)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-3485" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words, the simultaneous solutions of the given system of linear equations consists of the intersection of the hyperplanes $H_1,\dots ,H_n$.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3544' onmouseover='infoopen(3544)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3544' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{2}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2)$ and $\Vect{n}_2 = (b_1,b_2)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3522" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2NonParallel.gif" height="285" width="455" usemap="#TwoEqnsR2NonParallel"/><map name="TwoEqnsR2NonParallel"><area id="pic-3524" coords="264,126,292,93,294,50,275,44,238,104,251,114" shape="poly" href="#" onmouseover="popup(3524)"><div id="dialog-3524" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3526" coords="202,214,186,166,171,152,154,174,159,188,174,186,191,222,202,218" shape="poly" href="#" onmouseover="popup(3526)"><div id="dialog-3526" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3528" coords="374,220,378,206,323,169,314,180,368,218" shape="poly" href="#" onmouseover="popup(3528)"><div id="dialog-3528" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3530" coords="302,153,242,114,106,14,98,29,284,157" shape="poly" href="#" onmouseover="popup(3530)"><div id="dialog-3530" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3532" coords="323,164,426,109,414,96,312,149,323,168" shape="poly" href="#" onmouseover="popup(3532)"><div id="dialog-3532" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3534" coords="300,181,146,262,138,250,200,220,288,168,299,176" shape="poly" href="#" onmouseover="popup(3534)"><div id="dialog-3534" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3536" coords="308,169,5" shape="circle" href="#" onmouseover="popup(3536)"><div id="dialog-3536" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two nonparallel lines in the plane $\RNr{2}$always have a unique point of intersection. This is the one and only simultaneous solution of the two given equations.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with normal vector $\Vect{n}_1$ is the line $H_1$, while</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the solution hyperplane of the second the equation, with normal vector $\Vect{n}_2$, is the line $H_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel, the lines $H_1$ and $H_2$ are not parallel either. So these lines intersect precisely in one point, denoted here $(x_0,y_0)$. This means that there is exactly one solution of the given system of linear equations, namely:</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x = x_0$   and   $y = y_0$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Question</b>   Amongst all the systems of two linear equations with two unknowns, "how often" do we encounter the situation that there is exactly one common solution?</span>
            </p><div id="dialog-3543" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>This statement has only intuitive value here. It can be made precise using a combination of the more advanced mathematical subjects of measure theory and geometric probability.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Answer</b> &#xA0; Exactly one solution occurs exactly when the solution lines of the individual equations are not parallel. Now, given two arbitrary lines in the plane, their 
				<a id="hottag-3543" class="hottag" onmouseover="popup(3543)"> chances</a>  
				of not being parallel are greater than their chances of being parallel. Therefore "most of the time" a system of two linear equations in two unknowns will have exactly one solution.</span>
            </p>
</div><div id="dialog-3544" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3578' onmouseover='infoopen(3578)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3578' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{3}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2,a_3)$ and $\Vect{n}_2 = (b_1,b_2,b_3)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3554" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3NonParallel.gif" height="281" width="333" usemap="#TwoEqnsR3NonParallel"/><map name="TwoEqnsR3NonParallel"><area id="pic-3556" coords="109,8,8" shape="circle" href="#" onmouseover="popup(3556)"><div id="dialog-3556" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This red dot marks the origin in $\RNr{3}$.</span>
                                 </p>
                              </info></div></area><area id="pic-3558" coords="95,28,61,68,50,66,95,11,104,18" shape="poly" href="#" onmouseover="popup(3558)"><div id="dialog-3558" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3560" coords="27,91,31,107,1,139,2,118" shape="poly" href="#" onmouseover="popup(3560)"><div id="dialog-3560" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3562" coords="111,21,121,12,169,80,160,86" shape="poly" href="#" onmouseover="popup(3562)"><div id="dialog-3562" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3564" coords="205,126,194,133,218,166,229,159" shape="poly" href="#" onmouseover="popup(3564)"><div id="dialog-3564" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3566" coords="216,122,240,108,316,277,70,220,191,139,216,171,233,158,211,126,211,126,211,126" shape="poly" href="#" onmouseover="popup(3566)"><div id="dialog-3566" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3568" coords="82,49,133,63,63,183,11,32,57,46,42,68,55,81,77,53,77,53" shape="poly" href="#" onmouseover="popup(3568)"><div id="dialog-3568" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3570" coords="39,125,62,185,18,141,38,129" shape="poly" href="#" onmouseover="popup(3570)"><div id="dialog-3570" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3572" coords="157,55,229,9,332,41,78,201,68,191,138,69,142,67,163,95,181,83" shape="poly" href="#" onmouseover="popup(3572)"><div id="dialog-3572" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with coefficient vector $\Vect{n}_1$ pointing down-left, is a plane in the ordinary sense perpendicular to $\Vect{n}_1$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The solution hyperplane of the second equation, with coefficient vector $\Vect{n}_2$ pointing down-right, is a plane perpendicular to $\Vect{n}_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors of these planes are not parallel, these planes are not parallel either. So these planes intersect in a line $L$. Each point on $L$ represents a common solution of both equations, and the intersection line consists of all possible simultaneous solutions of these equations.</span>
            </p><p xmlns="Unit">
               <span>For emphasis, let us say in different words what this means: Pick a vector $\Vect{x}$ in $\RNr{3}$. Then $\Vect{x}$ is given by three coordinates: $(x_0,y_0,z_0)$. So these are three numbers, and choosing</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x:=x_0$   and   $y:=y_0$   and   $z:=z_0$
               </span>
            </p><p xmlns="Unit">
               <span>renders both equations true simultaneously if and only if $\Vect{x}$ belongs to the line of intersection of the two solution hyperplanes of the given equations.</span>
            </p></div><div id="dialog-3578" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3620' onmouseover='infoopen(3620)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3620' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3592" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3594" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3594)"><div id="dialog-3594" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3596" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3596)"><div id="dialog-3596" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3598" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3598)"><div id="dialog-3598" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3600" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3600)"><div id="dialog-3600" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3602" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3602)"><div id="dialog-3602" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3604" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3604)"><div id="dialog-3604" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3606" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3606)"><div id="dialog-3606" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3608" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3608)"><div id="dialog-3608" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3611" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3613" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3613)"><div id="dialog-3613" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3615" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3615)"><div id="dialog-3615" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3617" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3617)"><div id="dialog-3617" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3620" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3661' onmouseover='infoopen(3661)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3661' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3633" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3635" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3635)"><div id="dialog-3635" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3637" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3637)"><div id="dialog-3637" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3639" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3639)"><div id="dialog-3639" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3641" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3641)"><div id="dialog-3641" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3643" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3643)"><div id="dialog-3643" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3645" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3645)"><div id="dialog-3645" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3647" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3647)"><div id="dialog-3647" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3649" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3649)"><div id="dialog-3649" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3652" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3654" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3654)"><div id="dialog-3654" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3656" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3656)"><div id="dialog-3656" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3658" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3658)"><div id="dialog-3658" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3661" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>inhomogeneous     </span><ul class='chilren'><li><span>linear equation     </span><a id='glossaryinfo-3277' class='msm_infobutton' onmouseover='infoopen(3277)'>i</a><div id="dialog-3277" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = c$$
					                   <p>
                           <span>with $c \neq 0$. Look up the definition.</span>
                        </p>
				                 </info></div></li></ul></li><li><span>inhomogeneous system of linear equations     </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4225' onmouseover='infoopen(4225)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4225' style='display:none;'><div class='pack'><div class='title'>Homogeneous and Inhomogeneous Systems of Linear Equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called homogeneous if all of the augmented constants are $0$.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$3$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{-1}{\color{red}x_1}\ +\ \colorbox{lightgreen}{2}{\color{red}x_2}\ -\ \colorbox{lightgreen}{1}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$4$}{\color{red}x_5} \ -\ \colorbox{lightgreen}{$6$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$5$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$4$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$5$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			      <p>
            <span>This means that choosing all unknowns equal to $0$ is a solution. Therefore a homogeneous system of linear equations always has at least one solution, namely $x_1=\cdots =x_n=0$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called inhomogeneous if at least one of its augmented constants is different from $0$. This implies that setting all variables equal to $0$ can never be a solution of an inhomogeneous system.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$1$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$3$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$9$}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 11 \\
%
\colorbox{lightgreen}{20}{\color{red}x_1}\ +\ \colorbox{lightgreen}{0}{\color{red}x_2}\ +\ \colorbox{lightgreen}{3}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5} \ +\ \colorbox{lightgreen}{$0$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 2 \\
%
\colorbox{lightgreen}{$10$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_5}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$9$}{\color{red}x_7} &amp; = &amp; -3 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4225" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a homogeneous system of linear equations and an inhomogeneous system of linear equations.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>inverse     </span><ul class='chilren'><li><span>of a linear transformation     </span><a id='glossaryinfo-7839' class='msm_infobutton' onmouseover='infoopen(7839)'>i</a><div id="dialog-7839" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7839' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7803' onmouseover='infoopen(7803)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7803' style='display:none;'><div class='pack'><div class='title'>Invertible Linear Transformation: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>There is a special collection of linear transformations, called invertible, whose effect on space can be reversed. Here is an example: A dilation $D\from \RNr{n}\to \RNr{n}$ by the factor $ c &gt; 1 $ magnifies distances by the factor $c$. The effect of such a dilation can be reversed by a contraction with factor $1/c$.</span>
         </p>
			
			      <p>
            <span>The picture below illustrates this situation for $D\from \RNr{2}\to \RNr{2}$ with magnification factor $c=3/2$. Accordingly the $D$-inverting contraction $C$ has contraction factor $2/3$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/DilateContract.png" height="147" width="350"/></div>
			
			      <p>
            <span>Notice how $D$ and $C$ undo each other&#x2019;s transformation effect:</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$D\Comp C$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$C\Comp D$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr></table>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-7803" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An example of an invertible linear transformation</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-7829' onmouseover='popup(7829)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-7829" class="dialogs" title="Comment on: Invertible linear transformation"><info xmlns="Unit">
                           
                           <p>
                              <span>Notice how nicely this definition captures the idea of reversing the effect of the transformation $L$: The identity transformation $\Id{n}$ on $\RNr{n}$ leaves every point where it is. Thus to require that $M\Comp L=\Id{n}$ forces $\Mtrx{M}$ to reverse the effect of $L$. Likewise, to require that $L\Comp M=\Id{n}$ forces $\Mtrx{L}$ to reverse the effect of $\Mtrx{M}$ as well:</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of a $(2,2)$-matrix     </span><a id='glossaryinfo-10998' class='msm_infobutton' onmouseover='infoopen(10998)'>i</a><div id="dialog-10998" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10998' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-11010' onmouseover='infoopen(11010)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-11010' style='display:none;'><div class='pack'><div class='title'>Inverse of a (2,2)-Matrix</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the inverse of the $(2,2)$-matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rr}
3 &amp; 4 \\
1 &amp; 7
\end{array}
\right]

				$$
			
			      <p>
            <span>provided it exists.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To test whether $\Mtrx{A}$ is invertible, we compute:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{A})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$17 \neq 0$</td></tr></table>
			            <p>
                  <span>Therefore $\Mtrx{A}$ is invertible. According to the formula for the inverse of an invertible  (2,2)-matrix, we find</span>
               </p>
			            $$
					
\aligned
A^{-1}\ &amp;=\ \frac{1}{\text{det}(A)}\,
\left[
\begin{array}{rr}
7 &amp; -4 \\
-1 &amp; 3
\end{array}\right] \\
   &amp;=\ \frac{1}{17}\,
   \left[
\begin{array}{rr}
7 &amp; -4 \\
-1 &amp; 3
\end{array}\right]
\endaligned

				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-11010" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of inverting a $(2,2)$-matrix</span>
         </p>
      </info></div></ul></div><br /></div></li></ul></li><li><span>inversion     </span><a id='glossaryinfo-6943' class='msm_infobutton' onmouseover='infoopen(6943)'>i</a><div id="dialog-6943" class="dialogs" title="What is an inversion?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An inversion is a linear transformation $T$ of $\RNr{n}$ of the form $T(\Vect{x})= -\Vect{x}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6943' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6897' onmouseover='infoopen(6897)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6897' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6897" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘dilation’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6915' onmouseover='infoopen(6915)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6915' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6915" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘contraction’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6933' onmouseover='infoopen(6933)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6933' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6933" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘inversion’</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>invertible     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-5344' class='msm_infobutton' onmouseover='infoopen(5344)'>i</a><div id="dialog-5344" class="dialogs" title="Invertible Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>An analysis which motivates the concept of an invertible matrix.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5344' style='display:none;'><div class='title'>Matrix Multiplication: Exceptional Properties</div><p xmlns="Unit">
               <span>Let us recall: So far we have extended the operations of addition and multiplication of numbers to the world of matrices. How about division? i.e. how can we make sense of an expression like this one?
				</span>
               
            </p>$$
					
					\dfrac{
					\left[
					\begin{array}{rr}
					4 &amp; 3 \\
					1 &amp; 0
					\end{array}
					\right] }{
					\left[
					\begin{array}{rr}
					7 &amp; 4 \\
					5 &amp; 3
					\end{array}
					\right]}
					
				$$<p xmlns="Unit">
               <span>To answer this question, let us analyze division by a number to get an idea of how to extend division to the world of matrices: Dividing a number $x$ by another, say $2$, amounts to multiplying $x$  by  $1/2=2^{-1}$. Now, the number $1/2$ is characterized by the property</span>
            </p>$$2\cdot (1/2)\ =\ 1\ (1/2)\cdot 2$$<p xmlns="Unit">
               <span>This is the key: Our goal is to divide an $(n,n)$-matrix $\Mtrx{X}$ by another $(n,n)$-matrix $\Mtrx{A}$. So, if we can find a matrix $\Mtrx{B}$ with</span>
            </p>$$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$<p xmlns="Unit">
               <span>then it makes sense to define $\Mtrx{A}^{-1} := B$. So then we can define</span>
            </p>$$\dfrac{\Mtrx{X}}{\Mtrx{A}}\ :=\ \Mtrx{X}\cdot \Mtrx{B}$$<p xmlns="Unit">
               <span>
                  <b>Alert</b>   Here is a new point which we must really pay attention to: In the world of matrices there are two ways of multiplying $\Mtrx{X}$by $\Mtrx{A}$. Reason:</span>
            </p><div id="dialog-5390" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Review an example of this phenomenon.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-5390' style='display:none;'><div class='title'>Matrix Multiplication: Exceptional Properties</div><p xmlns="Unit">
               <span>Most rules for computing with numbers continue to hold when we compute with matrices, but not all: The multiplication of matrices is more delicate because there are two basic exceptions:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Exception 1</b>   When multiplying two matrices $A$ and $B$, the products $AB$ and $BA$ need not be the same, even if both products are defined. – For example</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$[1\ \ 4\ \ 3] \cdot \left[\begin{array}{r} 5 \\ -2 \\ 7 \end{array}\right]$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$[ 18 ]$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\left[\begin{array}{r} 5 \\ -2 \\ 7 \end{array}\right] \cdot [ 1\ \ 4\ \ 3 ]$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rrr}
					5 &amp; 20 &amp; 15 \\
					-2 &amp; -8 &amp; -6 \\
					7 &amp; 28 &amp; 21
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>In this case the two products don't even have the same size. So they cannot be equal. However, difference in size is not the only possible reason why $AB$ might be different from $BA$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right] \cdot
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					-48 &amp; -36 \\
					64 &amp; 48
					\end{array}\right]
					
				$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					0 &amp; 0 \\
					0 &amp; 0
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>Here $AB$ and $BA$ are both of size $(2,2)$. Still, they are distinct.</span>
            </p><div id="dialog-5380" class="dialogs" title="What is the 0-matrix?"><info xmlns="Unit">
                        
                        <p>
                           <span>A matrix all of whose entries are $0$ is called a $0$-matrix.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Exception 2</b> &#xA0; If $AX$ is the
				<a id="hottag-5380" class="hottag" onmouseover="popup(5380)"> 0-matrix</a>  ,
				it need not be true that at least one of $A$ or $X$ is the 0-matrix.</span>
            </p>
<p xmlns="Unit">
               <span>If $ax=0$ is an equation of numbers, and we know that $a\neq 0$, we conclude immediately that $x=0$. It is very tempting to assume that we can draw the same conclusion when presented with a matrix equation like</span>
            </p>$$AX = \mathbf{0}$$<p xmlns="Unit">
               <span>However, the example below shows that, in this situation, neither $A$ nor $X$ need be $\mathbf{0}$.</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					0 &amp; 0 \\
					0 &amp; 0
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>Therefore, a matrix identity like $\Mtrx{A}\Mtrx{X} = \Vect{0}$ by itself does not support the conclusion that $\Mtrx{A}$ or $\Mtrx{X}$ are $\Vect{0}$.</span>
            </p></div>
<p xmlns="Unit" align="center">
               <span>
                  $\Mtrx{B}\Mtrx{X}$ &#xA0; is 
				<a id="activehottag-5390" class="activehottag" onmouseover="infoopen(5390)"> generally distinct</a>  
				from $\Mtrx{X}\Mtrx{B}$.
			</span>
            </p>
<p xmlns="Unit">
               <span>Accordingly, we must carefully decide whether we want to</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the left; i.e. form the product  $\Mtrx{B}\Mtrx{X}$, or</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the right; i.e. form the product  $\Mtrx{X}\Mtrx{B}$.</span>
                  </p>
               </li>
            </ul></div></li><li><span>linear transformation     </span><a id='glossaryinfo-7833' class='msm_infobutton' onmouseover='infoopen(7833)'>i</a><div id="dialog-7833" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7833' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7803' onmouseover='infoopen(7803)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7803' style='display:none;'><div class='pack'><div class='title'>Invertible Linear Transformation: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>There is a special collection of linear transformations, called invertible, whose effect on space can be reversed. Here is an example: A dilation $D\from \RNr{n}\to \RNr{n}$ by the factor $ c &gt; 1 $ magnifies distances by the factor $c$. The effect of such a dilation can be reversed by a contraction with factor $1/c$.</span>
         </p>
			
			      <p>
            <span>The picture below illustrates this situation for $D\from \RNr{2}\to \RNr{2}$ with magnification factor $c=3/2$. Accordingly the $D$-inverting contraction $C$ has contraction factor $2/3$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/DilateContract.png" height="147" width="350"/></div>
			
			      <p>
            <span>Notice how $D$ and $C$ undo each other&#x2019;s transformation effect:</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$D\Comp C$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$C\Comp D$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr></table>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-7803" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An example of an invertible linear transformation</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-7829' onmouseover='popup(7829)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-7829" class="dialogs" title="Comment on: Invertible linear transformation"><info xmlns="Unit">
                           
                           <p>
                              <span>Notice how nicely this definition captures the idea of reversing the effect of the transformation $L$: The identity transformation $\Id{n}$ on $\RNr{n}$ leaves every point where it is. Thus to require that $M\Comp L=\Id{n}$ forces $\Mtrx{M}$ to reverse the effect of $L$. Likewise, to require that $L\Comp M=\Id{n}$ forces $\Mtrx{L}$ to reverse the effect of $\Mtrx{M}$ as well:</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>isomorphic linear transformation     </span><a id='glossaryinfo-18874' class='msm_infobutton' onmouseover='infoopen(18874)'>i</a><div id="dialog-18874" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18874' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>isomorphism     </span><a id='glossaryinfo-18878' class='msm_infobutton' onmouseover='infoopen(18878)'>i</a><div id="dialog-18878" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18878' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>kernel     </span><a id='glossaryinfo-8351' class='msm_infobutton' onmouseover='infoopen(8351)'>i</a><div id="dialog-8351" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>`kernel' appears here in the context of linear transformations providing another view toward linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8351' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-8333" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-8333" class="hottag" onmouseover="popup(8333)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-8348" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-8348' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-8348" class="activehottag" onmouseover="infoopen(8348)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li><li><span>kernel of a linear map     </span><a id='glossaryinfo-18618' class='msm_infobutton' onmouseover='infoopen(18618)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18618' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18647' onmouseover='infoopen(18647)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18647' style='display:none;'><div class='title'>Kernel / Image - Explanation</div><p xmlns="Unit">
               <span>
                  <b>On the definition of ‘kernel’:</b>
               </span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Ker{L}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$:=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$</td></tr></table><p xmlns="Unit">
               <span>Read this as: ‘kernel of L is, by definition, equal to the set of all those x in V such that L of x equals 0.’</span>
            </p><p xmlns="Unit">
               <span>Thus the kernel of $L$ consists of all those $\Vect{x}$ in $V$ with $L(\Vect{x}) = \Vect{0}$; that is the kernel of $L$ consists of those vectors of $V$ which get transformed into the $\Vect{0}$-vector by $L$.</span>
            </p><p xmlns="Unit">
               <span>If several vectors of $V$ get transformed into one, then this means that the distinction that previously existed between these vectors has been destroyed. Accordingly, a large kernel corresponds to a highly destructive map. A small kernel corresponds to a map which preserves most of the distinctions between various vectors of $V$. So such a map is less destructive or more faithful.</span>
            </p><p xmlns="Unit">
               <span>We will see soon that the kernel of $L$ is a subvector space of $V$. So it has a dimension, and this dimension provides a measure for the destructiveness of $L$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>On the definition of ‘image’:</b>
               </span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\im(L)$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$:=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table><p xmlns="Unit">
               <span>Read this as: ‘image of L is, by definition, equal to the set of all those y in W such that L of x equals y, for some x in V.’</span>
            </p><p xmlns="Unit">
               <span>In other words, a vector $\Vect{w}$ in $W$ belongs to the image of $L$ if the equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{x})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{y}$</td></tr></table><p xmlns="Unit">
               <span>has a solution or, in equivalently, if there is a vector in $V$ which gets transformed in $\Vect{y}$ by $L$.</span>
            </p><p xmlns="Unit">
               <span>Thus $\im(L)$ consists of all those $\Vect{y}$ in $W$ into which $L$ transforms some $\Vect{x}$ in $V$. Therefore $L$ transforms $V$ into its image $\im(L)$.</span>
            </p><p xmlns="Unit">
               <span>We will soon see that $\im(L)$ is a subspace of $W$.</span>
            </p></div><div id="dialog-18647" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Details on the definition of ‘kernel’ and ‘image’.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>kernel of a linear transformation     </span><a id='glossaryinfo-11546' class='msm_infobutton' onmouseover='infoopen(11546)'>i</a><div id="dialog-11546" class="dialogs" title="Kernel"><info xmlns="Unit">
                           
                           <p>
                              <span>The kernel of $L\from V\to W$ is the set of all $\Vect{x}\in V$ with $L(\Vect{x} )=\Vect{0}$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11546' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $V$ and $W$ be subspaces of $\RNr{n}$. The kernel of a linear transformation $L\from V\to W$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Ker{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11542" class="hottag" onmouseover="popup(11542)">$:=	$</a><div id="dialog-11542" class="dialogs" title="How do I read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#xA0;kernel of $L$ is by definition the set of all those $\Vect{x}$ in V such that $L$ of $\Vect{x}$ equals  zero.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st L(\Vect{x}) = \Vect{0} }$</td></tr></table>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11536' onmouseover='popup(11536)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-11536" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Read this as: ‘kernel of L is defined to be the set of all those x in V with L of x = 0’.</span>
                     </p>
                     <p>
                        <span>In words: $\Ker{L}$ is the collection of all those $\Vect{x}$ in $\RNr{n}$ for which $L(\Vect{x}) = \Vect{0}$.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>leading $1$     </span><a id='glossaryinfo-3857' class='msm_infobutton' onmouseover='infoopen(3857)'>i</a><div id="dialog-3857" class="dialogs" title="What is a leading $1$?"><info xmlns="Unit">
                                       
                                       <p>
                                          <span>The concept of ‘leading 1’ occurs within the context of linear equations in row reduced echelon form.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3857' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>left hand     </span><ul class='chilren'><li><span>orientation     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li><li><span>rule     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li></ul></li><li><span>length     </span><ul class='chilren'><li><span>of an arrow     </span><a id='glossaryinfo-662' class='msm_infobutton' onmouseover='infoopen(662)'>i</a><div id="dialog-662" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-662' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-651' onmouseover='infoopen(651)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-651' style='display:none;'><div class='title'>Illustration: Length of an Arrow</div><p xmlns="Unit">
               <span>The length of the arrow joining $P(x_1,\dots ,x_n)$ to $Q(y_1,\dots ,y_n)$ is given by the formula</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/ArrowLength_Illstrtn.gif" height="142.87257019438" width="350"/></div>
               </span>
            </p>
$$\Abs{ \overset{\longrightarrow}{PQ} }\ :=\ \text{dist}(P,Q)\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$<p xmlns="Unit">
               <span>This means that the length of an arrow is defined to be the distance between its end points.</span>
            </p></div><div id="dialog-651" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Illustration of Length of an Arrow</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-658' onmouseover='infoopen(658)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-658' style='display:none;'><div class='pack'><div class='title'>Length of an Arrow: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the length of the arrow joining the point $P(4,-1,11)$ to the point $Q(-2,6,4)$ in $\RNr{3}$.  
			</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The length of the arrow $\Arrow{P}{Q}$ is the distance from $P$ to $Q$:</span>
               </p>
			            $$
					
					\aligned
\Length{\Arrow{P}{Q}}\ &amp;=\ \Dstnc{P}{Q} \\
					&amp; =\ \sqrt{(-2-4)^2+(6-(-1))^2+(4-11)^2} \\
					&amp; =\ \sqrt{36+49+49} \\
					&amp; =\ \sqrt{134}
					\endaligned
					
				$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the length of the arrow joining the point $A(1,3,0,5)$ to the point $B(2,1,-2,4)$ in $\RNr{4}$.  
			</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The length of the arrow $\Arrow{A}{B}$ is the distance from $A$ to $B$:</span>
               </p>
			            $$
					
					\aligned
\Length{\Arrow{A}{B}}\ &amp;=\ \Dstnc{A}{B} \\
					&amp; =\ \sqrt{(2-1)^2 + (1-3)^2 + ((-2)-0)^2 + (4-5)^2 } \\
					&amp; =\ \sqrt{1 + 4 + 4 + 1} \\
					&amp; =\ \sqrt{10}
					\endaligned
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-658" class="dialogs" title="Example"><info xmlns="Unit">
                           
                           <p>
                              <span>Examples of computing the length of an arrow</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of a vector     </span><a id='glossaryinfo-1672' class='msm_infobutton' onmouseover='infoopen(1672)'>i</a><div id="dialog-1672" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1672' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-1666' onmouseover='popup(1666)'><span style='cursor:pointer'>Example</span></li><div id="dialog-1666" class="dialogs" title="Example of a Norm Computation"><info xmlns="Unit">
                     
                     <p>
                        <span>The norm of the vector $\Vect{x} = (1,2,2)$ in $\RNr{3}$ is</span>
                     </p>
                     $$\abs{\Vect{x}} = \sqrt{ 1^2 + 2^2 + 2^2 } = 3$$
                  </info></div><li class='defminibutton' id='defminibutton-1668' onmouseover='popup(1668)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1668" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the length of $\Vect{x}$ is obtained by summing up the squares of the components of $\Vect{x}$, and then taking the square root.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>level set     </span><ul class='chilren'><li><span>of a linear transformation     </span><a id='glossaryinfo-17260' class='msm_infobutton' onmouseover='infoopen(17260)'>i</a><div id="dialog-17260" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17260' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-17256" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-17256" class="hottag" onmouseover="popup(17256)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-17271" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-17271' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-17271" class="activehottag" onmouseover="infoopen(17271)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li></ul></li><li><span>linear     </span><ul class='chilren'><li><span>motion     </span><a id='glossaryinfo-1129' class='msm_infobutton' onmouseover='infoopen(1129)'>i</a><div id="dialog-1129" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>A motion of a particle whose location at time $t$ has position vector $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$. – Click to see to the definition.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1129' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-1131" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘ell of $t$ equals a plus t times v’</span>
                              </p>
                           </info></div><div id="dialog-1135" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘t in R’, which means: $t$ is a number in $\RNr{}$.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <a id="hottag-1131" class="hottag" onmouseover="popup(1131)"> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </a>  , with <a id="hottag-1135" class="hottag" onmouseover="popup(1135)"> 
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>equation     </span><a id='glossaryinfo-17270' class='msm_infobutton' onmouseover='infoopen(17270)'>i</a><div id="dialog-17270" class="dialogs" title="linear equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17270' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>function     </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15302' onmouseover='infoopen(15302)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15302' style='display:none;'><div class='title'>Explanation: Meaning of the Linear Transformation Properties</div><p xmlns="Unit">
               <span>A linear transformation $L\from \RNr{n} \to \RNr{m}$ satisfies the identities</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>What do these identities mean? – The short answer is that a linear $L$ commutes with the operations ‘vector addition’ and ‘scalar multiplication’. For a more detailed description, read on:</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the sum in $\RNr{n}$: $\Vect{x} + \Vect{y}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $(\Vect{x} +\Vect{y})$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result is the vector $L(\Vect{x}+\Vect{y})$ of $\RNr{m}$. It must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{y}$ into the vector $L(\Vect{y})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the sum $L(\Vect{x}) + L(\Vect{y})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First add $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, then transform the sum vector $\Vect{x}+\Vect{y}$ using $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ and $\Vect{y}$ individually, and then add the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$ in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first add and then transform or if we first transform and then add. This is what it means when we say: $L$ commutes with vector addition.</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with a number $t$ and a vector $\Vect{x}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the scalar product in $\RNr{n}$: $t\cdot \Vect{x}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $t\cdot \Vect{x}$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the scalar product $t\cdot L(\Vect{x})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First scalar multiply $\Vect{x}$ by the scalar $t$, then transform the resulting vector $t\cdot \Vect{x}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ using $L$, and then scalar multiply the transformed vector by $t$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first scalar multiply and then transform or if we first transform and then scalar multiply. This is what it means when we say: $L$ commutes with scalar multiplication.</span>
            </p><p xmlns="Unit">
               <span>Examples of two processes which do not commute include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Putting socks and shoes on.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Washing the salad and eating it (a cynical recommendation offered by a computing scientist to a fellow worker who just refused to pay attention to the order in which he invoked certain functions in his code).</span>
                  </p>
               </li>
            </ul></div><div id="dialog-15302" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation of the meaning of the requirements we place here on a linear transformation.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>transformation     </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15302' onmouseover='infoopen(15302)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15302' style='display:none;'><div class='title'>Explanation: Meaning of the Linear Transformation Properties</div><p xmlns="Unit">
               <span>A linear transformation $L\from \RNr{n} \to \RNr{m}$ satisfies the identities</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>What do these identities mean? – The short answer is that a linear $L$ commutes with the operations ‘vector addition’ and ‘scalar multiplication’. For a more detailed description, read on:</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the sum in $\RNr{n}$: $\Vect{x} + \Vect{y}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $(\Vect{x} +\Vect{y})$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result is the vector $L(\Vect{x}+\Vect{y})$ of $\RNr{m}$. It must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{y}$ into the vector $L(\Vect{y})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the sum $L(\Vect{x}) + L(\Vect{y})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First add $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, then transform the sum vector $\Vect{x}+\Vect{y}$ using $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ and $\Vect{y}$ individually, and then add the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$ in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first add and then transform or if we first transform and then add. This is what it means when we say: $L$ commutes with vector addition.</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with a number $t$ and a vector $\Vect{x}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the scalar product in $\RNr{n}$: $t\cdot \Vect{x}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $t\cdot \Vect{x}$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the scalar product $t\cdot L(\Vect{x})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First scalar multiply $\Vect{x}$ by the scalar $t$, then transform the resulting vector $t\cdot \Vect{x}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ using $L$, and then scalar multiply the transformed vector by $t$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first scalar multiply and then transform or if we first transform and then scalar multiply. This is what it means when we say: $L$ commutes with scalar multiplication.</span>
            </p><p xmlns="Unit">
               <span>Examples of two processes which do not commute include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Putting socks and shoes on.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Washing the salad and eating it (a cynical recommendation offered by a computing scientist to a fellow worker who just refused to pay attention to the order in which he invoked certain functions in his code).</span>
                  </p>
               </li>
            </ul></div><div id="dialog-15302" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation of the meaning of the requirements we place here on a linear transformation.</span>
                           </p>
                        </info></div></ul></div><br /></div><ul class='chilren'><li><span>scaling     </span><a id='glossaryinfo-6879' class='msm_infobutton' onmouseover='infoopen(6879)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6879' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6897' onmouseover='infoopen(6897)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6897' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6897" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘dilation’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6915' onmouseover='infoopen(6915)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6915' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6915" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘contraction’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6933' onmouseover='infoopen(6933)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6933' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6933" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘inversion’</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>rotation     </span><a id='glossaryinfo-15890' class='msm_infobutton' onmouseover='infoopen(15890)'>i</a><div id="dialog-15890" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15890' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15870' onmouseover='popup(15870)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-15870" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Here we use the symbol $\theta$ to denote the angle through which we rotate. This is a Greek letter, pronounced ‘theta’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-15879' onmouseover='infoopen(15879)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15879' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by </span>
            </p>$$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>To understand where this matrix comes from, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Rotation.png' height='167.5625' width='350'/></div><p xmlns="Unit">
               <span>Both $R(\StdBss{1})$ and $R(\StdBss{2})$ result from rotating $\StdBss{1}$ and $\StdBss{2}$ counterclockwise about the origin through the angle $\theta$. So they are vectors of length $1$. Therefore the coordinates of these vectors are as indicated.</span>
            </p></div><div id="dialog-15879" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the rotation transformation</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-15884' onmouseover='infoopen(15884)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15884' style='display:none;'><div class='pack'><div class='title'>Example of a Rotation of the Plane</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the counterclockwise rotation of the plane about the origin through the angle of $60$ degrees.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The specified rotation transformation has $\theta = \tfrac{\pi}{3}$. Therefore it rotates</span>
               </p>
			            <ul>
				              <li>
                     <p>
                        <span>the vector $\StdBss{1}=(1,0)$ into the vector $(\cos\theta , \sin\theta) = (\tfrac{1}{2} , \tfrac{\sqrt{3}}{2})$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>the vector $\StdBss{2}=(0,1)$ into the vector $(-\sin\theta , \cos\theta) = (-\tfrac{\sqrt{3}}{2},\tfrac{1}{2})$.</span>
                     </p>
                  </li>
			            </ul>
			            <p>
                  <span>These vectors form the columns of the rotation matrix:</span>
               </p>
			            $$
					
R_{\pi/3} := 
\left[
\begin{array}{rr}
\tfrac{1}{2} &amp; -\tfrac{\sqrt{3}}{2} \\
\tfrac{\sqrt{3}}{2} &amp; \tfrac{1}{2}
\end{array}
\right]\ =\ \dfrac{1}{2}\,
\left[
\begin{array}{rr}
1 &amp; -\sqrt{3} \\
\sqrt{3} &amp; 1
\end{array}
\right]
					
				$$
			            <p>
                  <span>This means that a point $(x,y)\in\RNr{2}$ gets transformed into the point</span>
               </p>
			
			            $$
					
R_{\pi/3}(x,y) = 
\left[
\begin{array}{rr}
\tfrac{1}{2} &amp; -\tfrac{\sqrt{3}}{2} \\
\tfrac{\sqrt{3}}{2} &amp; \tfrac{1}{2}
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right] = \dfrac{1}{2}\cdot
\left[
\begin{array}{r} x - \sqrt{3}\, y \\ \sqrt{3}\, x + y \end{array}
\right]
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-15884" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a rotation of $\RNr{2}$
                        </span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>map     </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15302' onmouseover='infoopen(15302)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15302' style='display:none;'><div class='title'>Explanation: Meaning of the Linear Transformation Properties</div><p xmlns="Unit">
               <span>A linear transformation $L\from \RNr{n} \to \RNr{m}$ satisfies the identities</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>What do these identities mean? – The short answer is that a linear $L$ commutes with the operations ‘vector addition’ and ‘scalar multiplication’. For a more detailed description, read on:</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the sum in $\RNr{n}$: $\Vect{x} + \Vect{y}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $(\Vect{x} +\Vect{y})$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result is the vector $L(\Vect{x}+\Vect{y})$ of $\RNr{m}$. It must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{y}$ into the vector $L(\Vect{y})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the sum $L(\Vect{x}) + L(\Vect{y})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First add $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, then transform the sum vector $\Vect{x}+\Vect{y}$ using $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ and $\Vect{y}$ individually, and then add the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$ in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first add and then transform or if we first transform and then add. This is what it means when we say: $L$ commutes with vector addition.</span>
            </p><p xmlns="Unit">
               <span>What does the identity $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ mean?</span>
            </p><p xmlns="Unit">
               <span>This identity begins with a number $t$ and a vector $\Vect{x}$ in $\RNr{n}$, and then demands the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Form the scalar product in $\RNr{n}$: $t\cdot \Vect{x}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Transform the resulting vector $t\cdot \Vect{x}$ of $\RNr{n}$ with $L$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The result must be equal to the outcome of the process:</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $L$, transform $\Vect{x}$ into the vector $L(\Vect{x})$ of $\RNr{m}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\RNr{m}$, form the scalar product $t\cdot L(\Vect{x})$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>In other words, we get the same result along each of these two computational paths:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First scalar multiply $\Vect{x}$ by the scalar $t$, then transform the resulting vector $t\cdot \Vect{x}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>First transform $\Vect{x}$ using $L$, and then scalar multiply the transformed vector by $t$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So, it doesn’t matter if we first scalar multiply and then transform or if we first transform and then scalar multiply. This is what it means when we say: $L$ commutes with scalar multiplication.</span>
            </p><p xmlns="Unit">
               <span>Examples of two processes which do not commute include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Putting socks and shoes on.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Washing the salad and eating it (a cynical recommendation offered by a computing scientist to a fellow worker who just refused to pay attention to the order in which he invoked certain functions in his code).</span>
                  </p>
               </li>
            </ul></div><div id="dialog-15302" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation of the meaning of the requirements we place here on a linear transformation.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>transformation of $\RNr{n}$     </span><ul class='chilren'><li><span>identity     </span><a id='glossaryinfo-6874' class='msm_infobutton' onmouseover='infoopen(6874)'>i</a><div id="dialog-6874" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6874' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6868' onmouseover='infoopen(6868)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6868' style='display:none;'><div class='title'>The Identity Transformation</div><p xmlns="Unit">
               <span>The identity transformation on $\RNr{n}$ is given by</span>
            </p>$$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$<p xmlns="Unit">
               <span>Why is it called the ‘identity transformation’? In general a linear transformation of $\RNr{n}$ changes location, size or shape of objects contained in it. However, there is one transformation which does not cause any change at all. This is the identity transformation. It sends every $\Vect{x}$ in $\RNr{n}$ to itself: </span>
            </p><p xmlns="Unit">
               <span>To find the matrix representing $\IdTrafo{n}$, we note that each basic vector $\StdBss{j}$ gets transformed into itself. </span>
            </p>$$\IdTrafo{n}(\StdBss{j}) = 1\cdot \StdBss{j} = (0,\dots ,0,1,0,\dots ,0)$$<p xmlns="Unit">
               <span>the ‘$1$’ appearing in position $j$. Therefore $\IdTrafo{n}$ is represented by the identity matrix of size $(n,n)$.</span>
            </p>$$
					
\IdMtrx{n}= 
\left[
\begin{array}{cccc}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1
\end{array}
\right]
					
				$$</div><div id="dialog-6868" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Details on the identity transformation</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>combination     </span><a id='glossaryinfo-11806' class='msm_infobutton' onmouseover='infoopen(11806)'>i</a><div id="dialog-11806" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11806' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear combination</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>A linear combination of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $\RNr{n}$ is a vector $\Vect{x}$ of the form
					</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{s}_1 + \cdots + t_r \Vect{s}_r$</td></tr></table>
                        <p>
                           <span>where $t_1,\dots ,t_r$ are numbers in $\RNr{}$.</span>
                        </p>
                     </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11739' onmouseover='infoopen(11739)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11739' style='display:none;'><div class='title'>Linear Combination Interpreted Geometrically</div><p xmlns="Unit">
               <span>A linear combination of vectors $\Vect{s}_1, \dots ,\Vect{s}_r$ constructs a vector $\Vect{w}$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Start with $t_1$ times vector $\Vect{s}_1$;</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>now add $t_2$ times vector  $\Vect{s}_2$, ... until</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>add $t_r$ times vector $\Vect{s}_r$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>The result is the vector</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{w}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{s}_1 + \cdots + t_r \Vect{s}_r$</td></tr></table><p xmlns="Unit">
               <span>It has been ‘combined’ by adding up rescalings of the vectors $\Vect{s}_1$, ... , $\Vect{s}_r$.</span>
            </p><p xmlns="Unit">
               <span>The picture below shows two linear combinations of the vectors  $\Vect{x}$  and  $\Vect{y}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination1.gif' height='202.16284987277' width='350'/></div><p xmlns="Unit">
               <span>The vectors</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{w}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(1.5)\Vect{x} + (2.5)\Vect{y}$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(-1)\Vect{x} + (1.5)\Vect{y}$</td></tr></table><p xmlns="Unit">
               <span>have been formed as linear combinations of the vectors $\Vect{x}$ and $\Vect{y}$.</span>
            </p></div><div id="dialog-11739" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An illustration of how to interpret ‘linear combination’ geometrically</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-11804' onmouseover='infoopen(11804)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-11804' style='display:none;'><div class='pack'><div class='title'>Linear Combination: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The linear combinations of a single vector $\Vect{x}$ consist of all vectors of the form $t\cdot \Vect{x}$, where $t$ in $\RNr{}$ is arbitrary. &#x2013; The graphic below shows some linear combinations of $\Vect{x} = (2,1)$.</span>
         </p>
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination1_Anim.gif" height="239.0243902439" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a vector $\Vect{x}$ is a linear combination of two vectors $\Vect{u}$ and $\Vect{v}$ if there are numbers $s$ and $t$ in $\RNr{}$ such that</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s \Vect{u} + t \Vect{v}$</td></tr></table>
			      <p>
            <span>Now if $\Vect{x}$, $\Vect{u}$, and $\Vect{v}$ are given, The question arises: Are there numbers $s$ and $t$ so that $\Vect{x} = s \Vect{u} + t \Vect{v}$? and, if so, what are the possible choices of $s$ and $t$? &#x2013; In general, this question leads to a system of linear equations. The animation below illustrates this issue for the vectors</span>
         </p>
			      $$\Vect{u} = (-1,-1),\quad \Vect{v} = (2,1), \quad \text{and}\quad \Vect{x} = (1,-1)$$
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination2_Anim.gif" height="338.59470468432" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The animation goes through this progression:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{u}$ through $(1,-1)$ intersects the line $t \Vect{v}$ at $2 \Vect{v}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{v}$ through $(1,-1)$ intersects the line $s \Vect{u}$ at $3 \Vect{u}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>Therefore $\Vect{x} = 3 \Vect{u} + 2 \Vect{v}$.</span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>This expression of $\Vect{x}$ as a linear combination of $\Vect{u}$ and $\Vect{v}$ can be found formally as the unique solution of the system of linear equations</span>
               </p>
			            $$
					
\begin{array}{rcrcr}
-s &amp; + &amp; 2t &amp; = &amp; 1 \\
-s &amp; + &amp; t &amp; = &amp; -1
\end{array}

				$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>For another example of the previous type, let</span>
         </p>
			      $$\Vect{u} = (-1,-1),\quad \Vect{v} = (2,1), \quad \text{and}\quad \Vect{x} = (3,2)$$
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination3_Anim.gif" height="249.49083503055" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The animation goes through this progression:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{u}$ through $(3,2)$ intersects the line $t \Vect{v}$ at $1 \Vect{v}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{v}$ through $(3,2)$ intersects the line $s \Vect{u}$ at $(-1) \Vect{u}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>Therefore $\Vect{x} = (-1) \Vect{u} + \Vect{v}$.</span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>This expression of $\Vect{x}$ as a linear combination of $\Vect{u}$ and $\Vect{v}$ can be found formally as the unique solution of the system of linear equations</span>
               </p>
			            $$
					
\begin{array}{rcrcr}
-s &amp; + &amp; 2t &amp; = &amp; 3 \\
-s &amp; + &amp; t &amp; = &amp; 2
\end{array}

				$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Any vector $\Vect{x}=(x,y)$ in $\RNr{2}$ can be expressed uniquely as a linear combination of the vectors</span>
         </p>
			      $$\Vect{u} = (-1,-1)\quad \text{and} \quad \Vect{v} = (2,1)$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To express $\Vect{x}$ as a linear combination of $\Vect{u}$ and $\Vect{v}$, we need to solve the system of linear equations</span>
               </p>
			            $$
					
\begin{array}{rcrcr}
-s &amp; + &amp; 2t &amp; = &amp; x \\
-s &amp; + &amp; t &amp; = &amp; y
\end{array}

				$$
			            <p>
                  <span>The coefficient matrix of the system if</span>
               </p>
			            $$
					
A = 
\left[
\begin{array}{rr}
-1 &amp; 2 \\
-1 &amp; 1
\end{array}
\right]

				$$
			            <p>
                  <span>which has $\det(\Mtrx{A}) = 1\neq 0$. Therefore this system has a unique solution.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The animation below illustrates how to express the vector $\Vect{x} = (2,1,2)$ of $\RNr{3}$ as a linear combination of the vectors.</span>
         </p>
			      $$\Vect{u} = (1,0,1/2)\quad \text{and} \quad \Vect{v} = (0,1,1).$$
			      <div class="picture"/>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The animation goes through this progression:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{u}$ through $(2,1,2)$ intersects the line $t \Vect{v}$ at $1 \cdot \Vect{v}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>The line parallel to $\Vect{v}$ through $(2,1,2)$ intersects the line $s \Vect{u}$ at $2 \cdot \Vect{u}$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>Therefore $\Vect{x} = 2 \Vect{u} + \Vect{v}$.</span>
                     </p>
                  </li>
			            </ol>
			
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>With your mouse point to vectors which are linear combinations of $\Vect{x}$.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img id="image-11772" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination2.gif" height="208.90868596882" width="350" usemap="#LinearCombination2"/><map name="LinearCombination2"><area id="pic-11774" coords="146,210,148,218,259,205,256,191" shape="poly" href="#" onmouseover="popup(11774)"><div id="dialog-11774" class="dialogs" title="Comment on vector $\Vect{x}$                               ">
<info xmlns="Compositor">
                              
							
							                       <p>
                                 <span>
                                    $\Vect{x}$ itself is a linear combination of $\Vect{x}$ because</span>
                              </p>
							                       <math.array column="3">
                                 <tr rowspan="1">
                                    <td colspan="2" halign="center" valign="middle">
                                       $\Vect{x}$
                                    </td>
                                    <td colspan="1" halign="center" valign="middle">
                                       $=$
                                    </td>
                                    <td colspan="2" halign="center" valign="middle">
                                       $1\cdot \Vect{x}$
                                    </td>
                                 </tr>
                              </math.array>
						                     </info>
</div></area><area id="pic-11776" coords="261,191,264,205,320,198,316,182" shape="poly" href="#" onmouseover="popup(11776)"><div id="dialog-11776" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is a linear combination of $\Vect{x}$ as it can be expressed as (approximately) $(3/2)\cdot \Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11778" coords="322,182,324,194,446,180,445,162" shape="poly" href="#" onmouseover="popup(11778)"><div id="dialog-11778" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is a linear combination of $\Vect{x}$ as it can be expressed as (approximately) $(5/2)\cdot \Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11780" coords="115,220,119,215,1,225,1,243" shape="poly" href="#" onmouseover="popup(11780)"><div id="dialog-11780" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is a linear combination of $\Vect{x}$ as it can be expressed as (approximately) $(-1)\cdot \Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11782" coords="63,119,115,214,129,206,75,109" shape="poly" href="#" onmouseover="popup(11782)"><div id="dialog-11782" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is not parallel to $\Vect{x}$. Therefore it cannot be expressed in the form $t\cdot \Vect{x}$; i.e. it is not a linear combination of $\Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11784" coords="139,205,251,26,236,22,130,208" shape="poly" href="#" onmouseover="popup(11784)"><div id="dialog-11784" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is not parallel to $\Vect{x}$. Therefore it cannot be expressed in the form $t\cdot \Vect{x}$; i.e. it is not a linear combination of $\Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11786" coords="145,201,150,204,443,2,417,2" shape="poly" href="#" onmouseover="popup(11786)"><div id="dialog-11786" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is not parallel to $\Vect{x}$. Therefore it cannot be expressed in the form $t\cdot \Vect{x}$; i.e. it is not a linear combination of $\Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11788" coords="117,221,58,245,62,257,124,222" shape="poly" href="#" onmouseover="popup(11788)"><div id="dialog-11788" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is not parallel to $\Vect{x}$. Therefore it cannot be expressed in the form $t\cdot \Vect{x}$; i.e. it is not a linear combination of $\Vect{x}$.</span>
                              </p>
						                     </info></div></area><area id="pic-11790" coords="134,222,307,266,321,261,144,218" shape="poly" href="#" onmouseover="popup(11790)"><div id="dialog-11790" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>This vector is not parallel to $\Vect{x}$. Therefore it cannot be expressed in the form $t\cdot \Vect{x}$; i.e. it is not a linear combination of $\Vect{x}$.</span>
                              </p>
						                     </info></div></area></map></div>
			         </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>A linear combination of $\Vect{x}$ is a vector of the form $t\cdot \Vect{x}$, where $t$ is in $\RNr{}$. This means that a linear combination of $\Vect{x}$ is any vector which is parallel to $\Vect{x}$ or, in other words, which lies on the line in the direction of $\Vect{x}$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Express the position vector of each of the yellow dots as a linear combination of $\mathbf{x}$, $\mathbf{y}$, and $\mathbf{z}$ in a least three distinct ways. &#x2013; Place your mouse over top the point in question to find answers.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img id="image-11793" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/LinearCombination3.gif" height="226.34730538922" width="350" usemap="#LinearCombination3"/><map name="LinearCombination3"><area id="pic-11795" coords="60,57,8" shape="circle" href="#" onmouseover="popup(11795)"><div id="dialog-11795" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>Ways in which the position vector for this point can be written include</span>
                              </p>
							                       $$
									
								\begin{array}{rcrcr}
								-\mathbf{x} &amp; &amp; &amp; &amp; \mathbf{z} \\ 
								-2\mathbf{x} &amp; &amp; \mathbf{y} &amp; &amp; \\
								&amp; - &amp; \mathbf{y} &amp; + &amp; 2\mathbf{z} \\ 
								\end{array}
								
								$$
						                     </info></div></area><area id="pic-11797" coords="251,104,8" shape="circle" href="#" onmouseover="popup(11797)"><div id="dialog-11797" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>Ways in which the position vector for this point can be written include</span>
                              </p>
							                       $$
									
								\begin{array}{rcrcr}
								\mathbf{x} &amp; &amp; &amp; &amp; \tfrac{1}{2}\mathbf{z} \\ 
								&amp; &amp; \mathbf{y} &amp; - &amp; \tfrac{1}{2}\mathbf{z} \\
								\tfrac{1}{2}\mathbf{x} &amp; + &amp; \tfrac{1}{2}\mathbf{y} &amp; &amp; \\ 
								\end{array}
								
								$$
						                     </info></div></area><area id="pic-11799" coords="298,105,8" shape="circle" href="#" onmouseover="popup(11799)"><div id="dialog-11799" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>Ways in which the position vector for this point can be written include</span>
                              </p>
							                       $$
									
								\begin{array}{rcrcr}
								\mathbf{x} &amp; + &amp; \tfrac{1}{2}\mathbf{y} &amp; &amp; \\ 
								\tfrac{3}{2}\mathbf{x} &amp; &amp; &amp; + &amp; \tfrac{1}{2}\mathbf{z} \\
								&amp; &amp; \tfrac{3}{2}\mathbf{y} &amp; - &amp; \mathbf{z} \\ 
								\end{array}
								
								$$
						                     </info></div></area><area id="pic-11801" coords="59,153,8" shape="circle" href="#" onmouseover="popup(11801)"><div id="dialog-11801" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>Ways in which the position vector for this point can be written include</span>
                              </p>
							                       $$
									
								\begin{array}{rcrcr}
								- \mathbf{x} &amp; &amp; &amp; &amp; \\ 
								&amp; - &amp; \mathbf{y} &amp; + &amp; \mathbf{z} \\
								-2\mathbf{x} &amp; + &amp; \mathbf{y} &amp; - &amp; \mathbf{z} \\ 
								\end{array}
								
								$$
						                     </info></div></area><area id="pic-11803" coords="203,200,8" shape="circle" href="#" onmouseover="popup(11803)"><div id="dialog-11803" class="dialogs"><info xmlns="Compositor">
							                       <p>
                                 <span>Ways in which the position vector for this point can be written include</span>
                              </p>
							                       $$
									
								\begin{array}{rcrcr}
								\tfrac{1}{2} \mathbf{x} &amp; &amp; &amp; - &amp; \tfrac{1}{2}\mathbf{z} \\ 
								\mathbf{x} &amp; - &amp; \tfrac{1}{2}\mathbf{y} &amp; &amp; \\
								&amp; &amp; \tfrac{1}{2}\mathbf{y} &amp; - &amp; \mathbf{z} \\ 
								\end{array}
								
								$$
						                     </info></div></area></map></div>
			         </span>
         </p>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-11804" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of linear combinations.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>linear transformation     </span><a id='glossaryinfo-14955' class='msm_infobutton' onmouseover='infoopen(14955)'>i</a><div id="dialog-14955" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>Appears here in the introduction to the topic of linear transformations.</span>
                  </p>
               </info></div><ul class='chilren'><li><span>shear map of $\RNr{n}$ parallel to a hyperspace     </span><a id='glossaryinfo-7143' class='msm_infobutton' onmouseover='infoopen(7143)'>i</a><div id="dialog-7143" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7143' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7113' onmouseover='infoopen(7113)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-7113' style='display:none;'><div class='title'>Shear Transformations</div><p xmlns="Unit">
               <span>Shear transformations occur in a variety of contexts, for example when converting ordinary type into italics.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearingText.gif' height='75.721153846154' width='350'/></div><p xmlns="Unit">
               <span>We can think of this transformation as resulting from holding the base of these characters fixed and sliding the top by a certain amount parallel to the base line (the shear line) of the characters.</span>
            </p><p xmlns="Unit">
               <span>To describe such a shear transformation $S\from \RNr{n}\to \RNr{n}$ mathematically, we adopt the following setup:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Let $\Vect{n}$ be a unit vector of $\RNr{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $H$ denote the hyperspace of $\RNr{n}$ perpendicular to $\Vect{n}$. This is the hyperspace parallel to which we shear.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{s} := S(\Vect{n}) - \Vect{n}$ denote the shear vector; i.e. $\Vect{s}$ is the vector by which $\Vect{n}$ must be slanted parallel to $H$ so as to transform it into $S(\Vect{n})$.</span>
                  </p>
               </li>
            </ul><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_1.png' height='266' width='350'/></div><p xmlns="Unit">
               <span>How to read the picture above:</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>The effect of $S$ on $\Vect{n}$ is $S(\Vect{n}) = \Vect{n} + \Vect{s}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The effect of $S$ on a stretched copy $t\cdot \Vect{n}$ of $\Vect{n}$ is $S(t\cdot \Vect{n}) = t\cdot \Vect{n} + t\cdot \Vect{s}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The effect of $S$ on an arbitrary vector $\Vect{x}$ with $\pr_{\Vect{n}}(\Vect{x}) = t\cdot \Vect{n}$ is </span>
                  </p>
                  $$S(\Vect{x}) = \Vect{x} + t\cdot \Vect{s} = \Vect{x} + (\DotPr{\Vect{x}}{\Vect{n}})\cdot \Vect{s}$$
               </li>
            </ol></div><div id="dialog-7113" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of shear transformations and their mathematical description</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-7139' onmouseover='infoopen(7139)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7139' style='display:none;'><div class='pack'><div class='title'>Examples of Shear Transformations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the shear transformation $S$ of $\RNr{2}$, parallel to the $x$-axis which transforms the vector $\Vect{n} = (0,1)$ into the vector $S(\Vect{n}) = (1,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-7123" class="dialogs"><info xmlns="Compositor">
						
						                        <p>
                                 <span>Look up how to find the matrix representing a given linear map</span>
                              </p>
					                      </info></div><div class='refcontent' id='refcontent-7123' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>
                     $\Vect{n}$ is a unit vector. Therefore the shear vector is</span>
               </p>
			
			            $$\Vect{s} = S(\Vect{n}) - \Vect{n} = (1,1) - (0,1) = (1,0)$$
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_2.png" height="133.875" width="350"/></div>
			
			            <p>
                  <span>To find the 
				<a id="activehottag-7123" class="activehottag" onmouseover="infoopen(7123)"> matrix representing $S$
                        </a>  , we determine  the effect of $S$ on the vectors  $\StdBss{1}=(1,0)$ and $\StdBss{2}=(0,1)$
                  </span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S(1,0)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0) + \left( \DotPr{(1,0)}{(0,1)}\right) \cdot \Vect{s} = (1,0)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S(0,1)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,1)$</td></tr></table>
			
			            <p>
                  <span>Therefore,</span>
               </p>
			
			            $$
					
A = 
\left[
\begin{array}{rr}
1 &amp; 1 \\
0 &amp; 1
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>As in the example above we see that the general shear transformation of $\RNr{2}$ parallel to the $x$-axis is described by</span>
         </p>
			
			      $$
					
S(x,y) = 
\left[
\begin{array}{rr}
1 &amp; a \\
0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y
\end{array}
\right]
					
				$$
			
			      <p>
            <span>In particular, $S$ leaves $\StdBss{1}$ unchanged, and it shears $\StdBss{2}$ into $(0,1) + (a,0) = (a,1)$. So the shear vector is $\Vect{s} = (a,0)$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_3.png" height="154" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Similarly, the shear transformation of $\RNr{3}$ parallel to the $xy$-plane with shear vector $\Vect{s} = (a,b,0)$  is given by</span>
         </p>
			
			      $$
					
S\from \RNr{3} \longrightarrow \RNr{3},\quad S(x,y,z) =
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; a \\
0 &amp; 1 &amp; b \\
0 &amp; 0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right]
					
				$$
			
			      <p>
            <span>The picture below shows the effect of such a shear transformation on the unit cube of $\RNr{3}$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg" height="262.5" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-7139" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of shear transformations</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>scalar product     </span><a id='glossaryinfo-17771' class='msm_infobutton' onmouseover='infoopen(17771)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17771' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17773' onmouseover='popup(17773)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17773" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the function $L$ and a number $t$, we define a new function here, namely $(t\cdot L)$. The effect of the function $(t\cdot L)$ on a vector $\Vect{x}$ is defined to be the scalar product of $L(\Vect{x})$ times $t$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with a linear function $L$ and a number $t$, we do not know if their scalar product  $(t\cdot L)$ is linear. Therefore we must check that $(t\cdot L)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>invertible     </span><a id='glossaryinfo-7835' class='msm_infobutton' onmouseover='infoopen(7835)'>i</a><div id="dialog-7835" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7835' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7803' onmouseover='infoopen(7803)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7803' style='display:none;'><div class='pack'><div class='title'>Invertible Linear Transformation: Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>There is a special collection of linear transformations, called invertible, whose effect on space can be reversed. Here is an example: A dilation $D\from \RNr{n}\to \RNr{n}$ by the factor $ c &gt; 1 $ magnifies distances by the factor $c$. The effect of such a dilation can be reversed by a contraction with factor $1/c$.</span>
         </p>
			
			      <p>
            <span>The picture below illustrates this situation for $D\from \RNr{2}\to \RNr{2}$ with magnification factor $c=3/2$. Accordingly the $D$-inverting contraction $C$ has contraction factor $2/3$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/DilateContract.png" height="147" width="350"/></div>
			
			      <p>
            <span>Notice how $D$ and $C$ undo each other&#x2019;s transformation effect:</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$D\Comp C$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$C\Comp D$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\IdMap{\RNr{2}}$</td></tr></table>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-7803" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An example of an invertible linear transformation</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-7829' onmouseover='popup(7829)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-7829" class="dialogs" title="Comment on: Invertible linear transformation"><info xmlns="Unit">
                           
                           <p>
                              <span>Notice how nicely this definition captures the idea of reversing the effect of the transformation $L$: The identity transformation $\Id{n}$ on $\RNr{n}$ leaves every point where it is. Thus to require that $M\Comp L=\Id{n}$ forces $\Mtrx{M}$ to reverse the effect of $L$. Likewise, to require that $L\Comp M=\Id{n}$ forces $\Mtrx{L}$ to reverse the effect of $\Mtrx{M}$ as well:</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>distance preserving     </span><a id='glossaryinfo-17037' class='msm_infobutton' onmouseover='infoopen(17037)'>i</a><div id="dialog-17037" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17037' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17003' onmouseover='popup(17003)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17003" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>The identity $\abs{ L(\Vect{x}) } = \abs{ \Vect{x} }$ says exactly that the length of $\Vect{x}$ equals the length of ($\Vect{x}$ transformed by $L$). If this happens for all $\Vect{x}$ in $\RNr{n}$, then $L$ preserves the length of all vectors and, hence, the distance between any pair of points in $\RNr{n}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-17009' onmouseover='infoopen(17009)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-17009' style='display:none;'><div class='pack'><div class='title'>Rotations are Distance Preserving</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a linear transformation $L$ preserves the distance between two points $\Vect{a}$  and $\Vect{b}$ if the distance from $\Vect{a}$ to $\Vect{b}$ is equal to the distance from $L(\Vect{a})$ to $L(\Vect{b})$. For example, a rotation of the plane about the origin preserves the distance between any two points.</span>
         </p>
			
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/RotationOrthogonal.png" height="349.125" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-17009" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>A rotation is an example of a distance preserving linear transformation.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>orthogonal     </span><a id='glossaryinfo-8120' class='msm_infobutton' onmouseover='infoopen(8120)'>i</a><div id="dialog-8120" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8120' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-8080' onmouseover='popup(8080)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-8080" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>The identity $\abs{ L(\Vect{x}) } = \abs{ \Vect{x} }$ says exactly that the length of $\Vect{x}$ equals the length of ($\Vect{x}$ transformed by $L$). If this happens for all $\Vect{x}$ in $\RNr{n}$, then $L$ preserves the length of all vectors and, hence, the distance between any pair of points in $\RNr{n}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-8086' onmouseover='infoopen(8086)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-8086' style='display:none;'><div class='pack'><div class='title'>Rotations are Distance Preserving</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a linear transformation $L$ preserves the distance between two points $\Vect{a}$  and $\Vect{b}$ if the distance from $\Vect{a}$ to $\Vect{b}$ is equal to the distance from $L(\Vect{a})$ to $L(\Vect{b})$. For example, a rotation of the plane about the origin preserves the distance between any two points.</span>
         </p>
			
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/RotationOrthogonal.png" height="349.125" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-8086" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>A rotation is an example of a distance preserving linear transformation.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>by specifying values on a basis     </span><a id='glossaryinfo-18173' class='msm_infobutton' onmouseover='infoopen(18173)'>i</a><div id="dialog-18173" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Look up the proposition which says that a linear map $f\from V\to W$ is given by specifying is values on a basis of $V$.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18173' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Linear map by values on a basis</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $V$ and $W$ be subspaces of $\RNr{k}$. Given a basis $\EuScript{A}=\Set{ \Vect{a}_1,\dots ,\Vect{a}_n}$ of $V$ and arbitrary vectors $\Vect{z}_1$, ... , $\Vect{z}_n$ in $W$, there is exactly one linear transformation $L\from V\to W$ with
			</span>
         
      </p>$$L(\Vect{a}_1)=\Vect{z}_1\ ,\quad \dots \ ,\quad L(\Vect{a}_n)=\Vect{z}_n$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>monomorphic     </span><a id='glossaryinfo-18864' class='msm_infobutton' onmouseover='infoopen(18864)'>i</a><div id="dialog-18864" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18864' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>epimorphic     </span><a id='glossaryinfo-18870' class='msm_infobutton' onmouseover='infoopen(18870)'>i</a><div id="dialog-18870" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18870' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>isomorphic     </span><a id='glossaryinfo-18876' class='msm_infobutton' onmouseover='infoopen(18876)'>i</a><div id="dialog-18876" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18876' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>linear transformations     </span><ul class='chilren'><li><span>composition     </span><a id='glossaryinfo-7648' class='msm_infobutton' onmouseover='infoopen(7648)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7648' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7650' onmouseover='popup(7650)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-7650" class="dialogs" title="How to read this"><info xmlns="Unit">
                           
                           $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                           <p>
                              <span>is read: ‘T following S from R p to Rm, T following S of x is defined to be T of S of x’.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-7652' onmouseover='popup(7652)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-7652" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the functions $S$ and $T$, we define a new function here, namely their composite $T\Comp S$. The effect of the function $T\Comp S$ on a vector $\Vect{x}$ is defined by successive evaluation: first evaluate $S$ on $\Vect{x}$ so as to obtain the vector $S(\Vect{x})$ in $\RNr{n}$. To this vector we apply $T$ so as to obtain the vector $T(S(\Vect{x}))$ in $\RNr{m}$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with two linear functions $S$ and $T$, we do not know if their composite $(T\Comp S)$ is linear. Therefore we must check that $(T\Comp S)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>linearly dependent set     </span><a id='glossaryinfo-12111' class='msm_infobutton' onmouseover='infoopen(12111)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12111' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-12151' onmouseover='infoopen(12151)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-12151' style='display:none;'><div class='title'>Linear Independence - Explanation</div><p xmlns="Unit">
               <span>We define a set $S$ to be linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$0$</td></tr></table><p xmlns="Unit">
               <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. – If $S$ fails to be linearly independent, it is called linearly dependent.</span>
            </p><p xmlns="Unit">
               <span>This definition is remarkable efficient as it relates the new concept of linear independence directly to the familiar concept of a system of linear equations having a unique solution. – But let us analyze a bit more what it actually means:</span>
            </p><p xmlns="Unit">
               <span>Using a collection of vectors $\Vect{a}_1,\dots ,\Vect{a}_r$, it is always possible to express the zero vector as a linear combination:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr></table><p xmlns="Unit">
               <span>All we need to do is set $t_1= \cdots = t_r = 0$. This is often called the ‘trivial’ linear combination of $\Vect{0}$. With the concept of linear independence we distinguish those vector collections $\Vect{a}_1,\dots ,\Vect{a}_r$ for which the trivial combination is the only way of expressing $\Vect{0}$ as a linear combination of $\Vect{a}_1, \dots ,\Vect{a}_r$.</span>
            </p><p xmlns="Unit">
               <span>In contrast, suppose this linear independence requirement is violated. Then it is possible to express the zero vector as a linear combination</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr></table><p xmlns="Unit">
               <span>in which at least one of the numbers $t_1, \dots , t_r$ is not zero. Consider, for example, the case where $t_1\neq 0$. We may then compute.</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_2\Vect{a}_2 + \cdots + t_r \Vect{a}_r$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{a}_1$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-12147' class='hottag' onmouseover='popup(12147)'>$=	$</a><div id="dialog-12147" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Notice: here we divide by $t_1$, and this is only allowed if $t_1\neq 0$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\frac{1}{t_1}\left( t_2\Vect{a}_2 + \cdots + t_r \Vect{a}_r \right)$</td></tr></table><p xmlns="Unit">
               <span>This last equation is a linear dependence relation amongst the vectors $\Vect{a}_1, \dots ,\Vect{a}_r$ as it expresses $\Vect{a}_1$ as a linear combination of the remaining ones.</span>
            </p></div><div id="dialog-12151" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Paraphrasing ‘Linear Independence’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-12191' onmouseover='infoopen(12191)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-12191' style='display:none;'><div class='pack'><div class='title'>Linear Independence: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the vectors</span>
         </p>
			      $$\Vect{a}_1=(1,2,5)\quad \text{and} \quad \Vect{a}_2=(2,-1,4)$$
			      <p>
            <span>of $\RNr{3}$ are linearly independent.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to examine the possible solutions of the vector equation</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + t_2 \Vect{a}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr></table>
							        $$
									
t_1
\left[
\begin{array}{c}
1 \\ 2 \\ 5
\end{array}
\right]\ +\ t_2
\left[
\begin{array}{r}
2 \\ -1 \\ 4
\end{array}
\right]\ =\ 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right]
					
								$$
			            <p>
                  <span>This homogeneous system of linear equations has as its reduced row echelon form</span>
               </p>
							        $$
									
\left[
\begin{array}{cc|c}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]
					
								$$
			            <p>
                  <span>This says that $t_1=t_2=0$ is the only solution of the given vector equation. We conclude that the set of vectors $\Set{ \Vect{a}_1 , \Vect{a}_2 }$  is linearly independent.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the vectors</span>
         </p>
			      $$\Vect{a}_1=(1,2,5), \quad \Vect{a}_2=(2,-1,4),\quad \text{and}\quad \Vect{a}_3=(0,5,6)$$
			      <p>
            <span>of $\RNr{3}$ are linearly independent. If they are not, express one vector as a linear combination of the others.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to examine the possible solutions of the vector equation</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + t_2 \Vect{a}_2 + t_3 \Vect{a}_3$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr></table>
			            $$
					
t_1
\left[
\begin{array}{c}
1 \\ 2 \\ 5
\end{array}
\right]\ +\ t_2
\left[
\begin{array}{r}
2 \\ -1 \\ 4
\end{array}
\right]\ +\ t_3
\left[
\begin{array}{r}
0 \\ 5 \\ 6
\end{array}
\right]
=\ 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right]
					
				$$
			            <p>
                  <span>This homogeneous system of linear equations has as its reduced row echelon form</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
1 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{array}
					
				$$
			            <p>
                  <span>Now we see that this system of linear equation has infinitely many solutions, as $t_3$ can be chosen arbitrarily. We conclude that the vectors $\Set{ \Vect{a}_1 , \Vect{a}_2 , \Vect{a}_3 }$ fail to be linearly independent: they are linearly dependent.</span>
               </p>
			
			            <p>
                  <span>To express one vector as a linear combination of the others, we may use any of the solutions of the above system of linear equations. For example, $t_3 = 4$ yields</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-2\cdot 4 = -8$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$4$</td></tr></table>
			            <p>
                  <span>This means that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-8\cdot \Vect{a}_1 + 4\cdot \Vect{a}_2 + 4\cdot \Vect{a}_3$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2\cdot \Vect{a}_1 - \Vect{a}_3$</td></tr></table>
			            <p>
                  <span>Notice that we could just as well have expressed $\Vect{a}_1$ as a linear combination of $\Vect{a}_2$ and $\Vect{a}_3$:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{1}{2}\cdot (\Vect{a}_2 +\Vect{a}_3)$</td></tr></table>
			            <p>
                  <span>Similarly, $\Vect{a}_3$ is a linear combination of $\Vect{a}_1$ and $\Vect{a}_2$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-12191" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Some examples of testing for linear independence</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>linearly independent set     </span><a id='glossaryinfo-12111' class='msm_infobutton' onmouseover='infoopen(12111)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12111' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-12151' onmouseover='infoopen(12151)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-12151' style='display:none;'><div class='title'>Linear Independence - Explanation</div><p xmlns="Unit">
               <span>We define a set $S$ to be linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$0$</td></tr></table><p xmlns="Unit">
               <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. – If $S$ fails to be linearly independent, it is called linearly dependent.</span>
            </p><p xmlns="Unit">
               <span>This definition is remarkable efficient as it relates the new concept of linear independence directly to the familiar concept of a system of linear equations having a unique solution. – But let us analyze a bit more what it actually means:</span>
            </p><p xmlns="Unit">
               <span>Using a collection of vectors $\Vect{a}_1,\dots ,\Vect{a}_r$, it is always possible to express the zero vector as a linear combination:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr></table><p xmlns="Unit">
               <span>All we need to do is set $t_1= \cdots = t_r = 0$. This is often called the ‘trivial’ linear combination of $\Vect{0}$. With the concept of linear independence we distinguish those vector collections $\Vect{a}_1,\dots ,\Vect{a}_r$ for which the trivial combination is the only way of expressing $\Vect{0}$ as a linear combination of $\Vect{a}_1, \dots ,\Vect{a}_r$.</span>
            </p><p xmlns="Unit">
               <span>In contrast, suppose this linear independence requirement is violated. Then it is possible to express the zero vector as a linear combination</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr></table><p xmlns="Unit">
               <span>in which at least one of the numbers $t_1, \dots , t_r$ is not zero. Consider, for example, the case where $t_1\neq 0$. We may then compute.</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{a}_1$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_2\Vect{a}_2 + \cdots + t_r \Vect{a}_r$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{a}_1$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-12147' class='hottag' onmouseover='popup(12147)'>$=	$</a><div id="dialog-12147" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Notice: here we divide by $t_1$, and this is only allowed if $t_1\neq 0$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\frac{1}{t_1}\left( t_2\Vect{a}_2 + \cdots + t_r \Vect{a}_r \right)$</td></tr></table><p xmlns="Unit">
               <span>This last equation is a linear dependence relation amongst the vectors $\Vect{a}_1, \dots ,\Vect{a}_r$ as it expresses $\Vect{a}_1$ as a linear combination of the remaining ones.</span>
            </p></div><div id="dialog-12151" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Paraphrasing ‘Linear Independence’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-12191' onmouseover='infoopen(12191)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-12191' style='display:none;'><div class='pack'><div class='title'>Linear Independence: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the vectors</span>
         </p>
			      $$\Vect{a}_1=(1,2,5)\quad \text{and} \quad \Vect{a}_2=(2,-1,4)$$
			      <p>
            <span>of $\RNr{3}$ are linearly independent.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to examine the possible solutions of the vector equation</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + t_2 \Vect{a}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr></table>
							        $$
									
t_1
\left[
\begin{array}{c}
1 \\ 2 \\ 5
\end{array}
\right]\ +\ t_2
\left[
\begin{array}{r}
2 \\ -1 \\ 4
\end{array}
\right]\ =\ 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right]
					
								$$
			            <p>
                  <span>This homogeneous system of linear equations has as its reduced row echelon form</span>
               </p>
							        $$
									
\left[
\begin{array}{cc|c}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}
\right]
					
								$$
			            <p>
                  <span>This says that $t_1=t_2=0$ is the only solution of the given vector equation. We conclude that the set of vectors $\Set{ \Vect{a}_1 , \Vect{a}_2 }$  is linearly independent.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the vectors</span>
         </p>
			      $$\Vect{a}_1=(1,2,5), \quad \Vect{a}_2=(2,-1,4),\quad \text{and}\quad \Vect{a}_3=(0,5,6)$$
			      <p>
            <span>of $\RNr{3}$ are linearly independent. If they are not, express one vector as a linear combination of the others.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to examine the possible solutions of the vector equation</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + t_2 \Vect{a}_2 + t_3 \Vect{a}_3$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr></table>
			            $$
					
t_1
\left[
\begin{array}{c}
1 \\ 2 \\ 5
\end{array}
\right]\ +\ t_2
\left[
\begin{array}{r}
2 \\ -1 \\ 4
\end{array}
\right]\ +\ t_3
\left[
\begin{array}{r}
0 \\ 5 \\ 6
\end{array}
\right]
=\ 
\left[
\begin{array}{c}
0 \\ 0 \\ 0
\end{array}
\right]
					
				$$
			            <p>
                  <span>This homogeneous system of linear equations has as its reduced row echelon form</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
1 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{array}
					
				$$
			            <p>
                  <span>Now we see that this system of linear equation has infinitely many solutions, as $t_3$ can be chosen arbitrarily. We conclude that the vectors $\Set{ \Vect{a}_1 , \Vect{a}_2 , \Vect{a}_3 }$ fail to be linearly independent: they are linearly dependent.</span>
               </p>
			
			            <p>
                  <span>To express one vector as a linear combination of the others, we may use any of the solutions of the above system of linear equations. For example, $t_3 = 4$ yields</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-2\cdot 4 = -8$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$4$</td></tr></table>
			            <p>
                  <span>This means that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-8\cdot \Vect{a}_1 + 4\cdot \Vect{a}_2 + 4\cdot \Vect{a}_3$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{0}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2\cdot \Vect{a}_1 - \Vect{a}_3$</td></tr></table>
			            <p>
                  <span>Notice that we could just as well have expressed $\Vect{a}_1$ as a linear combination of $\Vect{a}_2$ and $\Vect{a}_3$:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{1}{2}\cdot (\Vect{a}_2 +\Vect{a}_3)$</td></tr></table>
			            <p>
                  <span>Similarly, $\Vect{a}_3$ is a linear combination of $\Vect{a}_1$ and $\Vect{a}_2$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-12191" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Some examples of testing for linear independence</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>Lo Shu-magic square     </span><a id='glossaryinfo-4654' class='msm_infobutton' onmouseover='infoopen(4654)'>i</a><div id="dialog-4654" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>appears here as an early example of organizing numbers in a rectangular shape.</span>
                        </p>
                     </info></div></li><li><span>matrix     </span><a id='glossaryinfo-4554' class='msm_infobutton' onmouseover='infoopen(4554)'>i</a><div id="dialog-4554" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>General description as a rectangular arrangement of objects</span>
                  </p>
               </info></div><ul class='chilren'><li><span>square shaped     </span><a id='glossaryinfo-4780' class='msm_infobutton' onmouseover='infoopen(4780)'>i</a><div id="dialog-4780" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A square shaped matrix is one whose number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4780' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4776' onmouseover='infoopen(4776)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4776' style='display:none;'><div class='pack'><div class='title'>Examples of Types of Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A matrix is square shaped if it is of type $(n,n)$. For example, the matrices below are square shaped.</span>
         </p>
			
			      $$
					
					\left[
					\begin{array}{rr}
					6 &amp; 9 \\
					-9 &amp; 6
					\end{array}
					\right] \qquad
					\left[
					\begin{array}{rrr}
					4 &amp; -4 &amp; 1 \\
					3 &amp; 2 &amp; 3 \\
					1 &amp; -3 &amp; 6
					\end{array}
					\right] \qquad 
					\left[
					\begin{array}{rrrrr}
					3 &amp; 0 &amp; 2 &amp; 4 &amp; 3 \\
					6 &amp; 1 &amp; 4 &amp; 2 &amp; 0 \\
					1 &amp; 5 &amp; 7 &amp; 6 &amp; 9 \\
					6 &amp; 2 &amp; 4 &amp; 7 &amp; 4 \\
					3 &amp; 3 &amp; 3 &amp; 0 &amp; 3
					\end{array}
					\right] 
					
				$$
			      <p>
            <span>Indeed, the matrix on the left has size $(2,2)$. The matrix in the middle has size $(3,3)$. The matrix on the right has size $(5,5)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the following matrix is square shaped.</span>
         </p>
			      $$
				
				\left[
				\begin{array}{rrrrrrr}
				6 &amp; 5 &amp; 3 &amp; 12 &amp; 19 &amp; 403 &amp; 121 \\
				3 &amp; 0 &amp; 0 &amp; 1 &amp; 21 &amp; -12 &amp; 11 \\
				1 &amp; 1 &amp; 2 &amp; 2 &amp; 4 &amp; 4 &amp; 8
				\end{array}
				\right]
				
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The given matrix is not square shaped as its number of rows is $3$, while its number of columns is $7\neq 3$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4776" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Some examples of square shaped and non-square shaped matrices.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of one row     </span><a id='glossaryinfo-4787' class='msm_infobutton' onmouseover='infoopen(4787)'>i</a><div id="dialog-4787" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4787' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4783' onmouseover='popup(4783)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4783" class="dialogs" title="On row matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>A row matrix is one which has exactly one row, i.e. is of size $(1,n)$. Thus the matrices below are row matrices.</span>
                           </p>
                           $$[15\ \ 4\ \ -7]\qquad [2\ \ -1\ \ -2\ \ 3\ \ -1]$$
                        </info></div></ul></div><br /></div></li><li><span>of one column     </span><a id='glossaryinfo-4794' class='msm_infobutton' onmouseover='infoopen(4794)'>i</a><div id="dialog-4794" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4794' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4790' onmouseover='popup(4790)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4790" class="dialogs" title="On column matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>A column matrix is one which has exactly one column, i.e. is of size $(m,1)$. Thus the matrices below are column matrices.</span>
                           </p>
                           $$
								\left[
								\begin{array}{r}
								15 \\ 4 \\ -7
								\end{array}
								\right]\qquad
								\left[
								\begin{array}{r}
								3 \\ 1 \\ 1 \\ 0\\ 1
								\end{array}
								\right]
							$$
                        </info></div></ul></div><br /></div></li><li><span>0-     </span><a id='glossaryinfo-4812' class='msm_infobutton' onmouseover='infoopen(4812)'>i</a><div id="dialog-4812" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4812' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4808' onmouseover='popup(4808)'><span style='cursor:pointer'>Example</span></li><div id="dialog-4808" class="dialogs" title="Some Examples of 0-Matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The following are $0$-matrices</span>
                           </p>
                           $$
								
								\begin{bmatrix}
								0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0
								\end{bmatrix}\qquad
								\begin{bmatrix}
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 0
								\end{bmatrix} \qquad
								\begin{bmatrix}
								0 &amp; 0 \\
								0 &amp; 0 \\
								0 &amp; 0 \\
								0 &amp; 0
								\end{bmatrix}
								
							$$
                        </info></div></ul></div><br /></div></li><li><span>diagonal     </span><a id='glossaryinfo-4819' class='msm_infobutton' onmouseover='infoopen(4819)'>i</a><div id="dialog-4819" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4819' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4815' onmouseover='popup(4815)'><span style='cursor:pointer'>Example</span></li><div id="dialog-4815" class="dialogs" title="Some Examples of Diagonal Matrices"><info xmlns="Unit">
                           
                           $$
								
								\begin{bmatrix}
								2 &amp; 0 \\
								0 &amp; 1
								\end{bmatrix}\qquad
								\begin{bmatrix}
								\pi &amp; 0 &amp; 0 \\
								0 &amp; x &amp; 0 \\
								0 &amp; 0 &amp; 1
								\end{bmatrix}\qquad
								\begin{bmatrix}
								2 &amp; 0 &amp; 0 &amp; 0 \\
								0 &amp; 3 &amp; 0 &amp; 0 \\
								0 &amp; 0 &amp; 5 &amp; 0 \\
								0 &amp; 0 &amp; 0 &amp; 7
								\end{bmatrix}
								
							$$
                        </info></div></ul></div><br /></div></li><li><span>identity     </span><a id='glossaryinfo-4835' class='msm_infobutton' onmouseover='infoopen(4835)'>i</a><div id="dialog-4835" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4835' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4831' onmouseover='infoopen(4831)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-4831' style='display:none;'><div class='title'>Illustration of Identity Matrices</div><p xmlns="Unit">
               <span>The $(1,1)$-identity matrix is</span>
            </p>$$\IdMtrx{1}\ =\ [1]$$<p xmlns="Unit">
               <span>The $(2,2)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{2}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 \\
					0 &amp; 1
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>The $(3,3)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{3}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>The $(4,4)$-identity matrix is</span>
            </p>$$
					
					\IdMtrx{4}\ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0  \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$</div><div id="dialog-4831" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>A display of the identity matrices $\IdMtrx{1}$, $\IdMtrx{2}$, $\IdMtrx{3}$, $\IdMtrx{4}$.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of upper triangular shape     </span><a id='glossaryinfo-4852' class='msm_infobutton' onmouseover='infoopen(4852)'>i</a><div id="dialog-4852" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is of upper triangular shape if it is square shaped and only entries on or above the diagonal are different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4852' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4848' onmouseover='infoopen(4848)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-4848' style='display:none;'><div class='title'>Illustration of Upper Triangular Matrices</div><p xmlns="Unit">
               <span>Every $(1,1)$-identity matrix is an upper triangular matrix.</span>
            </p><p xmlns="Unit">
               <span>An example of an upper triangular $(2,2)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					2 &amp; 1 \\
					0 &amp; 3
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>An example of an upper triangular $(3,3)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					7 &amp; 0 &amp; 3 \\
					0 &amp; 1 &amp; 3 \\
					0 &amp; 0 &amp; 2
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>An example of an upper triangular $(4,4)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					9 &amp; 3 &amp; 2 &amp; 6  \\
					0 &amp; 7 &amp; 4 &amp; 3  \\
					0 &amp; 0 &amp; 0 &amp; 1\\
					0 &amp; 0 &amp; 0 &amp; 4
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>Other examples of upper triangular matrices include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>all diagonal matrices and,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>in  particular, all identity matrices</span>
                  </p>
               </li>
            </ul></div><div id="dialog-4848" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>A display of some upper triangular matrices.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>sum     </span><a id='glossaryinfo-4888' class='msm_infobutton' onmouseover='infoopen(4888)'>i</a><div id="dialog-4888" class="dialogs" title="matrix sum"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4888' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4879' onmouseover='popup(4879)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4879" class="dialogs" title="Comment on Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the sum of two matrices is only defined if both matrices have the same size.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4884' onmouseover='infoopen(4884)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4884' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Addition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The sum of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2} \\
					{\color{red}6} &amp; {\color{red}1}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined because both matrices are of the same size $(3,2)$. Their sum is</span>
         </p>
			
			      $$
					
					{\color{blue}A} + {\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} - {\color{red}3} &amp; {\color{blue}3} -{\color{red}3} \\
					{\color{blue}1} + {\color{red}1} &amp; {\color{blue}4} +{\color{red}2} \\
					{\color{blue}6} + {\color{red}6} &amp; {\color{blue}4} + {\color{red}1}
					\end{array}\right] \ =\ 
					\left[\begin{array}{cc}
					4 &amp; 0 \\
					2 &amp; 6 \\
					12 &amp; 5
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the sum of two matrices of size $(m,n)$
            </span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right]
					
				$$
			      <p>
            <span>is</span>
         </p>
			
			      $$
					
					\aligned
					{\color{blue}A}\ +\ {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\ +\
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right] \\
					&amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} + {\color{red}b_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} + {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} + {\color{red}b_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}} + {\color{red}b_{mn}}
					\end{array}\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4884" class="dialogs" title="Example of Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus, to add two matrices, we simply add their intries in matching positions. – Here are some examples.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>addition     </span><a id='glossaryinfo-4892' class='msm_infobutton' onmouseover='infoopen(4892)'>i</a><div id="dialog-4892" class="dialogs" title="matrix addition"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4892' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4879' onmouseover='popup(4879)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4879" class="dialogs" title="Comment on Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the sum of two matrices is only defined if both matrices have the same size.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4884' onmouseover='infoopen(4884)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4884' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Addition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The sum of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2} \\
					{\color{red}6} &amp; {\color{red}1}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined because both matrices are of the same size $(3,2)$. Their sum is</span>
         </p>
			
			      $$
					
					{\color{blue}A} + {\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} - {\color{red}3} &amp; {\color{blue}3} -{\color{red}3} \\
					{\color{blue}1} + {\color{red}1} &amp; {\color{blue}4} +{\color{red}2} \\
					{\color{blue}6} + {\color{red}6} &amp; {\color{blue}4} + {\color{red}1}
					\end{array}\right] \ =\ 
					\left[\begin{array}{cc}
					4 &amp; 0 \\
					2 &amp; 6 \\
					12 &amp; 5
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the sum of two matrices of size $(m,n)$
            </span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right]
					
				$$
			      <p>
            <span>is</span>
         </p>
			
			      $$
					
					\aligned
					{\color{blue}A}\ +\ {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\ +\
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right] \\
					&amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} + {\color{red}b_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} + {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} + {\color{red}b_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}} + {\color{red}b_{mn}}
					\end{array}\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4884" class="dialogs" title="Example of Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus, to add two matrices, we simply add their intries in matching positions. – Here are some examples.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>scalar product     </span><a id='glossaryinfo-4899' class='msm_infobutton' onmouseover='infoopen(4899)'>i</a><div id="dialog-4899" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div></li><li><span>multiplication     </span><a id='glossaryinfo-4917' class='msm_infobutton' onmouseover='infoopen(4917)'>i</a><div id="dialog-4917" class="dialogs" title="Matrix Multiplication"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4917' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4908' onmouseover='popup(4908)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4908" class="dialogs" title="Comment on Matrix multiplication"><info xmlns="Unit">
                     
                     <p>
                        <span>The product of matrices $A\cdot B$ is only defined if the number of (vertical) columns of $A$ is equal to the number of (horizontal) rows of $B$. The resulting matrix will have as many rows as $A$ and as many columns as $B$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4913' onmouseover='infoopen(4913)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4913' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Multiplication</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the product of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue} \Mtrx{A}}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red} \Mtrx{B}}\ =\ 
					\left[\begin{array}{rr}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined. If it is, compute the product $\Mtrx{A}\Mtrx{B}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Matrix $\Mtrx{A}$ has size $(3,2)$ and matrix $\Mtrx{B}$ has size $(2,2)$. Therefore the product $\Mtrx{A}\Mtrx{B}$ is defined because the number of columns of $A$ equals the number of rows of $B$: both numbers are 2. Their product is a matrix of size $(3,2)$. Its entry $c_{ij}$ in position $(i,j)$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $j$-th column of $\Mtrx{B}$. So there are a total of 6 dot products to compute. In detail:</span>
               </p>
			
			            $$
					
					\aligned
					{\color{blue}A} \cdot {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2}
					\end{array}\right] \\
					&amp;=\ \left[\begin{array}{cc}
					{\color{blue}7}\cdot {\color{red}(-3)} + {\color{blue}3} \cdot {\color{red}1} &amp; 
						{\color{blue}7}\cdot {\color{red}(-3)} + {\color{blue}3}\cdot {\color{red}2} \\
					{\color{blue}1}\cdot {\color{red}(-3)} + {\color{blue}4} \cdot {\color{red}1} &amp; 
						{\color{blue}1}\cdot {\color{red}(-3)} + {\color{blue}4}\cdot {\color{red}2} \\
					{\color{blue}6}\cdot {\color{red}(-3)} + {\color{blue}4} \cdot {\color{red}1} &amp; 
						{\color{blue}6}\cdot {\color{red}(-3)} + {\color{blue}4}\cdot {\color{red}2} \\
					\end{array}\right] \\
					&amp;=\ \left[\begin{array}{rr}
						-18 &amp; -15 \\
						1     &amp; 5 \\
						-14 &amp; -10
					\end{array}\right]
					\endaligned
					
				$$
			            <p>
                  <span>Notice that the product matrix $\Mtrx{A}\cdot \Mtrx{B}$ has as many rows as $\Mtrx{A}$, and as many columns as $\Mtrx{B}$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4913" class="dialogs" title="Example: Matrix Multiplication"><info xmlns="Unit">
                     
                     <p>
                        <span>To form the matrix product $\Mtrx{A}\cdot \Mtrx{B}$ we take dot products of the rows of $\Mtrx{A}$ by the columns of $B$. – Here is an example.</span>
                     </p>
                  </info></div></ul></div><br /></div><ul class='chilren'><li><span>associative     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>distributive     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>neutral element     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>transpose     </span><a id='glossaryinfo-4931' class='msm_infobutton' onmouseover='infoopen(4931)'>i</a><div id="dialog-4931" class="dialogs" title="Matrix Transpose"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4931' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4920' onmouseover='popup(4920)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4920" class="dialogs" title="Explanation on Matrix Transposition"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus when transposing a matrix, we simply turn its rows into columns and vice versa; i.e. the first row of $A$ turns into the first column of $B$. The second row of $A$ turns into the second column of $B$, etc.
					</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4925' onmouseover='infoopen(4925)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4925' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Transposition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The transpose of the $(3,2)$-matrix</span>
         </p>
			
			      $$
					
					A\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{red}3} \\
					{\color{blue}1} &amp; {\color{red}4} \\
					{\color{blue}6} &amp; {\color{red}4}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is the $(2,3)$-matrix</span>
         </p>
			
			      $$
					
					A^T\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}7} &amp; {\color{blue}1} &amp; {\color{blue}6} \\
					{\color{red}3} &amp; {\color{red}4} &amp; {\color{red}4}
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the transpose of an $(m,n)$-matrix</span>
         </p>
			      $$
					
					A\ =\ 
					\left[\begin{array}{rrr}
					a_{11} &amp; \cdots &amp; a_{1n} \\
					\vdots &amp; \ddots &amp; \vdots \\
					a_{m1} &amp; \cdots &amp; a_{mn}
					\end{array}\right]
					
				$$
			      <p>
            <span>is the $(m,n)$-matrix</span>
         </p>
			      $$
					
					\aligned
					A^T\ &amp;=\  
					\left[\begin{array}{rrrrr}
					a_{11} &amp; \cdots &amp; {\color{red}a_{1j}} &amp; \cdots &amp; a_{1n} \\
					\vdots  &amp;             &amp; {\color{red}\vdots} &amp;             &amp; \vdots \\
					a_{m1} &amp; \cdots &amp; {\color{red}a_{mj}} &amp; \cdots &amp; a_{mn}
					\end{array}\right]^T \\
					&amp;=\ \left[\begin{array}{rrr}
					a_{11} &amp; \cdots &amp; a_{m1} \\
					\vdots &amp;               &amp; \vdots \\
					{\color{red}a_{1j}} &amp; \cdots &amp; {\color{red}a_{mj}} \\
					\vdots &amp;               &amp; \vdots \\
					a_{1n} &amp; \cdots &amp; a_{mn}
					\end{array}
					\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4925" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Some examples of matrix transposition.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>symmetric     </span><a id='glossaryinfo-4944' class='msm_infobutton' onmouseover='infoopen(4944)'>i</a><div id="dialog-4944" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4944' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4935' onmouseover='popup(4935)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4935" class="dialogs" title="Comment on: Symmetric Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>The first thing to observe about a symmetric matrix $A$ is that its number of rows must be the same as its number of columns. Therefore $A$ is square shaped. Moreover, we have the identity of entries $a_{ij}=a_{ji}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4940' onmouseover='infoopen(4940)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4940' style='display:none;'><div class='pack'><div class='title'>Examples of (non-)Symmetric Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 5 &amp; 7 \\
					5 &amp; -1 &amp; 4 \\
					7 &amp; 4 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					4 &amp; a &amp; -2 &amp; 1 \\
					a &amp; 6 &amp; 3 &amp; b \\
					-2 &amp; 3 &amp; c &amp; 1 \\
					1 &amp; b &amp; 1 &amp; 0
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are not symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 0 &amp; 0 \\
					5 &amp; -1 &amp; 0 \\
					7 &amp; 6 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					0 &amp; 1 &amp; -2 &amp; 1 \\
					5 &amp; 6 &amp; 3 &amp; -2 \\
					b &amp; 3 &amp; 6 &amp; 1 \\
					1 &amp; b &amp; 5 &amp; 0
					\end{array}\right]
					
				$$
			      <p>
            <span>Note that, while the $(4,4)$-matrix on the right displays a different kind of symmetry, it is not equal to its transpose, and so it is not symmetric.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4940" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of (non-)symmetric matrices.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>antisymmetric     </span><a id='glossaryinfo-4948' class='msm_infobutton' onmouseover='infoopen(4948)'>i</a><div id="dialog-4948" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4948' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4935' onmouseover='popup(4935)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4935" class="dialogs" title="Comment on: Symmetric Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>The first thing to observe about a symmetric matrix $A$ is that its number of rows must be the same as its number of columns. Therefore $A$ is square shaped. Moreover, we have the identity of entries $a_{ij}=a_{ji}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4940' onmouseover='infoopen(4940)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4940' style='display:none;'><div class='pack'><div class='title'>Examples of (non-)Symmetric Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 5 &amp; 7 \\
					5 &amp; -1 &amp; 4 \\
					7 &amp; 4 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					4 &amp; a &amp; -2 &amp; 1 \\
					a &amp; 6 &amp; 3 &amp; b \\
					-2 &amp; 3 &amp; c &amp; 1 \\
					1 &amp; b &amp; 1 &amp; 0
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are not symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 0 &amp; 0 \\
					5 &amp; -1 &amp; 0 \\
					7 &amp; 6 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					0 &amp; 1 &amp; -2 &amp; 1 \\
					5 &amp; 6 &amp; 3 &amp; -2 \\
					b &amp; 3 &amp; 6 &amp; 1 \\
					1 &amp; b &amp; 5 &amp; 0
					\end{array}\right]
					
				$$
			      <p>
            <span>Note that, while the $(4,4)$-matrix on the right displays a different kind of symmetry, it is not equal to its transpose, and so it is not symmetric.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4940" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of (non-)symmetric matrices.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>scalar multiplication     </span><ul class='chilren'><li><span>distributes over matrix sums     </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5192' onmouseover='infoopen(5192)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5192' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>We verify the first distributivity property. The other two properties can be proved with the same method. So let $A$ and $B$ be two matrices of size $(m,n)$, and let $t\in\RNr{}$. We focus our attention on the matrix entries in position $(i,j)$, for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributes over a matrix sum
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Let us consider the entry in position $(i,j)$ of the relevant matrix expressions:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $t\cdot (A+B)$ has the number $t\cdot (a_{ij}+b_{ij})$ in position $(i,j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $tA +tB$ has the number $ta_{ij} + tb_{ij}$ in position $(i,j)$.</span>
               </p>
            </li>
         </ul><p>
            <span>These numbers are equal because of the distributivity law for multiplication and addition of real numbers.</span>
         </p><p>
            <span>Thus $t(A+B)$ and $tA+tB$ both have the same number in position $(i,j)$. This computation applies to each position. So the two matrices are equal and, therefore, the distributivity identity for scalar multiplication of matrices holds.</span>
         </p><p>
            <span>You should try proving the remaining properties of scalar multiplication by adapting the above method.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>is associative     </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5192' onmouseover='infoopen(5192)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5192' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>We verify the first distributivity property. The other two properties can be proved with the same method. So let $A$ and $B$ be two matrices of size $(m,n)$, and let $t\in\RNr{}$. We focus our attention on the matrix entries in position $(i,j)$, for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributes over a matrix sum
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Let us consider the entry in position $(i,j)$ of the relevant matrix expressions:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $t\cdot (A+B)$ has the number $t\cdot (a_{ij}+b_{ij})$ in position $(i,j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $tA +tB$ has the number $ta_{ij} + tb_{ij}$ in position $(i,j)$.</span>
               </p>
            </li>
         </ul><p>
            <span>These numbers are equal because of the distributivity law for multiplication and addition of real numbers.</span>
         </p><p>
            <span>Thus $t(A+B)$ and $tA+tB$ both have the same number in position $(i,j)$. This computation applies to each position. So the two matrices are equal and, therefore, the distributivity identity for scalar multiplication of matrices holds.</span>
         </p><p>
            <span>You should try proving the remaining properties of scalar multiplication by adapting the above method.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>commutes with matrix multiplication     </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-5192' onmouseover='infoopen(5192)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5192' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>We verify the first distributivity property. The other two properties can be proved with the same method. So let $A$ and $B$ be two matrices of size $(m,n)$, and let $t\in\RNr{}$. We focus our attention on the matrix entries in position $(i,j)$, for some fixed $1\leq i\leq m$ and $1\leq j\leq n$. Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A$ has the number $a_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B$ has the number $b_{ij}$ in position $(i,j)$
                  </span>
               </p>
            </li>
         </ul></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributes over a matrix sum
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Let us consider the entry in position $(i,j)$ of the relevant matrix expressions:</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $t\cdot (A+B)$ has the number $t\cdot (a_{ij}+b_{ij})$ in position $(i,j)$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $tA +tB$ has the number $ta_{ij} + tb_{ij}$ in position $(i,j)$.</span>
               </p>
            </li>
         </ul><p>
            <span>These numbers are equal because of the distributivity law for multiplication and addition of real numbers.</span>
         </p><p>
            <span>Thus $t(A+B)$ and $tA+tB$ both have the same number in position $(i,j)$. This computation applies to each position. So the two matrices are equal and, therefore, the distributivity identity for scalar multiplication of matrices holds.</span>
         </p><p>
            <span>You should try proving the remaining properties of scalar multiplication by adapting the above method.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>transposition     </span><ul class='chilren'><li><span>commutes with addition     </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5260' onmouseover='popup(5260)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5260" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication and addition is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5262' onmouseover='popup(5262)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5262" class="dialogs" title="Comment on multiplication and transposition of matrices"><info xmlns="Theorem">
         
         <p>
            <span>When transposing the product $\Mtrx{A}\Mtrx{B}$ of two matrices the result is not ‘transpose of $\Mtrx{A}$’ times ‘transpose of $\Mtrx{B}$’. Rather, the result is</span>
         </p>
         $$\Mtrx{B}^T\cdot \Mtrx{A}^T$$
         <p>
            <span>i.e. the order in which $\Mtrx{A}^T$ and $\Mtrx{B}^T$ need to be multiplied is the reverse of what one might naively expect.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-5251' onmouseover='infoopen(5251)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5251' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition is its own inverse
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Why does double transposition of a matrix return the original matrix? – Applying transposition once turns the  $i$-th row into the  $i$-th column. Applying transposition again turns this  $i$-th column back into the  $i$-th row, thus restoring the original matrix. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with addition of matrices</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>So why does the transposition operation commute with matrix addition? Let $\Mtrx{A}$ and $\Mtrx{B}$ be matrices of size $(m,n)$. Then  $(\Mtrx{A} + \Mtrx{B})^T$  and $\Mtrx{A}^T + \Mtrx{B}^T$ are matrices of size $(n,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq n$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, in both cases this entry is $a_{ij} + b_{ij}$. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with scalar multiplication of a matrix by a number
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this fact.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition anticommutes with multiplication of matrices.
		</div></li><div id="dialog-5258" class="dialogs" title="Explanation"><info xmlns="Theorem">
                           
                           <p>
                              <span>This is the entry in position $(i,j)$ of $AB$. It turns into the entry in position $(j,i)$ of $(AB)^T$.</span>
                           </p>
                        </info></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>A new phenomenon is that transposition anticommutes with matrix multiplication. To see why this is so, let </span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A = [a_{ij}]$ be a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B = [b_{jk}]$ be a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(\Mtrx{A}\Mtrx{B})^T$ and $\Mtrx{B}^T \cdot \Mtrx{A}^T$ are matrices of size $(p,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq p$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, we find:</span>
         </p><ul>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $(\Mtrx{A}\Mtrx{B})^T$ is: &#xA0; 
				<a id="hottag-5258" class="hottag" onmouseover="popup(5258)"> 
                           $a_{i1}b_{1j} + \cdots + a_{in}b_{nj}$
                        </a>  
				.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $\Mtrx{B}^T \Mtrx{A}^T$ is: &#xA0; $b_{1j}a_{i1} + \cdots + b_{nj}a_{in}$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Visibly these two expressions are equal. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>commutes with scalar multiplication     </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5260' onmouseover='popup(5260)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5260" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication and addition is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5262' onmouseover='popup(5262)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5262" class="dialogs" title="Comment on multiplication and transposition of matrices"><info xmlns="Theorem">
         
         <p>
            <span>When transposing the product $\Mtrx{A}\Mtrx{B}$ of two matrices the result is not ‘transpose of $\Mtrx{A}$’ times ‘transpose of $\Mtrx{B}$’. Rather, the result is</span>
         </p>
         $$\Mtrx{B}^T\cdot \Mtrx{A}^T$$
         <p>
            <span>i.e. the order in which $\Mtrx{A}^T$ and $\Mtrx{B}^T$ need to be multiplied is the reverse of what one might naively expect.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-5251' onmouseover='infoopen(5251)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5251' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition is its own inverse
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Why does double transposition of a matrix return the original matrix? – Applying transposition once turns the  $i$-th row into the  $i$-th column. Applying transposition again turns this  $i$-th column back into the  $i$-th row, thus restoring the original matrix. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with addition of matrices</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>So why does the transposition operation commute with matrix addition? Let $\Mtrx{A}$ and $\Mtrx{B}$ be matrices of size $(m,n)$. Then  $(\Mtrx{A} + \Mtrx{B})^T$  and $\Mtrx{A}^T + \Mtrx{B}^T$ are matrices of size $(n,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq n$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, in both cases this entry is $a_{ij} + b_{ij}$. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with scalar multiplication of a matrix by a number
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this fact.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition anticommutes with multiplication of matrices.
		</div></li><div id="dialog-5258" class="dialogs" title="Explanation"><info xmlns="Theorem">
                           
                           <p>
                              <span>This is the entry in position $(i,j)$ of $AB$. It turns into the entry in position $(j,i)$ of $(AB)^T$.</span>
                           </p>
                        </info></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>A new phenomenon is that transposition anticommutes with matrix multiplication. To see why this is so, let </span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A = [a_{ij}]$ be a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B = [b_{jk}]$ be a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(\Mtrx{A}\Mtrx{B})^T$ and $\Mtrx{B}^T \cdot \Mtrx{A}^T$ are matrices of size $(p,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq p$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, we find:</span>
         </p><ul>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $(\Mtrx{A}\Mtrx{B})^T$ is: &#xA0; 
				<a id="hottag-5258" class="hottag" onmouseover="popup(5258)"> 
                           $a_{i1}b_{1j} + \cdots + a_{in}b_{nj}$
                        </a>  
				.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $\Mtrx{B}^T \Mtrx{A}^T$ is: &#xA0; $b_{1j}a_{i1} + \cdots + b_{nj}a_{in}$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Visibly these two expressions are equal. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>anticommutes with multiplication     </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5260' onmouseover='popup(5260)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5260" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication and addition is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5262' onmouseover='popup(5262)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5262" class="dialogs" title="Comment on multiplication and transposition of matrices"><info xmlns="Theorem">
         
         <p>
            <span>When transposing the product $\Mtrx{A}\Mtrx{B}$ of two matrices the result is not ‘transpose of $\Mtrx{A}$’ times ‘transpose of $\Mtrx{B}$’. Rather, the result is</span>
         </p>
         $$\Mtrx{B}^T\cdot \Mtrx{A}^T$$
         <p>
            <span>i.e. the order in which $\Mtrx{A}^T$ and $\Mtrx{B}^T$ need to be multiplied is the reverse of what one might naively expect.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-5251' onmouseover='infoopen(5251)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5251' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition is its own inverse
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Why does double transposition of a matrix return the original matrix? – Applying transposition once turns the  $i$-th row into the  $i$-th column. Applying transposition again turns this  $i$-th column back into the  $i$-th row, thus restoring the original matrix. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with addition of matrices</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>So why does the transposition operation commute with matrix addition? Let $\Mtrx{A}$ and $\Mtrx{B}$ be matrices of size $(m,n)$. Then  $(\Mtrx{A} + \Mtrx{B})^T$  and $\Mtrx{A}^T + \Mtrx{B}^T$ are matrices of size $(n,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq n$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, in both cases this entry is $a_{ij} + b_{ij}$. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition commutes with scalar multiplication of a matrix by a number
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this fact.</span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Transposition anticommutes with multiplication of matrices.
		</div></li><div id="dialog-5258" class="dialogs" title="Explanation"><info xmlns="Theorem">
                           
                           <p>
                              <span>This is the entry in position $(i,j)$ of $AB$. It turns into the entry in position $(j,i)$ of $(AB)^T$.</span>
                           </p>
                        </info></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>A new phenomenon is that transposition anticommutes with matrix multiplication. To see why this is so, let </span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A = [a_{ij}]$ be a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B = [b_{jk}]$ be a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(\Mtrx{A}\Mtrx{B})^T$ and $\Mtrx{B}^T \cdot \Mtrx{A}^T$ are matrices of size $(p,m)$. We need to show that in each position $(j,i)$, $1\leq j\leq p$ and $1\leq i\leq m$, the entries of these two matrices are equal. Indeed, we find:</span>
         </p><ul>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $(\Mtrx{A}\Mtrx{B})^T$ is: &#xA0; 
				<a id="hottag-5258" class="hottag" onmouseover="popup(5258)"> 
                           $a_{i1}b_{1j} + \cdots + a_{in}b_{nj}$
                        </a>  
				.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>Entry in position $(j,i)$ of $\Mtrx{B}^T \Mtrx{A}^T$ is: &#xA0; $b_{1j}a_{i1} + \cdots + b_{nj}a_{in}$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Visibly these two expressions are equal. So the proof is complete.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li></ul></li><li><span>invertible     </span><a id='glossaryinfo-5402' class='msm_infobutton' onmouseover='infoopen(5402)'>i</a><div id="dialog-5402" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5402' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ of size $(n,n)$ is invertible if there is a matrix $\Mtrx{B}$ such that</span>
                  </p>
                  $$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$
                  <p>
                     <span>In this case, $\Mtrx{B}$ is called the inverse of $\Mtrx{A}$, and is denoted $\Mtrx{A}^{-1}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-5396' onmouseover='popup(5396)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5396" class="dialogs" title="Size of the inverse matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>If $\Mtrx{A}$ is invertible, and $\Mtrx{B}$ is its inverse, then $\Mtrx{B}$ is automatically of size $(n,n)$.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>row rescaling     </span><a id='glossaryinfo-5535' class='msm_infobutton' onmouseover='infoopen(5535)'>i</a><div id="dialog-5535" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5535' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-5522' onmouseover='infoopen(5522)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-5522' style='display:none;'><div class='pack'><div class='title'>Examples of Row Rescaling Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(2,2)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 \\
					0 &amp; 3
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(3,3)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(3,3)$-matrices, the matrix which multiplies the third row by $5$ is</span>
         </p>
			
			      $$
					
					D_{3}(5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 5
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $3$-rd row by $2$ is</span>
         </p>
			
			      $$
					
					D_{3}(2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-5522" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of row rescaling matrices</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-5531' onmouseover='infoopen(5531)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-5531' style='display:none;'><div class='pack'><div class='title'>Explanation for Row Rescaling Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The row rescaling matrices</span>
         </p>
			
			      $$
					
					D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}
					
				$$
			
			      <p>
            <span>are named thus because, if $\Mtrx{B}$ is an arbitrary matrix of size $(n,p)$, then</span>
         </p>
			
			      $$
					
					\begin{bmatrix}
					1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
					\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
					0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
					\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
					0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
					\end{bmatrix}
					\begin{bmatrix}
					* &amp; \cdots &amp; * \\
					\vdots &amp; &amp; \vdots \\
					a_{u1} &amp; \cdots &amp; a_{up} \\
					\vdots &amp; &amp; \vdots \\
					{*} &amp; \cdots &amp; *
					\end{bmatrix}\ =\
					\begin{bmatrix}
					* &amp; \cdots &amp; * \\
					\vdots &amp; &amp; \vdots \\
					sa_{u1} &amp; \cdots &amp; sa_{up} \\
					\vdots &amp; &amp; \vdots \\
					{*} &amp; \cdots &amp; *
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>i.e. multiplying $\Mtrx{B}$ on the left with $D_{u}(s)$ has the effect of muyltiplying the $u$-th row of $\Mtrx{B}$ by $s$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(3,3)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_2(3)$ is</span>
         </p>
			
			      $$
					
					D_{2}(1/3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1/3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(3,3)$-matrices, the matrix which multiplies the third row by $5$ is</span>
         </p>
			
			      $$
					
					D_{3}(5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 5
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of  $D_3(5)$ is</span>
         </p>
			
			      $$
					
					D_{3}(1/5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 1/5
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_1(6)$ is</span>
         </p>
			
			      $$
					
					D_{1}(1/6) \ =\ 
					\begin{bmatrix}
					1/6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $2$-nd row by $6$ is</span>
         </p>
			
			      $$
					
					D_{2}(6) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 6 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_2(6)$ is</span>
         </p>
			
			      $$
					
					D_{2}(1/6) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1/6 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(4,4)$-matrices, the matrix which multiplies the $3$-rd row by $2$ is</span>
         </p>
			
			      $$
					
					D_{3}(2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_3(2)$ is</span>
         </p>
			
			      $$
					
					D_{3}(1/2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1/2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-5531" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation for the name ‘row rescaling matrix’</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>equation     </span><a id='glossaryinfo-10983' class='msm_infobutton' onmouseover='infoopen(10983)'>i</a><div id="dialog-10983" class="dialogs" title="matrix equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10983' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>of a dilation     </span><a id='glossaryinfo-19466' class='msm_infobutton' onmouseover='infoopen(19466)'>i</a><div id="dialog-19466" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19466' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>representing a linear map     </span><a id='glossaryinfo-15515' class='msm_infobutton' onmouseover='infoopen(15515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15515' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-15528' onmouseover='infoopen(15528)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15528' style='display:none;'><div class='title'>Linear Map Comes from a Matrix: Explanation</div><p xmlns="Unit">
               <span>Every linear transformation $L\from \RNr{n}\to \RNr{m}$ may be represented by a matrix, ... which matrix? – Here we explain first how the representing matrix is built. Then we explain which fundamental property of a linear map which makes this result possible.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>How to build the matrix representing a linear map</b>   Here we explain the procedure by which we build the matrix $\Mtrx{A}$ representing a linear transformation $L\from \RNr{n}\to \RNr{m}$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First apply $L$ to the vector $\StdBss{1}=(1,0,\dots ,0)$; then use the resulting vector of $\RNr{m}$ as the first column of $\Mtrx{A}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Next apply $L$ to the vector $\StdBss{2}=(0,1,0,\dots ,0)$, then use the resulting vector of $\RNr{m}$ as the second column of $\Mtrx{A}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>etc. until</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Finally apply $L$ to the vector $\StdBss{n}=(0,\dots ,0,1)$, then use the resulting vector of $\RNr{m}$ as the $n$-th and last column of $\Mtrx{A}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>
                  <b>Why does the representing matrix exist?</b>   Recall that for $n\geq 1$, $\RNr{n}$ contains infinitely many points. Therefore the function $L$ must make infinitely many assignments, one assignment of a point $L(\Vect{x})$ in $\RNr{m}$ for each $\Vect{x}$ in $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>What we learn here is that, because $L$ is linear, all of these infinitely many assignments are determined by the finite collection of assignments</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{1}$ to $L(\StdBss{1})$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{2}$ to $L(\StdBss{2})$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>etc.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{n}$ to $L(\StdBss{n})$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So this is it: finite base information implies information about infinitely many transformation situations. – What we describe here is a generalization of familiar linear functions like</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Info: A particle moves at the constant speed of $100km/h$. This is a single bit of information. Yet it enables us to recover the distance traveled by the particle within any interval of time of length $t$: $t \cdot 100$[km].</span>
                  </p>
                  <p>
                     <span>In this example, the fact that the particle travels at constant speed means that the distance traveled function $d\from \RNr{}\to \RNr{}$ is a linear function of time. – Without the information that the particle travels at constant speed, we have no way of telling how far it has traveled after 2 hours or 3 hours, etc.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Info: Henry earns 20 dollars per hour. This is a single bit of information. Yet it enables us to tell how much Henry earns after any number of hours at work. His earnings are a linear function of time. If Henry’s income is by commission only, his earnings are a nonlinear function of time; we have no way of telling how much he will earn after the first two hours if we only know what he earned after one hour.</span>
                  </p>
               </li>
            </ul></div><div id="dialog-15528" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>An explanation of the content of the proposition and how to use it.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-15588' onmouseover='infoopen(15588)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15588' style='display:none;'><div class='pack'><div class='title'>Example: Matrices for Coordinate Projection and Coordinate Inclusion</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The matrix which represents the projection of $\RNr{m}$ onto its $j$-th coordinate</span>
         </p>
			
			      $$\Prjctn{i}\from \RNr{m}\longrightarrow \RNr,\qquad \Prjctn{i}(x_1,\dots ,x_m)= x_i$$
			
			      <p>
            <span>is given by $A := [0\ \dots \ 0\ \ 1\ \ 0\ \dots \ 0]$, the ‘$1$’ sitting in position $i$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Given $\Vect{x}=(x_1,\dots ,x_m)\in\RNr{m}$,</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[0\ \dots \ 0\ \ 1\ \ 0\ \dots \ 0]\cdot \left[\begin{array}{c} x_1 \\ \vdots \\ x_m\end{array}\right]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_i$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Prjctn{i}(x_1,\dots ,x_n)$</td></tr></table>
			
			            <p>
                  <span>as required.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The inclusion of $\RNr{}$ in $\RNr{n}$ as the $j$-th coordinate axis</span>
         </p>
			
			      $$\Inclsn{j}\from \RNr{} \longrightarrow \RNr{n},\quad \Inclsn{j}(x) := (0,\dots ,0,x,0,\dots , 0)$$
			
			      <p>
            <span>is represented by the $(n,1)$-matrix</span>
         </p>
			
			      $$
					
B := \left[\begin{array}{c}
0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots \\ 0
\end{array}\right]
					
				$$
			
			      <p>
            <span>the $1$ in row $j$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Given $x\in \RNr{1}$,</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$B[x]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[\begin{array}{c} 0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right]\cdot [x] = \left[\begin{array}{c} 0 \\ \vdots \\ 0 \\ x \\ 0 \\ \vdots \\ 0 \end{array}\right] = \Inclsn{j}(x)$</td></tr></table>
			            <p>
                  <span>as was to be shown.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-15588" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>The matrix representing a projection onto a coordinate axis, and the matrix representing an inclusion of $\RNr{}$ as a coordinate axis.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-15610' onmouseover='infoopen(15610)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15610' style='display:none;'><div class='pack'><div class='title'>Example: The Matrix which Describes a Given Linear Map</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the linear transformation</span>
         </p>
			
			      $$L\from \RNr{2} \longrightarrow \RNr{2},\quad L(x,y) = (3x+y,x+2y)$$
			
			      <p>
            <span>and analyze the transformation properties of $L$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by finding the effect of $L$ on the unit vectors $\StdBss{1}=(1,0)$ and $\StdBss{2}=(0,2)$ in the direction of the coordinate axes.</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15598" class="hottag" onmouseover="popup(15598)">$=	$</a><div id="dialog-15598" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>This vector will form the first column of the matrix representing $L$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,0) = (3,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15603" class="hottag" onmouseover="popup(15603)">$=	$</a><div id="dialog-15603" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>This vector will form the second column of the matrix representing $L$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(0,1) = (1,2)$</td></tr></table>
			
			            <p>
                  <span>Therefore the matrix representing $L$ is</span>
               </p>
			
			            $$
					
A := \left[\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 2
\end{array}\right]
					
				$$
			
			            <p>
                  <span>This tells us that the unit square spanned by the vectors $\StdBss{1}$ and $\StdBss{2}$ gets transformed into the parallelogram spanned by the vectors $(3,1)$ and $(1,2)$.
				
				
			</span>
                  
               </p>
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo2To2_1.png" height="147" width="350"/></div>
			
			            <p>
                  <span>Thus we see that $L$ transforms the unit lattice of $\RNr{2}$ into the &#x2018;slanted&#x2019; below.
				
			</span>
                  
               </p>
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo2To2_2.png" height="233.1875" width="350"/></div>
			
			            <p>
                  <span>We now have two methods to compute how $L$ transforms a specific point, say $\Vect{x}=(2,5)$. We can either use the original definition of $L$ and find </span>
               </p>
			
			            $$L(2,5) = (3\cdot 2 + 5 , 2 + 2\cdot 5) = (11,12)$$
			
			            <p>
                  <span>Alternatively, we can use the matrix $\Mtrx{A}$ representing $L$ to obtain</span>
               </p>
			
			            $$
					
L(2,5) = \left[\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 2
\end{array}\right]
\left[\begin{array}{c}
2 \\ 5
\end{array}\right] = 
\left[\begin{array}{c}
3\cdot 2 + 5 \\ 2 + 2\cdot 5
\end{array}\right] =
\left[\begin{array}{c}
11 \\ 12
\end{array}\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-15610" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of finding the matrix representing a linear map $L\from \RNr{2}\to \RNr{2}$
            </span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-15530' onmouseover='infoopen(15530)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-15530' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>
               <b>Existence of</b>
               $\Mtrx{A}$ &#xA0; We begin by expressing the vectors  $L(\StdBss{j})$ of $\RNr{m}$ in coordinates</span>
         </p>$$L(\StdBss{j}) = (a_{1j},\dots ,a_{mj}) = a_{1j}\StdBss{1} + \dots + a_{mj}\StdBss{m}$$<p>
            <span>Now if</span>
         </p>$$\Vect{x} = (x_1,\dots ,x_n) = x_1\StdBss{1} + \dots + x_n\StdBss{n}$$<p>
            <span>then the following computation shows that $L(\Vect{x})$ can be computed from the vectors $L(\StdBss{1}),\dots ,L(\StdBss{n})$ alone</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\Vect{x})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1} + \cdots + x_n\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15539" class="hottag" onmouseover="popup(15539)">$=	$</a><div id="dialog-15539" class="dialogs" title=""><info>
                        <p>
                           <span>Here we use the linearity property of $L$ twice</span>
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1} + \cdots + x_n\StdBss{n})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1}) + \cdots + L(x_n\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1L(\StdBss{1}) + \cdots + x_nL(\StdBss{n})$</td></tr></table>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1 L(\StdBss{1}) + \cdots + x_n L(\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15544" class="hottag" onmouseover="popup(15544)">$=	$</a><div id="dialog-15544" class="dialogs" title=""><info>
                        <p>
                           <span>Substitute $a_{1j}\StdBss{1} + \cdots + a_{mj}\StdBss{m}$ for $L(\StdBss{j})$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1(a_{11}\StdBss{1} + \cdots + a_{m1}\StdBss{m}) + \cdots + x_n(a_{1n}\StdBss{1} + \cdots + a_{mn}\StdBss{m})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
				
\begin{array}{cccccc}
(a_{11}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{1n}x_n)\StdBss{1} + \\
\vdots &amp; &amp; &amp; &amp; \vdots \\
(a_{m1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{mn}x_n)\StdBss{m}
\end{array}
				
			$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
				
\left[
\begin{array}{ccc}
a_{11} &amp; \dots &amp; a_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; \dots &amp; a_{mn}
\end{array}
\right]
\left[
\begin{array}{c}
x_1 \\ \vdots \\ x_n
\end{array}
\right]
				
			$</td></tr></table><p>
            <span>This means exactly that $L$ can be computed by the matrix product stated in the theorem.</span>
         </p><p>
            <span>
               <b>Uniqueness of</b>
               $\Mtrx{A}$ &#xA0; It remains to show the matrix $\Mtrx{A}$ we found above is the only matrix with the property $L(\Vect{x}) = \Mtrx{A}\Vect{x}$. So suppose $\Mtrx{B}$ is another matrix satisfying</span>
         </p>$$\Mtrx{A}\Vect{x} = L(\Vect{x}) = \Mtrx{B}\Vect{x},\quad \text{for all $\Vect{x}\in \RNr{n}$}$$<p>
            <span>Choosing $\Vect{x} = \StdBss{j}$, we find</span>
         </p><p align="center">
            <span>
               $j$-th column of $\Mtrx{A} = A\StdBss{j} = L(\StdBss{j}) = B\StdBss{j} =$
               $j$-th column of $\Mtrx{B}$.</span>
         </p><p>
            <span> This holds for each $j$ with $1\leq j\leq n$, and so $\Mtrx{A} = \Mtrx{B}$, as was to be shown.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>of a contraction     </span><a id='glossaryinfo-6907' class='msm_infobutton' onmouseover='infoopen(6907)'>i</a><div id="dialog-6907" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6907' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>orthogonal     </span><a id='glossaryinfo-17139' class='msm_infobutton' onmouseover='infoopen(17139)'>i</a><div id="dialog-17139" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17139' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17133' onmouseover='popup(17133)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17133" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>In view of the previous corollary: a matrix is orthogonal exactly when it represents a distance preserving linear map.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-17135' onmouseover='popup(17135)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-17135" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>The terminology ‘orthogonal matrix’ is historically entrenched. It is, however, not optimally descriptive because ‘orthogonal’ only suggests that the column vectors of $\Mtrx{A}$ must be mutually perpendicular.</span>
                     </p>
                     <p>
                        <span>A bit more descriptive would be something like ‘orthonormal matrix’. This would truly mean that the columns of $\Mtrx{A}$ are normed, i.e. have length $1$, and must be mutually perpendicular. These are exactly the properties $\Mtrx{A}$ needs to represent a distance preserving linear map.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>inverse of a $(2,2)$-matrix     </span><a id='glossaryinfo-11000' class='msm_infobutton' onmouseover='infoopen(11000)'>i</a><div id="dialog-11000" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11000' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-11010' onmouseover='infoopen(11010)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-11010' style='display:none;'><div class='pack'><div class='title'>Inverse of a (2,2)-Matrix</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the inverse of the $(2,2)$-matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rr}
3 &amp; 4 \\
1 &amp; 7
\end{array}
\right]

				$$
			
			      <p>
            <span>provided it exists.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>To test whether $\Mtrx{A}$ is invertible, we compute:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{A})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$17 \neq 0$</td></tr></table>
			            <p>
                  <span>Therefore $\Mtrx{A}$ is invertible. According to the formula for the inverse of an invertible  (2,2)-matrix, we find</span>
               </p>
			            $$
					
\aligned
A^{-1}\ &amp;=\ \frac{1}{\text{det}(A)}\,
\left[
\begin{array}{rr}
7 &amp; -4 \\
-1 &amp; 3
\end{array}\right] \\
   &amp;=\ \frac{1}{17}\,
   \left[
\begin{array}{rr}
7 &amp; -4 \\
-1 &amp; 3
\end{array}\right]
\endaligned

				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-11010" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of inverting a $(2,2)$-matrix</span>
         </p>
      </info></div></ul></div><br /></div></li><li><span>diagonalizable     </span><a id='glossaryinfo-20285' class='msm_infobutton' onmouseover='infoopen(20285)'>i</a><div id="dialog-20285" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20285' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20276' onmouseover='infoopen(20276)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-20276' style='display:none;'><div class='title'>Diagonalizable Matrix - Explanation</div><p xmlns="Unit">
               <span>To see the meaning of the concept of ‘diagonalizable matrix’, let's do the following:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>use the column vectors of $\Mtrx{C}$ to form an ordered basis $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_n)$ of $\RNr{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then $\Mtrx{C}=\Mtrx{C}_{\EuScript{S}\EuScript{B}}$ converts from $\EuScript{B}$-coordinates to standard coordinates.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Both matrices $\Mtrx{A}$ and $\Mtrx{D}$ represent the same linear transformation of $\RNr{n}$. The difference is: $\Mtrx{A}$ describes it in standard coordinates, while $\Mtrx{D}$ describes it in $\EuScript{B}$-coordinates.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>Now, denote the diagonal entries of $\Mtrx{D}$ by $d_1,\dots ,d_n$:</span>
            </p>$$
					
\Mtrx{D} = 
\left[
\begin{array}{cccc}
d_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; d_2 &amp; &amp; \vdots \\
\vdots &amp; &amp; \ddots &amp; 0 \\
0 &amp; \cdots &amp; 0 &amp; d_n
\end{array}
\right]

				$$<p xmlns="Unit">
               <span>Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{D}\cdot (\Vect{b}_i)_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$d_i\cdot \Vect{b}_i$</td></tr></table><p xmlns="Unit">
               <span>In other words, $\Vect{b}_i$ is an eigenvector of $\Mtrx{A}$ with eigenvalue $d_i$.</span>
            </p><p xmlns="Unit">
               <span>Conclusion: Given $\Mtrx{A}$ we may try to diagonalize it by looking for a basis of $\RNr{n}$ consisting of eigenvectors of $\Mtrx{A}$.</span>
            </p></div><div id="dialog-20276" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concept of a diagonalizable matrix.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>power     </span><a id='glossaryinfo-20405' class='msm_infobutton' onmouseover='infoopen(20405)'>i</a><div id="dialog-20405" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>A method of computing powers $\Mtrx{A}^r$ of a diagonalizable matrix $\Mtrx{A}$
                  </span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20405' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Matrix exponentiation</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>For an integer $r\geq 1$ and a diagonalizable matrix $\Mtrx{A}$ with $\Mtrx{D} = \Mtrx{C}^{-1} \Mtrx{A} \Mtrx{C}$ diagonal,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{A}^r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C} \Mtrx{D}^r \Mtrx{C}^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-20437' onmouseover='infoopen(20437)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20437' style='display:none;'><div class='pack'><div class='title'>Diagonalize to Power a Matrix: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Compute $\Mtrx{A}^{10}$ if</span>
         </p>
			      $$
					
\Mtrx{A} =
\left[
\begin{array}{rr}
-9 &amp; 4 \\
-33 &amp; 14
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by trying to diagonalize $\Mtrx{A}$. The characteristic polynomial of $\Mtrx{A}$ is</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ 
	\det
	\left[
\begin{array}{cc}
-9-\lambda &amp; 4 \\
-33 &amp; 14 -\lambda
\end{array}
\right] \\
	&amp;=\ -(9+\lambda)(14 - \lambda)\ +\ 132 \\
	&amp;=\ \lambda^2 - 5\lambda + 6 \\
	&amp;=\ (\lambda - 2)(\lambda-3)
\endaligned

				$$
			            <p>
                  <span>So $\Mtrx{A}$ has two distinct eigenvalues:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\lambda_1 = 2$ with algebraic multiplicity $1$
                        </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\lambda_2 = 3$ with algebraic multiplicity $1$
                        </span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_1$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
-11 &amp; 4 \\
-33 &amp; 12
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>Therefore, $E_1 = \span(4,11)$
                  </span>
               </p>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_2$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
-12 &amp; 4 \\
-33 &amp; 11
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>Therefore, $E_2 = \span(1,3)$
                  </span>
               </p>
			            <p>
                  <span>It follows that $\EuScript{B}:= ((4,11),(1,3))$ is an ordered basis of $\RNr{2}$ consisting only of eigenvectors of $\Mtrx{A}$. Therefore $\Mtrx{A}$ is diagonalizable, and a diagonalizing matrix is given by</span>
               </p>
			            $$
					
\Mtrx{C} :=
\left[
\begin{array}{rr}
4 &amp; 1 \\
11 &amp; 3
\end{array}
\right] \qquad \text{with}\qquad
\Mtrx{C}^{-1} =
\left[
\begin{array}{rr}
3 &amp; -1 \\
-11 &amp; 4
\end{array}
\right]

				$$
			            <p>
                  <span>Accordingly,</span>
               </p>
			            $$
					
\Mtrx{D} :=
\left[
\begin{array}{cc}
2 &amp; 0 \\
0 &amp; 3
\end{array}
\right] =
\left[
\begin{array}{rr}
3 &amp; -1 \\
-11 &amp; 4
\end{array}
\right]
\left[
\begin{array}{rr}
-9 &amp; 4 \\
-33 &amp; 14
\end{array}
\right]
\left[
\begin{array}{rr}
4 &amp; 1 \\
11 &amp; 3
\end{array}
\right]

				$$
			            <p>
                  <span>We now have the easy computation of $\Mtrx{A}^{10}$:</span>
               </p>
			            $$
					
\aligned
\Mtrx{A}^{10}\ &amp;=\ 
\left(\left[
\begin{array}{rr}
4 &amp; 1 \\
11 &amp; 3
\end{array}
\right]
\left[
\begin{array}{rr}
2 &amp; 0 \\
0 &amp; 3
\end{array}
\right]
\left[
\begin{array}{rr}
3 &amp; -1 \\
-11 &amp; 4
\end{array}
\right] \right)^{10} \\
	&amp;=\ 
\left[
\begin{array}{rr}
4 &amp; 1 \\
11 &amp; 3
\end{array}
\right]
\left[
\begin{array}{rr}
2 &amp; 0 \\
0 &amp; 3
\end{array}
\right]^{10}
\left[
\begin{array}{rr}
3 &amp; -1 \\
-11 &amp; 4
\end{array}
\right] \\
	&amp;=\ 
\left[
\begin{array}{rr}
4 &amp; 1 \\
11 &amp; 3
\end{array}
\right]
\left[
\begin{array}{rr}
2^{10} &amp; 0 \\
0 &amp; 3^{10}
\end{array}
\right]
\left[
\begin{array}{rr}
3 &amp; -1 \\
-11 &amp; 4
\end{array}
\right] \\
	&amp;=\ 
\left[
\begin{array}{rr}
3\cdot 2^{12} - 11\cdot 3^{10} &amp; 4\cdot 3^{10} - 2^{12} \\
33\cdot 2^{10} - 11\cdot 3^{11} &amp; 4\cdot 3^{11} - 11\cdot 2^{10}
\end{array}
\right]
\endaligned

				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-20437" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of powering a diagonalizable matrix.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-20411' onmouseover='infoopen(20411)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-20411' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>The equality $\Mtrx{D} = \Mtrx{C}^{-1} \Mtrx{A} \Mtrx{C}$ is equivalent to</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{A}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C} \Mtrx{D} \Mtrx{C}^{-1}$</td></tr></table><p>
            <span>Therefore</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{A}^r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( \Mtrx{C} \Mtrx{D} \Mtrx{C}^{-1} \right)^r$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-20425" class="hottag" onmouseover="popup(20425)">$=	$</a><div id="dialog-20425" class="dialogs" title=""><info>
                        <p>
                           <span>
                              $r$ factors</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( \Mtrx{C} \Mtrx{D} \Mtrx{C}^{-1} \right) \left( \Mtrx{C} \Mtrx{D} \Mtrx{C}^{-1} \right)\ \cdots\ \left( \Mtrx{C} \Mtrx{D} \Mtrx{C}^{-1} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-20430" class="hottag" onmouseover="popup(20430)">$=	$</a><div id="dialog-20430" class="dialogs" title=""><info>
                        <p>
                           <span>Here we use that the pairs $\Mtrx{C}^{-1} \Mtrx{C}$ cancel.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}\, \Mtrx{D}^r\, \Mtrx{C}^{-1}$</td></tr></table><p>
            <span>as claimed.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li></ul></li><li><span>matrix multiplication     </span><ul class='chilren'><li><span>commutes with determinant     </span><a id='glossaryinfo-9650' class='msm_infobutton' onmouseover='infoopen(9650)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9650' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9669' onmouseover='popup(9669)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-9669" class="dialogs" title="Comment"><info xmlns="Theorem">
         
         <p>
            <span>This corollary says that the determinant of a product of two matrices is the product of the two determinants.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-9686' onmouseover='infoopen(9686)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9686' style='display:none;'><div class='pack'><div class='title'>Examples: Determinant of a Product</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Given an $(n,n)$-matrix $\Mtrx{A}$ with $\det(\Mtrx{A}) = 5$, find $\det(\Mtrx{A}^3)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We apply the fact that matrix multiplication commutes with the determinant operation:</span>
               </p>
			            $$\det(\Mtrx{A}\Mtrx{B})=\det(\Mtrx{A})\det(\Mtrx{B})$$
			            <p>
                  <span>In the case at hand we obtain</span>
               </p>
			            $$\det( \Mtrx{A}^3 ) = \left( \det(\Mtrx{A}) \right)^3 = 5^3 = 125$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>For an $(n,n)$-matrix $\Mtrx{C}$ and an integer $n\geq 1$ prove the formula</span>
         </p>
			      $$\det(\Mtrx{C}^n) = \left( \det(\Mtrx{C}) \right)^n$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We apply the fact that matrix multiplication commutes with the determinant operation:</span>
               </p>
			            $$\det(\Mtrx{A}\Mtrx{B})=\det(\Mtrx{A})\det(\Mtrx{B})$$
			            <p>
                  <span>In the case at hand we obtain</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{C}^n)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9679" class="hottag" onmouseover="popup(9679)">$=	$</a><div id="dialog-9679" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>on the right: $n$ copies of $\Mtrx{C}$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\left( \underset{\leftarrow\hfill \text{$n$ copies of $C$}\hfill\rightarrow}{\Mtrx{C} \cdots \cdots \Mtrx{C}}\right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\underset{\leftarrow\hfill \text{$n$ copies of $\det(C)$}\hfill\rightarrow}{\det(\Mtrx{C}) \cdots \cdots \det(\Mtrx{C})}$</td></tr></table>
			            <p>
                  <span>Notice: on the left hand side we first go through the labor intensive process of multiplying the matrix $\Mtrx{C}$ 
                     $n$ times by itself; then we compute the determinant of the resulting matrix. On the right hand side, we first evaluate the determinant, and then raise the resulting number to its $n$-th power - a much less labor intensive process.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-9686" class="dialogs" title="Example"><info xmlns="Theorem">
         
         <p>
            <span>A nice way of computing $\det(\Mtrx{A}^n)$
            </span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9654' onmouseover='infoopen(9654)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9654' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><div id="dialog-9657" class="dialogs" title="Why is this so?"><info>
                     
                     <p>
                        <span>Consider a non invertible $\Mtrx{A}$, and assume there is a matrix $\Mtrx{B}$ such that $\Mtrx{A}\Mtrx{B}$ is invertible. We know there is an invertible matrix $\Mtrx{R}$ such that $\Mtrx{R}\Mtrx{A}$ is in RREF. Given that $\Mtrx{A}$ is not invertible this means that $\Mtrx{R}\Mtrx{A}$ has at least one bottom row consisting of $0$’s only.</span>
                     </p>
                     <p>
                        <span>Now $\Mtrx{R}(\Mtrx{A}\Mtrx{B})$ is 
						<subordinate>
                              <a href="">invertible</a>  
                              <info>
                                 <p>
                                    <span>because it is a product of invertible matrices</span>
                                 </p>
                              </info>
                           </subordinate>
						and is equal to $(\Mtrx{R} \Mtrx{A})\Mtrx{B}$, which has at least one bottom row consisting of $0$’s only. So it is not invertible. This contradiction is a consequence of the assumption that $\Mtrx{A}\Mtrx{B}$ is invertible. So this assumption is false, and $\Mtrx{A}\Mtrx{B}$ is not invertible. 
					</span>
                     </p>
                  </info></div><div id="dialog-9659" class="dialogs"><info>
                                 <p>
                                    <span>because it is a product of invertible matrices</span>
                                 </p>
                              </info></div><div id="dialog-9663" class="dialogs"><info>
                        <p>
                           <span>Look up the determinant test for the invertibility of a matrix.</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9663' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div><div id="dialog-9665" class="dialogs" title="Why is $F$ linear in each column?"><info>
                     
                     <p>
                        <span>Given a matrix $\Mtrx{} = [B_1\ \dots\ B_n]$, expressed in terms of its column vectors. Then</span>
                     </p>
                     $$\Mtrx{A}\Mtrx{B} = [\Mtrx{A}B_1\ \dots\ \Mtrx{A}B_n]$$
                     <p>
                        <span>So each column $j$ of the matrix $\Mtrx{A}\Mtrx{B}$ is a linear function of the $j$-th column of $\Mtrx{B}$. The determinant operation is linear in the $j$-th column as well, and this implies that $F$ is linear in each column.</span>
                     </p>
                  </info></div><div id="dialog-9667" class="dialogs" title="Why is $F$ alternating?"><info>
                     
                     <p>
                        <span>To see why $F$ is alternating observe first that the following two processes have the same result:</span>
                     </p>
                     <ul>
                        <li>
                           <p>
                              <span>Interchange two columns $j$ and $k$ of $\Mtrx{B}$, then multiply on the left by $\Mtrx{A}$.</span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>Multiply $\Mtrx{B}$ on the left by $\Mtrx{A}$, then interchange columns $j$ and $k$.</span>
                           </p>
                        </li>
                     </ul>
                     <p>
                        <span>Following the second process with the determinant operation gives the required change of sign.</span>
                     </p>
                  </info></div>
<proof.block.body><proof.block.body><p>
            <span>We distinguish two cases. If $\Mtrx{A}$ is not invertible, then $\Mtrx{A}\Mtrx{B}$ is 
			<a id="hottag-9657" class="hottag" onmouseover="popup(9657)"> not invertible</a>  
			either. 
			<a id="hottag-9659" class="hottag" onmouseover="popup(9659)"> invertible</a>  
			both sides of the claimed identity above are $0$.</span>
         </p><p>
            <span>So let us turn to the case where $\Mtrx{A}$ is invertible; i.e. $\det(\Mtrx{A}) \neq 0$. We have the function</span>
         </p>$$F\from M_{nn} \longrightarrow \RNr,\quad F(\Mtrx{B}) := \dfrac{\det(\Mtrx{A}\Mtrx{B})}{\det(\Mtrx{A})}$$<p>
            <span>where $M_{nn}$ denotes the set of all $(n,n)$-matrices. Then $F$ is 
			<a id="activehottag-9663" class="activehottag" onmouseover="infoopen(9663)"> Therefore</a>  
			and is
			<a id="hottag-9665" class="hottag" onmouseover="popup(9665)"> linear in each column</a>  . 
			Moreover,
		</span>
         </p>$$F(\IdMtrx{n}) = \dfrac{\det(\Mtrx{A} \IdMtrx{n})}{\det(\Mtrx{A})} = \dfrac{\det(\Mtrx{A})}{\det(\Mtrx{A})} = 1$$<p>
            <span>
               <a id="hottag-9667" class="hottag" onmouseover="popup(9667)"> alternating</a>  
               $F=\det$; i.e. $\det(\Mtrx{B}) = \det(\Mtrx{A}\Mtrx{B})/\det(\Mtrx{A})$, and so
		</span>
         </p>$$\det(\Mtrx{A})\det(\Mtrx{B}) = \det(\Mtrx{A}\Mtrx{B})$$<p>
            <span>as claimed.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li></ul></li><li><span>minor     </span><a id='glossaryinfo-8909' class='msm_infobutton' onmouseover='infoopen(8909)'>i</a><div id="dialog-8909" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-minor of a matrix $\Mtrx{A}$ is the result of omitting the $i$-th row and the $j$-th column from $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8909' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-minor of $\Mtrx{A}$ is the $(r-1,r-1)$-matrix $\Mtrx{A}_{ij}$ which results from $\Mtrx{A}$ by omitting the $i$-th row and the $j$-th column.</span>
                        </p>
                        $$
						
\Mtrx{A}_{ij} = 
\left[
\begin{array}{cccccc}
a_{11} &amp; \cdots &amp; {\color{red} a_{1j}} &amp; \cdots &amp; \cdots &amp; a_{1r} \\
\vdots &amp; \ddots &amp; {\color{red} \vdots} &amp; &amp; &amp; \vdots \\
\vdots &amp;        &amp; {\color{red} \ddots} &amp;              &amp; &amp; \vdots \\
{\color{red} a_{i1}} &amp; {\color{red} \cdots} &amp; {\color{red} a_{ij}} &amp; {\color{red} \ddots } &amp; {\color{red} \cdots} &amp; {\color{red} a_{ir}} \\
\vdots &amp;  &amp; {\color{red} \vdots} &amp; &amp; \ddots &amp; \vdots \\
a_{r1} &amp; \cdots &amp; {\color{red} a_{rj}} &amp; \cdots &amp; \cdots &amp; a_{rr}
\end{array}
\right]

					$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-8899' onmouseover='popup(8899)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-8899" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>The minor $\Mtrx{A}_{ij}$ is $\Mtrx{A}$ without the $i$-th row and the $j$-th column.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-8903' onmouseover='infoopen(8903)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-8903' style='display:none;'><div class='pack'><div class='title'>Minors of a Matrix: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rrrr}
4 &amp; 1 &amp; 6 &amp; 5 \\
3 &amp; -2 &amp; -3 &amp; 2 \\
9 &amp; 2 &amp; 4 &amp; 7 \\
1 &amp; -9 &amp; -3 &amp; 1
\end{array}
\right]

				$$
			
			      <p>
            <span>has as its $(1,3)$-minor the matrix $\Mtrx{A}_{13}$ below. The $1$st row and the $3$rd column of $\Mtrx{A}$ have been omitted.</span>
         </p>
			
			      $$
					
\Mtrx{A}_{13} = 
\left[
\begin{array}{rrr}
3 &amp; -2  &amp; 2 \\
9 &amp; 2 &amp; 7 \\
1 &amp; -9 &amp; 1
\end{array}
\right]

				$$
			
			      <p>
            <span>For another example, the $(4,2)$-minor of $\Mtrx{A}$ is</span>
         </p>
			
			      $$
					
\Mtrx{A}_{42} = 
\left[
\begin{array}{rrrr}
4 &amp; 6 &amp; 5 \\
3 &amp; -3 &amp; 2 \\
9 &amp; 4 &amp; 7 
\end{array}
\right]

				$$
			      <p>
            <span>The $4$th row and the $2$nd column of $\Mtrx{A}$ have been omitted.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-8903" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of minors of a $(4,4)$-matrix</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-8905' onmouseover='popup(8905)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-8905" class="dialogs" title="Comment on the number of minors"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix of size $(n,n)$ has $n^2$ minors: one minor for each position in $\Mtrx{A}$.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>monomorphic linear transformation     </span><a id='glossaryinfo-18862' class='msm_infobutton' onmouseover='infoopen(18862)'>i</a><div id="dialog-18862" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18862' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>monomorphism     </span><a id='glossaryinfo-18866' class='msm_infobutton' onmouseover='infoopen(18866)'>i</a><div id="dialog-18866" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18866' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-18860' onmouseover='infoopen(18860)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-18860' style='display:none;'><div class='title'>Mono-, Epi-, Isomorphism: Explanation</div><p xmlns="Unit">
               <span>Let us analyze what the concepts of monomorphism, epimorphism, and isomorphism actually mean.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Epimorphism</b>   Suppose $L$ is an epimorphism. Now, if $\Vect{y}\in W$ is arbitrary, there is at least one $\Vect{x}\in V$ with $L(\Vect{x}) = \Vect{y}$.</span>
            </p><p xmlns="Unit">
               <span>In other words, the transform of $V$ inside $W$ fills all of $W$. – Note, however, that while $L$ transforms $V$ to cover $W$, it is possible that $L$ collapses parts of $V$ to single points.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Monomorphism</b>   If $L\from V\to W$ is a monomorphism, it can not collapse distinct parts of $V$. To see this, consider vectors $\Vect{u}$ and $\Vect{v}$ in $V$, and suppose</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{u})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v})$</td></tr></table><p xmlns="Unit">
               <span>Then we compute</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{0}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v}) - L(\Vect{u})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-18849' class='hottag' onmouseover='popup(18849)'>$=	$</a><div id="dialog-18849" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we use that $L$ is linear.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$L(\Vect{v} - \Vect{u})$</td></tr></table><p xmlns="Unit">
               <span>Now the only vector which gets transformed into $\Vect{0}$ by the monomorphic $L$ is the 0-vector. So</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{u}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{v}$</td></tr></table><p xmlns="Unit">
               <span>We conclude that a monomorphic $L$ transforms distinct points of $V$ into distinct points of $W$. In  other words, a monomorphic linear transformation does no collapsing. – Note, however, that there might be vectors $\Vect{w}$ in $W$ for which there is no $\Vect{v}$ in $V$ with $L(\Vect{v}) = \Vect{w}$: the transform of $V$ via $L$ need not cover $W$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Isomorphism</b>   An isomorphism $L\from V\to W$ combines both properties of a epimorphism and an monomorphism: it transforms $V$ to cover all of $W$ without collapsing any parts of $V$.</span>
            </p></div><div id="dialog-18860" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>An explanation of the concepts of monomorphism, epimorphism, and isomorphism.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>multilinear     </span><ul class='chilren'><li><span>property of the determinant operation     </span><a id='glossaryinfo-9074' class='msm_infobutton' onmouseover='infoopen(9074)'>i</a><div id="dialog-9074" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9074' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9201' onmouseover='infoopen(9201)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-9201' style='display:none;'><div class='title'>The Multilinearity Property of Determinants</div><p xmlns="Unit">
               <span>The determinant operation is linear in each column. What exactly does this mean? Let $1\leq j\leq n$ be an integer. Let's build an $(n,n)$-matrix by placing a fixed column vector in each column position, except for one, say in position $j$. The result is an $(n,n)$-matrix which looks like this:</span>
            </p>$$[A_1\ \dots\ A_{j-1}\ \ -\ \ A_{j+1}\ \dots\ A_n]$$<p xmlns="Unit">
               <span>Allowing the still vacant $j$-th column to be filled by vectors from $\RNr{n}$ yields a function $L\from \RNr{n}\longrightarrow \RNr{}$:</span>
            </p>$$L(X) := \det[A_1\ \dots A_{j-1}\ X\ A_{j+1}\ \dots\ A_n]$$<div id="dialog-9191" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>So $L$ commutes with vector addition and scalar multiplicaiton. Look up the definition of ‘linear transformation’.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-9191' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>To say that the determinant operation is linear in the $j$-th column means that the function $L$ above is 
				<a id="activehottag-9191" class="activehottag" onmouseover="infoopen(9191)"> linear</a>  . To say the determinant operation is multilinear means that this happens for each column $1\leq j\leq n$. In other words, these two identities hold:</span>
            </p>
$$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$$$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$<p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the determinant operation as a whole is linear and, consequently, to assert that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(\Mtrx{A} + \Mtrx{B})$   and   $(\det(\Mtrx{A}) + \det(\Mtrx{B}))$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(t\cdot \Mtrx{A})$ and $t\cdot \det(\Mtrx{A})$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>. Instead, if $\Mtrx{A}$ has size $(n,n)$, we have the identity</span>
            </p>$$\det(t\cdot \Mtrx{A}) = t^n\cdot \det(\Mtrx{A})$$</div><div id="dialog-9201" class="dialogs" title="Explanation: Multilinear"><info xmlns="Theorem">
         
         <p>
            <span>What exactly does it mean: ‘the determinant operation is linear in each column’? Here you can find a detailed explanation.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-9219' onmouseover='infoopen(9219)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9219' style='display:none;'><div class='pack'><div class='title'>Multilinearity Property of the Determinant: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid:</span>
         </p>
			
			      $$
					
\det\, 
\left[
\begin{array}{cc}
a &amp; 1 \\
b &amp; 3
\end{array}
\right] = 
\det\, 
\left[
\begin{array}{cc}
a &amp; 1 \\
0 &amp; 3
\end{array}
\right]\ +\ 
\det\, 
\left[
\begin{array}{cc}
0 &amp; 1 \\
b &amp; 3
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here $j=1$, and we have fixed the one and only remaining column, namely the second. To say that the  $(2,2)$-determinant is linear in the first column means, in particular, that the function</span>
               </p>
			
			            $$
					
L\from \RNr{2} \longrightarrow \RNr,\quad L(x,y):=
\det\, 
\left[
\begin{array}{cc}
x &amp; 1 \\
y &amp; 3
\end{array}
\right]

				$$
			
			            <p>
                  <span>satisfies</span>
               </p>
			
			            $$L(a,b) = L\left( (a,0) + (0,b)\right) = L(a,0) + L(0,b)$$
			
			            <p>
                  <span>and this is exactly the identity of determinants above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid.</span>
         </p>
			
			      $$
					
\det\, 
\left[
\begin{array}{cc}
10 &amp; 27 \\
25 &amp; 18
\end{array}
\right]\ =\ 
5\cdot \det\, 
\left[
\begin{array}{cc}
2 &amp; 27 \\
5 &amp; 18
\end{array}
\right]\ =\ 5\cdot 9\cdot \det\, 
\left[
\begin{array}{cc}
2 &amp; 3 \\
5 &amp; 2
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we have first applied linearity of the $(2,2)$-determinant in the first column and then linearity in the second column. In detail: First choose $j=1$, and fix the second column as $C_2:= [ 27\ \ 18]^T$. Then we obtain a linear function $L_1\from \RNr{2} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            $$L_1(10,25) = L_1(5\cdot (2,5)) = 5\cdot L_1(2,5)$$
			
			            <p>
                  <span>and this is the first equation of determinants above. Next choose $j=2$, and fix the first column as $C_2:= [2\ \ 5]^T$. Then we obtain a linear function $L_2\from \RNr{2} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            $$L_2(27,18) = L_2(9\cdot (3,2)) = 9\cdot L_2(3,2)$$
			
			            <p>
                  <span>and this is exactly the second equation of determinants above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following computation is valid.</span>
         </p>
			
			      $$
					
\aligned
\det\, 
\left[
\begin{array}{ccc}
4 &amp; 1+a &amp; 3 \\
1 &amp; 2+a &amp; 1 \\
5 &amp; 3+a &amp; 2
\end{array}
\right]\ &amp;=\ 
\det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 2 &amp; 1 \\
5 &amp; 3 &amp; 2
\end{array}
\right]\ +\ \det\, 
\left[
\begin{array}{ccc}
4 &amp; a &amp; 3 \\
1 &amp; a &amp; 1 \\
5 &amp; a &amp; 2
\end{array}
\right] \\
	&amp;=\ \det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 2 &amp; 1 \\
5 &amp; 3 &amp; 2
\end{array}
\right]\ +\ a\cdot \det\, 
\left[
\begin{array}{ccc}
4 &amp; 1 &amp; 3 \\
1 &amp; 1 &amp; 1 \\
5 &amp; 1 &amp; 2
\end{array}
\right] 
\endaligned

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we have applied linearity in the second column twice; first in the additive sense, then in the multiplicative sense. In detail: choose $j=2$, and fix the remaining columns as</span>
               </p>
			
			            <p align="center">
                  <span>
                     $C_1:=[4\ 1\ 5]^T$ and $C_3:=[3\ 1\ 2]^T$.</span>
               </p>
			
			            <p>
                  <span>Then we obtain a linear function $L\from \RNr{3} \longrightarrow \RNr{}$ which satisfies</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1+a,2+a,3+a)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,2,3) + L(a,a,a)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,2,3) + a\cdot L(1,1,1)$</td></tr></table>
			
			            <p>
                  <span>and this is exactly the computation above.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-9219" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>Examples of how to use the multilinearity property of the determinant.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9078' onmouseover='infoopen(9078)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9078' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>For $1\leq j\leq n$ and column vectors $A_1,\dots, A_{j-1},X,Y,A_{j+1},\dots ,A_n$ in $\RNr{n}$, set</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{R}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ X+Y\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{U}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ X\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{V}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ Y\ \ A_{j+1}\ \dots\ A_n]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{W}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[A_1\ \dots\ A_{j-1}\ \ t\cdot X\ \ A_{j+1}\ \dots\ A_n]$</td></tr></table><p>
            <span>Then we need to verify the following two identities</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{U}) + \det(\Mtrx{V})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(\Mtrx{V})$</td></tr></table><p>
            <span>For both statements we argue by induction on $n$.</span>
         </p><p>
            <span>
               <b>Anchoring the induction</b> &#xA0; If $n=1$, $\Mtrx{A}$ consists just of a single number. Necessarily, $j=1$, and</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[x+y]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x+y = \det[x] + \det[y]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[t\cdot x]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot x = t\cdot \det[x]$</td></tr></table><p>
            <span>So the claim holds for $n=1$.</span>
         </p><p>
            <span>
               <b>Induction hypothesis</b> &#xA0; Now let $n\geq 1$, and suppose that the determinant operation has the stated properties for matrices of size $(n,n)$.</span>
         </p><p>
            <span>
               <b>The induction step</b> &#xA0; We need to infer that the determinant operation has the stated properties for matrices of size  $(n+1,n+1)$. We begin with the additivity property in the first column; i.e. $j=1$. So</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{R}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[X+Y\ \ A_2\ \dots \ A_{n+1}]$</td></tr></table><p>
            <span>with $\Mtrx{X}=[x_1\ \dots\ x_{n+1}]^T$ and $\Mtrx{Y}= [y_1\ \dots\ y_{n+1}]^T$. Now the cofactor expansion of $\det(\Mtrx{R})$ along the first column yields</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}(x_i+y_i)\det(\Mtrx{R}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}x_i\det(\Mtrx{R}_{i1})\ +\ \sum_{i=1}^{n+1} (-1)^{i+1}y_i\det(\Mtrx{R}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det[X\ \ A_2\ \dots\ A_{n+1}]\ +\ \det[Y\ \ A_2\ \dots\ A_{n+1}]$</td></tr></table><p>
            <span>This shows that the determinant operation commutes with addition in the first column. To see that it commutes with scalar multiplication as well, consider $\Mtrx{W}= [tX\ \ A_2\ \dots\ A_{n+1}]$, for some  in $t\in\RNr{}$. We find</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} (-1)^{i+1}(tx_i)\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \sum_{i=1}^{n+1} (-1)^{i+1} x_i\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(U)$</td></tr></table><p>
            <span>This shows that the determinant operation commutes with scalar multiplication in the first column. We have shown that the determinant operation on  $(n+1,n+1)$-matrices is linear in the first column. Now consider columns $j$ with $j\geq 2$. We find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{R})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(R_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9153" class="hottag" onmouseover="popup(9153)">$=	$</a><div id="dialog-9153" class="dialogs" title=""><info>
                        <p>
                           <span>Here we apply the induction hypothesis to the $(n,n)$-matrix $R_{i1}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}\cdot (-1)^{i+1}( \det(U_{i1}) + \det(V_{i1}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1}\left( a_{i1}\cdot (-1)^{i+1} \det(U_{i1})\right)\ +\ \sum_{i=1}^{n+1}\left( a_{i1}\cdot (-1)^{i+1} \det(V_{i1}) \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{U}) + \det(\Mtrx{V})$</td></tr></table><p>
            <span>This completes the induction which establishes that the determinant operation commutes with addition in each column. To see that it commutes with scalar multiplication in each column as well, we compute:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(\Mtrx{W})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(\Mtrx{W}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9171" class="hottag" onmouseover="popup(9171)">$=	$</a><div id="dialog-9171" class="dialogs" title=""><info>
                        <p>
                           <span>Here we use the induction hypothesis</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}t\cdot \det(\Mtrx{U}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \sum_{i=1}^{n+1} a_{i1}(-1)^{i+1}\det(\Mtrx{U}_{i1})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \det(U)$</td></tr></table><p>
            <span>This completes the induction step which shows that the determinant operation commutes with scalar multiplication in each column. &#x2013; The proof of the multilinearity property of the determinant operation is complete.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li></ul></li><li><span>multiplication     </span><ul class='chilren'><li><span>of a vector by a number     </span><a id='glossaryinfo-847' class='msm_infobutton' onmouseover='infoopen(847)'>i</a><div id="dialog-847" class="dialogs"><info xmlns="Unit">
                                 $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-847' style='display:none;'><br /><div class='def'><span class='deftitle'>Multiplication of a Vector by a Scalar</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a vector $\Vect{x}=(x_1,\dots ,x_n)$ in $\RNr{n}$ by a number $t$ in $\RNr{}$ is
					</span>
                           
                        </p>
                        $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n).$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-845' onmouseover='infoopen(845)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-845' style='display:none;'><div class='pack'><div class='title'>Multiplying a Vector by a Scalar: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>To multiply a vector $\Vect{x}$ by a scalar $t$, we multiply each coordinate of $\Vect{x}$ by $t$. For example, we find the scalar product of $\Vect{x}=(-2,1)$ by $t=2$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            $$t\cdot \Vect{x}\ =\ 2\cdot (-2,1)\ =\ (-4,2).$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In $\RNr{3}$ find the scalar product of $\Vect{x}=(3,2,-1)$ by $t=-\frac{3}{2}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            $$t\cdot \Vect{x}\ =\ -\frac{3}{2}\cdot (3,2,-1)\ =\ \left(-\frac{9}{2},-3,\frac{3}{2}\right).$$
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In $\RNr{3}$ find the scalar product of $\Vect{x}=(-1,3,0,4)$ and $t=6$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            $$t\cdot \Vect{x}\ =\ 6\cdot (-1,3,0,4)\ =\ (-6,18,0,24).$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-845" class="dialogs" title="Examples of multiplying a vector by a scalar"><info xmlns="Unit">
                           
                           <p>
                              <span>Thus, when multiplying a vector by a number $t$, we just multiply each coordinate by $t$. – View some examples of this.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>multiplicity     </span><ul class='chilren'><li><span>algebraic     </span><a id='glossaryinfo-20083' class='msm_infobutton' onmouseover='infoopen(20083)'>i</a><div id="dialog-20083" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20083' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20074' onmouseover='infoopen(20074)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20074' style='display:none;'><div class='pack'><div class='title'>Algebraic Multiplicity: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Find the roots of the polynomial $q(\lambda)$ and their algebraic multiplicities if</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda^3 +4\lambda^2-3\lambda-18$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>First we need to find the roots of $q$, that is those number values for $\lambda$ with $q(\lambda)=0$.</span>
               </p>
			            <p>
                  <span>By trial and error we find</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(2)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2^3 + 4\cdot 2^2 - 3\cdot 2-18$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
			            <p>
                  <span>So $\lambda_1:=2$ is a root of $q$. So we know that $(\lambda-2)$ divides $q$. Via long division we find</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$q(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-2)(\lambda^2 +6\lambda +9)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-2)^1(\lambda+3)^2$</td></tr></table>
			            <p>
                  <span>We conclude that $q$ has</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>the root $\lambda_1=2$ with algebraic multiplicity $1$, and</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>the root $\lambda_2=3$ with algebraic multiplicity $2$.</span>
                     </p>
				              </li>
			            </ol>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Find the algebraic multiplicities of the roots of the polynomial</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-3)^5(\lambda+1)^2$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Here we get lucky: $p$ is given to us in a form from which we can read off its roots and their multiplicities right away.</span>
               </p>
			            <p>
                  <span>Indeed, the product $(\lambda-3)^5(\lambda+1)^2$ is $0$ exactly when at least one of its factors $(\lambda-3)$ or $(\lambda+1)$ is $0$.</span>
               </p>
			            <p>
                  <span>Now, $\lambda-3=0$ exactly when $\lambda=3$. So $p$ has the root $\lambda_1 = 3$ with algebraic multiplicity $5$.</span>
               </p>
			            <p>
                  <span>Similarly, $\lambda+1=0$ exactly when $\lambda=-1$. So $p$ has the root $\lambda_2=-1$ with algebraic multiplicity $2$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-20074" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>How to find the algebraic multiplicities of roots of a polynomial:</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>geometric     </span><a id='glossaryinfo-20132' class='msm_infobutton' onmouseover='infoopen(20132)'>i</a><div id="dialog-20132" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20132' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-20091' onmouseover='infoopen(20091)'><span style='cursor:pointer'>Comment</span></li><div class='refcontent' id='refcontent-20091' style='display:none;'><div class='title'>Eigenspace - Comments</div><p xmlns="Unit">
               <span>
                  <b>Subspace property of an eigenspace</b>   Given an $(n,n)$-matrix $\Mtrx{A}$, the eigenspace $E_k$ of $\Mtrx{A}$ with eigenvalue $\lambda_k$ is a subvector space of $\RNr{n}$. This is so because $E_k$ is the null space of the matrix $(\Mtrx{A} - \IdMtrx{n})$, hence is the orthogonal complement of the row vectors of $(\Mtrx{A} - \IdMtrx{n})$, and this is a subspace of $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Algebraic vs. geometric multiplicity</b>   One can show that the algebraic and geometric multiplicity of an eigenvalue are related by the inequality</span>
            </p>$$1 \leq \text{geometric multiplicity} \leq \text{algebraic multiplicity}$$</div><div id="dialog-20091" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Some comments on the concept of  on ‘Eigenspace’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-20128' onmouseover='infoopen(20128)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-20128' style='display:none;'><div class='pack'><div class='title'>Eigenvectors and Eigenvalues: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the eigenvalues and eigenspaces of the matrix</span>
         </p>
			      $$
					
\Mtrx{A} =
\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-20102" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>because the exponent of the factor $(\lambda - 2)$ of $p(\lambda)$ is $1$
                                    </span>
                                 </p>
                              </info></div><div id="dialog-20104" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>because the exponent of the factor $(\lambda - 4)$ of $p(\lambda)$ is $1$
                                    </span>
                                 </p>
                              </info></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by looking for the eigenvalues of $\Mtrx{A}$. First we find its characteristic polynomial:</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ 
	\det\left(
	\left[
\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 3
\end{array}
\right]\ -\ 
\lambda\cdot \left[
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right] \right) \\
	&amp;=\ \det
\left[
\begin{array}{cc}
3 - \lambda &amp; 1 \\
1 &amp; 3 - \lambda
\end{array}
\right] \\
	&amp;=\ (3-\lambda)^2 - 1 \\
	&amp;=\ \lambda^2 -6\lambda + 8 \\
	&amp;=\ (\lambda - 4)(\lambda - 2)
\endaligned

				$$
			            <p>
                  <span>So $\Mtrx{A}$ has two distinct eigenvalues:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\lambda_1 = 2$ with 
					<a id="hottag-20102" class="hottag" onmouseover="popup(20102)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\lambda_2 = 4$ with 
					<a id="hottag-20104" class="hottag" onmouseover="popup(20104)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_1$ consists of the solutions of the matrix equation $(\Mtrx{A} - \lambda_1 \IdMtrx{2})\Vect{x} = \Vect{0}$:</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
1 &amp; 1 \\
1 &amp; 1
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>The solutions of the corresponding system of linear equations are of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x,y)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s(-1,1)$</td></tr></table>
			            <p>
                  <span>where $s$ in $\RNr{}$ is arbitrary. Therefore the eigenspace of $\lambda_1$ is</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$E_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\span(-1,1)$</td></tr></table>
			            <p>
                  <span>and $\EuScript{B}_1 := (-1,1)$ is a basis of $E_1$. Thus $\Mtrx{A}$ transforms $E_1$ by scaling it by the factor of $2$.</span>
               </p>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_2$ consists of the solutions of the matrix equation $(\Mtrx{A} - \lambda_2 \IdMtrx{2})\Vect{x} = \Vect{0}$:</span>
               </p>
			            $$
					
\left[
\begin{array}{rr}
-1 &amp; 1 \\
1 &amp; -1
\end{array}
\right] 
\left[
\begin{array}{c}
x \\ y
\end{array}
\right] = 
\left[
\begin{array}{c}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>The solutions of the corresponding system of linear equations are of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x,y)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t(1,1)$</td></tr></table>
			            <p>
                  <span>where $t$ in $\RNr{}$ is arbitrary. Therefore the eigenspace of $\lambda_2$ is</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$E_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\span(1,1)$</td></tr></table>
			            <p>
                  <span>and $\EuScript{B}_ {2} := (1,1)$ is a basis of $E_2$. Thus $\Mtrx{A}$ transforms $E_2$ by scaling it by the factor of $4$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the eigenvalues and eigenspaces of the matrix</span>
         </p>
			      $$
					
\Mtrx{A}\ =\ \dfrac{1}{6}\left[
\begin{array}{rrr}
5 &amp; -1 &amp; -2 \\
-3 &amp; 3 &amp; -6 \\
-1 &amp; -1 &amp; 4
\end{array}\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-20123" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>Because the exponent of $(\lambda - 0)$ in $p(\lambda)$ is $1$.</span>
                                 </p>
                              </info></div><div id="dialog-20125" class="dialogs"><info xmlns="Compositor">
                                 <p>
                                    <span>Because the exponent of $(\lambda - 1)$ in $p(\lambda)$ is $2$.</span>
                                 </p>
                              </info></div><div id="dialog-20127" class="dialogs" title="Why do these vectors form a basis of $E_2$?"><info xmlns="Compositor">
                           
						
						                     <p>
                              <span>Visibly the vectors span $E_2$. Their linear independence can be seen with the determinant test applied to rows $1$ and $3$. So they form a basis of $E_2$.</span>
                           </p>
					                   </info></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by looking for the eigenvalues of  ; i.e. all those values of $\lambda$ for which the characteristic polynomial below vanishes.</span>
               </p>
			            $$
					
\aligned
p(\lambda)\ &amp;=\ \text{det}
\begin{bmatrix}
\tfrac{5}{6} - \lambda &amp; -\tfrac{1}{6} &amp; -\tfrac{1}{3} \\
-\tfrac{1}{2} &amp; \tfrac{1}{2} - \lambda &amp; -1 \\
-\tfrac{1}{6} &amp; -\tfrac{1}{6} &amp; \tfrac{2}{3} - \lambda
\end{bmatrix} \\
6^3\cdot p(\lambda)\ &amp;=\ \text{det}
\begin{bmatrix}
5 - 6\lambda &amp; -1 &amp; -2 \\
-3 &amp; 3 - 6\lambda &amp; -6 \\
-1 &amp; -1 &amp; 4 - 6\lambda
\end{bmatrix} \\
   &amp;=\ \lambda^3\ -\ 2 \lambda^2\ +\ \lambda \\
   &amp;=\ (\lambda - 0)^1(\lambda-1)^2
\endaligned

				$$
			            <p>
                  <span>Thus $\Mtrx{A}$ has two distinct eigenvalues:</span>
               </p>
			            <ol>
				              <li>
                     <p>
                        <span>
                           $\lambda_1=0$ with <a id="hottag-20123" class="hottag" onmouseover="popup(20123)"> algebraic multiplicity $1$
                              </a>  
				                    </span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>
                           $\lambda_2=1$ with <a id="hottag-20125" class="hottag" onmouseover="popup(20125)"> algebraic multiplicity $2$
                              </a>  
                        </span>
                     </p>
                  </li>
			            </ol>
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_1$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\dfrac{1}{6}
\left[\begin{array}{rrr}
5 &amp; -1 &amp; -2 \\
-3 &amp; 3 &amp; -6 \\
-1 &amp; -1 &amp; 4
\end{array}\right]\,
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}\ =\
\begin{bmatrix}
0 \\ 0 \\ 0
\end{bmatrix}

				$$
			            <p>
                  <span>The solutions of the corresponding system of homogeneous linear equations are of the form</span>
               </p>
			            $$
					
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = s
\left[
\begin{array}{c}
1 \\ 3 \\ 1
\end{array}
\right]

				$$
			            <p>
                  <span>with $s$ an arbitrary number in $\RNr{}$. Thus $\EuScript{B}_1=(\Vect{b}_1)$ with $\Vect{b}_1=(1,3,1)$ is a basis for $E_1$, the eigenspace of $\Mtrx{A}$ associated to $\lambda_1$. Therefore the geometric multiplicity of $\lambda_1$ is 1, and every nonzero vector in $E_1$ is an eigenvector of $\Mtrx{A}$ with eigenvalue    $0$. This means that $\Mtrx{A}$ transforms all of $E_1$ into the zerovector.</span>
               </p>
			
			
			            <p>
                  <span>The eigenspace of $\Mtrx{A}$ associated to $\lambda_2$ consists of the solutions of the matrix equation</span>
               </p>
			            $$
					
\dfrac{1}{6}
\left[\begin{array}{rrr}
-1 &amp; -1 &amp; -2 \\
-3 &amp; -3 &amp; -6 \\
-1 &amp; -1 &amp; -2
\end{array}\right]\,
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}\ =\
\begin{bmatrix}
0 \\ 0 \\ 0
\end{bmatrix}

				$$
			            <p>
                  <span>The solutions of the corresponding system of homogeneous linear equations are of the form</span>
               </p>
			            $$
					
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right] = s_1
\left[
\begin{array}{r}
1 \\ -1 \\ 0
\end{array}
\right] + s_2
\left[
\begin{array}{r}
0 \\ -2 \\ 1
\end{array}
\right]

				$$
			            <p>
                  <span>with $s_1$ and $s_2$ arbitrary numbers in $\RNr{}$. Thus $\EuScript{B}_2=(\Vect{b}_2,\Vect{b}_3)$ with</span>
               </p>
			            $$\Vect{b}_2 = (1,-1,0) \quad\text{and}\quad \Vect{b}_3=(0,-2,1)$$
			            <p>
                  <span>form a 
				<a id="hottag-20127" class="hottag" onmouseover="popup(20127)"> basis</a>  
				of $E_2$, the eigenspace associated to $\lambda_2$. Thus the geometric multiplicity of $\lambda_2$ is 2, and every nonzero vector in $E_2$ is an eigenvector of $\lambda_2$ with eigenvalue   $1$. This means that $\Mtrx{A}$ transforms each such vector into itself; i.e. $\Mtrx{A}$ acts as the identity transformation on $E_2$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-20128" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of finding eigenvalues and associated eigenspaces</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>neutral element     </span><ul class='chilren'><li><span>matrix multiplication     </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-5238' onmouseover='popup(5238)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5238" class="dialogs" title="Convention when reading this proposition"><info xmlns="Theorem">
         
         <p>
            <span>In the formuli of this proposition, we assume that the matrices involved satisfy the size property so that multiplication is defined.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-5240' onmouseover='popup(5240)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-5240" class="dialogs" title="On the neutral element property"><info xmlns="Theorem">
         
         <p>
            <span>In the formula   $\IdMtrx{m}A = A\IdMtrx{n}$, we also say</span>
         </p>
         <ul>
            <li>
               <p>
                  <span>
                     $\IdMtrx{m}$ is left neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $\IdMtrx{n}$ is right neutral with respect to multiplication by by $(m,n)$-matrices</span>
               </p>
            </li>
         </ul>
      </info></div><li class='proofminibutton' id='proofminibutton-5207' onmouseover='infoopen(5207)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-5207' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body><p>
            <span>To verify these claims we compute the entries in matching positions of both sides of the suggested equation.</span>
         </p></proof.block.body></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Associativity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ is a matrix of size $(n,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $C=[c_{kl}]$ is a matrix of size $(p,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $(AB)C$ and $A(BC)$ are matrices of size $(m,q)$. We need to show that in each position $(i,l)$, $1\leq i\leq m$    and  $1\leq l\leq q$, the entries of these two matrices are equal. To simplify the exposition, let</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $X := AB =[x_{ik}]$ &#xA0; be the matrix of size $(m,p)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $Y := BC = [y_{jl}]$ &#xA0; be the matrix of size $(n,q)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then we need to show that $XC = AY$. For the entry in position $(i,l)$ of these matrices we find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p} x_{ik}c_{kl}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\left( \sum_{j=1}^{n} a_{ij} b_{jk} \right) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{p}\sum_{j=1}^{n} (a_{ij}b_{jk}) c_{kl}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{k=1}^{n}\sum_{j=1}^{p} a_{ij} ( b_{jk}c_{kl} )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} \sum_{k=1}^{p} a_{ij} ( b_{jk} c_{kl})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij} \left( \sum_{k=1}^{p} b_{jk} c_{kl} \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sum_{j=1}^{n} a_{ij}y_{jl}$</td></tr></table><p>
            <span>This says exactly that the matrices $XC$ and $AY$ have the same entry in each position $(i,l)$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Distributivity
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Suppose</span>
         </p><ul>
            <li>
               <p>
                  <span>
                     $A=[a_{ij}]$ is a matrix of size $(m,n)$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $B=[b_{jk}]$ and $C=[c_{jk}]$ are matrices of size $(n,p)$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Then $A(B+C)$ and $AB + AC$ are matrices of size $(m,p)$. We need to show that in each position $(i,k)$, $1\leq i\leq m$ and $1\leq k\leq p$, the entries in those two matrices are equal. We find</span>
         </p><ul>
            <li>
               <p>
                  <span>of $A(B+C)$:   $a_{i1}(b_{1j}+c_{1j}) + \cdots + a_{in}(b_{nj} + c_{nj})$
                  </span>
               </p>
            </li>
            <li>
               <p>
                  <span>of $AB + AC$   $(a_{i1}b_{1j}+\cdots + a_{in}b_{nj})\ +\ a_{i1}c_{1j}+\cdots +a_{in}c_{nj})$
                  </span>
               </p>
            </li>
         </ul><p>
            <span>Rules for computing with numbers show that these entries are equal, and the distributivity property of matrix multiplication follows. - We second distributivity law follows with the same method. </span>
         </p></proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>Identity matrix is neutral with respect to multiplication</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We leave it to the reader to establish this claim.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>non-degeneracy     </span><ul class='chilren'><li><span>dot product     </span><a id='glossaryinfo-1885' class='msm_infobutton' onmouseover='infoopen(1885)'>i</a><div id="dialog-1885" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the dot product asserts that </span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1885' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>non-degenerate     </span><ul class='chilren'><li><span>norm     </span><a id='glossaryinfo-1487' class='msm_infobutton' onmouseover='infoopen(1487)'>i</a><div id="dialog-1487" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1484" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1484" class="hottag" onmouseover="popup(1484)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li></ul></li><li><span>norm     </span><ul class='chilren'><li><span>of a vector: properties     </span><a id='glossaryinfo-1691' class='msm_infobutton' onmouseover='infoopen(1691)'>i</a><div id="dialog-1691" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the norm operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1691' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1696" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1696" class="hottag" onmouseover="popup(1696)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-1741' onmouseover='popup(1741)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-1741" class="dialogs" title="Explanation of $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
         "><info xmlns="Theorem">
         
         <p>
            <span>This property is intuitively quite plausible: The vector $t\cdot \Vect{x}$ results from $\Vect{x}$ by stretching or shrinking its length by a factor of $|t|$, followed by reversing it, in case $t$ is negative. In either case, the length of the resulting vector is $|t|\cdot |\Vect{x}|$, and this is exactly what the formula claims.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-1743' onmouseover='popup(1743)'><span style='cursor:pointer'>Example</span></li><div id="dialog-1743" class="dialogs" title="Example of a Unit Vector"><info xmlns="Theorem">
         
         <p>
            <span>For example, the unit vector in the direction of $\Vect{x}=(4,2,4)$ is</span>
         </p>
         $$\Vect{u} = \tfrac{1}{\abs{\Vect{x}} }\cdot \Vect{x} = \tfrac{1}{6}\cdot (4,2,4)$$
      </info></div><li class='minibutton' id='minibutton-1745' onmouseover='popup(1745)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1745" class="dialogs" title="Comment on nondegeneracy property of norm"><info xmlns="Theorem">
         
         <p>
            <span>In other words: there is exactly one vector in $\RNr{n}$ whose norm is $0$, namely the zero-vector.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1702' onmouseover='infoopen(1702)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1702' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			We verify this property by direct computation:
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$|t\cdot \Vect{x}|$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$|t\cdot (x_1,\dots ,x_n)|$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$|(tx_1,\dots ,tx_n)|$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sqrt{(tx_1)^2+\cdots + (tx_n)^2}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sqrt{t^2x_{1}^{2}+ \cdots + t^2x_{n}^{2}}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\sqrt{t^2(x_{1}^{2}+\cdots + x_{n}^{2})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$|t|\cdot \sqrt{x_{1}^{2}+\cdots +x_{n}^{2}}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$|t|\cdot |\Vect{x}|$</td></tr></table><p>
            <span>as was to be shown.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			We verify this property by direct computation:
		</div></li><div id="dialog-1736" class="dialogs" title="Explanation"><info xmlns="Theorem">
                     
                     <p>
                        <span>Here we use the previous property of the norm operation: $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$.</span>
                     </p>
                  </info></div><div id="dialog-1738" class="dialogs" title="Explanation"><info xmlns="Theorem">
                     
                     <p>
                        <span>Here we use that $|\Vect{x}| &gt; 0$
                        </span>
                     </p>
                  </info></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p align="center">
            <span>
               $\left| \frac{\Vect{x}}{|\Vect{x}|} \right|$
               <a id="hottag-1736" class="hottag" onmouseover="popup(1736)"> 
                     $=$
                  </a>  
               $|1/|\Vect{x}| | \cdot |\Vect{x}|$
               <a id="hottag-1738" class="hottag" onmouseover="popup(1738)"> 
                     $=$
                  </a>  
               $= 1$
            </span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non degeneracy of norm:
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If $\Vect{x} = (x_1,\dots ,x_n)$, consider first the case where $\Vect{x}= \Vect{0}$. In this case $|\Vect{x}| = \sqrt{0^2+\cdots +0^2} = 0$. So, as expected: the zero vector has norm $0$.</span>
         </p><p>
            <span>For the converse, suppose $\Vect{x}$ satisfies $|\Vect{x}| = 0$. We verify by direct computation that $\Vect{x} = \Vect{0}$. Indeed, we have</span>
         </p>$$0 = |\Vect{x}|^2 = x_{1}^{2} + \cdots + x_{n}^{2}$$<p>
            <span>Each of the squares on the right is greater than or equal to $0$. So, if the sum of these squares vanishes, so must each square by itself. Therefore $x_1=\cdots =x_n=0$; i.e. $\Vect{x}=\Vect{0}$ as claimed.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li><li><span>non-degeneracy     </span><a id='glossaryinfo-1489' class='msm_infobutton' onmouseover='infoopen(1489)'>i</a><div id="dialog-1489" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1489' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1484" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1484" class="hottag" onmouseover="popup(1484)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>relationship to dot product     </span><a id='glossaryinfo-1959' class='msm_infobutton' onmouseover='infoopen(1959)'>i</a><div id="dialog-1959" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1959' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>of a vector     </span><a id='glossaryinfo-1676' class='msm_infobutton' onmouseover='infoopen(1676)'>i</a><div id="dialog-1676" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm or length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1676' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-1666' onmouseover='popup(1666)'><span style='cursor:pointer'>Example</span></li><div id="dialog-1666" class="dialogs" title="Example of a Norm Computation"><info xmlns="Unit">
                     
                     <p>
                        <span>The norm of the vector $\Vect{x} = (1,2,2)$ in $\RNr{3}$ is</span>
                     </p>
                     $$\abs{\Vect{x}} = \sqrt{ 1^2 + 2^2 + 2^2 } = 3$$
                  </info></div><li class='defminibutton' id='defminibutton-1668' onmouseover='popup(1668)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1668" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the length of $\Vect{x}$ is obtained by summing up the squares of the components of $\Vect{x}$, and then taking the square root.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>property of the determinant operation     </span><a id='glossaryinfo-9467' class='msm_infobutton' onmouseover='infoopen(9467)'>i</a><div id="dialog-9467" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9467' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li></ul></li><li><span>normal     </span><ul class='chilren'><li><span>vector     </span><a id='glossaryinfo-2346' class='msm_infobutton' onmouseover='infoopen(2346)'>i</a><div id="dialog-2346" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>to a hyperspace in $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2346' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-2328' onmouseover='popup(2328)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-2328" class="dialogs" title="Explanation: How to read this expression"><info xmlns="Unit">
                           
                           <p>
                              <span>Read $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$ as:</span>
                           </p>
                           <p>
                              <span>‘Perp of $\Vect{n}$ is defined to be the set of all those $\Vect{x}$ in $\RNr{}\ \ n$ such that the dot product of $\Vect{x}$ and $\Vect{n}$ is $0$’.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-2342' onmouseover='infoopen(2342)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2342' style='display:none;'><div class='title'>Hyperspace – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate the concept of a hyperspace in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{2}$ is just a line through the origin. Thus the red line in the picture below is a hyperspace. We characterize it as the collection of all those vectors which are perpendicular to the green vector $\Vect{n}$, called a normal vector to the hyperspace.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace2D.png' height='274.4' width='350'/></div><p xmlns="Unit">
               <span>Notice that a hyperspace has many normal vectors: if $\Vect{n}$ is a normal  vector, so are $2\cdot \Vect{n}$, $3\cdot \Vect{n}$, $(-1)\cdot \Vect{n}$ and, in general, $t\cdot \Vect{n}$ for any $t\neq 0$.</span>
            </p><p xmlns="Unit">
               <span>A hyperspace in $\RNr{3}$ is just a plane, in the usual sense of the word, which passes through the origin.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperSpace3D.gif" height="328.43942505133" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, if we call the hyperspace $H$, then the blue arrow $\Vect{n}$, is called a normal vector of $H$ because it is perpendicular to all those vectors which belong to $H$. The second plane in this picture (horizontal) is only there to provide visual reference points. Note that any non-zero multiple of $\Vect{n}$ is also a normal vector of $H$: if $n\geq 1$, there are always many normal vectors to a given hyperspace.</span>
            </p><p xmlns="Unit">
               <span>If $n \geq 4$, we cannot visualize a hyperspace in $\RNr{n}$. Still we can characterize it as the collection of all those vectors in $\RNr{n}$ which are perpendicular to a given nonzero vector $\Vect{n}$.</span>
            </p></div><div id="dialog-2342" class="dialogs" title="Illustration"><info xmlns="Unit">
                           
                           <p>
                              <span>For this definition to make sense we need to recall that the word ‘normal’ here means ‘perpendicular’. So $\text{Perp}(\Vect{n})$ consists of all those $\Vect{x}$ which are perpendicular to the given vector $\Vect{n}$. The mathematical test for being perpendicular is: $\DotPr{\Vect{x}}{\Vect{n}} = 0$.</span>
                           </p>
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>null space     </span><a id='glossaryinfo-11523' class='msm_infobutton' onmouseover='infoopen(11523)'>i</a><div id="dialog-11523" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11523' style='display:none;'><br /><div class='def'><span class='deftitle'>Null space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The null space of an $(m,n)$-matrix $\Mtrx{A}$ is the collection of all those $\Vect{x}$ in $\RNr{n}$ with $\Mtrx{A}\cdot \Vect{x} = \Vect{0}$. We denote it by $\NllSp{ \Mtrx{A} }$
                     </span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11519' onmouseover='infoopen(11519)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-11519' style='display:none;'><div class='pack'><div class='title'>Null Space: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the null space of the matrix</span>
         </p>
			      $$
					
\Mtrx{A} = 
\left[
\begin{array}{rrr}
3 &amp; 1 &amp; 7 \\
-2 &amp; 1 &amp; 4 \\
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We are looking for the solutions of the vector equation</span>
               </p>
			            $$
					 
\left[
\begin{array}{rrr}
3 &amp; 1 &amp; 7 \\
-2 &amp; 1 &amp; 4 \\
\end{array}
\right]\cdot 
\left[
\begin{array}{r}
x \\ y \\ z
\end{array}
\right]\ =\ 
\left[
\begin{array}{cc}
0 \\ 0
\end{array}
\right]

				$$
			            <p>
                  <span>We see that the solutions of this vector equation correspond to the simultaneous solutions of the system of two homogeneous linear equations</span>
               </p>
			            $$
					
\begin{array}{rcrcrcl}
3x &amp; + &amp; y &amp; + &amp; 7z &amp; = &amp; 0 \\
-2x&amp; + &amp; y &amp; + &amp; 4z &amp; = &amp; 0
\end{array}

				$$
			            <p>
                  <span>The augmented coefficient matrix of this system of linear equations is</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
3 &amp; 1 &amp; 7 &amp; 0 \\
-2&amp; 1 &amp; 4 &amp; 0
\end{array}

				$$
			            <p>
                  <span>The RREF of this matrix is</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
1 &amp; 0 &amp; \tfrac{3}{5} &amp; 0 \\
0 &amp; 1 &amp; \tfrac{26}{5}&amp; 0
\end{array}

				$$
			            <p>
                  <span>This means that $(x,y,z)$ solves the system exactly when, for arbitrary $z$ in $\RNr{}$,</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-\tfrac{3}{5}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$y$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-\tfrac{26}{5}$</td></tr></table>
			            <p>
                  <span>In other words,</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x,y,z)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$z\cdot (-\tfrac{3}{5},-\tfrac{26}{5},1)$</td></tr></table>
			            <p>
                  <span>Therefore, the null space of $\Mtrx{A}$ consists of all vectors of the form $z\cdot (-\tfrac{3}{5},-\tfrac{26}{5},1)$, with $z$ in $\RNr{}$ arbitrary. This is the line in $\RNr{3}$ through the origin in the direction of the vector $(-3,-26,5)$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-11519" class="dialogs" title="Examples"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of the null space of a matrix.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>of linear transformations     </span><ul class='chilren'><li><span>sum     </span><a id='glossaryinfo-17715' class='msm_infobutton' onmouseover='infoopen(17715)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17715' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17717' onmouseover='popup(17717)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17717" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the functions $L$ and $T$, we define a new function here, namely $(L+T)$. The effect of the sum function $(L+T)$ on a vector $\Vect{x}$ is the sum $L(\Vect{x})$ plus $T(\Vect{x})$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with two linear function $L$ and $T$, we do not know if their sum $(L+T)$ is linear. Therefore we must check that $(L+T)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>ordered     </span><ul class='chilren'><li><span>basis     </span><a id='glossaryinfo-13325' class='msm_infobutton' onmouseover='infoopen(13325)'>i</a><div id="dialog-13325" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13325' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div></li></ul></li><li><span>ordered pair     </span><a id='glossaryinfo-105' class='msm_infobutton' onmouseover='infoopen(105)'>i</a><div id="dialog-105" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>another word for $2$-tuple; i.e. an expression of the form $(x,y)$, where $x$ and $y$ are numbers.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-105' style='display:none;'><div class='title'>Visualizing $\RNr{n}$
      </div><p xmlns="Unit">
               <span>If $n$ is one of the integers $1,2,3$, then we may visualize $\RNr{n}$ as follows</span>
            </p><div id="dialog-99" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. a single number $x$ between brackets: $(x)$
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{}=\RNr{1}$: The set of all <a id="hottag-99" class="hottag" onmouseover="popup(99)"> 
                        $1$-tuples</a>   forms a line on which one point has been designated to be $0$, and a unit of measurement has been chosen. &#x2013; It is customary to call the line the $x$-<b>axis</b>.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R1_illstrtn.gif" height="50" width="350"/></div>
               </span>
            </p>
<div id="dialog-107" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. two number $x$ and $y$ between brackets: $(x,y)$. Such $2$-tuples are also called <b>ordered pairs</b>.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{2}$: The set of all <a id="hottag-107" class="hottag" onmouseover="popup(107)"> 
                        $2$-tuples or ordered pairs</a>  
			forms a plane on which one point $\mathbf{0}$ has been designated to be the origin, and two perpendicular lines with a unit of measurement have been chosen. &#x2013; It is customary to draw one of these axes horizontal and call it the $x$-<b>axis</b>. The other line will then appear vertical and will be called the $y$-<b>axis</b>.
		</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R2_illstrtn.gif" height="345.47413793103" width="350"/></div>
               </span>
            </p>
<div id="dialog-113" class="dialogs" title="Animation of relating ordered pairs to points in the plane">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnCrdnts2_anm.gif" height="223.33333333333" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>If we want to give the name $P$ to the point $(2,1)$
                  <a id="hottag-113" class="hottag" onmouseover="popup(113)"> displayed above</a>  , we write $P(2,1)$ to express that it has coordinates $2$ and $1$.</span>
            </p>
<div id="dialog-118" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. three numbers $x,y,z$ between brackets: $(x,y,z)$
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{3}$: The set of all <a id="hottag-118" class="hottag" onmouseover="popup(118)"> 
                        $3$-tuples or ordered triples</a>   can be related to points in the world surrounding us. We pick one point, $\mathbf{0}$, to act as the origin. Then we pick three perpendicular lines with a unit of measurement.. &#x2013; In the picture below,
		</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>the first coordinate axis points toward you. We call it the $x$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> the second coordinate axis goes from left to right. We call the $y$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the third coordinate axis has a vertical direction. We call it the $z$-axis</span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R3_illstrtn.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we want to give the name $Q$ to the point $(3,2,2)$ displayed above, we write $Q(3,2,2)$. To plot it, consider the box in the picture above. Then, starting from the origin,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>move 3 units in the $x$-direction (to arrive a the bottom front left corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $y$-direction (to arrive at the front right bottom corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $z$-direction (to arrive at the blue corner of the box)</span>
                  </p>
               </li>
            </ol><div id="dialog-127" class="dialogs" title="Animation of plotting ordered triples in a 3D-coordinate system.">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnCrdnts3_anm.gif" height="250.6976744186" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>You can also see an 
			<a id="hottag-127" class="hottag" onmouseover="popup(127)"> animation</a>    of this plotting process for several points in $\RNr{3}$.</span>
            </p>
<p xmlns="Unit">
               <span>Note that, in $\RNr{3}$,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>points on the first coordinate axis are given by triples of the form $(x,0,0)$, where $x$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the second coordinate axis are given by triples of the form $(0,y,0)$, where $y$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the third coordinate axis are given by triples of the form $(0,0,z)$, where $z$ is an arbitrary number.</span>
                  </p>
               </li>
            </ol></div></li><li><span>orientation     </span><ul class='chilren'><li><span>1-dimensional     </span><a id='glossaryinfo-10030' class='msm_infobutton' onmouseover='infoopen(10030)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10030' style='display:none;'><div class='title'>1-Dimensional Orientation</div><div id="dialog-10042" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10042' style='display:none;'><div class='title'>1-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Forward’ and ‘backward’ on a line are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation1.png' height='35.4375' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{}$ is given by a choice of one of these two directions. Thus a nonzero vector $\Vect{x}=(x)$ represents an orientation $\omega(\Vect{x})$ of  $\RNr{}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $ x&gt;0 $
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Vect{x}$ represents the positive orientation of $\RNr{}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $ x&lt;0 $
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Vect{x}$ represents the negative orientation of $\RNr{}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, $\Vect{x}=(2)$ below represents the positive orientation of $\RNr{}$. We express this by writing $\omega(\Vect{x}) = +1$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the pair $\Vect{v}=(-3)$ represents the negative orientation of $\RNr{}$. We express this by writing $\omega(\Vect{v}) = -1$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Forward&#x2019; and &#x2018;backward&#x2019; on a line are 
				<a id="activehottag-10042" class="activehottag" onmouseover="infoopen(10042)"> mirrored siblings</a>  .
				An orientation of $\RNr{}$ is given by a choice of one of these two directions. We use a nonzero vector $\Vect{x}=(x)$ to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&gt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the positive orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&lt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the negative orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>2-dimensional     </span><a id='glossaryinfo-10044' class='msm_infobutton' onmouseover='infoopen(10044)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10044' style='display:none;'><div class='title'>2-Dimensional Orientation</div><div id="dialog-10067" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10067' style='display:none;'><div class='title'>2-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Counterclockwise’ and ‘clockwise’ motions in the plane are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2.png' height='188.125' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{2}$ is given by a choice of one of these two directions. Any pair $(\Vect{x},\Vect{y})$ of noncolinear vectors represents an orientation $\omega(\Vect{x},\Vect{y})$ of  $\RNr{2}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the counterclockwise direction</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y})$ represents the positive orientation of $\RNr{2}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the clockwise direction</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y})$ represents the negative orientation of $\RNr{2}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the pair $(\Vect{x},\Vect{y})$ below represents the positive or counterclockwise orientation of $\RNr{2}$. We express this by writing $\omega(\Vect{x},\Vect{y}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2CClockwise.png' height='178.0625' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the pair $(\Vect{x},\Vect{y})$ below represents the negative or clockwise orientation of $\RNr{2}$. We express this by writing $\omega(\Vect{x},\Vect{y}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2Clockwise.png' height='206.5' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging vectors in a pair of vectors reverses orientation</b>
               </span>
            </p><p xmlns="Unit">
               <span>Start with a pair of vectors $(\Vect{x},\Vect{y})$ representing a given orientation. Then interchange the vectors so as to obtain a new pair of ordered vectors: $(\Vect{y},\Vect{x})$. This new pair also represents an orientation of $\RNr{2}$. However, this time the shorter of the two arcs from $\Vect{y}$ to $\Vect{x}$ is the same as the shorter of the two arcs from $\Vect{x}$ to $\Vect{y}$, just in the opposite direction. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x})$</td></tr></table></div>
<p xmlns="Unit">
                     <span>&#x2018;Counterclockwise&#x2019; and &#x2018;clockwise&#x2019; motions in the plane are 
				<a id="activehottag-10067" class="activehottag" onmouseover="infoopen(10067)"> mirrored siblings</a>  .
				An orientation of $\RNr{2}$ is given by a choice of one of these two directions. We use an ordered pair $(\Vect{x},\Vect{y})$ of noncolinear vectors to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the counterclockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the positive orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the clockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the negative orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>3-dimensional     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li><li><span>right hand     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li><li><span>left hand     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li><li><span>of a subspace of $\RNr{k}$     </span><a id='glossaryinfo-14517' class='msm_infobutton' onmouseover='infoopen(14517)'>i</a><div id="dialog-14517" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is given by the choice of an ordered $n$-tuple $\EuScript{B} = (\Vect{b}_1, \dots , \Vect{b}_n)$ of $V$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14517' style='display:none;'><br /><div class='def'><span class='deftitle'>Orientation of a subspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>An orientation of an $n$-dimensional subspace $V$ of $\RNr{k}$ is given by a choice of an ordered basis $\EuScript{B} = (\Vect{b}_1 , \dots , \Vect{b}_n )$ of $V$.
				</span>
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-14515' onmouseover='infoopen(14515)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-14515' style='display:none;'><div class='pack'><div class='title'>Orientation in General: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Describe possible orientations of a 1-dimensional subspace $V$ of $\RNr{k}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Discussion</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>A 1-dimensional subspace $V$ of $\RNr{k}$ is just a line through the origin. Therefore, an ordered basis of $V$ consists just of a single nonzero vector $\Vect{b}$ in $V$. It determines a direction of `increasing' in $V$, together with its opposite: a direction of decreasing.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Describe possible orientations of a 2-dimensional subspace $V$ of $\RNr{k}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Discussion</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>A 2-dimensional subspace $V$ of $\RNr{k}$ is a plane passing through the origin. Therefore, an ordered basis of $V$ consists of an ordered pair of linearly independent vectors $\EuScript{B} = (\Vect{a} , \Vect{b} )$ in $V$. Such a pair of vectors determines a preferred direction of rotation about a point, namely the shorter of the two possible trips from $\Vect{a}$ to $\Vect{b}$. This direction of rotation is taken to be the ‘positive’ direction of rotation. The opposite direction of rotation is taken to be the negative direction of orientation.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-14515" class="dialogs" title="Examples"><info xmlns="Unit">
                     
                     <p>
                        <span>Some examples of orientation in a general subvector space of $\RNr{n}$.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>oriented     </span><ul class='chilren'><li><span>volume     </span><a id='glossaryinfo-10274' class='msm_infobutton' onmouseover='infoopen(10274)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10274' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-10300' onmouseover='infoopen(10300)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-10300' style='display:none;'><div class='title'>Oriented Volume - Illustration</div><p xmlns="Unit">
               <span>To see the difference between ‘volume’ and ‘oriented volume’, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/OrientedVolume.png' height='189.875' width='350'/></div><p xmlns="Unit">
               <span>Here we have</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vol(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vol(\Vect{u},\Vect{v})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr></table><p xmlns="Unit">
               <span>However, taking into account orientations, note that $\omega(\Vect{x},\Vect{y})=+1$, while $\omega(\Vect{u},\Vect{v})=-1$. Therefore</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\OriVol(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\OriVol(\Vect{u},\Vect{v})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-6$</td></tr></table></div><div id="dialog-10300" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An illustration of the ‘oriented volume’.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>orthogonal     </span><ul class='chilren'><li><span>projection of a vector along a line     </span><a id='glossaryinfo-6982' class='msm_infobutton' onmouseover='infoopen(6982)'>i</a><div id="dialog-6982" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6982' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>projection of a vector along another     </span><a id='glossaryinfo-2236' class='msm_infobutton' onmouseover='infoopen(2236)'>i</a><div id="dialog-2236" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The orthogonal projection of a vector $\Vect{x}$ along $\Vect{y} \neq \Vect{0}$ is the vector </span>
                           </p>
                           $$\pr_{\Vect{y}}(\Vect{x}) := \dfrac{\Vect{x} \bullet \Vect{y} }{\Vect{y} \bullet \Vect{y} \cdot \Vect{y}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2236' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>projection     </span><ul class='chilren'><li><span>$\RNr{n}$ onto a hyperspace     </span><a id='glossaryinfo-15956' class='msm_infobutton' onmouseover='infoopen(15956)'>i</a><div id="dialog-15956" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15956' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15912' onmouseover='infoopen(15912)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15912' style='display:none;'><div class='title'>The Orthogonal Projections</div><div id="dialog-15897" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of a hyperspace</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15897' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>Here we explain how to compute the orthogonal projection of $\RNr{n}$ onto the 
				<a id="activehottag-15897" class="activehottag" onmouseover="infoopen(15897)"> hyperspace</a>  
                  $H$ which is perpendicular to a nonzero vector $\Vect{c}$. We know that $H$ consists of all those vectors $\Vect{x}$ in $\RNr{n}$ with $\DotPr{\Vect{x}}{\Vect{c}}=0$. The orthogonal projection $P$ of $\RNr{n}$ onto $H$ transforms a point $\Vect{x}$ in $\RNr{n}$ into the point on $H$ which is closest to $\Vect{x}$.</span>
            </p>
<div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/OrthogonalProjection.png' height='226.625' width='350'/></div><div id="dialog-15910" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Review this projection construction</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15910' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>Thus we find $P(\Vect{x})$ by subtracting from $\Vect{x}$ the 
				<a id="activehottag-15910" class="activehottag" onmouseover="infoopen(15910)"> projection</a>  
				of $\Vect{x}$ along $\Vect{c}$.
			</span>
            </p>
$$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$</div><div id="dialog-15912" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the construction of orthogonal projections</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-15954' onmouseover='infoopen(15954)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15954' style='display:none;'><div class='pack'><div class='title'>Example of an Orthogonal Projection of $\RNr{3}$
   </div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the orthogonal projection $P$ of $\RNr{3}$ onto the hyperspace perpendicular to $\Vect{c}=(1,2,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that the matrix $A$ representing $P$ is of size $(3,3)$, and that its  $j$-th column consists of the coordinates of $P(\StdBss{j})$, $1\leq j\leq 3$. Therefore we compute</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \dfrac{\DotPr{(1,0,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \tfrac{1}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(5,-2,-1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \dfrac{\DotPr{(0,1,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-2,2,-2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{3})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \dfrac{\DotPr{(0,0,1)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \tfrac{1}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-1,-2,5)$</td></tr></table>
			
			            <p>
                  <span>
                     $P(\StdBss{1})$, $P(\StdBss{2})$, and $P(\StdBss{3})$ form the columns of the matrix $\Mtrx{A}$ representing $P$:</span>
               </p>
			            $$
					
A = \dfrac{1}{6}
\left[
\begin{array}{rrr}
5 &amp; -2 &amp; -1 \\
-2 &amp; 2 &amp; -2 \\
-1 &amp; -2 &amp; 5
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-15954" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An orthogonal projection of $\RNr{3}$ onto a hyperspace</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>     </span></li></ul></li><li><span>reflection     </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace     </span><a id='glossaryinfo-16020' class='msm_infobutton' onmouseover='infoopen(16020)'>i</a><div id="dialog-16020" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-16020' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-15973' onmouseover='infoopen(15973)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15973' style='display:none;'><div class='title'>The Orthogonal Reflections</div><p xmlns="Unit">
               <span>An orthogonal reflection works like a mirror: The mirror is represented by a hyperspace $H$ in $\RNr{n}$. Now the reflection operations about $H$ transforms a point $\Vect{x}$ into its mirrored image with respect to $H$. </span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/LeftHandMirrorRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>To describe such an orthogonal reflectiion $M$ mathematically, we consider the following schematic sketch.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/OrthogonalReflection.png' height='254.625' width='350'/></div><p xmlns="Unit">
               <span>In the picture above, we reflect $\RNr{2}$ over the hyperspace $H$:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\Vect{c}$ is a nonzero vector perpendicular to $H$ – there are many vectors with this property</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Vect{x}$ is the position vector of a point before being reflected</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\pr_{\Vect{c}}(\Vect{x})$ is the orthogonal projection of $\Vect{x}$ along $\Vect{c}$. It is computed as</span>
                  </p>
                  $$\pr_{\Vect{c}}(\Vect{x}) = \dfrac{ \DotPr{ \Vect{x} }{ \Vect{c} } }{ \DotPr{ \Vect{c} }{ \Vect{c} } }\, \cdot\, \Vect{c}$$
               </li>
               <li>
                  <p>
                     <span>Subtracting $2\cdot \pr_{\Vect{c}}(\Vect{x})$ from $\Vect{x}$ gives $M(\Vect{x})$, the position vector of the point $\Vect{x}$ over $H$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Therefore the orthogonal reflection of $M$ about the hyperspace $H$ perpendicular to $\Vect{c}$ is given by</span>
            </p>$$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$<p xmlns="Unit">
               <span>We remark that nature does not normally carry out such reflections  in a bodily way: there is no known mechanism which turns a person into one whose heart is on the right hand side and whose right and left hands are interchanged. To the eye a mirror merely creates the impression of such a thing happening.</span>
            </p></div><div id="dialog-15973" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the construction of orthogonal reflections</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-16018' onmouseover='infoopen(16018)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-16018' style='display:none;'><div class='pack'><div class='title'>Example of an Orthogonal Reflection of $\RNr{3}$
   </div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the orthogonal reflection $M$ of $\RNr{3}$ about the hyperspace perpendicular to $\Vect{c}=(1,2,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that the matrix $B$ representing $M$ is of size $(3,3)$, and that its  $j$-th column consists of the coordinates of $M(\StdBss{j})$, $1\leq j\leq 3$. Therefore we compute</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - 2\cdot \dfrac{\DotPr{(1,0,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(4,-4,-2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - 2\cdot \dfrac{\DotPr{(0,1,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \tfrac{4}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-4,-2,-4)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{3})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - 2\cdot \dfrac{\DotPr{(0,0,1)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-2,-4,4)$</td></tr></table>
			
			            <p>
                  <span>The vectors $M(\StdBss{1})$, $M(\StdBss{2})$, $M(\StdBss{3})$ form the columns of the matrix $\Mtrx{B}$representing $M$:</span>
               </p>
			            $$
					
B = \dfrac{1}{6}
\left[
\begin{array}{rrr}
4 &amp; -4 &amp; -2 \\
-4 &amp; -2 &amp; -4 \\
-2 &amp; -4 &amp; 4
\end{array}
\right]\ =\
\dfrac{1}{3}
\left[
\begin{array}{rrr}
2 &amp; -2 &amp; -1 \\
-2 &amp; -1 &amp; -2 \\
-1 &amp; -2 &amp; 2
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Here is another view of an orthogonal projection. It displays its effect on a box in 3-space.</span>
         </p>
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ReflectionHyperplaneBox.jpg" height="262.5" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-16018" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An orthogonal reflection of $\RNr{3}$ onto a hyperspace</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>linear transformation     </span><a id='glossaryinfo-8116' class='msm_infobutton' onmouseover='infoopen(8116)'>i</a><div id="dialog-8116" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8116' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-8080' onmouseover='popup(8080)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-8080" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>The identity $\abs{ L(\Vect{x}) } = \abs{ \Vect{x} }$ says exactly that the length of $\Vect{x}$ equals the length of ($\Vect{x}$ transformed by $L$). If this happens for all $\Vect{x}$ in $\RNr{n}$, then $L$ preserves the length of all vectors and, hence, the distance between any pair of points in $\RNr{n}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-8086' onmouseover='infoopen(8086)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-8086' style='display:none;'><div class='pack'><div class='title'>Rotations are Distance Preserving</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a linear transformation $L$ preserves the distance between two points $\Vect{a}$  and $\Vect{b}$ if the distance from $\Vect{a}$ to $\Vect{b}$ is equal to the distance from $L(\Vect{a})$ to $L(\Vect{b})$. For example, a rotation of the plane about the origin preserves the distance between any two points.</span>
         </p>
			
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/RotationOrthogonal.png" height="349.125" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-8086" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>A rotation is an example of a distance preserving linear transformation.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>matrix     </span><a id='glossaryinfo-17137' class='msm_infobutton' onmouseover='infoopen(17137)'>i</a><div id="dialog-17137" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17137' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17133' onmouseover='popup(17133)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17133" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>In view of the previous corollary: a matrix is orthogonal exactly when it represents a distance preserving linear map.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-17135' onmouseover='popup(17135)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-17135" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>The terminology ‘orthogonal matrix’ is historically entrenched. It is, however, not optimally descriptive because ‘orthogonal’ only suggests that the column vectors of $\Mtrx{A}$ must be mutually perpendicular.</span>
                     </p>
                     <p>
                        <span>A bit more descriptive would be something like ‘orthonormal matrix’. This would truly mean that the columns of $\Mtrx{A}$ are normed, i.e. have length $1$, and must be mutually perpendicular. These are exactly the properties $\Mtrx{A}$ needs to represent a distance preserving linear map.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>complement     </span><a id='glossaryinfo-11490' class='msm_infobutton' onmouseover='infoopen(11490)'>i</a><div id="dialog-11490" class="dialogs" title="Orthogonal complement"><info xmlns="Unit">
                           
                           <p>
                              <span>The orthogonal complement of a subset $S$ in a sub vector space $V$ of $\RNr{n}$ is the set of those $\Vect{x}$ in $V$ which are perpendicular to every $\Vect{s}$ in $S$.   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11490' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal complement</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal complement of a subset $S$ in a subvector space $V$ of $\RNr{n}$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S^{\bot}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11486" class="hottag" onmouseover="popup(11486)">$:=	$</a><div id="dialog-11486" class="dialogs" title="How do you read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#x2018;S perp is defined to be the set of all those $\Vect{x}$ in $V$ such that $\Vect{x}$ dot $\Vect{s}$ equals 0, for all $\Vect{s}$ in S&#x2019;</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st \DotPr{ \Vect{x} }{ \Vect{s} }=0,\ \ \text{for all $\Vect{s}\in S$} }$</td></tr></table>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11478' onmouseover='infoopen(11478)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11478' style='display:none;'><div class='title'>Orthogonal Complement - Illustration</div><p xmlns="Unit">
               <span>The orthogonal complement of a collection of vectors $S$ in $\RNr{n}$ consists of all those vectors in $\RNr{n}$ which are perpendicular to every vector in $S$.</span>
            </p><p xmlns="Unit">
               <span>For example, the orthogonal complement of a single nonzero vector $\Vect{n}$ in $\RNr{n}$ consists of all those vectors $\Vect{x}$ for which $\DotPr{ \Vect{x} }{ \Vect{n} } = 0$. This, we recognize, is the hyperspace of vectors perpendicular to $\Vect{n}$.</span>
            </p><p xmlns="Unit">
               <span>For example, the orthogonal complement of two vectors $\Vect{u}$ and $\Vect{v}$ consists of all those vectors $\Vect{x}$ which are perpendicular to both $\Vect{u}$ and $\Vect{v}$; etc. – </span>
            </p><p xmlns="Unit">
               <span>The picture below shows a vector $\Vect{s}$ in $\RNr{2}$, together with its orthogonal complement $\Vect{s}^{\bot}$, the line perpendicular to $\Vect{s}$. (The red dot represents the origin.)</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/OrthogonalComplement1.png' height='199.19507575758' width='350'/></div><p xmlns="Unit">
               <span>Note that $\Vect{s}^{\bot}$ consists of an infinite collection of vectors, namely all those vectors which are perpendicular to $\Vect{s}$
               </span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/OrthogonalComplement3.png' height='199.15' width='350'/></div><p xmlns="Unit">
               <span>The orthogonal complement of a single nonzero vector is always a hyperspace.</span>
            </p><p xmlns="Unit">
               <span>The picture below shows two vectors $\Vect{s}$ and $\Vect{t}$ in $\RNr{2}$, together with their respective orthogonal complements:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>the line perpendicular to $\Vect{s}$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the line perpendicular to $\Vect{t}$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>The orthogonal complement of the set $S:=\Set{ \Vect{s},\Vect{t} }$ consists of all vectors in the plane which are perpendicular to both $\Vect{s}$ and $\Vect{t}$. Thus the orthogonal complement of $S$ is the intersection of the hyperspace perpendicular to $\Vect{s}$ and the hyperspace perpendicular to $\Vect{t}$. In this case $S^{\bot}$ is just the origin, represented here by a red dot.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/OrthogonalComplement2.png' height='174.65' width='350'/></div></div><div id="dialog-11478" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Illustration of orthogonal complement</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-11480' onmouseover='popup(11480)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-11480" class="dialogs" title="Explanation"><info xmlns="Unit">
                     
                     <p>
                        <span>Read this as: ‘S perp is defined to be the set of all those x in V such that the dot product of x by s is 0 for all s in S’.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>set of vectors     </span><a id='glossaryinfo-12432' class='msm_infobutton' onmouseover='infoopen(12432)'>i</a><div id="dialog-12432" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12432' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>splitting of a subspace     </span><a id='glossaryinfo-13682' class='msm_infobutton' onmouseover='infoopen(13682)'>i</a><div id="dialog-13682" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13682' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-13676" class="dialogs" title="What does this notation mean?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>
                                          $U\cup V$ is the union of the sets $U$ and $V$; i.e. a vector belongs to $U\cup V$ if it belongs to $U$ or to $V$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <a id="hottag-13676" class="hottag" onmouseover="popup(13676)"> 
                                    $W=\span(U\cup V)$
                                 </a>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>splitting     </span><a id='glossaryinfo-13871' class='msm_infobutton' onmouseover='infoopen(13871)'>i</a><div id="dialog-13871" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The construction of orthogonal splittings.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13871' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal splitting by orthogonal complement</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>In subspaces $V\subseteq W$ of $\RNr{n}$, the spaces $V$ and $V^{\bot}$ form an orthogonal splitting of $W$. Consequently,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(V) + \dim(V^{\bot})$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-13967' onmouseover='infoopen(13967)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-13967' style='display:none;'><div class='pack'><div class='title'>Orthogonal Splittings: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In $\RNr{3}$ let $V$ be the subvector space generated by $\Vect{a}:=(1,1,1)$. Describe $V$ and $V^{\bot}$, and compute their dimensions.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The vector $\Vect{a}$ is not the zero vector. Therefore its span $V$ is a line in $\RNr{3}$; in fact it is the line through $\Vect{0}$ in the direction of $\Vect{a}$. An basis for $V$ is $\EuScript{A}:=\Set{ \Vect{a} }$. So</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{V}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1$</td></tr></table>
			            <p>
                  <span>The orthogonal complement of $V$ is a hyperspace: it is the plane through the origin with normal vector $\Vect{a}$. The dimension formula confirms</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{V^{\bot}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{\RNr{3}} - \Dim{V}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3 - 1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In $\RNr{5}$ let $V$ be the subvector space generated by $\Vect{a}$, $\Vect{b}$, and $\Vect{c}$ with</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(3,5,-2,1,4)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(2,-2,2,3,-3)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{c}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-1,9,-6,-5,10)$</td></tr></table>
			      <p>
            <span>Find the dimension of $V$ and its orthogonal complement.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We notice that $\Vect{a}$ and $\Vect{b}$ are not parallel. So they are linearly independent. Are these vectors also linearly independent of $\Vect{c}$? &#x2013; Solving the vector equation</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s\cdot \Vect{a} + t\cdot \Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{c}$</td></tr></table>
			            <p>
                  <span>yields the solution $s=1$ and $t=-2$; i.e. $\Vect{c}$ is a linear combination of $\Vect{a}$ and $\Vect{b}$. Therefore</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$V$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\span\Set{ \Vect{a},\Vect{b} }$</td></tr></table>
			            <p>
                  <span>and $\EuScript{B} = (\Vect{a},\Vect{b})$ is an ordered basis for $V$. So</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{V}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
			            <p>
                  <span>The dimension of the orthogonal complement $V^{\bot}$ may be computed using the dimension formula:</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{V^{\bot}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{\RNr{5}} - \Dim{ V }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$5 - 2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-13967" class="dialogs" title="Examples"><info xmlns="Theorem">
         
         <p>
            <span>Examples of splittings by orthogonal complement.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-13877' onmouseover='infoopen(13877)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-13877' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><div id="dialog-13891" class="dialogs"><info>
                        <p>
                           <span>Look up this formula</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-13891' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>
            $\EuScript{B}$ spans $W$.</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><div id="dialog-13883" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Read this as: ‘U intersection V equals the set consisting of the $\Vect{0}$-vector</span>
                        </p>
                        <p>
                           <span>Meaning: $U$ and $V$ have only the zero vector in common.</span>
                        </p>
                     </info></div><div id="dialog-13890" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Read this as: ‘U union V equals W</span>
                        </p>
                        <p>
                           <span>Meaning: the sets $U$ and $V$ together span $W$.</span>
                        </p>
                     </info></div>
<statement.theorem><p xmlns="Theorem">
         <span>Let $U$, $V$, and $W$ be sub vector spaces of $\RNr{n}$ satisfying</span>
      </p><ol xmlns="Theorem">
         <li>
            <p>
               <span>
                  <a id="hottag-13883" class="hottag" onmouseover="popup(13883)"> 
                        $\span(U\cap V) = \Set{ \Vect{0} }$
                     </a>  
               </span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  <a id="hottag-13890" class="hottag" onmouseover="popup(13890)"> 
                        $\span(U\cup V) = W$
                     </a>  
               </span>
            </p>
         </li>
      </ol><p xmlns="Theorem">
         <span>If $\EuScript{A}$ is a basis of $U$, and $\EuScript{C}$ is a basis of $V$, then $\EuScript{B} := \EuScript{A} \cup \EuScript{C}$ is a basis of $W$ and, consequently,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(U) + \dim(V)$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body><p>
            <span>If $V$ contains only the zero vector, we have $V^{\bot}=W$, and so the dimension formula is valid in this case:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0 + \dim(V^{\bot})$</td></tr></table><p>
            <span>Consider now the case where $V$ contains a nonzero vector. Then we have</span>
         </p><ol>
            <li>
               <p>
                  <span>
                     $\span(V\cup V^{\bot}) = W$, because every $\Vect{x}\in W$ can be written as $\Vect{x} = \Vect{x}_V + \Vect{x}_{\bot}$ which is a linear combination of a vector in $V$ and one in $V_{\bot}$.</span>
               </p>
            </li>
            <li>
               <p>
                  <span>
                     $V$ and $V^{\bot}$ have only the zero vector in common. &#x2013; If not, the decomposition of $\Vect{x}\in W$ as $\Vect{x} = \Vect{x}_{V} + \Vect{x}_{\bot}$ would not be unique.</span>
               </p>
            </li>
         </ol><p>
            <span>This means that $V$ and $V^{\bot}$ form a splitting of $W$. Now the formula</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(V) + \dim(V^{\bot})$</td></tr></table><p>
            <span>follows from the 
			<a id="activehottag-13891" class="activehottag" onmouseover="infoopen(13891)"> dimension formula</a>  
			for arbitrary splittings of a vector space.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /></div></li></ul></li><li><span>orthonormal     </span><ul class='chilren'><li><span>set of vectors     </span><a id='glossaryinfo-12434' class='msm_infobutton' onmouseover='infoopen(12434)'>i</a><div id="dialog-12434" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12434' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li></ul></li><li><span>overdetermined     </span><ul class='chilren'><li><span>system of linear equations     </span><a id='glossaryinfo-3666' class='msm_infobutton' onmouseover='infoopen(3666)'>i</a><div id="dialog-3666" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3666' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3485' onmouseover='popup(3485)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-3485" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words, the simultaneous solutions of the given system of linear equations consists of the intersection of the hyperplanes $H_1,\dots ,H_n$.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3544' onmouseover='infoopen(3544)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3544' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{2}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2)$ and $\Vect{n}_2 = (b_1,b_2)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3522" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2NonParallel.gif" height="285" width="455" usemap="#TwoEqnsR2NonParallel"/><map name="TwoEqnsR2NonParallel"><area id="pic-3524" coords="264,126,292,93,294,50,275,44,238,104,251,114" shape="poly" href="#" onmouseover="popup(3524)"><div id="dialog-3524" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3526" coords="202,214,186,166,171,152,154,174,159,188,174,186,191,222,202,218" shape="poly" href="#" onmouseover="popup(3526)"><div id="dialog-3526" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3528" coords="374,220,378,206,323,169,314,180,368,218" shape="poly" href="#" onmouseover="popup(3528)"><div id="dialog-3528" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3530" coords="302,153,242,114,106,14,98,29,284,157" shape="poly" href="#" onmouseover="popup(3530)"><div id="dialog-3530" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3532" coords="323,164,426,109,414,96,312,149,323,168" shape="poly" href="#" onmouseover="popup(3532)"><div id="dialog-3532" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3534" coords="300,181,146,262,138,250,200,220,288,168,299,176" shape="poly" href="#" onmouseover="popup(3534)"><div id="dialog-3534" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3536" coords="308,169,5" shape="circle" href="#" onmouseover="popup(3536)"><div id="dialog-3536" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two nonparallel lines in the plane $\RNr{2}$always have a unique point of intersection. This is the one and only simultaneous solution of the two given equations.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with normal vector $\Vect{n}_1$ is the line $H_1$, while</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the solution hyperplane of the second the equation, with normal vector $\Vect{n}_2$, is the line $H_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel, the lines $H_1$ and $H_2$ are not parallel either. So these lines intersect precisely in one point, denoted here $(x_0,y_0)$. This means that there is exactly one solution of the given system of linear equations, namely:</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x = x_0$   and   $y = y_0$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Question</b>   Amongst all the systems of two linear equations with two unknowns, "how often" do we encounter the situation that there is exactly one common solution?</span>
            </p><div id="dialog-3543" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>This statement has only intuitive value here. It can be made precise using a combination of the more advanced mathematical subjects of measure theory and geometric probability.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Answer</b> &#xA0; Exactly one solution occurs exactly when the solution lines of the individual equations are not parallel. Now, given two arbitrary lines in the plane, their 
				<a id="hottag-3543" class="hottag" onmouseover="popup(3543)"> chances</a>  
				of not being parallel are greater than their chances of being parallel. Therefore "most of the time" a system of two linear equations in two unknowns will have exactly one solution.</span>
            </p>
</div><div id="dialog-3544" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3578' onmouseover='infoopen(3578)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3578' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{3}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2,a_3)$ and $\Vect{n}_2 = (b_1,b_2,b_3)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3554" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3NonParallel.gif" height="281" width="333" usemap="#TwoEqnsR3NonParallel"/><map name="TwoEqnsR3NonParallel"><area id="pic-3556" coords="109,8,8" shape="circle" href="#" onmouseover="popup(3556)"><div id="dialog-3556" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This red dot marks the origin in $\RNr{3}$.</span>
                                 </p>
                              </info></div></area><area id="pic-3558" coords="95,28,61,68,50,66,95,11,104,18" shape="poly" href="#" onmouseover="popup(3558)"><div id="dialog-3558" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3560" coords="27,91,31,107,1,139,2,118" shape="poly" href="#" onmouseover="popup(3560)"><div id="dialog-3560" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3562" coords="111,21,121,12,169,80,160,86" shape="poly" href="#" onmouseover="popup(3562)"><div id="dialog-3562" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3564" coords="205,126,194,133,218,166,229,159" shape="poly" href="#" onmouseover="popup(3564)"><div id="dialog-3564" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3566" coords="216,122,240,108,316,277,70,220,191,139,216,171,233,158,211,126,211,126,211,126" shape="poly" href="#" onmouseover="popup(3566)"><div id="dialog-3566" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3568" coords="82,49,133,63,63,183,11,32,57,46,42,68,55,81,77,53,77,53" shape="poly" href="#" onmouseover="popup(3568)"><div id="dialog-3568" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3570" coords="39,125,62,185,18,141,38,129" shape="poly" href="#" onmouseover="popup(3570)"><div id="dialog-3570" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3572" coords="157,55,229,9,332,41,78,201,68,191,138,69,142,67,163,95,181,83" shape="poly" href="#" onmouseover="popup(3572)"><div id="dialog-3572" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with coefficient vector $\Vect{n}_1$ pointing down-left, is a plane in the ordinary sense perpendicular to $\Vect{n}_1$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The solution hyperplane of the second equation, with coefficient vector $\Vect{n}_2$ pointing down-right, is a plane perpendicular to $\Vect{n}_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors of these planes are not parallel, these planes are not parallel either. So these planes intersect in a line $L$. Each point on $L$ represents a common solution of both equations, and the intersection line consists of all possible simultaneous solutions of these equations.</span>
            </p><p xmlns="Unit">
               <span>For emphasis, let us say in different words what this means: Pick a vector $\Vect{x}$ in $\RNr{3}$. Then $\Vect{x}$ is given by three coordinates: $(x_0,y_0,z_0)$. So these are three numbers, and choosing</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x:=x_0$   and   $y:=y_0$   and   $z:=z_0$
               </span>
            </p><p xmlns="Unit">
               <span>renders both equations true simultaneously if and only if $\Vect{x}$ belongs to the line of intersection of the two solution hyperplanes of the given equations.</span>
            </p></div><div id="dialog-3578" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3620' onmouseover='infoopen(3620)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3620' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3592" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3594" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3594)"><div id="dialog-3594" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3596" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3596)"><div id="dialog-3596" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3598" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3598)"><div id="dialog-3598" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3600" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3600)"><div id="dialog-3600" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3602" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3602)"><div id="dialog-3602" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3604" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3604)"><div id="dialog-3604" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3606" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3606)"><div id="dialog-3606" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3608" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3608)"><div id="dialog-3608" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3611" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3613" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3613)"><div id="dialog-3613" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3615" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3615)"><div id="dialog-3615" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3617" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3617)"><div id="dialog-3617" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3620" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3661' onmouseover='infoopen(3661)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3661' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3633" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3635" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3635)"><div id="dialog-3635" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3637" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3637)"><div id="dialog-3637" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3639" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3639)"><div id="dialog-3639" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3641" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3641)"><div id="dialog-3641" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3643" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3643)"><div id="dialog-3643" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3645" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3645)"><div id="dialog-3645" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3647" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3647)"><div id="dialog-3647" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3649" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3649)"><div id="dialog-3649" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3652" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3654" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3654)"><div id="dialog-3654" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3656" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3656)"><div id="dialog-3656" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3658" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3658)"><div id="dialog-3658" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3661" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>parallel     </span><ul class='chilren'><li><span>vectors     </span><a id='glossaryinfo-874' class='msm_infobutton' onmouseover='infoopen(874)'>i</a><div id="dialog-874" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-874' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-872' onmouseover='infoopen(872)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-872' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-866" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-866" class="hottag" onmouseover="popup(866)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-872" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Click for an illustration of parallel vectors.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>hyperplanes     </span><a id='glossaryinfo-3477' class='msm_infobutton' onmouseover='infoopen(3477)'>i</a><div id="dialog-3477" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3477' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-3475' onmouseover='infoopen(3475)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-3475' style='display:none;'><div class='pack'><div class='title'>Parallel Hyperplanes - Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the solution hyperplanes of the equations below are parallel.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x + 4y - 1z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2x - 8y - 2z$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to determine if the normal vectors of the two hyperplanes are parallel.</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>The first hyperplane has $\Vect{u}:=(1,4,-1)$ as a normal vector.</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second hyperplane has $\Vect{v}:=(2,-8,-2)$ as a normal vector.</span>
                     </p>
				              </li>
			            </ol>
			            <p>
                  <span>These vectors are parallel exactly when there exists a number $t$ with</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \Vect{u}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[ \begin{array}{r} 2 \\ -8 \\ -2 \end{array} \right]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \left[ \begin{array}{r} 1 \\ 4 \\ -1 \end{array} \right]$</td></tr></table>
			            <p>
                  <span>Comparing the first coordinates requires $t=2$, while comparing the second coordinates requires $t=-2$. This means that there is no number $t$ with</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \Vect{u}$</td></tr></table>
			            <p>
                  <span>So the normal vectors to the two hyperplanes are  not parallel and, therefore, the hyperplanes themselves are not parallel.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the solution hyperplanes of the equations below are parallel.</span>
         </p>
			      <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$3u + v - w + 2x$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-1$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$2w - 6u - 2v - 4x$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\pi$</td></tr></table>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We need to determine if the normal vectors of the two hyperplanes are parallel.</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>The first hyperplane has $\Vect{v}:=(3,1,-1,2))$ as a normal vector.</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>The second hyperplane has $\Vect{w}:=(-6,-2,2,-4)$ as a normal vector.</span>
                     </p>
				              </li>
			            </ol>
			            <p>
                  <span>We note that</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{w}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(-2)\cdot \Vect{v}$</td></tr></table>
			            <p>
                  <span>So the normal vectors to the two hyperplanes are  parallel and, therefore, the hyperplanes themselves are parallel.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-3475" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of parallel hyperplanes</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>point     </span><a id='glossaryinfo-281' class='msm_infobutton' onmouseover='infoopen(281)'>i</a><div id="dialog-281" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An $n$-tuple of $\RNr{n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-281' style='display:none;'><div class='title'>The Space $\RNr{n}$
            </div><br /><div class='def'><span class='deftitle'>The set $\RNr{n}$
                     </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For a positive integer $n$, the space $\RNr{n}$ is the set of all $n$-tuples of numbers; in symbols</span>
                           
                        </p>
                        $$\RNr{n}\ :=\ \Set{(x_1,\dots ,x_n)\st x_1,\dots ,x_n\in \RNr{} }$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-272' onmouseover='popup(272)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-272" class="dialogs" title="Explanation: How to Read this"><info xmlns="Unit">
                           
                           <p>
                              <span>Read this expression as follows:</span>
                           </p>
                           <p>
                              <span>R n is defined to be the set of all n-tuples $(x_1,\dots ,x_n)$ such that $x_1,\dots, x_n$ are in $\RNr{}$.</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-274' onmouseover='popup(274)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-274" class="dialogs" title="Explanation: on the Meaning of this Definition"><info xmlns="Unit">
                           
                           <p>
                              <span>Thus, each $n$-tuple forms a single element in $\RNr{n}$. The collection of all such $n$-tuples forms the space $\RNr{n}$.</span>
                           </p>
                        </info></div></ul></div><br /><p xmlns="Unit">
                     <span>We refer to an $n$-tuple of $\RNr{n}$ as a <b>point</b>.
				 
				This terminology is motivated by the following paragraph on ‘Visualizing $\RNr{n}$. We write $P(x_1,\dots ,x_n)$ to say that a point, named $P$, is given by the $n$-tuple $(x_1,\dots ,x_n)$.</span>
                     
                     
                  </p></div></li><li><span>position vector     </span><a id='glossaryinfo-717' class='msm_infobutton' onmouseover='infoopen(717)'>i</a><div id="dialog-717" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The position vector of a $X$ point in $\RNr{n}$ is represented by the arrow $\Arrow{\Vect{0}}{X}$ joining the origin to $X$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-717' style='display:none;'><div class='title'>
               $n$-Tuples for Points and Vectors</div><p xmlns="Unit">
                     <span>Consider these two expressions</span>
                  </p><p xmlns="Unit" align="center">
                     <span>
                        $X(x_1,\dots ,x_n)$   and  $\Vect{x} = (x_1,\dots ,x_n)$.</span>
                  </p><p xmlns="Unit">
                     <span>In the first expression the $n$-tuple  $(x_1,\dots ,x_n)$ characterizes the location of a point. In the second expression the same $n$-tuple forms a coordinate vector. This ambiguity in notation is firmly entrenched in the literature. Fortunately, we can untangle it nicely if we keep in mind the following dictionary for translating between points and vectors.</span>
                     
                  </p>$$
					
            				\xymatrix@C=15pt{
				*+[F-,]{ \txt{A given point\\$X(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{\txt{yields the vector $\Vect{x}=(x_1,\dots ,x_n)$.\\It is represented by the arrow $\Arrow{\Vect{0}}{X}$.\\We call it the {\bf position vector}\index{position vector} of $X$.}} \\
				*+[F-,]{ \txt{A given vector\\$\Vect{x}=(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{ \txt{yields the point $X(x_1,\dots ,x_n)$.\\It is the tip of the arrow with tail at $\Vect{0}$\\and representing $\Vect{x}$.} }
				}
            	
				$$</div></li><li><span>positive definite     </span><ul class='chilren'><li><span>dot product     </span><a id='glossaryinfo-1880' class='msm_infobutton' onmouseover='infoopen(1880)'>i</a><div id="dialog-1880" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The positive definiteness property of the dot product asserts that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1880' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>preimage     </span><ul class='chilren'><li><span>under a function     </span><a id='glossaryinfo-6230' class='msm_infobutton' onmouseover='infoopen(6230)'>i</a><div id="dialog-6230" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Given a function $f\from X\to Y$ and $y\in Y$, the preimage of $y$ under $f$ consists of all those $x\in X$ such that $f(x)=y$; notation $f^{-1}(y)$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6230' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>of a linear transformation     </span><a id='glossaryinfo-17258' class='msm_infobutton' onmouseover='infoopen(17258)'>i</a><div id="dialog-17258" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17258' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-17256" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-17256" class="hottag" onmouseover="popup(17256)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-17271" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-17271' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-17271" class="activehottag" onmouseover="infoopen(17271)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li></ul></li><li><span>product     </span><ul class='chilren'><li><span>of subsets of $\RNr{n}$     </span><a id='glossaryinfo-511' class='msm_infobutton' onmouseover='infoopen(511)'>i</a><div id="dialog-511" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to jump to the definition of ‘product of subsets of $\RNr{n}$’.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-511' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of Sets</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a subset $S$ of $\RNr{m}$ by a subset $T$ of $\RNr{n}$ is the subset $S\times T$ of $\RNr{m+n}$ consisting of all those $(m+n)$-tuples $(x_1,\dots ,x_m\, ,\, y_1,\dots ,y_n)$ with $(x_1,\dots ,x_m)$ in $S$ and $(y_1,\dots ,y_n)$ in $T$.</span>
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-509' onmouseover='infoopen(509)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-509' style='display:none;'><div class='pack'><div class='title'>Examples of Products of Subsets of $\RNr{n}$
   </div><br /><div class='showme'><span class='showmetitle'>Products of Two Intervals</span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The cartesian product of the intervals  $[0,1]$  and  $[0,2]$  is  $[0,1] \times [0,2]$  i.e. the rectangle with corners $(0,0), (1,0), (0,2), (1,2)$.</span>
         </p>
			      <p align="center">
            <span>
				           <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnPrdctR2.gif" height="312.89752650177" width="350"/></div>
			         </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The product $[0,1]\times [0,2]$ consists of all pairs $(x,y)$ with</span>
               </p>
			            <p align="center">
                  <span>
				                 $0\leq x\leq 1$ and $0\leq y\leq 2$
			               </span>
               </p>
			            <p>
                  <span>The set of all such pairs forms the rectangle in $\RNr{2}$ with the corners listed above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'>Product of Three Intervals</span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The cartesian product of the intervals  $[-1,2], [2,3]$  and  $[0,5]$  is  $[-1,2] \imes [2,3] \imes [0,5]$  i.e. the rectangular block in $\RNr{3}$ with corners </span>
         </p>
			      $$(-1,2,0), (-1,2,5), (-1,3,0), (-1,3,5), (2,2,0), (2,2,5), (2,3,0), (2,3,5)$$
			
			      <p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnPrdctR3.gif" height="276.15384615385" width="350"/></div>
            </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The product $[-1,2]\times [2,3]\times [0,5]$ consists of all triples $(x,y,z)$ with</span>
               </p>
			            <p align="center">
                  <span>
				                 $-1\leq x\leq 2$, $2\leq y\leq 3$, and $0\leq z\leq 5$
			               </span>
               </p>
			            <p>
                  <span>The set of all such triples forms the box in $\RNr{3}$ with the corners listed above.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{}$ sits inside $\RNr{2}$ as $\RNr{} \imes \{ 0\}$; i.e. as the set of all ordered pairs of the form $(x,0)$, with $x$ in $\RNr{}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>
				           $\RNr{2}$ sits inside $\RNr{3}$ as $\RNr{2}\times \{ 0\}$; i.e. as the set of all triples of the form $(x,y,0)$ with $(x,y)$ in $\RNr{2}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-509" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Click for some examples of such products</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>of two matrices     </span><a id='glossaryinfo-4915' class='msm_infobutton' onmouseover='infoopen(4915)'>i</a><div id="dialog-4915" class="dialogs" title="product of two matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $B$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4915' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4908' onmouseover='popup(4908)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4908" class="dialogs" title="Comment on Matrix multiplication"><info xmlns="Unit">
                     
                     <p>
                        <span>The product of matrices $A\cdot B$ is only defined if the number of (vertical) columns of $A$ is equal to the number of (horizontal) rows of $B$. The resulting matrix will have as many rows as $A$ and as many columns as $B$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4913' onmouseover='infoopen(4913)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4913' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Multiplication</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the product of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue} \Mtrx{A}}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red} \Mtrx{B}}\ =\ 
					\left[\begin{array}{rr}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined. If it is, compute the product $\Mtrx{A}\Mtrx{B}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Matrix $\Mtrx{A}$ has size $(3,2)$ and matrix $\Mtrx{B}$ has size $(2,2)$. Therefore the product $\Mtrx{A}\Mtrx{B}$ is defined because the number of columns of $A$ equals the number of rows of $B$: both numbers are 2. Their product is a matrix of size $(3,2)$. Its entry $c_{ij}$ in position $(i,j)$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $j$-th column of $\Mtrx{B}$. So there are a total of 6 dot products to compute. In detail:</span>
               </p>
			
			            $$
					
					\aligned
					{\color{blue}A} \cdot {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2}
					\end{array}\right] \\
					&amp;=\ \left[\begin{array}{cc}
					{\color{blue}7}\cdot {\color{red}(-3)} + {\color{blue}3} \cdot {\color{red}1} &amp; 
						{\color{blue}7}\cdot {\color{red}(-3)} + {\color{blue}3}\cdot {\color{red}2} \\
					{\color{blue}1}\cdot {\color{red}(-3)} + {\color{blue}4} \cdot {\color{red}1} &amp; 
						{\color{blue}1}\cdot {\color{red}(-3)} + {\color{blue}4}\cdot {\color{red}2} \\
					{\color{blue}6}\cdot {\color{red}(-3)} + {\color{blue}4} \cdot {\color{red}1} &amp; 
						{\color{blue}6}\cdot {\color{red}(-3)} + {\color{blue}4}\cdot {\color{red}2} \\
					\end{array}\right] \\
					&amp;=\ \left[\begin{array}{rr}
						-18 &amp; -15 \\
						1     &amp; 5 \\
						-14 &amp; -10
					\end{array}\right]
					\endaligned
					
				$$
			            <p>
                  <span>Notice that the product matrix $\Mtrx{A}\cdot \Mtrx{B}$ has as many rows as $\Mtrx{A}$, and as many columns as $\Mtrx{B}$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4913" class="dialogs" title="Example: Matrix Multiplication"><info xmlns="Unit">
                     
                     <p>
                        <span>To form the matrix product $\Mtrx{A}\cdot \Mtrx{B}$ we take dot products of the rows of $\Mtrx{A}$ by the columns of $B$. – Here is an example.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>projection     </span><ul class='chilren'><li><span>of a vector along a line     </span><a id='glossaryinfo-17612' class='msm_infobutton' onmouseover='infoopen(17612)'>i</a><div id="dialog-17612" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17612' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>$\RNr{n}$ onto a hyperspace     </span><a id='glossaryinfo-7035' class='msm_infobutton' onmouseover='infoopen(7035)'>i</a><div id="dialog-7035" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7035' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6989' onmouseover='infoopen(6989)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6989' style='display:none;'><div class='title'>The Orthogonal Projections</div><div id="dialog-6974" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of a hyperspace</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6974' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>Here we explain how to compute the orthogonal projection of $\RNr{n}$ onto the 
				<a id="activehottag-6974" class="activehottag" onmouseover="infoopen(6974)"> hyperspace</a>  
                  $H$ which is perpendicular to a nonzero vector $\Vect{c}$. We know that $H$ consists of all those vectors $\Vect{x}$ in $\RNr{n}$ with $\DotPr{\Vect{x}}{\Vect{c}}=0$. The orthogonal projection $P$ of $\RNr{n}$ onto $H$ transforms a point $\Vect{x}$ in $\RNr{n}$ into the point on $H$ which is closest to $\Vect{x}$.</span>
            </p>
<div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/OrthogonalProjection.png' height='226.625' width='350'/></div><div id="dialog-6987" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Review this projection construction</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6987' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<p xmlns="Unit">
               <span>Thus we find $P(\Vect{x})$ by subtracting from $\Vect{x}$ the 
				<a id="activehottag-6987" class="activehottag" onmouseover="infoopen(6987)"> projection</a>  
				of $\Vect{x}$ along $\Vect{c}$.
			</span>
            </p>
$$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$</div><div id="dialog-6989" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the construction of orthogonal projections</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-7031' onmouseover='infoopen(7031)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7031' style='display:none;'><div class='pack'><div class='title'>Example of an Orthogonal Projection of $\RNr{3}$
   </div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the orthogonal projection $P$ of $\RNr{3}$ onto the hyperspace perpendicular to $\Vect{c}=(1,2,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that the matrix $A$ representing $P$ is of size $(3,3)$, and that its  $j$-th column consists of the coordinates of $P(\StdBss{j})$, $1\leq j\leq 3$. Therefore we compute</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \dfrac{\DotPr{(1,0,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \tfrac{1}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(5,-2,-1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \dfrac{\DotPr{(0,1,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-2,2,-2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$P(\StdBss{3})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \dfrac{\DotPr{(0,0,1)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \tfrac{1}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-1,-2,5)$</td></tr></table>
			
			            <p>
                  <span>
                     $P(\StdBss{1})$, $P(\StdBss{2})$, and $P(\StdBss{3})$ form the columns of the matrix $\Mtrx{A}$ representing $P$:</span>
               </p>
			            $$
					
A = \dfrac{1}{6}
\left[
\begin{array}{rrr}
5 &amp; -2 &amp; -1 \\
-2 &amp; 2 &amp; -2 \\
-1 &amp; -2 &amp; 5
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-7031" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An orthogonal projection of $\RNr{3}$ onto a hyperspace</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>rank     </span><ul class='chilren'><li><span>of a system of linear equations     </span><a id='glossaryinfo-13102' class='msm_infobutton' onmouseover='infoopen(13102)'>i</a><div id="dialog-13102" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Use of the concept while describing the general solution of such a system.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13102' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Infinitely many solutions - constructive version</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><div id="dialog-13109" class="dialogs"><info xmlns="Theorem">
                  <p>
                     <span>Recall: the rank of a system of linear equations is the number of leading $1$'s in the non-augmented part of its RREF-matrix</span>
                  </p>
               </info></div>
<statement.theorem><p xmlns="Theorem">
         <span>Suppose a system of linear equations with $n$ variables has 
			<a id="hottag-13109" class="hottag" onmouseover="popup(13109)"> rank</a>  
            $ r&lt;n $. If its RREF-matrix has no leading 1 in the augmentation column</span>
      </p>$$
				
\begin{array}{ccccccccccccccc|c}
0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_1 } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_2 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_r } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 }
\end{array}
					
			$$<p xmlns="Theorem">
         <span>then this system has infinitely many solutions. Moreover, each of its solutions is of the form</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{d}\ + \ t_1 \Vect{b}_1 + \cdots + t_{n-r} \Vect{b}_{n-r}$</td></tr></table><p xmlns="Theorem">
         <span>Here $t_1,\dots ,t_{n-r}$ are arbitrary numbers; and the vectors $\Vect{d}, \Vect{b}_1,\dots ,\Vect{b}_{n-r}$ of $\RNr{n}$ are constructed from the RREF-matrix as follows.
			</span>
         
      </p><ol xmlns="Theorem">
         <li>
            <p>
               <span>Let $\Mtrx{B} = [ b_{ij} ]$ denote the unaugmented part of the RREF-matrix;</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $u_1,\dots ,u_r$ are the columns of $\Mtrx{B}$ containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $j_1,\dots ,j_{n-r}$ are the columns of $\Mtrx{B}$ not containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $\Vect{d}$ is the vector in $\RNr{n}$ with $d_k$ in position $u_k$ and $0$'s elsewhere.</span>
            </p>
         </li>
         <li>
            <p>
               <span>For $1\leq k\leq n-r$, let $\Vect{b}_k$ in $\RNr{n}$ be the vector which has</span>
            </p>
            <ul>
               <li>
                  <p>
                     <span>a &#x2018;$1$&#x2019; in position $j_k$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the entry $(-b_{i,j_k})$ in position $u_i$;</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>a &#x2018;$0$&#x2019; in each remaining position.</span>
                  </p>
               </li>
            </ul>
         </li>
      </ol></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>formula for matrices     </span><a id='glossaryinfo-18734' class='msm_infobutton' onmouseover='infoopen(18734)'>i</a><div id="dialog-18734" class="dialogs" title="Rank formula for matrices"><info xmlns="Theorem">
               
               $$
							
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18734' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Rank formula</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For a matrix $\Mtrx{A}$ of size $(m,n)$,
			</span>
         
      </p>$$
				
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li></ul></li><li><span>reflection     </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace     </span><a id='glossaryinfo-19676' class='msm_infobutton' onmouseover='infoopen(19676)'>i</a><div id="dialog-19676" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19676' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-19627' onmouseover='infoopen(19627)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-19627' style='display:none;'><div class='title'>The Orthogonal Reflections</div><p xmlns="Unit">
               <span>An orthogonal reflection works like a mirror: The mirror is represented by a hyperspace $H$ in $\RNr{n}$. Now the reflection operations about $H$ transforms a point $\Vect{x}$ into its mirrored image with respect to $H$. </span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/LeftHandMirrorRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>To describe such an orthogonal reflectiion $M$ mathematically, we consider the following schematic sketch.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/OrthogonalReflection.png' height='254.625' width='350'/></div><p xmlns="Unit">
               <span>In the picture above, we reflect $\RNr{2}$ over the hyperspace $H$:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\Vect{c}$ is a nonzero vector perpendicular to $H$ – there are many vectors with this property</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Vect{x}$ is the position vector of a point before being reflected</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\pr_{\Vect{c}}(\Vect{x})$ is the orthogonal projection of $\Vect{x}$ along $\Vect{c}$. It is computed as</span>
                  </p>
                  $$\pr_{\Vect{c}}(\Vect{x}) = \dfrac{ \DotPr{ \Vect{x} }{ \Vect{c} } }{ \DotPr{ \Vect{c} }{ \Vect{c} } }\, \cdot\, \Vect{c}$$
               </li>
               <li>
                  <p>
                     <span>Subtracting $2\cdot \pr_{\Vect{c}}(\Vect{x})$ from $\Vect{x}$ gives $M(\Vect{x})$, the position vector of the point $\Vect{x}$ over $H$.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Therefore the orthogonal reflection of $M$ about the hyperspace $H$ perpendicular to $\Vect{c}$ is given by</span>
            </p>$$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$<p xmlns="Unit">
               <span>We remark that nature does not normally carry out such reflections  in a bodily way: there is no known mechanism which turns a person into one whose heart is on the right hand side and whose right and left hands are interchanged. To the eye a mirror merely creates the impression of such a thing happening.</span>
            </p></div><div id="dialog-19627" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the construction of orthogonal reflections</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19672' onmouseover='infoopen(19672)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-19672' style='display:none;'><div class='pack'><div class='title'>Example of an Orthogonal Reflection of $\RNr{3}$
   </div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the orthogonal reflection $M$ of $\RNr{3}$ about the hyperspace perpendicular to $\Vect{c}=(1,2,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We know that the matrix $B$ representing $M$ is of size $(3,3)$, and that its  $j$-th column consists of the coordinates of $M(\StdBss{j})$, $1\leq j\leq 3$. Therefore we compute</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - 2\cdot \dfrac{\DotPr{(1,0,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0,0) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(4,-4,-2)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - 2\cdot \dfrac{\DotPr{(0,1,0)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,1,0) - \tfrac{4}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-4,-2,-4)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$M(\StdBss{3})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - 2\cdot \dfrac{\DotPr{(0,0,1)}{(1,2,1)}}{\DotPr{(1,2,1)}{(1,2,1)}} \cdot (1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(0,0,1) - \tfrac{2}{6}(1,2,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\tfrac{1}{6}(-2,-4,4)$</td></tr></table>
			
			            <p>
                  <span>The vectors $M(\StdBss{1})$, $M(\StdBss{2})$, $M(\StdBss{3})$ form the columns of the matrix $\Mtrx{B}$representing $M$:</span>
               </p>
			            $$
					
B = \dfrac{1}{6}
\left[
\begin{array}{rrr}
4 &amp; -4 &amp; -2 \\
-4 &amp; -2 &amp; -4 \\
-2 &amp; -4 &amp; 4
\end{array}
\right]\ =\
\dfrac{1}{3}
\left[
\begin{array}{rrr}
2 &amp; -2 &amp; -1 \\
-2 &amp; -1 &amp; -2 \\
-1 &amp; -2 &amp; 2
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Here is another view of an orthogonal projection. It displays its effect on a box in 3-space.</span>
         </p>
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ReflectionHyperplaneBox.jpg" height="262.5" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-19672" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An orthogonal reflection of $\RNr{3}$ onto a hyperspace</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>representing matrix     </span><ul class='chilren'><li><span>of a linear map     </span><a id='glossaryinfo-15515' class='msm_infobutton' onmouseover='infoopen(15515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15515' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-15528' onmouseover='infoopen(15528)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-15528' style='display:none;'><div class='title'>Linear Map Comes from a Matrix: Explanation</div><p xmlns="Unit">
               <span>Every linear transformation $L\from \RNr{n}\to \RNr{m}$ may be represented by a matrix, ... which matrix? – Here we explain first how the representing matrix is built. Then we explain which fundamental property of a linear map which makes this result possible.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>How to build the matrix representing a linear map</b>   Here we explain the procedure by which we build the matrix $\Mtrx{A}$ representing a linear transformation $L\from \RNr{n}\to \RNr{m}$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>First apply $L$ to the vector $\StdBss{1}=(1,0,\dots ,0)$; then use the resulting vector of $\RNr{m}$ as the first column of $\Mtrx{A}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Next apply $L$ to the vector $\StdBss{2}=(0,1,0,\dots ,0)$, then use the resulting vector of $\RNr{m}$ as the second column of $\Mtrx{A}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>etc. until</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Finally apply $L$ to the vector $\StdBss{n}=(0,\dots ,0,1)$, then use the resulting vector of $\RNr{m}$ as the $n$-th and last column of $\Mtrx{A}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>
                  <b>Why does the representing matrix exist?</b>   Recall that for $n\geq 1$, $\RNr{n}$ contains infinitely many points. Therefore the function $L$ must make infinitely many assignments, one assignment of a point $L(\Vect{x})$ in $\RNr{m}$ for each $\Vect{x}$ in $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>What we learn here is that, because $L$ is linear, all of these infinitely many assignments are determined by the finite collection of assignments</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{1}$ to $L(\StdBss{1})$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{2}$ to $L(\StdBss{2})$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>etc.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L$ sends $\StdBss{n}$ to $L(\StdBss{n})$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>So this is it: finite base information implies information about infinitely many transformation situations. – What we describe here is a generalization of familiar linear functions like</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Info: A particle moves at the constant speed of $100km/h$. This is a single bit of information. Yet it enables us to recover the distance traveled by the particle within any interval of time of length $t$: $t \cdot 100$[km].</span>
                  </p>
                  <p>
                     <span>In this example, the fact that the particle travels at constant speed means that the distance traveled function $d\from \RNr{}\to \RNr{}$ is a linear function of time. – Without the information that the particle travels at constant speed, we have no way of telling how far it has traveled after 2 hours or 3 hours, etc.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Info: Henry earns 20 dollars per hour. This is a single bit of information. Yet it enables us to tell how much Henry earns after any number of hours at work. His earnings are a linear function of time. If Henry’s income is by commission only, his earnings are a nonlinear function of time; we have no way of telling how much he will earn after the first two hours if we only know what he earned after one hour.</span>
                  </p>
               </li>
            </ul></div><div id="dialog-15528" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>An explanation of the content of the proposition and how to use it.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-15588' onmouseover='infoopen(15588)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15588' style='display:none;'><div class='pack'><div class='title'>Example: Matrices for Coordinate Projection and Coordinate Inclusion</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The matrix which represents the projection of $\RNr{m}$ onto its $j$-th coordinate</span>
         </p>
			
			      $$\Prjctn{i}\from \RNr{m}\longrightarrow \RNr,\qquad \Prjctn{i}(x_1,\dots ,x_m)= x_i$$
			
			      <p>
            <span>is given by $A := [0\ \dots \ 0\ \ 1\ \ 0\ \dots \ 0]$, the ‘$1$’ sitting in position $i$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Given $\Vect{x}=(x_1,\dots ,x_m)\in\RNr{m}$,</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$[0\ \dots \ 0\ \ 1\ \ 0\ \dots \ 0]\cdot \left[\begin{array}{c} x_1 \\ \vdots \\ x_m\end{array}\right]$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_i$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Prjctn{i}(x_1,\dots ,x_n)$</td></tr></table>
			
			            <p>
                  <span>as required.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The inclusion of $\RNr{}$ in $\RNr{n}$ as the $j$-th coordinate axis</span>
         </p>
			
			      $$\Inclsn{j}\from \RNr{} \longrightarrow \RNr{n},\quad \Inclsn{j}(x) := (0,\dots ,0,x,0,\dots , 0)$$
			
			      <p>
            <span>is represented by the $(n,1)$-matrix</span>
         </p>
			
			      $$
					
B := \left[\begin{array}{c}
0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots \\ 0
\end{array}\right]
					
				$$
			
			      <p>
            <span>the $1$ in row $j$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Given $x\in \RNr{1}$,</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$B[x]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left[\begin{array}{c} 0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right]\cdot [x] = \left[\begin{array}{c} 0 \\ \vdots \\ 0 \\ x \\ 0 \\ \vdots \\ 0 \end{array}\right] = \Inclsn{j}(x)$</td></tr></table>
			            <p>
                  <span>as was to be shown.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-15588" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>The matrix representing a projection onto a coordinate axis, and the matrix representing an inclusion of $\RNr{}$ as a coordinate axis.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-15610' onmouseover='infoopen(15610)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-15610' style='display:none;'><div class='pack'><div class='title'>Example: The Matrix which Describes a Given Linear Map</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the linear transformation</span>
         </p>
			
			      $$L\from \RNr{2} \longrightarrow \RNr{2},\quad L(x,y) = (3x+y,x+2y)$$
			
			      <p>
            <span>and analyze the transformation properties of $L$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Proof</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We begin by finding the effect of $L$ on the unit vectors $\StdBss{1}=(1,0)$ and $\StdBss{2}=(0,2)$ in the direction of the coordinate axes.</span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\StdBss{1})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15598" class="hottag" onmouseover="popup(15598)">$=	$</a><div id="dialog-15598" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>This vector will form the first column of the matrix representing $L$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(1,0) = (3,1)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\StdBss{2})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15603" class="hottag" onmouseover="popup(15603)">$=	$</a><div id="dialog-15603" class="dialogs" title=""><info xmlns="Compositor">
                              <p>
                                 <span>This vector will form the second column of the matrix representing $L$.</span>
                              </p>
                           </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(0,1) = (1,2)$</td></tr></table>
			
			            <p>
                  <span>Therefore the matrix representing $L$ is</span>
               </p>
			
			            $$
					
A := \left[\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 2
\end{array}\right]
					
				$$
			
			            <p>
                  <span>This tells us that the unit square spanned by the vectors $\StdBss{1}$ and $\StdBss{2}$ gets transformed into the parallelogram spanned by the vectors $(3,1)$ and $(1,2)$.
				
				
			</span>
                  
               </p>
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo2To2_1.png" height="147" width="350"/></div>
			
			            <p>
                  <span>Thus we see that $L$ transforms the unit lattice of $\RNr{2}$ into the &#x2018;slanted&#x2019; below.
				
			</span>
                  
               </p>
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo2To2_2.png" height="233.1875" width="350"/></div>
			
			            <p>
                  <span>We now have two methods to compute how $L$ transforms a specific point, say $\Vect{x}=(2,5)$. We can either use the original definition of $L$ and find </span>
               </p>
			
			            $$L(2,5) = (3\cdot 2 + 5 , 2 + 2\cdot 5) = (11,12)$$
			
			            <p>
                  <span>Alternatively, we can use the matrix $\Mtrx{A}$ representing $L$ to obtain</span>
               </p>
			
			            $$
					
L(2,5) = \left[\begin{array}{cc}
3 &amp; 1 \\
1 &amp; 2
\end{array}\right]
\left[\begin{array}{c}
2 \\ 5
\end{array}\right] = 
\left[\begin{array}{c}
3\cdot 2 + 5 \\ 2 + 2\cdot 5
\end{array}\right] =
\left[\begin{array}{c}
11 \\ 12
\end{array}\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-15610" class="dialogs" title=""><info xmlns="Theorem">
         <p>
            <span>An example of finding the matrix representing a linear map $L\from \RNr{2}\to \RNr{2}$
            </span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-15530' onmouseover='infoopen(15530)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-15530' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>
               <b>Existence of</b>
               $\Mtrx{A}$ &#xA0; We begin by expressing the vectors  $L(\StdBss{j})$ of $\RNr{m}$ in coordinates</span>
         </p>$$L(\StdBss{j}) = (a_{1j},\dots ,a_{mj}) = a_{1j}\StdBss{1} + \dots + a_{mj}\StdBss{m}$$<p>
            <span>Now if</span>
         </p>$$\Vect{x} = (x_1,\dots ,x_n) = x_1\StdBss{1} + \dots + x_n\StdBss{n}$$<p>
            <span>then the following computation shows that $L(\Vect{x})$ can be computed from the vectors $L(\StdBss{1}),\dots ,L(\StdBss{n})$ alone</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\Vect{x})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1} + \cdots + x_n\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15539" class="hottag" onmouseover="popup(15539)">$=	$</a><div id="dialog-15539" class="dialogs" title=""><info>
                        <p>
                           <span>Here we use the linearity property of $L$ twice</span>
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1} + \cdots + x_n\StdBss{n})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(x_1\StdBss{1}) + \cdots + L(x_n\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1L(\StdBss{1}) + \cdots + x_nL(\StdBss{n})$</td></tr></table>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1 L(\StdBss{1}) + \cdots + x_n L(\StdBss{n})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-15544" class="hottag" onmouseover="popup(15544)">$=	$</a><div id="dialog-15544" class="dialogs" title=""><info>
                        <p>
                           <span>Substitute $a_{1j}\StdBss{1} + \cdots + a_{mj}\StdBss{m}$ for $L(\StdBss{j})$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$x_1(a_{11}\StdBss{1} + \cdots + a_{m1}\StdBss{m}) + \cdots + x_n(a_{1n}\StdBss{1} + \cdots + a_{mn}\StdBss{m})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
				
\begin{array}{cccccc}
(a_{11}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{1n}x_n)\StdBss{1} + \\
\vdots &amp; &amp; &amp; &amp; \vdots \\
(a_{m1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{mn}x_n)\StdBss{m}
\end{array}
				
			$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$
				
\left[
\begin{array}{ccc}
a_{11} &amp; \dots &amp; a_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; \dots &amp; a_{mn}
\end{array}
\right]
\left[
\begin{array}{c}
x_1 \\ \vdots \\ x_n
\end{array}
\right]
				
			$</td></tr></table><p>
            <span>This means exactly that $L$ can be computed by the matrix product stated in the theorem.</span>
         </p><p>
            <span>
               <b>Uniqueness of</b>
               $\Mtrx{A}$ &#xA0; It remains to show the matrix $\Mtrx{A}$ we found above is the only matrix with the property $L(\Vect{x}) = \Mtrx{A}\Vect{x}$. So suppose $\Mtrx{B}$ is another matrix satisfying</span>
         </p>$$\Mtrx{A}\Vect{x} = L(\Vect{x}) = \Mtrx{B}\Vect{x},\quad \text{for all $\Vect{x}\in \RNr{n}$}$$<p>
            <span>Choosing $\Vect{x} = \StdBss{j}$, we find</span>
         </p><p align="center">
            <span>
               $j$-th column of $\Mtrx{A} = A\StdBss{j} = L(\StdBss{j}) = B\StdBss{j} =$
               $j$-th column of $\Mtrx{B}$.</span>
         </p><p>
            <span> This holds for each $j$ with $1\leq j\leq n$, and so $\Mtrx{A} = \Mtrx{B}$, as was to be shown.</span>
         </p></proof.block.body></proof.block.body>
</div></div></ul></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li></ul></li><li><span>right hand     </span><ul class='chilren'><li><span>orientation     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li><li><span>rule     </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /><ul class='commentminibuttons'></ul></div><br /></div></li></ul></li><li><span>rotation     </span><a id='glossaryinfo-19540' class='msm_infobutton' onmouseover='infoopen(19540)'>i</a><div id="dialog-19540" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19540' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-19524' onmouseover='popup(19524)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-19524" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Here we use the symbol $\theta$ to denote the angle through which we rotate. This is a Greek letter, pronounced ‘theta’.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19533' onmouseover='infoopen(19533)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-19533' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by </span>
            </p>$$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>To understand where this matrix comes from, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Rotation.png' height='167.5625' width='350'/></div><p xmlns="Unit">
               <span>Both $R(\StdBss{1})$ and $R(\StdBss{2})$ result from rotating $\StdBss{1}$ and $\StdBss{2}$ counterclockwise about the origin through the angle $\theta$. So they are vectors of length $1$. Therefore the coordinates of these vectors are as indicated.</span>
            </p></div><div id="dialog-19533" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of the rotation transformation</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-19538' onmouseover='infoopen(19538)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-19538' style='display:none;'><div class='pack'><div class='title'>Example of a Rotation of the Plane</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the counterclockwise rotation of the plane about the origin through the angle of $60$ degrees.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The specified rotation transformation has $\theta = \tfrac{\pi}{3}$. Therefore it rotates</span>
               </p>
			            <ul>
				              <li>
                     <p>
                        <span>the vector $\StdBss{1}=(1,0)$ into the vector $(\cos\theta , \sin\theta) = (\tfrac{1}{2} , \tfrac{\sqrt{3}}{2})$.</span>
                     </p>
                  </li>
				              <li>
                     <p>
                        <span>the vector $\StdBss{2}=(0,1)$ into the vector $(-\sin\theta , \cos\theta) = (-\tfrac{\sqrt{3}}{2},\tfrac{1}{2})$.</span>
                     </p>
                  </li>
			            </ul>
			            <p>
                  <span>These vectors form the columns of the rotation matrix:</span>
               </p>
			            $$
					
R_{\pi/3} := 
\left[
\begin{array}{rr}
\tfrac{1}{2} &amp; -\tfrac{\sqrt{3}}{2} \\
\tfrac{\sqrt{3}}{2} &amp; \tfrac{1}{2}
\end{array}
\right]\ =\ \dfrac{1}{2}\,
\left[
\begin{array}{rr}
1 &amp; -\sqrt{3} \\
\sqrt{3} &amp; 1
\end{array}
\right]
					
				$$
			            <p>
                  <span>This means that a point $(x,y)\in\RNr{2}$ gets transformed into the point</span>
               </p>
			
			            $$
					
R_{\pi/3}(x,y) = 
\left[
\begin{array}{rr}
\tfrac{1}{2} &amp; -\tfrac{\sqrt{3}}{2} \\
\tfrac{\sqrt{3}}{2} &amp; \tfrac{1}{2}
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right] = \dfrac{1}{2}\cdot
\left[
\begin{array}{r} x - \sqrt{3}\, y \\ \sqrt{3}\, x + y \end{array}
\right]
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-19538" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a rotation of $\RNr{2}$
                        </span>
                     </p>
                  </info></div></ul></div><br /></div><ul class='chilren'><li><span>of 3-space     </span><a id='glossaryinfo-19082' class='msm_infobutton' onmouseover='infoopen(19082)'>i</a><div id="dialog-19082" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>A section on arbitrary rotations in $\RNr{3}$
                        </span>
                     </p>
                  </info></div></li><li><span>finding axis of rotation     </span><a id='glossaryinfo-20251' class='msm_infobutton' onmouseover='infoopen(20251)'>i</a><div id="dialog-20251" class="dialogs"><info xmlns="Compositor">
						            <p>
                     <span>An application of the theory of eigenvectors and eigenvalues: given a rotation of $\RNr{3}$, find its axis of rotation.</span>
                  </p>
					          </info></div></li></ul></li><li><span>row     </span><ul class='chilren'><li><span>reduced echelon form     </span><a id='glossaryinfo-3853' class='msm_infobutton' onmouseover='infoopen(3853)'>i</a><div id="dialog-3853" class="dialogs" title="What is row reduced echelon form?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>
                                       <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm is defined here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3853' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>matrix     </span><a id='glossaryinfo-4785' class='msm_infobutton' onmouseover='infoopen(4785)'>i</a><div id="dialog-4785" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4785' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4783' onmouseover='popup(4783)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4783" class="dialogs" title="On row matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>A row matrix is one which has exactly one row, i.e. is of size $(1,n)$. Thus the matrices below are row matrices.</span>
                           </p>
                           $$[15\ \ 4\ \ -7]\qquad [2\ \ -1\ \ -2\ \ 3\ \ -1]$$
                        </info></div></ul></div><br /></div></li></ul></li><li><span>row rescaling matrix     </span><a id='glossaryinfo-5537' class='msm_infobutton' onmouseover='infoopen(5537)'>i</a><div id="dialog-5537" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5537' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-5522' onmouseover='infoopen(5522)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-5522' style='display:none;'><div class='pack'><div class='title'>Examples of Row Rescaling Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(2,2)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 \\
					0 &amp; 3
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(3,3)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(3,3)$-matrices, the matrix which multiplies the third row by $5$ is</span>
         </p>
			
			      $$
					
					D_{3}(5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 5
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $3$-rd row by $2$ is</span>
         </p>
			
			      $$
					
					D_{3}(2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-5522" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Examples of row rescaling matrices</span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-5531' onmouseover='infoopen(5531)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-5531' style='display:none;'><div class='pack'><div class='title'>Explanation for Row Rescaling Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The row rescaling matrices</span>
         </p>
			
			      $$
					
					D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}
					
				$$
			
			      <p>
            <span>are named thus because, if $\Mtrx{B}$ is an arbitrary matrix of size $(n,p)$, then</span>
         </p>
			
			      $$
					
					\begin{bmatrix}
					1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
					\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
					0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
					\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
					0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
					\end{bmatrix}
					\begin{bmatrix}
					* &amp; \cdots &amp; * \\
					\vdots &amp; &amp; \vdots \\
					a_{u1} &amp; \cdots &amp; a_{up} \\
					\vdots &amp; &amp; \vdots \\
					{*} &amp; \cdots &amp; *
					\end{bmatrix}\ =\
					\begin{bmatrix}
					* &amp; \cdots &amp; * \\
					\vdots &amp; &amp; \vdots \\
					sa_{u1} &amp; \cdots &amp; sa_{up} \\
					\vdots &amp; &amp; \vdots \\
					{*} &amp; \cdots &amp; *
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>i.e. multiplying $\Mtrx{B}$ on the left with $D_{u}(s)$ has the effect of muyltiplying the $u$-th row of $\Mtrx{B}$ by $s$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(3,3)$-matrices, the matrix which multiplies the second row by $3$ is</span>
         </p>
			
			      $$
					
					D_{2}(3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_2(3)$ is</span>
         </p>
			
			      $$
					
					D_{2}(1/3) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1/3 &amp; 0 \\
					0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(3,3)$-matrices, the matrix which multiplies the third row by $5$ is</span>
         </p>
			
			      $$
					
					D_{3}(5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 5
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of  $D_3(5)$ is</span>
         </p>
			
			      $$
					
					D_{3}(1/5) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 1/5
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(4,4)$-matrices, the matrix which multiplies the $1$-st row by $6$ is</span>
         </p>
			
			      $$
					
					D_{1}(6) \ =\ 
					\begin{bmatrix}
					6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_1(6)$ is</span>
         </p>
			
			      $$
					
					D_{1}(1/6) \ =\ 
					\begin{bmatrix}
					1/6 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the world of $(4,4)$-matrices, the matrix which multiplies the $2$-nd row by $6$ is</span>
         </p>
			
			      $$
					
					D_{2}(6) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 6 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_2(6)$ is</span>
         </p>
			
			      $$
					
					D_{2}(1/6) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1/6 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In the set of $(4,4)$-matrices, the matrix which multiplies the $3$-rd row by $2$ is</span>
         </p>
			
			      $$
					
					D_{3}(2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
			
			      <p>
            <span>The inverse of $D_3(2)$ is</span>
         </p>
			
			      $$
					
					D_{3}(1/2) \ =\ 
					\begin{bmatrix}
					1 &amp; 0 &amp; 0 &amp; 0 \\
					0 &amp; 1 &amp; 0 &amp; 0 \\
					0 &amp; 0 &amp; 1/2 &amp; 0 \\
					0 &amp; 0 &amp; 0 &amp; 1
					\end{bmatrix}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-5531" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An explanation for the name ‘row rescaling matrix’</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>row space     </span><a id='glossaryinfo-11906' class='msm_infobutton' onmouseover='infoopen(11906)'>i</a><div id="dialog-11906" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>The column space of an $(m,n)$-matrix $\Mtrx{A}$ is the subspace of $\RNr{m}$ spanned by the column vectors of $\Mtrx{A}$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11906' style='display:none;'><br /><div class='def'><span class='deftitle'>Row space / column space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given an $(m,n)$-matrix $\Mtrx{A}$ express it in terms of its row and columns vectors</span>
                        </p>
                        $$
					
\Mtrx{A} =
\left[
\begin{array}{ccc}
a_{11} &amp; \cdots &amp; a_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; \cdots &amp; a_{mn}
\end{array}
\right] = 
\left[
\begin{array}{c}
R_1 \\ \vdots \\ R_m
\end{array}
\right] = 
\left[
\begin{array}{ccc}
C_1 &amp; \dots &amp; C_n
\end{array}
\right]
					
					$$
                        <ul>
                           <li>
                              <p>
                                 <span>The row space of $\Mtrx{A}$ is $\RowSp{\Mtrx{A}} := \span \Set{ R_1,\dots ,R_m }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The column space of $\Mtrx{A}$ is $\ColSp{\Mtrx{A}} := \span \Set{ C_1,\dots ,C_n }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                        </ul>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11898' onmouseover='infoopen(11898)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-11898' style='display:none;'><div class='title'>Row / Column Space - Explanation</div><p xmlns="Unit">
               <span>An element of the row space of the $(m,n)$-matrix $\Mtrx{A}$ is of the form</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$s_1R_1+\cdots + s_mR_m$</td></tr></table><p xmlns="Unit">
               <span>Each row of $\Mtrx{A}$ is a vector in $\RNr{n}$. Therefore the row space of $\Mtrx{A}$ is a subvector space of $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>An element of the column space of $(m,n)$-matrix $\Mtrx{A}$ is of the form</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{y}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1C_1+\cdots + t_nC_n$</td></tr></table><p xmlns="Unit">
               <span>Each column of $\Mtrx{A}$ is a vector in $\RNr{m}$. Therefore the column space of $\Mtrx{A}$ is a subvector space of $\RNr{m}$.</span>
            </p></div><div id="dialog-11898" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Details on the row and column space of a matrix.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>RREF     </span><a id='glossaryinfo-3855' class='msm_infobutton' onmouseover='infoopen(3855)'>i</a><div id="dialog-3855" class="dialogs" title="What does RREF mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>RREF is the acronym for <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm. Its definition is given here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3855' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>scalar product     </span><ul class='chilren'><li><span>of a matrix     </span><a id='glossaryinfo-4897' class='msm_infobutton' onmouseover='infoopen(4897)'>i</a><div id="dialog-4897" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div></li><li><span>of a linear map by a number     </span><a id='glossaryinfo-16514' class='msm_infobutton' onmouseover='infoopen(16514)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16514' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-16516' onmouseover='popup(16516)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-16516" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the function $L$ and a number $t$, we define a new function here, namely $(t\cdot L)$. The effect of the function $(t\cdot L)$ on a vector $\Vect{x}$ is defined to be the scalar product of $L(\Vect{x})$ times $t$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with a linear function $L$ and a number $t$, we do not know if their scalar product  $(t\cdot L)$ is linear. Therefore we must check that $(t\cdot L)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>of a linear transformation     </span><ul class='chilren'><li><span>represented by scalar product of matrix     </span><a id='glossaryinfo-17776' class='msm_infobutton' onmouseover='infoopen(17776)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17776' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Scalar product  of a linear map is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L\from \RNr{n} \longrightarrow \RNr{m}$ is a linear transformations and $t\in \RNr{}$ is a number, the scalar product of $L$ by $t$
         </span>
         
      </p>$$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) = t\cdot L(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(m,n)$-matrix representing $L$, then $(t\cdot \Mtrx{A})$ represents $(tL)$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-17778' onmouseover='popup(17778)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-17778" class="dialogs" title="Comment: What does this proposition tell us?"><info xmlns="Theorem">
         
         <p>
            <span>This proposition gives us two strong pieces of information:</span>
         </p>
         <ol>
            <li>
               <p>
                  <span>The scalar product of a linear transformation by a number is again linear</span>
               </p>
            </li>
            <li>
               <p>
                  <span>If the linear map $L$ is represented by $\Mtrx{A}$, then the linear map $(tL)$ is represented by the scalar product $(t\cdot \Mtrx{A})$.</span>
               </p>
            </li>
         </ol>
         <p>
            <span>In short: the scalar product  of a linear map corresponds to the scalar product of the representing matrix.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-17781' onmouseover='infoopen(17781)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-17781' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><div class='proofblocktitle'>Linearity of $(tL)$
         </div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We need to show that $(tL)$ satisfies the properties of a linear transformation. To see that it commutes with vector addition, let $\Vect{x},\Vect{y}\in \RNr{n}$. We find</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(tL)(\Vect{x}+\Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17787" class="hottag" onmouseover="popup(17787)">$=	$</a><div id="dialog-17787" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $(tL)$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot L(\Vect{x}+\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17792" class="hottag" onmouseover="popup(17792)">$=	$</a><div id="dialog-17792" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>As $L$ is linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot L(\Vect{x}) + t\cdot L(\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$tL(\Vect{x}) + tL(\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(tL)(\Vect{x})\ +\ (tL)(\Vect{y})$</td></tr></table><p>
            <span>So $(tL)$ commutes with vector addition.</span>
         </p><p>
            <span>To see that $(tL)$ commutes with scalar multiplication, let $\Vect{x}\in\RNr{n}$ and $a\in\RNr{}$. We find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(tL)(s\Vect{x})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17806" class="hottag" onmouseover="popup(17806)">$=	$</a><div id="dialog-17806" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $(tL)$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot (L(a \Vect{x}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-17811" class="hottag" onmouseover="popup(17811)">$=	$</a><div id="dialog-17811" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>... because $L$ is linear</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot ( aL(\Vect{x}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(ta)\cdot L(\Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s\cdot \left( t\cdot L(\Vect{x}) \right)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a\cdot (tL(\Vect{x}))$</td></tr></table><p>
            <span>This means that $(tL)$ commutes with scalar multiplication. &#x2013; The proof that $(tL)$ is linear is complete.</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><div class='proofblocktitle'>The matrix which represents $(tL)$
         </div><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We know now that $(tL)$ is linear. Therefore there is a unique $(m,n)$-matrix  which represents it. On the other hand, if $\Mtrx{A}$ represents $L$, we find for arbitrary $\Vect{x}\in\RNr{n}$
            </span>
         </p>$$(tA)\Vect{x} = t\cdot (A \Vect{x}) = t\cdot ( L(\Vect{x}) ) = (tL)(\Vect{x})$$<p>
            <span>Therefore $\Mtrx{C}:=t\Mtrx{A}$ is the unique matrix representing $(tL)$.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li></ul></li></ul></li><li><span>scaling     </span><ul class='chilren'><li><span>transformation     </span><a id='glossaryinfo-6935' class='msm_infobutton' onmouseover='infoopen(6935)'>i</a><div id="dialog-6935" class="dialogs" title="What is a scaling transformation?"><info xmlns="Unit">
                           
                           <p>
                              <span>A scaling transformation is a linear transformation of $\RNr{n}$ of the form $S(\Vect{x}) = s\cdot \Vect{x}$, with $s\in\RNr{}$ fixed.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6935' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6897' onmouseover='infoopen(6897)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6897' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6897" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘dilation’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6915' onmouseover='infoopen(6915)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6915' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6915" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘contraction’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6933' onmouseover='infoopen(6933)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6933' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6933" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘inversion’</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>factor     </span><a id='glossaryinfo-6879' class='msm_infobutton' onmouseover='infoopen(6879)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6879' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-6897' onmouseover='infoopen(6897)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6897' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6897" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘dilation’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6915' onmouseover='infoopen(6915)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6915' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6915" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘contraction’</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-6933' onmouseover='infoopen(6933)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-6933' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6933" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept of ‘inversion’</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>shear     </span><ul class='chilren'><li><span>transformation of $\RNr{n}$ parallel to a hyperspace     </span><a id='glossaryinfo-7141' class='msm_infobutton' onmouseover='infoopen(7141)'>i</a><div id="dialog-7141" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7141' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-7113' onmouseover='infoopen(7113)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-7113' style='display:none;'><div class='title'>Shear Transformations</div><p xmlns="Unit">
               <span>Shear transformations occur in a variety of contexts, for example when converting ordinary type into italics.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearingText.gif' height='75.721153846154' width='350'/></div><p xmlns="Unit">
               <span>We can think of this transformation as resulting from holding the base of these characters fixed and sliding the top by a certain amount parallel to the base line (the shear line) of the characters.</span>
            </p><p xmlns="Unit">
               <span>To describe such a shear transformation $S\from \RNr{n}\to \RNr{n}$ mathematically, we adopt the following setup:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>Let $\Vect{n}$ be a unit vector of $\RNr{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $H$ denote the hyperspace of $\RNr{n}$ perpendicular to $\Vect{n}$. This is the hyperspace parallel to which we shear.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{s} := S(\Vect{n}) - \Vect{n}$ denote the shear vector; i.e. $\Vect{s}$ is the vector by which $\Vect{n}$ must be slanted parallel to $H$ so as to transform it into $S(\Vect{n})$.</span>
                  </p>
               </li>
            </ul><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_1.png' height='266' width='350'/></div><p xmlns="Unit">
               <span>How to read the picture above:</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>The effect of $S$ on $\Vect{n}$ is $S(\Vect{n}) = \Vect{n} + \Vect{s}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The effect of $S$ on a stretched copy $t\cdot \Vect{n}$ of $\Vect{n}$ is $S(t\cdot \Vect{n}) = t\cdot \Vect{n} + t\cdot \Vect{s}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The effect of $S$ on an arbitrary vector $\Vect{x}$ with $\pr_{\Vect{n}}(\Vect{x}) = t\cdot \Vect{n}$ is </span>
                  </p>
                  $$S(\Vect{x}) = \Vect{x} + t\cdot \Vect{s} = \Vect{x} + (\DotPr{\Vect{x}}{\Vect{n}})\cdot \Vect{s}$$
               </li>
            </ol></div><div id="dialog-7113" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An explanation of shear transformations and their mathematical description</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-7139' onmouseover='infoopen(7139)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-7139' style='display:none;'><div class='pack'><div class='title'>Examples of Shear Transformations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the matrix representing the shear transformation $S$ of $\RNr{2}$, parallel to the $x$-axis which transforms the vector $\Vect{n} = (0,1)$ into the vector $S(\Vect{n}) = (1,1)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><div id="dialog-7123" class="dialogs"><info xmlns="Compositor">
						
						                        <p>
                                 <span>Look up how to find the matrix representing a given linear map</span>
                              </p>
					                      </info></div><div class='refcontent' id='refcontent-7123' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>
                     $\Vect{n}$ is a unit vector. Therefore the shear vector is</span>
               </p>
			
			            $$\Vect{s} = S(\Vect{n}) - \Vect{n} = (1,1) - (0,1) = (1,0)$$
			
			            <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_2.png" height="133.875" width="350"/></div>
			
			            <p>
                  <span>To find the 
				<a id="activehottag-7123" class="activehottag" onmouseover="infoopen(7123)"> matrix representing $S$
                        </a>  , we determine  the effect of $S$ on the vectors  $\StdBss{1}=(1,0)$ and $\StdBss{2}=(0,1)$
                  </span>
               </p>
			
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S(1,0)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,0) + \left( \DotPr{(1,0)}{(0,1)}\right) \cdot \Vect{s} = (1,0)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S(0,1)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(1,1)$</td></tr></table>
			
			            <p>
                  <span>Therefore,</span>
               </p>
			
			            $$
					
A = 
\left[
\begin{array}{rr}
1 &amp; 1 \\
0 &amp; 1
\end{array}
\right]
					
				$$
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>As in the example above we see that the general shear transformation of $\RNr{2}$ parallel to the $x$-axis is described by</span>
         </p>
			
			      $$
					
S(x,y) = 
\left[
\begin{array}{rr}
1 &amp; a \\
0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y
\end{array}
\right]
					
				$$
			
			      <p>
            <span>In particular, $S$ leaves $\StdBss{1}$ unchanged, and it shears $\StdBss{2}$ into $(0,1) + (a,0) = (a,1)$. So the shear vector is $\Vect{s} = (a,0)$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/ShearR2_3.png" height="154" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>Similarly, the shear transformation of $\RNr{3}$ parallel to the $xy$-plane with shear vector $\Vect{s} = (a,b,0)$  is given by</span>
         </p>
			
			      $$
					
S\from \RNr{3} \longrightarrow \RNr{3},\quad S(x,y,z) =
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; a \\
0 &amp; 1 &amp; b \\
0 &amp; 0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
x \\ y \\ z
\end{array}
\right]
					
				$$
			
			      <p>
            <span>The picture below shows the effect of such a shear transformation on the unit cube of $\RNr{3}$.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg" height="262.5" width="350"/></div>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-7139" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of shear transformations</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>slanted box     </span><a id='glossaryinfo-10255' class='msm_infobutton' onmouseover='infoopen(10255)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10255' style='display:none;'><br /><div class='def'><span class='deftitle'>Slanted box</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{n}$, the slanted box determined by an $n$-tuple of vectors $(\Vect{x}_1,\dots ,\Vect{x}_n)$ is
					</span>
                           
                        </p>
                        $$\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } := \Set{ t_1 \Vect{x}_1+\cdots +t_n \Vect{x}_n \st 0\leq t_1,\dots ,t_n\leq 1 }$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-10257' onmouseover='popup(10257)'><span style='cursor:pointer'>Example</span></li><div id="dialog-10257" class="dialogs" title="Box in $\RNr{1}$
                           "><info xmlns="Unit">
                           
                           <p>
                              <span>In $\RNr{1}$, $\SltdBox{x}$ is the interval $[0,x]$
                              </span>
                           </p>
                        </info></div><li class='defminibutton' id='defminibutton-10272' onmouseover='infoopen(10272)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-10272' style='display:none;'><div class='title'>2-Dimensional Slanted Box</div><p xmlns="Unit">
               <span>In $\RNr{2}$ the slanted box construction is applied to two vectors $\Vect{x}$ and $\Vect{y}$. Visually this is the parallelogram spanned by $\Vect{x}$ and $\Vect{y}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Box2_1.png' height='192.9375' width='350'/></div><p xmlns="Unit">
               <span>Let us explain how this results from the definition of</span>
            </p>$$\SltdBox{\Vect{x},\Vect{y}} = \Set{ r \Vect{x} + s \Vect{y} \st 0\leq s,t\leq 1 }$$<p xmlns="Unit">
               <span>
                  <b>Picture of</b>  $\SltdBox{\Vect{x},\Vect{y}}$   Let $X$ denote the point in $\RNr{2}$ whose position vector is $\Vect{x}$. Then the vectors $r \Vect{x}$ with $0\leq r\leq 1$ are the position vectors for points on the line segment $[\Vect{0},X]$ joining the origin to $X$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/ParallelogramSpan.png' height='124.25' width='350'/></div><p xmlns="Unit">
               <span>Now a vector sum of the form $r \Vect{x} + s \Vect{y}$ with $0\leq r\leq 1$ parallel translates the line segment $[0,X]$ by the vector $s \Vect{y}$. As $0\leq s\leq 1$, these parallel translated line segments fill the parallelogram spanned by $\Vect{x}$ and $\Vect{y}$ as shown.</span>
            </p><p xmlns="Unit">
               <span>Here is another example of such a parallelogram, the slanted box spanned by vectors $\Vect{u}$ and $\Vect{v}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Box2_2.png' height='282.625' width='350'/></div></div><div id="dialog-10272" class="dialogs" title="Box in $\RNr{2}$
                           "><info xmlns="Unit">
                           
                           <p>
                              <span>In $\RNr{2}$, $\SltdBox{\Vect{x},\Vect{y}}$ is the parallelogram spanned by the vectors $\Vect{x}$ and $\Vect{y}$. – See details of this construction.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>span     </span><a id='glossaryinfo-11854' class='msm_infobutton' onmouseover='infoopen(11854)'>i</a><div id="dialog-11854" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors in $S$. – Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11854' style='display:none;'><br /><div class='def'><span class='deftitle'>Span</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $S$. – The span of the empty set is, by definition, the vector space consisting of the origin alone.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11850' onmouseover='infoopen(11850)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-11850' style='display:none;'><div class='pack'><div class='title'>Span: Examples</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the span of the vector $\Vect{u} = (1,1,0)$ in $\RNr{3}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The span of $\Vect{u}$ is the collection of all vectors of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot (1,1,0)$</td></tr></table>
			            <p>
                  <span>This is the line in $\RNr{3}$ passing through the origin and in the direction of $\Vect{u}$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the span of a single vector $\Vect{s}$ in $\RNr{n}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The span of $\Vect{s}$ is the collection of all vectors of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot \Vect{s}$</td></tr></table>
			            <p>
                  <span>To describe the outcome of this operation we distinguish two cases:</span>
               </p>
			            <ol type="1">
				              <li>
					                <p>
                        <span>
                           $\Vect{s} = \Vect{0}$: in this case $t\cdot \Vect{s} = \Vect{0}$ and, therefore, $\span(\Vect{s})$ is just the $\Vect{0}$-vector.</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
                           $\Vect{s}\neq \Vect{0}$: in this case $\span(\Vect{s})$ is the line through the origin in the direction of $\Vect{s}$.</span>
                     </p>
				              </li>
			            </ol>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the span of the vectors $\Vect{u}=(2,0)$ and $\Vect{v}=(0,3)$ in $\RNr{2}$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The span of $\Vect{u}$ and $\Vect{v}$ consists of all vectors of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s\cdot \Vect{u} + t\cdot \Vect{v}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$s\cdot (2,0)\ +\ t\cdot (0,3)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(2s,3t)$</td></tr></table>
			            <p>
                  <span>We conclude that $\span(\Vect{u},\Vect{v})$ is all of $\RNr{2}$ because an arbitrary vector $(a,b)$ in $\RNr{2}$ is of the form</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a,b)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(2\cdot\tfrac{a}{2},3\cdot\tfrac{b}{3})$</td></tr></table>
			            <p>
                  <span>So it is in the span of $\Vect{u}$ and $\Vect{v}$.</span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-11850" class="dialogs" title="Example"><info xmlns="Unit">
                           
                           <p>
                              <span>Examples of the span operation</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>splitting     </span><ul class='chilren'><li><span>of a subspace     </span><a id='glossaryinfo-13678' class='msm_infobutton' onmouseover='infoopen(13678)'>i</a><div id="dialog-13678" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13678' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-13676" class="dialogs" title="What does this notation mean?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>
                                          $U\cup V$ is the union of the sets $U$ and $V$; i.e. a vector belongs to $U\cup V$ if it belongs to $U$ or to $V$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <a id="hottag-13676" class="hottag" onmouseover="popup(13676)"> 
                                    $W=\span(U\cup V)$
                                 </a>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li></ul></li><li><span>square     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4778' class='msm_infobutton' onmouseover='infoopen(4778)'>i</a><div id="dialog-4778" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4778' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4776' onmouseover='infoopen(4776)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4776' style='display:none;'><div class='pack'><div class='title'>Examples of Types of Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A matrix is square shaped if it is of type $(n,n)$. For example, the matrices below are square shaped.</span>
         </p>
			
			      $$
					
					\left[
					\begin{array}{rr}
					6 &amp; 9 \\
					-9 &amp; 6
					\end{array}
					\right] \qquad
					\left[
					\begin{array}{rrr}
					4 &amp; -4 &amp; 1 \\
					3 &amp; 2 &amp; 3 \\
					1 &amp; -3 &amp; 6
					\end{array}
					\right] \qquad 
					\left[
					\begin{array}{rrrrr}
					3 &amp; 0 &amp; 2 &amp; 4 &amp; 3 \\
					6 &amp; 1 &amp; 4 &amp; 2 &amp; 0 \\
					1 &amp; 5 &amp; 7 &amp; 6 &amp; 9 \\
					6 &amp; 2 &amp; 4 &amp; 7 &amp; 4 \\
					3 &amp; 3 &amp; 3 &amp; 0 &amp; 3
					\end{array}
					\right] 
					
				$$
			      <p>
            <span>Indeed, the matrix on the left has size $(2,2)$. The matrix in the middle has size $(3,3)$. The matrix on the right has size $(5,5)$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Determine if the following matrix is square shaped.</span>
         </p>
			      $$
				
				\left[
				\begin{array}{rrrrrrr}
				6 &amp; 5 &amp; 3 &amp; 12 &amp; 19 &amp; 403 &amp; 121 \\
				3 &amp; 0 &amp; 0 &amp; 1 &amp; 21 &amp; -12 &amp; 11 \\
				1 &amp; 1 &amp; 2 &amp; 2 &amp; 4 &amp; 4 &amp; 8
				\end{array}
				\right]
				
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The given matrix is not square shaped as its number of rows is $3$, while its number of columns is $7\neq 3$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4776" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Some examples of square shaped and non-square shaped matrices.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>subspace     </span><a id='glossaryinfo-11450' class='msm_infobutton' onmouseover='infoopen(11450)'>i</a><div id="dialog-11450" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Subspace = subvector space;   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11450' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11427' onmouseover='infoopen(11427)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11427' style='display:none;'><div class='title'>Sub Vector Space is Closed under Addition - Illustration</div><p xmlns="Unit">
               <span>The collection of vectors in a subvector space $V$ of $\RNr{n}$ is closed under vector addition. Here are some illustrations of what this means.</span>
            </p><p xmlns="Unit">
               <span>The subset below is closed under vector addition and scalar multiplication. So it is a subspace of $\RNr{n}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSpaceClosedAddition.gif' height='107.69230769231' width='350'/></div><p xmlns="Unit">
               <span>In contrast, here is a subset $V$ of $\RNr{2}$ which fails to be closed under vector addition. It is, therefore, not a subvector space.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSetNotClosedAddition.gif' height='100.12019230769' width='350'/></div><p xmlns="Unit">
               <span>Indeed, there are (at least) two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{3}$ whose sum $\Vect{x} + \Vect{y}$ is not in $V$. This means that this line is not closed under vector addition, hence is not a subvector space.</span>
            </p><p xmlns="Unit">
               <span>The green half plane below is closed under vector addition, but not under scalar multiplication. For example, the vector $-\Vect{x}$ is not in $S$. Therefore $S$ is not a subvector space.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSetClosedAdditionNotScalarMult.gif' height='134.61538461538' width='350'/></div></div><div id="dialog-11427" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Illustration of closedness under vector addition</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-11442' onmouseover='infoopen(11442)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11442' style='display:none;'><div class='title'>Sub Vector Space is Closed under Scalar Multiplication - Illustration</div><p xmlns="Unit">
               <span>The collection of vectors in a subvector space $V$ of $\RNr{n}$ is closed under scalar multiplication. Here are some illustrations of what this means.</span>
            </p><p xmlns="Unit">
               <span>The subset below is closed under vector addition and scalar multiplication. So it is a subspace of $\RNr{n}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSpaceClosedScalarMultiplication.gif' height='86.666666666667' width='350'/></div><p xmlns="Unit">
               <span>The two lines below form a set $S$ which is closed under scalar multiplication: For any vector $\Vect{x}$ in $S$, the entire line through the origin in the direction of $\Vect{x}$ also belongs to $V$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ClosedScalarMultiplication_1.gif' height='188.14229249012' width='350'/></div><p xmlns="Unit">
               <span>The set $S$ above is, however, not closed under vector addition. Therefore it is not a subvector space of $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>The blue dots below form a set $S$ which is closed under vector addition but not under scalar multiplication. To see that it is not closed under scalar multiplication, consider any vector in $S$: there are points on the line through $\Vect{x}$ which do not belong to $S$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/Lattice2_2.gif' height='192.05776173285' width='350'/></div><p xmlns="Unit">
               <span>Therefore this set $S$ is not a subvector space.</span>
            </p></div><div id="dialog-11442" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Illustration of closedness under scalar multiplication</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-11444' onmouseover='popup(11444)'><span style='cursor:pointer'>Example</span></li><div id="dialog-11444" class="dialogs" title="Examples"><info xmlns="Unit">
                     
                     <ol>
                        <li>
                           <p>
                              <span>
                                 $\RNr{n}$ is a subvector space of itself.</span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>The set $\Set{ \Vect{0} }$ consisting only of the zero vector is a sub vector space of $\RNr{n}$.</span>
                           </p>
                        </li>
                     </ol>
                  </info></div><li class='defminibutton' id='defminibutton-11446' onmouseover='popup(11446)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-11446" class="dialogs" title="Comment on $\Vect{0}$ is in $V$
                     "><info xmlns="Unit">
                     
                     <p>
                        <span>The requirement that $V$ contain the $\Vect{0}$-vector can be dropped if, instead, we require that the set $V$ is not empty.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>subvector space     </span><a id='glossaryinfo-11448' class='msm_infobutton' onmouseover='infoopen(11448)'>i</a><div id="dialog-11448" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11448' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-11427' onmouseover='infoopen(11427)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11427' style='display:none;'><div class='title'>Sub Vector Space is Closed under Addition - Illustration</div><p xmlns="Unit">
               <span>The collection of vectors in a subvector space $V$ of $\RNr{n}$ is closed under vector addition. Here are some illustrations of what this means.</span>
            </p><p xmlns="Unit">
               <span>The subset below is closed under vector addition and scalar multiplication. So it is a subspace of $\RNr{n}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSpaceClosedAddition.gif' height='107.69230769231' width='350'/></div><p xmlns="Unit">
               <span>In contrast, here is a subset $V$ of $\RNr{2}$ which fails to be closed under vector addition. It is, therefore, not a subvector space.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSetNotClosedAddition.gif' height='100.12019230769' width='350'/></div><p xmlns="Unit">
               <span>Indeed, there are (at least) two vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{3}$ whose sum $\Vect{x} + \Vect{y}$ is not in $V$. This means that this line is not closed under vector addition, hence is not a subvector space.</span>
            </p><p xmlns="Unit">
               <span>The green half plane below is closed under vector addition, but not under scalar multiplication. For example, the vector $-\Vect{x}$ is not in $S$. Therefore $S$ is not a subvector space.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSetClosedAdditionNotScalarMult.gif' height='134.61538461538' width='350'/></div></div><div id="dialog-11427" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Illustration of closedness under vector addition</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-11442' onmouseover='infoopen(11442)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-11442' style='display:none;'><div class='title'>Sub Vector Space is Closed under Scalar Multiplication - Illustration</div><p xmlns="Unit">
               <span>The collection of vectors in a subvector space $V$ of $\RNr{n}$ is closed under scalar multiplication. Here are some illustrations of what this means.</span>
            </p><p xmlns="Unit">
               <span>The subset below is closed under vector addition and scalar multiplication. So it is a subspace of $\RNr{n}$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/SubSpaceClosedScalarMultiplication.gif' height='86.666666666667' width='350'/></div><p xmlns="Unit">
               <span>The two lines below form a set $S$ which is closed under scalar multiplication: For any vector $\Vect{x}$ in $S$, the entire line through the origin in the direction of $\Vect{x}$ also belongs to $V$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ClosedScalarMultiplication_1.gif' height='188.14229249012' width='350'/></div><p xmlns="Unit">
               <span>The set $S$ above is, however, not closed under vector addition. Therefore it is not a subvector space of $\RNr{n}$.</span>
            </p><p xmlns="Unit">
               <span>The blue dots below form a set $S$ which is closed under vector addition but not under scalar multiplication. To see that it is not closed under scalar multiplication, consider any vector in $S$: there are points on the line through $\Vect{x}$ which do not belong to $S$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/Lattice2_2.gif' height='192.05776173285' width='350'/></div><p xmlns="Unit">
               <span>Therefore this set $S$ is not a subvector space.</span>
            </p></div><div id="dialog-11442" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Illustration of closedness under scalar multiplication</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-11444' onmouseover='popup(11444)'><span style='cursor:pointer'>Example</span></li><div id="dialog-11444" class="dialogs" title="Examples"><info xmlns="Unit">
                     
                     <ol>
                        <li>
                           <p>
                              <span>
                                 $\RNr{n}$ is a subvector space of itself.</span>
                           </p>
                        </li>
                        <li>
                           <p>
                              <span>The set $\Set{ \Vect{0} }$ consisting only of the zero vector is a sub vector space of $\RNr{n}$.</span>
                           </p>
                        </li>
                     </ol>
                  </info></div><li class='defminibutton' id='defminibutton-11446' onmouseover='popup(11446)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-11446" class="dialogs" title="Comment on $\Vect{0}$ is in $V$
                     "><info xmlns="Unit">
                     
                     <p>
                        <span>The requirement that $V$ contain the $\Vect{0}$-vector can be dropped if, instead, we require that the set $V$ is not empty.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>sum     </span><ul class='chilren'><li><span>of matrices     </span><a id='glossaryinfo-4886' class='msm_infobutton' onmouseover='infoopen(4886)'>i</a><div id="dialog-4886" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4886' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4879' onmouseover='popup(4879)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4879" class="dialogs" title="Comment on Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the sum of two matrices is only defined if both matrices have the same size.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4884' onmouseover='infoopen(4884)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4884' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Addition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The sum of the two matrices</span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{blue}3} \\
					{\color{blue}1} &amp; {\color{blue}4} \\
					{\color{blue}6} &amp; {\color{blue}4}
					\end{array}\right] \qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{red}-3} &amp; {\color{red}-3} \\
					{\color{red}1} &amp; {\color{red}2} \\
					{\color{red}6} &amp; {\color{red}1}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is defined because both matrices are of the same size $(3,2)$. Their sum is</span>
         </p>
			
			      $$
					
					{\color{blue}A} + {\color{red}B}\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} - {\color{red}3} &amp; {\color{blue}3} -{\color{red}3} \\
					{\color{blue}1} + {\color{red}1} &amp; {\color{blue}4} +{\color{red}2} \\
					{\color{blue}6} + {\color{red}6} &amp; {\color{blue}4} + {\color{red}1}
					\end{array}\right] \ =\ 
					\left[\begin{array}{cc}
					4 &amp; 0 \\
					2 &amp; 6 \\
					12 &amp; 5
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the sum of two matrices of size $(m,n)$
            </span>
         </p>
			
			      $$
					
					{\color{blue}A}\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\qquad \text{and}\qquad
					{\color{red}B}\ =\ 
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right]
					
				$$
			      <p>
            <span>is</span>
         </p>
			
			      $$
					
					\aligned
					{\color{blue}A}\ +\ {\color{red}B}\ &amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}}
					\end{array}\right]\ +\
					\left[\begin{array}{ccc}
					{\color{red}b_{11}} &amp; \cdots &amp; {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{red}b_{m1}} &amp; \cdots &amp; {\color{red}b_{mn}}
					\end{array}\right] \\
					&amp;=\ 
					\left[\begin{array}{ccc}
					{\color{blue}a_{11}} + {\color{red}b_{11}} &amp; \cdots &amp; {\color{blue}a_{1n}} + {\color{red}b_{1n}} \\
					\vdots &amp; \ddots &amp; \vdots \\
					{\color{blue}a_{m1}} + {\color{red}b_{m1}} &amp; \cdots &amp; {\color{blue}a_{mn}} + {\color{red}b_{mn}}
					\end{array}\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4884" class="dialogs" title="Example of Sum of Matrices"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus, to add two matrices, we simply add their intries in matching positions. – Here are some examples.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>of linear transformations     </span><a id='glossaryinfo-16458' class='msm_infobutton' onmouseover='infoopen(16458)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16458' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-16460' onmouseover='popup(16460)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-16460" class="dialogs" title="Explanation"><info xmlns="Unit">
                           
                           <p>
                              <span>Given the functions $L$ and $T$, we define a new function here, namely $(L+T)$. The effect of the sum function $(L+T)$ on a vector $\Vect{x}$ is the sum $L(\Vect{x})$ plus $T(\Vect{x})$.</span>
                           </p>
                           <p>
                              <span>Note: At this stage of making a definition, if we start with two linear function $L$ and $T$, we do not know if their sum $(L+T)$ is linear. Therefore we must check that $(L+T)$ satisfies the properties of a linear transformation</span>
                           </p>
                        </info></div></ul></div><br /></div><ul class='chilren'><li><span>represented by sum of matrices     </span><a id='glossaryinfo-7540' class='msm_infobutton' onmouseover='infoopen(7540)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7540' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Sum of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L,T\from \RNr{n} \longrightarrow \RNr{m}$ are two linear transformations, then their sum
			</span>
         
      </p>$$(L+T)\from \RNr{n} \longrightarrow \RNr{m},\quad (L+T)(\Vect{x}) = L(\Vect{x}) + T(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Further, if $\Mtrx{A}$ and $\Mtrx{B}$ are the $(m,n)$-matrices representing $L$ and $T$ respectively, then $\Mtrx{A} + \Mtrx{B}$ represents $L+T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-7589' onmouseover='popup(7589)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-7589" class="dialogs" title="Comment: What does this proposition tell us?"><info xmlns="Theorem">
         
         <p>
            <span>This proposition gives us two strong pieces of information:</span>
         </p>
         <ol>
            <li>
               <p>
                  <span>The sum of two linear transformations is again linear</span>
               </p>
            </li>
            <li>
               <p>
                  <span>If the linear map $L$ is represented by $\Mtrx{A}$ and $T$ is represented by $\Mtrx{B}$, then the linear map $(L+T)$ is represented by the sum of the matrices $\Mtrx{A} + \Mtrx{B}$.</span>
               </p>
            </li>
         </ol>
         <p>
            <span>In short: the sum of two linear maps corresponds to the sum of their representing matrices.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-7543' onmouseover='infoopen(7543)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-7543' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><div class='proofblocktitle'>Linearity of $(L+T)$
         </div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We need to show that $(L+T)$ satisfies the properties of a linear transformation. To see that it commutes with vector addition, let $\Vect{x},\Vect{y}\in \RNr{n}$. We find</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(L+T)(\Vect{x}+\Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7549" class="hottag" onmouseover="popup(7549)">$=	$</a><div id="dialog-7549" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $(L+T)$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\Vect{x}+\Vect{y}) + T(\Vect{x}+\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7554" class="hottag" onmouseover="popup(7554)">$=	$</a><div id="dialog-7554" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $L$ and $T$ are linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\Vect{x}) + L(\Vect{y})\ +\ T(\Vect{x}) + T(\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7559" class="hottag" onmouseover="popup(7559)">$=	$</a><div id="dialog-7559" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Rearrange summands; remember: vector addition is commutative.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(\Vect{x}) + T(\Vect{x})\ +\ L(\Vect{y}) + T(\Vect{y})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7564" class="hottag" onmouseover="popup(7564)">$=	$</a><div id="dialog-7564" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the definition of $(L+T)$ again.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(L+T)(\Vect{x})\ +\ (L+T)(\Vect{y})$</td></tr></table><p>
            <span>So $(L+T)$ commutes with vector addition.</span>
         </p><p>
            <span>To see that $(L+T)$ commutes with scalar multiplication, let $\Vect{x}\in\RNr{n}$ and $t\in\RNr{}$. We find:</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(L+T)(t \Vect{x})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7570" class="hottag" onmouseover="popup(7570)">$=	$</a><div id="dialog-7570" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $(L+T)$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$L(t \Vect{x}) + T(t \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7575" class="hottag" onmouseover="popup(7575)">$=	$</a><div id="dialog-7575" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Because $L$ and $T$ are linear.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot L(\Vect{x}) + t\cdot T(\Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot ( L(\Vect{x}) + T(\Vect{x}) )$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-7584" class="hottag" onmouseover="popup(7584)">$=	$</a><div id="dialog-7584" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the definition of $(L+T)$ again.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t\cdot (L+T)(\Vect{x})$</td></tr></table><p>
            <span>This means that $(L+T)$ commutes with scalar multiplication. &#x2013; The proof that $(L+T)$ is linear is complete.</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><div class='proofblocktitle'>The matrix which represents $(L+T)$
         </div><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>We know now that $(L+T)$ is linear. Therefore there is a unique $(m,n)$-matrix  which represents it. On the other hand, if $\Mtrx{A}$ represents $L$, and if $\Mtrx{B}$ represents $T$, we find for arbitrary $\Vect{x}\in\RNr{n}$
            </span>
         </p>$$(A+B)\Vect{x} = A \Vect{x} + B \Vect{x} = L(\Vect{x}) + T(\Vect{x}) = (L+T)(\Vect{x})$$<p>
            <span>Therefore $\Mtrx{C}:=\Mtrx{A} + \Mtrx{B}$ is the unique matrix representing $(L+T)$.</span>
         </p></proof.block.body></proof.block.body></div></div></ul></div><br /></div></li></ul></li></ul></li><li><span>symmetric     </span><ul class='chilren'><li><span>matrix     </span><a id='glossaryinfo-4942' class='msm_infobutton' onmouseover='infoopen(4942)'>i</a><div id="dialog-4942" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4942' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4935' onmouseover='popup(4935)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-4935" class="dialogs" title="Comment on: Symmetric Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>The first thing to observe about a symmetric matrix $A$ is that its number of rows must be the same as its number of columns. Therefore $A$ is square shaped. Moreover, we have the identity of entries $a_{ij}=a_{ji}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4940' onmouseover='infoopen(4940)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4940' style='display:none;'><div class='pack'><div class='title'>Examples of (non-)Symmetric Matrices</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 5 &amp; 7 \\
					5 &amp; -1 &amp; 4 \\
					7 &amp; 4 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					4 &amp; a &amp; -2 &amp; 1 \\
					a &amp; 6 &amp; 3 &amp; b \\
					-2 &amp; 3 &amp; c &amp; 1 \\
					1 &amp; b &amp; 1 &amp; 0
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The following matrices are not symmetric</span>
         </p>
			      $$
					
					\left[\begin{array}{rrr}
					1 &amp; 0 &amp; 0 \\
					5 &amp; -1 &amp; 0 \\
					7 &amp; 6 &amp; 9
					\end{array}\right]\qquad
					\left[\begin{array}{rrrr}
					0 &amp; 1 &amp; -2 &amp; 1 \\
					5 &amp; 6 &amp; 3 &amp; -2 \\
					b &amp; 3 &amp; 6 &amp; 1 \\
					1 &amp; b &amp; 5 &amp; 0
					\end{array}\right]
					
				$$
			      <p>
            <span>Note that, while the $(4,4)$-matrix on the right displays a different kind of symmetry, it is not equal to its transpose, and so it is not symmetric.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4940" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Examples of (non-)symmetric matrices.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>symmetry     </span><ul class='chilren'><li><span>of dot product     </span><a id='glossaryinfo-1873' class='msm_infobutton' onmouseover='infoopen(1873)'>i</a><div id="dialog-1873" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The symmetry property of the dot product asserts that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1873' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='proofminibutton' id='proofminibutton-1888' onmouseover='infoopen(1888)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1888' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div>
<proof.block.body><proof.block.body><p>
            <span>Each of these identities follows by computing both sides of the given equation, and checking that the results are equal. So suppose we are given vectors</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{a}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(a_1,\dots ,a_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{b}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(b_1,\dots ,b_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{y}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(y_1,\dots ,y_n)$</td></tr></table><p>
            <span>Then we compute:</span>
         </p></proof.block.body></proof.block.body>
</div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Bilinearity
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The bilinearity property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (\Vect{a} + \Vect{b}) }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ ((a_1,\dots ,a_n) + (b_1,\dots ,b_n)) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1910" class="hottag" onmouseover="popup(1910)"> 
                              $=$
                           </a>  
                     <div id="dialog-1910" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of vector addition</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1,\dots ,a_n+b_n)) \bullet (x_1,\dots ,x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1912" class="hottag" onmouseover="popup(1912)"> 
                              $=$
                           </a>  
                     <div id="dialog-1912" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $(a_1+b_1)x_1 + \cdots + (a_n+b_n) x_n)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1914" class="hottag" onmouseover="popup(1914)"> 
                              $=$
                           </a>  
                     <div id="dialog-1914" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the distributivity law for real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $(a+b)\cdot c = ac + bc$ &#xA0; for arbitrary numbers $a,b,c$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+b_1x_1 + \cdots + a_nx_n+b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1916" class="hottag" onmouseover="popup(1916)"> 
                              $=$
                           </a>  
                     <div id="dialog-1916" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the commutativity law for the addition of real numbers; i.e.</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $s + t = t + s$ &#xA0; for arbitrary numbers $s,t$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1+ \cdots + a_nx_n\ +\ b_1x_1 + \cdots + b_n x_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1918" class="hottag" onmouseover="popup(1918)"> 
                              $=$
                           </a>  
                     <div id="dialog-1918" class="dialogs" title="This computational step holds because"><info xmlns="Theorem">
                              
                              <p>
                                 <span>... by the definition of the dot product.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} } + \DotPr{ \Vect{b} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>as was to be shown. &#x2013; The remaining bilinearity properties are proved similarly.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Symmetry
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The symmetry property holds because</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{a} }{ \Vect{x} }$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ (a_1,\dots ,a_n) }{ (x_1,\dots ,x_n) }$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1922" class="hottag" onmouseover="popup(1922)"> 
                              $=$
                           </a>  
                     <div id="dialog-1922" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $a_1x_1 + \cdots + a_nx_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1924" class="hottag" onmouseover="popup(1924)"> 
                              $=$
                           </a>  
                     <div id="dialog-1924" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the commutativity property of multiplication of numbers: $st = ts$
                                 </span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $x_1a_1 + \cdots + x_na_n$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1926" class="hottag" onmouseover="popup(1926)"> 
                              $=$
                           </a>  
                     <div id="dialog-1926" class="dialogs" title="This computational step holds because ..."><info xmlns="Theorem">
                              
                              <p>
                                 <span>... of the definition of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{ \Vect{x} }{ \Vect{a} }$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Positive Definite
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product is positive definite because</span>
         </p>$$\DotPr{ \Vect{x} }{ \Vect{x} } = \DotPr{ (x_1,\dots ,x_n) }{ (x_1,\dots ,x_n) } = x_{1}^{2} + \cdots + x_{n}^{2} \geq 0$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Non Degenerate
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>The dot product operation is non-degenerate because $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if</span>
         </p>$$x_{1}^{2} + \cdots + x_{n}^{2} = 0$$<p>
            <span>Now this sum of squares is zero if and only if $x_{i}^{2} = 0$ for each $1\leq i\leq n$. Now $x_{i}^{2} = 0$ if and only if $x_i=0$, and this is equivalent to</span>
         </p><p align="center">
            <span>
               $(x_1,\dots ,x_n) = \Vect{x} = \Vect{0}$.</span>
         </p></proof.block.body></proof.block.body></ul></div></div></ul></div><br /></div></li></ul></li><li><span>system of linear equations     </span><a id='glossaryinfo-3483' class='msm_infobutton' onmouseover='infoopen(3483)'>i</a><div id="dialog-3483" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>solutions discussed in geometrical terms</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3483' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3485' onmouseover='popup(3485)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-3485" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words, the simultaneous solutions of the given system of linear equations consists of the intersection of the hyperplanes $H_1,\dots ,H_n$.</span>
         </p>
      </info></div></ul></div><br /></div><ul class='chilren'><li><span>inconsistent     </span><a id='glossaryinfo-3668' class='msm_infobutton' onmouseover='infoopen(3668)'>i</a><div id="dialog-3668" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3668' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3485' onmouseover='popup(3485)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-3485" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words, the simultaneous solutions of the given system of linear equations consists of the intersection of the hyperplanes $H_1,\dots ,H_n$.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3544' onmouseover='infoopen(3544)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3544' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{2}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2)$ and $\Vect{n}_2 = (b_1,b_2)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3522" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2NonParallel.gif" height="285" width="455" usemap="#TwoEqnsR2NonParallel"/><map name="TwoEqnsR2NonParallel"><area id="pic-3524" coords="264,126,292,93,294,50,275,44,238,104,251,114" shape="poly" href="#" onmouseover="popup(3524)"><div id="dialog-3524" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3526" coords="202,214,186,166,171,152,154,174,159,188,174,186,191,222,202,218" shape="poly" href="#" onmouseover="popup(3526)"><div id="dialog-3526" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3528" coords="374,220,378,206,323,169,314,180,368,218" shape="poly" href="#" onmouseover="popup(3528)"><div id="dialog-3528" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3530" coords="302,153,242,114,106,14,98,29,284,157" shape="poly" href="#" onmouseover="popup(3530)"><div id="dialog-3530" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3532" coords="323,164,426,109,414,96,312,149,323,168" shape="poly" href="#" onmouseover="popup(3532)"><div id="dialog-3532" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3534" coords="300,181,146,262,138,250,200,220,288,168,299,176" shape="poly" href="#" onmouseover="popup(3534)"><div id="dialog-3534" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3536" coords="308,169,5" shape="circle" href="#" onmouseover="popup(3536)"><div id="dialog-3536" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two nonparallel lines in the plane $\RNr{2}$always have a unique point of intersection. This is the one and only simultaneous solution of the two given equations.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with normal vector $\Vect{n}_1$ is the line $H_1$, while</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the solution hyperplane of the second the equation, with normal vector $\Vect{n}_2$, is the line $H_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel, the lines $H_1$ and $H_2$ are not parallel either. So these lines intersect precisely in one point, denoted here $(x_0,y_0)$. This means that there is exactly one solution of the given system of linear equations, namely:</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x = x_0$   and   $y = y_0$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Question</b>   Amongst all the systems of two linear equations with two unknowns, "how often" do we encounter the situation that there is exactly one common solution?</span>
            </p><div id="dialog-3543" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>This statement has only intuitive value here. It can be made precise using a combination of the more advanced mathematical subjects of measure theory and geometric probability.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Answer</b> &#xA0; Exactly one solution occurs exactly when the solution lines of the individual equations are not parallel. Now, given two arbitrary lines in the plane, their 
				<a id="hottag-3543" class="hottag" onmouseover="popup(3543)"> chances</a>  
				of not being parallel are greater than their chances of being parallel. Therefore "most of the time" a system of two linear equations in two unknowns will have exactly one solution.</span>
            </p>
</div><div id="dialog-3544" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3578' onmouseover='infoopen(3578)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3578' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{3}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2,a_3)$ and $\Vect{n}_2 = (b_1,b_2,b_3)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3554" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3NonParallel.gif" height="281" width="333" usemap="#TwoEqnsR3NonParallel"/><map name="TwoEqnsR3NonParallel"><area id="pic-3556" coords="109,8,8" shape="circle" href="#" onmouseover="popup(3556)"><div id="dialog-3556" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This red dot marks the origin in $\RNr{3}$.</span>
                                 </p>
                              </info></div></area><area id="pic-3558" coords="95,28,61,68,50,66,95,11,104,18" shape="poly" href="#" onmouseover="popup(3558)"><div id="dialog-3558" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3560" coords="27,91,31,107,1,139,2,118" shape="poly" href="#" onmouseover="popup(3560)"><div id="dialog-3560" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3562" coords="111,21,121,12,169,80,160,86" shape="poly" href="#" onmouseover="popup(3562)"><div id="dialog-3562" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3564" coords="205,126,194,133,218,166,229,159" shape="poly" href="#" onmouseover="popup(3564)"><div id="dialog-3564" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3566" coords="216,122,240,108,316,277,70,220,191,139,216,171,233,158,211,126,211,126,211,126" shape="poly" href="#" onmouseover="popup(3566)"><div id="dialog-3566" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3568" coords="82,49,133,63,63,183,11,32,57,46,42,68,55,81,77,53,77,53" shape="poly" href="#" onmouseover="popup(3568)"><div id="dialog-3568" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3570" coords="39,125,62,185,18,141,38,129" shape="poly" href="#" onmouseover="popup(3570)"><div id="dialog-3570" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3572" coords="157,55,229,9,332,41,78,201,68,191,138,69,142,67,163,95,181,83" shape="poly" href="#" onmouseover="popup(3572)"><div id="dialog-3572" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with coefficient vector $\Vect{n}_1$ pointing down-left, is a plane in the ordinary sense perpendicular to $\Vect{n}_1$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The solution hyperplane of the second equation, with coefficient vector $\Vect{n}_2$ pointing down-right, is a plane perpendicular to $\Vect{n}_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors of these planes are not parallel, these planes are not parallel either. So these planes intersect in a line $L$. Each point on $L$ represents a common solution of both equations, and the intersection line consists of all possible simultaneous solutions of these equations.</span>
            </p><p xmlns="Unit">
               <span>For emphasis, let us say in different words what this means: Pick a vector $\Vect{x}$ in $\RNr{3}$. Then $\Vect{x}$ is given by three coordinates: $(x_0,y_0,z_0)$. So these are three numbers, and choosing</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x:=x_0$   and   $y:=y_0$   and   $z:=z_0$
               </span>
            </p><p xmlns="Unit">
               <span>renders both equations true simultaneously if and only if $\Vect{x}$ belongs to the line of intersection of the two solution hyperplanes of the given equations.</span>
            </p></div><div id="dialog-3578" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3620' onmouseover='infoopen(3620)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3620' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3592" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3594" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3594)"><div id="dialog-3594" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3596" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3596)"><div id="dialog-3596" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3598" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3598)"><div id="dialog-3598" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3600" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3600)"><div id="dialog-3600" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3602" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3602)"><div id="dialog-3602" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3604" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3604)"><div id="dialog-3604" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3606" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3606)"><div id="dialog-3606" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3608" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3608)"><div id="dialog-3608" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3611" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3613" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3613)"><div id="dialog-3613" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3615" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3615)"><div id="dialog-3615" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3617" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3617)"><div id="dialog-3617" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3620" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3661' onmouseover='infoopen(3661)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3661' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3633" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3635" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3635)"><div id="dialog-3635" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3637" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3637)"><div id="dialog-3637" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3639" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3639)"><div id="dialog-3639" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3641" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3641)"><div id="dialog-3641" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3643" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3643)"><div id="dialog-3643" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3645" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3645)"><div id="dialog-3645" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3647" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3647)"><div id="dialog-3647" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3649" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3649)"><div id="dialog-3649" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3652" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3654" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3654)"><div id="dialog-3654" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3656" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3656)"><div id="dialog-3656" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3658" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3658)"><div id="dialog-3658" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3661" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li><li><span>overdetermined     </span><a id='glossaryinfo-3670' class='msm_infobutton' onmouseover='infoopen(3670)'>i</a><div id="dialog-3670" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3670' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3485' onmouseover='popup(3485)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-3485" class="dialogs" title="Explanation"><info xmlns="Theorem">
         
         <p>
            <span>In other words, the simultaneous solutions of the given system of linear equations consists of the intersection of the hyperplanes $H_1,\dots ,H_n$.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3511' onmouseover='infoopen(3511)'><span style='cursor:pointer'>Explanation</span></li><div class='refcontent' id='refcontent-3511' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-3505" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-3505" class="hottag" onmouseover="popup(3505)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-3511" class="dialogs" title="Explanation: How do I test if two vectors are parallel?"><info xmlns="Theorem">
         
         <p>
            <span>
               $\Vect{n}_1$ and $\Vect{n}_2$ are parallel if there is $t\in \RNr{}$ with $\Vect{n}_1=t\cdot \Vect{n}_2$. – Review an illustration of this.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3544' onmouseover='infoopen(3544)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3544' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{2}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2)$ and $\Vect{n}_2 = (b_1,b_2)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3522" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2NonParallel.gif" height="285" width="455" usemap="#TwoEqnsR2NonParallel"/><map name="TwoEqnsR2NonParallel"><area id="pic-3524" coords="264,126,292,93,294,50,275,44,238,104,251,114" shape="poly" href="#" onmouseover="popup(3524)"><div id="dialog-3524" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3526" coords="202,214,186,166,171,152,154,174,159,188,174,186,191,222,202,218" shape="poly" href="#" onmouseover="popup(3526)"><div id="dialog-3526" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The normal vector formed from the coefficients of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3528" coords="374,220,378,206,323,169,314,180,368,218" shape="poly" href="#" onmouseover="popup(3528)"><div id="dialog-3528" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3530" coords="302,153,242,114,106,14,98,29,284,157" shape="poly" href="#" onmouseover="popup(3530)"><div id="dialog-3530" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3532" coords="323,164,426,109,414,96,312,149,323,168" shape="poly" href="#" onmouseover="popup(3532)"><div id="dialog-3532" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3534" coords="300,181,146,262,138,250,200,220,288,168,299,176" shape="poly" href="#" onmouseover="popup(3534)"><div id="dialog-3534" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$ a hyperplane is just a line. This is the line of solutions of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3536" coords="308,169,5" shape="circle" href="#" onmouseover="popup(3536)"><div id="dialog-3536" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two nonparallel lines in the plane $\RNr{2}$always have a unique point of intersection. This is the one and only simultaneous solution of the two given equations.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with normal vector $\Vect{n}_1$ is the line $H_1$, while</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the solution hyperplane of the second the equation, with normal vector $\Vect{n}_2$, is the line $H_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel, the lines $H_1$ and $H_2$ are not parallel either. So these lines intersect precisely in one point, denoted here $(x_0,y_0)$. This means that there is exactly one solution of the given system of linear equations, namely:</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x = x_0$   and   $y = y_0$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Question</b>   Amongst all the systems of two linear equations with two unknowns, "how often" do we encounter the situation that there is exactly one common solution?</span>
            </p><div id="dialog-3543" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>This statement has only intuitive value here. It can be made precise using a combination of the more advanced mathematical subjects of measure theory and geometric probability.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Answer</b> &#xA0; Exactly one solution occurs exactly when the solution lines of the individual equations are not parallel. Now, given two arbitrary lines in the plane, their 
				<a id="hottag-3543" class="hottag" onmouseover="popup(3543)"> chances</a>  
				of not being parallel are greater than their chances of being parallel. Therefore "most of the time" a system of two linear equations in two unknowns will have exactly one solution.</span>
            </p>
</div><div id="dialog-3544" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3578' onmouseover='infoopen(3578)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3578' style='display:none;'><div class='title'>Two Linear Equations in $\RNr{3}$ with Non-Parallel Normal Vectors</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\Vect{n}_1 = (a_1,a_2,a_3)$ and $\Vect{n}_2 = (b_1,b_2,b_3)$ are not parallel, we find ourselves in the situation sketched below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3554" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3NonParallel.gif" height="281" width="333" usemap="#TwoEqnsR3NonParallel"/><map name="TwoEqnsR3NonParallel"><area id="pic-3556" coords="109,8,8" shape="circle" href="#" onmouseover="popup(3556)"><div id="dialog-3556" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This red dot marks the origin in $\RNr{3}$.</span>
                                 </p>
                              </info></div></area><area id="pic-3558" coords="95,28,61,68,50,66,95,11,104,18" shape="poly" href="#" onmouseover="popup(3558)"><div id="dialog-3558" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3560" coords="27,91,31,107,1,139,2,118" shape="poly" href="#" onmouseover="popup(3560)"><div id="dialog-3560" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3562" coords="111,21,121,12,169,80,160,86" shape="poly" href="#" onmouseover="popup(3562)"><div id="dialog-3562" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3564" coords="205,126,194,133,218,166,229,159" shape="poly" href="#" onmouseover="popup(3564)"><div id="dialog-3564" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector of the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3566" coords="216,122,240,108,316,277,70,220,191,139,216,171,233,158,211,126,211,126,211,126" shape="poly" href="#" onmouseover="popup(3566)"><div id="dialog-3566" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3568" coords="82,49,133,63,63,183,11,32,57,46,42,68,55,81,77,53,77,53" shape="poly" href="#" onmouseover="popup(3568)"><div id="dialog-3568" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the first equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3570" coords="39,125,62,185,18,141,38,129" shape="poly" href="#" onmouseover="popup(3570)"><div id="dialog-3570" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3572" coords="157,55,229,9,332,41,78,201,68,191,138,69,142,67,163,95,181,83" shape="poly" href="#" onmouseover="popup(3572)"><div id="dialog-3572" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the solution hyperplane of the second equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>The solution hyperplane of the first equation, with coefficient vector $\Vect{n}_1$ pointing down-left, is a plane in the ordinary sense perpendicular to $\Vect{n}_1$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The solution hyperplane of the second equation, with coefficient vector $\Vect{n}_2$ pointing down-right, is a plane perpendicular to $\Vect{n}_2$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>If the normal vectors of these planes are not parallel, these planes are not parallel either. So these planes intersect in a line $L$. Each point on $L$ represents a common solution of both equations, and the intersection line consists of all possible simultaneous solutions of these equations.</span>
            </p><p xmlns="Unit">
               <span>For emphasis, let us say in different words what this means: Pick a vector $\Vect{x}$ in $\RNr{3}$. Then $\Vect{x}$ is given by three coordinates: $(x_0,y_0,z_0)$. So these are three numbers, and choosing</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $x:=x_0$   and   $y:=y_0$   and   $z:=z_0$
               </span>
            </p><p xmlns="Unit">
               <span>renders both equations true simultaneously if and only if $\Vect{x}$ belongs to the line of intersection of the two solution hyperplanes of the given equations.</span>
            </p></div><div id="dialog-3578" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with non parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3620' onmouseover='infoopen(3620)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3620' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3592" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3594" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3594)"><div id="dialog-3594" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3596" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3596)"><div id="dialog-3596" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3598" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3598)"><div id="dialog-3598" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3600" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3600)"><div id="dialog-3600" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3602" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3602)"><div id="dialog-3602" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3604" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3604)"><div id="dialog-3604" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3606" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3606)"><div id="dialog-3606" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3608" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3608)"><div id="dialog-3608" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3611" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3613" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3613)"><div id="dialog-3613" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3615" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3615)"><div id="dialog-3615" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3617" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3617)"><div id="dialog-3617" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3620" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in two variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-3661' onmouseover='infoopen(3661)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-3661' style='display:none;'><div class='title'>Solutions of Two Linear Equations with Parallel Solution Hyperplanes</div><p xmlns="Unit">
               <span>Here we consider the simultaneous solutions of two linear equations with two unknowns</span>
            </p>$$
					
						\begin{array}{rcrccccrcl}
						a_1x_1 &amp; + &amp; a_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; a_nx_n &amp; = &amp; c \\
						b_1x_1 &amp; + &amp; b_2x_2 &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; b_nx_n &amp; = &amp; d
						\end{array}
					
				$$<p xmlns="Unit">
               <span>If the coefficient vectors $\mathbf{n}_1 = (a_1,a_2,\dots ,a_n)$ and $\mathbf{n}_2 = (b_1,b_2,\dots ,b_n)$ are not $\mathbf{0}$ but parallel, this means that there exists a unique number $t$ such that $t\cdot \mathbf{n}_1 = \mathbf{n}_2$; i.e.</span>
            </p>$$t\cdot (a_1,a_2,\dots ,a_n) = (ta_1,ta_2,\dots ,ta_n) = (b_1,b_2,\dots ,b_n)$$<p xmlns="Unit">
               <span>This means that, for any choice of $\mathbf{x} = (x_1,\dots ,x_n)$ the left hand side of the second equation is $t$ times the left hand side of the first. So there are two possibilities:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>First possibility</b>
                  $d\neq tc$   In this case a solution of the first equation cannot simultaneously be a solution of the second. This is reflected in the fact that the corresponding solution hyperplanes are parallel and distinct.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3633" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR2Parallel.gif" height="274" width="345" usemap="#TwoEqnsR2Parallel"/><map name="TwoEqnsR2Parallel"><area id="pic-3635" coords="86,98,112,92,101,33,85,39,73,92" shape="poly" href="#" onmouseover="popup(3635)"><div id="dialog-3635" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the first linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3637" coords="196,137,221,131,212,71,195,79,183,131,201,139" shape="poly" href="#" onmouseover="popup(3637)"><div id="dialog-3637" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3639" coords="179,192,169,187,180,145,194,152" shape="poly" href="#" onmouseover="popup(3639)"><div id="dialog-3639" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is the normal vector associated to the second linear equation.</span>
                                 </p>
                              </info></div></area><area id="pic-3641" coords="299,188,306,163,194,136,191,149" shape="poly" href="#" onmouseover="popup(3641)"><div id="dialog-3641" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3643" coords="181,130,176,144,83,108,88,98" shape="poly" href="#" onmouseover="popup(3643)"><div id="dialog-3643" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3645" coords="70,94,66,106,2,83,6,67,71,91" shape="poly" href="#" onmouseover="popup(3645)"><div id="dialog-3645" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3647" coords="326,271,329,243,183,198,295,252,301,272,329,272,329,272" shape="poly" href="#" onmouseover="popup(3647)"><div id="dialog-3647" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the first linear equation form a line.</span>
                                 </p>
                              </info></div></area><area id="pic-3649" coords="163,191,154,203,22,155,29,143" shape="poly" href="#" onmouseover="popup(3649)"><div id="dialog-3649" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{2}$, the hyperplane of solutions of the second linear equation form a line.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3652" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/TwoEqnsR3Parallel.gif" height="350" width="377" usemap="#TwoEqnsR3Parallel"/><map name="TwoEqnsR3Parallel"><area id="pic-3654" coords="163,115,174,111,150,15,123,30" shape="poly" href="#" onmouseover="popup(3654)"><div id="dialog-3654" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>This is a normal vector common to both hyperplanes.</span>
                                 </p>
                              </info></div></area><area id="pic-3656" coords="163,31,227,2,377,86,133,246,5,129,134,55,162,115,175,115,182,107,165,37" shape="poly" href="#" onmouseover="popup(3656)"><div id="dialog-3656" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the first equation form a plane in the ordinary sense.</span>
                                 </p>
                              </info></div></area><area id="pic-3658" coords="310,138,374,180,131,344,3,216,55,186,130,254" shape="poly" href="#" onmouseover="popup(3658)"><div id="dialog-3658" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>In $\RNr{3}$ the solution hyperplane of the second equation form a plane in the ordinary sense, and this plane is parallel and distinct from the solution plane of the first equation.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>As the solution hyperplanes of the given two equations are parallel and distinct, there is no point which belongs to both hyperplanes. Therefore the given system of linear equations has no solution. We express this by saying that the solution set of this system of linear equations is empty; or: The two equations are inconsistent.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Second Possibility</b>   $d\neq t\cdot c$   We know that $t\neq 0$. So, in this case each solution of one of the equations is also a solution of the other. So both equations have the same solution hyperplane. Consequently, this system of two equations is equivalent to the system consisting of just one them.</span>
            </p></div><div id="dialog-3661" class="dialogs" title="Illustration"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the solutions of two linear equations in three variables with parallel coefficient vectors.</span>
         </p>
      </info></div></ul></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li><li><span>homogeneous     </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4225' onmouseover='infoopen(4225)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4225' style='display:none;'><div class='pack'><div class='title'>Homogeneous and Inhomogeneous Systems of Linear Equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called homogeneous if all of the augmented constants are $0$.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$3$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{-1}{\color{red}x_1}\ +\ \colorbox{lightgreen}{2}{\color{red}x_2}\ -\ \colorbox{lightgreen}{1}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$4$}{\color{red}x_5} \ -\ \colorbox{lightgreen}{$6$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$5$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$4$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$5$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			      <p>
            <span>This means that choosing all unknowns equal to $0$ is a solution. Therefore a homogeneous system of linear equations always has at least one solution, namely $x_1=\cdots =x_n=0$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called inhomogeneous if at least one of its augmented constants is different from $0$. This implies that setting all variables equal to $0$ can never be a solution of an inhomogeneous system.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$1$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$3$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$9$}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 11 \\
%
\colorbox{lightgreen}{20}{\color{red}x_1}\ +\ \colorbox{lightgreen}{0}{\color{red}x_2}\ +\ \colorbox{lightgreen}{3}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5} \ +\ \colorbox{lightgreen}{$0$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 2 \\
%
\colorbox{lightgreen}{$10$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_5}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$9$}{\color{red}x_7} &amp; = &amp; -3 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4225" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a homogeneous system of linear equations and an inhomogeneous system of linear equations.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>inhomogeneous     </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4225' onmouseover='infoopen(4225)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4225' style='display:none;'><div class='pack'><div class='title'>Homogeneous and Inhomogeneous Systems of Linear Equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called homogeneous if all of the augmented constants are $0$.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$3$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{-1}{\color{red}x_1}\ +\ \colorbox{lightgreen}{2}{\color{red}x_2}\ -\ \colorbox{lightgreen}{1}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$4$}{\color{red}x_5} \ -\ \colorbox{lightgreen}{$6$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$5$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$4$}{\color{red}x_2}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$5$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			      <p>
            <span>This means that choosing all unknowns equal to $0$ is a solution. Therefore a homogeneous system of linear equations always has at least one solution, namely $x_1=\cdots =x_n=0$
            </span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>A system of linear equations is called inhomogeneous if at least one of its augmented constants is different from $0$. This implies that setting all variables equal to $0$ can never be a solution of an inhomogeneous system.</span>
         </p>
			      $$
					
\begin{array}{rcr}
\colorbox{lightgreen}{$1$}{\color{red}x_1}\ +\ \colorbox{lightgreen}{$3$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$9$}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_4}\ -\ \colorbox{lightgreen}{$6$}{\color{red}x_5}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_7} &amp; = &amp; 11 \\
%
\colorbox{lightgreen}{20}{\color{red}x_1}\ +\ \colorbox{lightgreen}{0}{\color{red}x_2}\ +\ \colorbox{lightgreen}{3}{\color{red}x_3}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_5} \ +\ \colorbox{lightgreen}{$0$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$3$}{\color{red}x_7} &amp; = &amp; 2 \\
%
\colorbox{lightgreen}{$10$}{\color{red}x_1}\ -\ \colorbox{lightgreen}{$2$}{\color{red}x_2}\ +\ \colorbox{lightgreen}{$2$}{\color{red}x_3}\ +\ \colorbox{lightgreen}{$1$}{\color{red}x_4}\ +\ \colorbox{lightgreen}{$0$}{\color{red}x_5}\ -\ \colorbox{lightgreen}{$1$}{\color{red}x_6}\ -\ \colorbox{lightgreen}{$9$}{\color{red}x_7} &amp; = &amp; -3 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4225" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a homogeneous system of linear equations and an inhomogeneous system of linear equations.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>translation     </span><ul class='chilren'><li><span>vector     </span><a id='glossaryinfo-3087' class='msm_infobutton' onmouseover='infoopen(3087)'>i</a><div id="dialog-3087" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3087' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li></ul></li><li><span>transposition     </span><ul class='chilren'><li><span>of a matrix     </span><a id='glossaryinfo-4929' class='msm_infobutton' onmouseover='infoopen(4929)'>i</a><div id="dialog-4929" class="dialogs" title="Transpose of a Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4929' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4920' onmouseover='popup(4920)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-4920" class="dialogs" title="Explanation on Matrix Transposition"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus when transposing a matrix, we simply turn its rows into columns and vice versa; i.e. the first row of $A$ turns into the first column of $B$. The second row of $A$ turns into the second column of $B$, etc.
					</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-4925' onmouseover='infoopen(4925)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4925' style='display:none;'><div class='pack'><div class='title'>Examples of Matrix Transposition</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>The transpose of the $(3,2)$-matrix</span>
         </p>
			
			      $$
					
					A\ =\ 
					\left[\begin{array}{cc}
					{\color{blue}7} &amp; {\color{red}3} \\
					{\color{blue}1} &amp; {\color{red}4} \\
					{\color{blue}6} &amp; {\color{red}4}
					\end{array}\right]
					
				$$
			
			      <p>
            <span>is the $(2,3)$-matrix</span>
         </p>
			
			      $$
					
					A^T\ =\ 
					\left[\begin{array}{ccc}
					{\color{blue}7} &amp; {\color{blue}1} &amp; {\color{blue}6} \\
					{\color{red}3} &amp; {\color{red}4} &amp; {\color{red}4}
					\end{array}\right]
					
				$$
		    </statement.showme></div><br /></div><br /><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>In general, the transpose of an $(m,n)$-matrix</span>
         </p>
			      $$
					
					A\ =\ 
					\left[\begin{array}{rrr}
					a_{11} &amp; \cdots &amp; a_{1n} \\
					\vdots &amp; \ddots &amp; \vdots \\
					a_{m1} &amp; \cdots &amp; a_{mn}
					\end{array}\right]
					
				$$
			      <p>
            <span>is the $(m,n)$-matrix</span>
         </p>
			      $$
					
					\aligned
					A^T\ &amp;=\  
					\left[\begin{array}{rrrrr}
					a_{11} &amp; \cdots &amp; {\color{red}a_{1j}} &amp; \cdots &amp; a_{1n} \\
					\vdots  &amp;             &amp; {\color{red}\vdots} &amp;             &amp; \vdots \\
					a_{m1} &amp; \cdots &amp; {\color{red}a_{mj}} &amp; \cdots &amp; a_{mn}
					\end{array}\right]^T \\
					&amp;=\ \left[\begin{array}{rrr}
					a_{11} &amp; \cdots &amp; a_{m1} \\
					\vdots &amp;               &amp; \vdots \\
					{\color{red}a_{1j}} &amp; \cdots &amp; {\color{red}a_{mj}} \\
					\vdots &amp;               &amp; \vdots \\
					a_{1n} &amp; \cdots &amp; a_{mn}
					\end{array}
					\right]
					\endaligned
					
				$$
		    </statement.showme></div><br /></div><br /><br /></div></div><div id="dialog-4925" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>Some examples of matrix transposition.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>commutes with determinant     </span><a id='glossaryinfo-9441' class='msm_infobutton' onmouseover='infoopen(9441)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9441' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-9503' onmouseover='infoopen(9503)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-9503' style='display:none;'><div class='pack'><div class='title'>Examples: Computing with Determinants</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the determinant of the matrix</span>
         </p>
			      $$
					
\Mtrx{A}\ :=\  
\left[
\begin{array}{rrrrr}
-1 &amp; 4 &amp; 3 &amp; 4 &amp; 5 \\
5 &amp; -2 &amp; 3 &amp; -2 &amp; 1 \\
0 &amp; 6 &amp; 0 &amp; 6 &amp; 2 \\
-1 &amp; -1 &amp; 2 &amp; -1 &amp; 4 \\
9 &amp; 3 &amp; 3 &amp; 3 &amp; -1
\end{array}
\right] = 0

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The 2nd and 4th columns of matrix $\Mtrx{A}$ are equal:</span>
               </p>
			            $$
					
\left[
\begin{array}{rrrrr}
-1 &amp; {\color{red} 4} &amp; 3 &amp; {\color{red} 4} &amp; 5 \\
5 &amp; {\color{red} -2} &amp; 3 &amp; {\color{red} -2} &amp; 1 \\
0 &amp; {\color{red} 6} &amp; 0 &amp; {\color{red} 6} &amp; 2 \\
-1 &amp; {\color{red} -1} &amp; 2 &amp; {\color{red} -1} &amp; 4 \\
9 &amp; {\color{red} 3} &amp; 3 &amp; {\color{red} 3} &amp; -1
\end{array}
\right] = 0

				$$
			            <p>
                  <span>Therefore</span>
               </p>
			            <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, \Mtrx{A}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Compute the determinant of the $(3,3)$-matrix</span>
         </p>
			      $$
					
\Mtrx{B}\ :=  
\left[
\begin{array}{rrr}
2 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Of course we can always compute $\det\, \Mtrx{B}$ using the cofactor method. However, here is an opportunity which makes our live a lot easier: we may turn $\Mtrx{B}$ into an upper triangular matrix by subtracting the third column from the first. This process does not change the determinant, and the result is</span>
               </p>
			            $$
					
\det\, 
\left[
\begin{array}{rrr}
2 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right] = \det
\left[
\begin{array}{rrr}
1 &amp; 3 &amp; 1 \\
0 &amp; 5 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right] = 5

				$$
			            <p>
                  <span>Recall that the determinant of an upper triangular matrix is just the product of its diagonal entries, hence the final answer.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the determinant of the matrix</span>
         </p>
			      $$
					
\Mtrx{C}\ :=  
\left[
\begin{array}{rrrr}
4 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; -1 &amp; 0 &amp; 0 \\
1 &amp; 7 &amp; 3 &amp; 0 \\
5 &amp; 0 &amp; 1 &amp; 2
\end{array}
\right]

				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>We notice that $\Mtrx{C}$ is a lower triangular matrix, and we recall that the determinant of an upper triangular matrix is just the product of its diagonal entries. How can we make use of this fact?</span>
               </p>
			            <p>
                  <span>We also just learned that $\det(\Mtrx{C}) = \det(\Mtrx{C}^T)$. Now transposition turns a lower triangular matrix into an upper triangular matrix, and so:</span>
               </p>
			            $$
					
\det(\Mtrx{C}) = \det(\Mtrx{C}^T)\ =  
\left[
\begin{array}{rrrr}
4 &amp; 3 &amp; 1 &amp; 5 \\
0 &amp; -1 &amp; 7 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 2
\end{array}
\right] = -24
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-9503" class="dialogs" title="Example"><info xmlns="Theorem">
         
         <p>
            <span>See some examples which explain how to use these rules</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-9448' onmouseover='infoopen(9448)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-9448' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'> Equal columns gives 0-determinant</div></li><div id="dialog-9470" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Look up the alternating property of the determinant operation</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9470' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If two columns in a square matrix $\Mtrx{A}$ are equal, then $\Mtrx{A}$ is of the form</span>
         </p>$$A = [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$$<p>
            <span>But then the 
			<a id="activehottag-9470" class="activehottag" onmouseover="infoopen(9470)"> alternating property</a>  
			of the determinant operation gives</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9454" class="hottag" onmouseover="popup(9454)">$=	$</a><div id="dialog-9454" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Interchange the two columns containing the vector $X$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$-\det [ A_1\ \dots \ X\ \dots\ X\ \dots\ A_n]$</td></tr></table><p>
            <span>Therefore $\det(\Mtrx{A}) = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><i><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></i></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If the square matrix $\Mtrx{A} = [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]$, we need to show</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-9475" class="hottag" onmouseover="popup(9475)">$=	$</a><div id="dialog-9475" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Add $t\cdot Y$ to the $X$-column</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det\, [A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$</td></tr></table><p>
            <span>We invoke the multilinearity property of the determinant operation in the $X$-column:</span>
         </p>$$
				
\aligned
&amp;\det\, [A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n] \\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]\ +\ \det\, [A_1\ \dots\ (tY)\ \dots\ Y\ \dots\ A_n] \\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]\ +\ t\cdot \det\, [A_1\ \dots\ Y\ \dots\ Y\ \dots\ A_n]\\
&amp;\quad =\ \det\, [A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n]
\endaligned

			$$<p>
            <span>Because $[A_1\ \dots\ Y\ \dots\ Y\ \dots\ A_n]$ has two equal columns and, hence, vanishing determinant.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'> Determinant commutes with transposition</div></li><div id="dialog-9489" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Look up this result.</span>
                        </p>
                     </info></div><div class='refcontent' id='refcontent-9489' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Properties of alternating multilinear functions</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $F\from M_{nn}\to \RNr{}$ be any function which is linear in each column and alternating. Then $F$ has the following properties:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}=[A_1\ \dots\ X\ \dots\ X\ \dots\ A_n]$, then $F(\Mtrx{A}) =0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $F[A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n] = F[A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-9486" class="dialogs" title="Explanation of the symbols in this formula"><info xmlns="Theorem">
                        
                        <p>
                           <span>
                              $\SymGrp{n}$ denotes the group of all invertible functions from $\Set{ 1,\dots ,n}$ to itself. $E_{j}$ denotes the $(n,1)$-column matrix which has a ‘$1$’ in position $j$ and $0$’s everywhere else.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}= [a_{ij}]$, 
				<a id="hottag-9486" class="hottag" onmouseover="popup(9486)"> then</a>  
               </span>
            </p>
            $$F(\Mtrx{A}) = \sum_{r\in \SymGrp{n}} a_{r(1)1}\cdots a_{r(n)n} F[E_{r(1)}\ \dots\ E_{r(n)}]$$
         </part.body>
</li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>There exists a unique number $c$ in $\RNr{}$ such that, for each invertible  $r\from \Set{1,\dots ,n} \to \Set{1,\dots ,n}$,</span>
            </p>
            $$F[E(r(1))\dots E(r(n))] = c\cdot \det [E(r(1))\dots E(r(n))] = c\cdot \sign(r)$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>For each $(n,n)$-matrix $\Mtrx{A}$, $F(\Mtrx{A}) = F(\Mtrx{A}^T)$.</span>
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>This is a special case of a 
			<a id="activehottag-9489" class="activehottag" onmouseover="infoopen(9489)"> more general result about alternating multilinear functions</a>  
			which will be proved in the next section.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li></ul></li><li><span>triangle inequality     </span><a id='glossaryinfo-1974' class='msm_infobutton' onmouseover='infoopen(1974)'>i</a><div id="dialog-1974" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The triangle inequality asserts that, for any two vectors $\Vect{x}$ and $\Vect{y}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1974' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'><li class='minibutton' id='minibutton-2057' onmouseover='infoopen(2057)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2057' style='display:none;'><div class='title'>Triangle Inequality – Illustration</div><p xmlns="Unit">
               <span>Given vectors $\Vect{x}$ and $\Vect{y}$, the triangle inequality $|\Vect{x} + \Vect{y}| \leq |\Vect{x}| + |\Vect{y}|$ deserves its name: It asserts that in a triangle any one edge is at most as long as the sum of the other two.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="288.75" width="480"/></div>
               </span>
            </p>
</div><div id="dialog-2057" class="dialogs" title="Illustration of the Triangle Inequality"><info xmlns="Theorem">
         
         <p>
            <span>Why the name triangle inequality? – An illustration motivates this name easily.</span>
         </p>
      </info></div><li class='minibutton' id='minibutton-2078' onmouseover='infoopen(2078)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-2078' style='display:none;'><div class='title'>Angle between Vectors: Illustration</div><p xmlns="Unit">
               <span>What exactly do we mean by the angle between two nonzero vectors? – Consider the image below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/AngleVectors.png' height='160.65' width='350'/></div><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are not parallel, the angle $\theta$ from $\Vect{x}$ to $\Vect{y}$ is the shorter of the two possible arcs from $\Vect{x}$ to $\Vect{y}$; the angle $\theta$ in the image above. It is always a number between $0$ and $\pi$.</span>
            </p><p xmlns="Unit">
               <span>If $\Vect{x}$ and $\Vect{y}$ are parallel,</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $\theta = 0$ if the vectors have the same directions.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\theta = \pi$ if the vectors have opposite directions.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>Remarkable is that $\cos \theta$ is readily computable using the dot product:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\DotPr{ \Vect{x} }{ \Vect{y} }$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Abs{ \Vect{x} }\Abs{ \Vect{y} } \cdot \cos\theta$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\cos\theta$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-2074' class='hottag' onmouseover='popup(2074)'>$= $</a><div id="dialog-2074" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Here we assume that $\Vect{x},\Vect{y} \neq \Vect{0}$.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\dfrac{ \DotPr{ \Vect{x} }{ \Vect{y} } }{ \Abs{ \Vect{x} }\Abs{ \Vect{y} } }$</td></tr></table><p xmlns="Unit">
               <span>So the cos of the angle between the vectors is their dot product divided by their lengths. </span>
            </p></div><div id="dialog-2078" class="dialogs" title="Illustration of the Angle Between Vectors"><info xmlns="Theorem">
         
         <p>
            <span>An illustration of the angle between two vectors.</span>
         </p>
      </info></div><li class='proofminibutton' id='proofminibutton-1982' onmouseover='infoopen(1982)'><span style='cursor:pointer'>Proof</span></li><div class='proof' id='proof-1982' style='display:none;'><div class='proofblock'><div class='proofblocktitle'></div><proof.block.body><proof.block.body/></proof.block.body></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Dot product and norm
		</div></li><proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To establish the relationship between the dot product and the norm, let $\Vect{x} = (x_1,\dots ,x_n)$. Then we find</span>
         </p>$$\DotPr{\Vect{x}}{\Vect{x}} = x_{1}^{2} + \cdots + x_{n}^{2} = | \Vect{x} |^2$$</proof.block.body></proof.block.body></ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Orthogonality criterion
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see what the identity $\DotPr{\Vect{x}}{\Vect{x}} = 0$ means, consider the vector triangle</span>
         </p><div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/TriangleInequality.png" height="210.546875" width="350"/></div><p>
            <span>We know that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} + \Vect{y} |^2$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1988" class="hottag" onmouseover="popup(1988)"> 
                              $=$
                           </a>  
                     <div id="dialog-1988" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{(\Vect{x} + \Vect{y})}{( \Vect{x} + \Vect{y})}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1990" class="hottag" onmouseover="popup(1990)"> 
                              $=$
                           </a>  
                     <div id="dialog-1990" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use a binomial identity for dot products.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{x}} + 2(\DotPr{\Vect{x}}{\Vect{y}}) + \DotPr{\Vect{y}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1992" class="hottag" onmouseover="popup(1992)"> 
                              $=$
                           </a>  
                     <div id="dialog-1992" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>From property (i) we already know that $\DotPr{\Vect{u}}{\Vect{u}} = | \Vect{u} |^2$ for every vector $\Vect{u}$.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $|\Vect{x}|^2 + 2(\DotPr{\Vect{x}}{\Vect{y}}) + |\Vect{y}|^2$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>Now the theorem of Pythagoras (actually its inverse) says that the identity below</span>
         </p>$$|\Vect{x} + \Vect{y}|^2 = | \Vect{x} |^2 + | \Vect{y} |^2$$<p>
            <span>holds if and only if  $\Vect{x}$  is perpendicular to $\Vect{y}$. Comparing the two equations shows that this happens exactly when  $\DotPr{\Vect{x}}{\Vect{y}} = 0$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Angle between two vectors
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>To see the relationship between the dot product of two vectors $\Vect{x}$ and $\Vect{y}$ and the angle between the two vectors, consider first the case where both vectors have length $1$; i.e. $| \Vect{x} | = 1 = | \Vect{y} |$. Then we are in the situation illustrated below:</span>
         </p><p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/DotProductAngle_Prf1.png" height="302.25" width="480"/></div>
            </span>
         </p><p>
            <span>So we may write $\Vect{y} = (\cos\theta)\cdot \Vect{x}\ +\ (\Vect{y} - (\cos \theta)\cdot \Vect{x})$. Taking the dot product on both sides with $\Vect{x}$ we obtain</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\Vect{y}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2006" class="hottag" onmouseover="popup(2006)">$=$</a><div id="dialog-2006" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Substitute the expression we found for $\Vect{y}$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{\left( (\cos\theta)\cdot \Vect{x}\ +(\Vect{y} - (\cos\theta)\cdot \Vect{x})\right)}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2011" class="hottag" onmouseover="popup(2011)">$=$</a><div id="dialog-2011" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the distributivity property of the dot product operation.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\DotPr{\Vect{x}}{ (\cos\theta)\cdot \Vect{x}) }\ + \DotPr{\Vect{x}}{ (\Vect{y} - (\cos\theta)\cdot \Vect{x})}$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2016" class="hottag" onmouseover="popup(2016)">$=
				$</a><div id="dialog-2016" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>This is the essential step in the argument. By design $\Vect{x}$ is perpendicular to $\Vect{y} - (\cos\theta)\cdot \Vect{x}$. So the dot product of these two vectors is $0$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x} \bullet  (\cos\theta)\cdot \Vect{x})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2021" class="hottag" onmouseover="popup(2021)">$=
				$</a><div id="dialog-2021" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use the linearity property of the dot product in the second factor.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta \cdot (\DotPr{\Vect{x}}{\Vect{x}})$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-2026" class="hottag" onmouseover="popup(2026)">$=
				$</a><div id="dialog-2026" class="dialogs" title=""><info xmlns="Theorem">
                        <p>
                           <span>Here we use that $| \Vect{x} | = 1$, and so $\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} | = 1$.</span>
                        </p>
                     </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\cos\theta$</td></tr></table><p>
            <span>Next consider the case where $\Vect{x}$ and $\Vect{y}$ are arbitrary but of positive length. Then we find that</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\DotPr{\Vect{x}}{\Vect{y}}$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-1998" class="hottag" onmouseover="popup(1998)"> 
                              $=$
                           </a>  
                     <div id="dialog-1998" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>We can write</span>
                              </p>
                              <p align="center">
                                 <span>
                                    $\Vect{x} = | \Vect{x} | \cdot ( \Vect{x} / | \Vect{x} |)$ &#xA0; and &#xA0; $\Vect{y} = | \Vect{y} | \cdot ( \Vect{y} / | \Vect{y} |)$
                                 </span>
                              </p>
                              <p>
                                 <span>because $\Vect{x}$ and $\Vect{y}$ have positive length.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left( | \Vect{x} | \cdot \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left( | \Vect{y} | \bullet \dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2000" class="hottag" onmouseover="popup(2000)"> 
                              $=$
                           </a>  
                     <div id="dialog-2000" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>Here we use the bilinearity property of the dot product</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cdot \left( \dfrac{ \Vect{x} }{ | \Vect{x} | } \right) \bullet \left(\dfrac{ \Vect{y} }{ | \Vect{y} | } \right)$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        <a id="hottag-2002" class="hottag" onmouseover="popup(2002)"> 
                              $=$
                           </a>  
                     <div id="dialog-2002" class="dialogs"><info xmlns="Theorem">
                              <p>
                                 <span>By design, $\Vect{x} / | \Vect{x} |$ and $\Vect{y} / | \Vect{y} |$ have length $1$. So we can use the previous result.</span>
                              </p>
                           </info></div></span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} | | \Vect{y} | \cos \sphericalangle( \Vect{x} , \Vect{y} )$
                     </span>
                  </p>
               </td>
            </tr></table></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Triangle Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>Here we rely heavily on the relationship between norm and dot product. The triangle inequality is true if and only if</span>
         </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} + \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left( | \Vect{x} | + | \Vect{y} | \right)^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\Vect{x} + \Vect{y}) \bullet (\Vect{x} + \Vect{y})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 \Vect{x} \bullet \Vect{y} + | \Vect{y} |^2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} |^2 + 2 | \Vect{x} | | \Vect{y} | +  | \Vect{y} |^2$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} | \cos \sphericalangle ( \Vect{x} , \Vect{y} )$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$\leq$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$| \Vect{x} | | \Vect{y} |$</td></tr></table><p>
            <span>The latter inequality is true because $\cos \sphericalangle( \Vect{x} , \Vect{y} ) \leq 1$. This implies the triangle inequality.</span>
         </p></proof.block.body></proof.block.body>
</ul></div><div class='proofblock'><ul><li><div class='proofblocktitle'>
			Cauchy Schwarz Inequality
		</div></li>
<proof.block.body><proof.block.body xmlns="Theorem"><p>
            <span>If both $\Vect{x}$ and $\Vect{y}$ have positive length, we have the calculation</span>
         </p><table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x} \bullet \Vect{y} |$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\left| | \Vect{x}|\, |\Vect{y}| \cdot \cos \sphericalangle( \Vect{x}, \Vect{y} ) \right|$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|\, | \cos \sphericalangle( \Vect{x}, \Vect{y} ) |$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $\leq$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}| \cdot 1$
                     </span>
                  </p>
               </td>
            </tr><tr>
               <td style="border-width:0px !important;">
                  <p>
                     <span>&#xA0;</span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $=$
                     </span>
                  </p>
               </td>
               <td style="border-width:0px !important;">
                  <p>
                     <span>
                        $| \Vect{x}|\, |\Vect{y}|$
                     </span>
                  </p>
               </td>
            </tr></table><p>
            <span>The previous calculation does not apply If $\Vect{x} = \Vect{0}$ or if $\Vect{y} = \Vect{0}$. However, in this case we compute directly as follows:</span>
         </p><p align="center">
            <span>
               $| \Vect{x} \bullet \Vect{y} | = 0 = | \Vect{x} | | \Vect{y} |$.</span>
         </p><p>
            <span>So the Cauchy-Schwarz inequality holds for all vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$.</span>
         </p></proof.block.body></proof.block.body>
</ul></div></div></ul></div><br /></div></li><li><span>unit     </span><ul class='chilren'><li><span>vector     </span><a id='glossaryinfo-1482' class='msm_infobutton' onmouseover='infoopen(1482)'>i</a><div id="dialog-1482" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>A vector of length $1$; click to see how to compute the unit vector in the direction of a given nonzero vector.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1482' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1484" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1484" class="hottag" onmouseover="popup(1484)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /><ul class='minibuttons'></ul></div><br /></div></li><li><span>square of $\RNr{2}$     </span></li><li><span>lattice of $\RNr{2}$     </span></li></ul></li><li><span>unitary     </span><ul class='chilren'><li><span>linear transformation     </span><a id='glossaryinfo-17041' class='msm_infobutton' onmouseover='infoopen(17041)'>i</a><div id="dialog-17041" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17041' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-17003' onmouseover='popup(17003)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-17003" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>The identity $\abs{ L(\Vect{x}) } = \abs{ \Vect{x} }$ says exactly that the length of $\Vect{x}$ equals the length of ($\Vect{x}$ transformed by $L$). If this happens for all $\Vect{x}$ in $\RNr{n}$, then $L$ preserves the length of all vectors and, hence, the distance between any pair of points in $\RNr{n}$.</span>
                     </p>
                  </info></div><li class='defminibutton' id='defminibutton-17009' onmouseover='infoopen(17009)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-17009' style='display:none;'><div class='pack'><div class='title'>Rotations are Distance Preserving</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>We say that a linear transformation $L$ preserves the distance between two points $\Vect{a}$  and $\Vect{b}$ if the distance from $\Vect{a}$ to $\Vect{b}$ is equal to the distance from $L(\Vect{a})$ to $L(\Vect{b})$. For example, a rotation of the plane about the origin preserves the distance between any two points.</span>
         </p>
			
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/RotationOrthogonal.png" height="349.125" width="350"/></div>
			
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-17009" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>A rotation is an example of a distance preserving linear transformation.</span>
                     </p>
                  </info></div></ul></div><br /></div></li></ul></li><li><span>upper triangular matrix     </span><a id='glossaryinfo-4850' class='msm_infobutton' onmouseover='infoopen(4850)'>i</a><div id="dialog-4850" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4850' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4848' onmouseover='infoopen(4848)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-4848' style='display:none;'><div class='title'>Illustration of Upper Triangular Matrices</div><p xmlns="Unit">
               <span>Every $(1,1)$-identity matrix is an upper triangular matrix.</span>
            </p><p xmlns="Unit">
               <span>An example of an upper triangular $(2,2)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					2 &amp; 1 \\
					0 &amp; 3
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>An example of an upper triangular $(3,3)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					7 &amp; 0 &amp; 3 \\
					0 &amp; 1 &amp; 3 \\
					0 &amp; 0 &amp; 2
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>An example of an upper triangular $(4,4)$ matrix is</span>
            </p>$$
					
					\begin{bmatrix}
					9 &amp; 3 &amp; 2 &amp; 6  \\
					0 &amp; 7 &amp; 4 &amp; 3  \\
					0 &amp; 0 &amp; 0 &amp; 1\\
					0 &amp; 0 &amp; 0 &amp; 4
					\end{bmatrix}
					
				$$<p xmlns="Unit">
               <span>Other examples of upper triangular matrices include</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>all diagonal matrices and,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>in  particular, all identity matrices</span>
                  </p>
               </li>
            </ul></div><div id="dialog-4848" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>A display of some upper triangular matrices.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>value     </span><ul class='chilren'><li><span>of element under a function     </span><a id='glossaryinfo-6181' class='msm_infobutton' onmouseover='infoopen(6181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6181' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>Van der Monde determinant     </span></li><li><span>vector     </span><a id='glossaryinfo-694' class='msm_infobutton' onmouseover='infoopen(694)'>i</a><div id="dialog-694" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of ‘vector’</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-694' style='display:none;'><br /><div class='def'><span class='deftitle'>Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>The vector represented by an arrow $\Arrw{AB}$ is the collection of all those arrows in $\RNr{n}$ which are equivalent to $\Arrw{AB}$. We write $\Vect{x} = (x_1,\dots ,x_n)$ if, for any of these arrows
					</span>
                           
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\text{(tip coordinates)} - \text{tail coordinates}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr></table>
                     </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-678' onmouseover='popup(678)'><span style='cursor:pointer'>Explanation</span></li><div id="dialog-678" class="dialogs" title="What do the vector coordinates mean?"><info xmlns="Unit">
                           
                           <p>
                              <span>Given a vector $\Vect{x} = (x_1,\dots ,x_n)$ and a point $P$, you can find the tip of the arrow whose tail is $P$ by</span>
                           </p>
                           <ol>
                              <li>
                                 <p>
                                    <span>going from $P$, $x_1$ units in the first coordinate direction</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>from there $x_2$ units in the second coordinate direction,</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>etc. .... until</span>
                                 </p>
                              </li>
                              <li>
                                 <p>
                                    <span>from the last found position $x_n$ units in the $n$-th coordinate direction.</span>
                                 </p>
                              </li>
                           </ol>
                        </info></div><li class='defminibutton' id='defminibutton-685' onmouseover='infoopen(685)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-685' style='display:none;'><div class='pack'><div class='title'>Vectors and Coordinates: Examples</div><br /><div class='showme'><span class='showmetitle'>Arrows representing $\Vect{x} = (3,-1)$
		    </span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>The vector $\Vect{x} = (3,-1)$ is represented by any of the arrows in the picture below.</span>
         </p>
			      <p align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorCoordinates_Exmpl1.gif" height="196.19718309859" width="350"/></div>
            </span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Explanation</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Indeed, consider any of these arrows. Starting from its tail, we find its tip by</span>
               </p>
			            <ol>
				              <li>
					                <p>
                        <span>moving $3$ units in the first coordinate direction, and</span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>from there moving $-1$ unit in the second coordinate direction.</span>
                     </p>
				              </li>
			            </ol>
			            <p>
                  <span>For example, if we choose</span>
               </p>
			            <ul>
				              <li>
					                <p>
                        <span>
						                     $R(2,2)$ as the tail point of an arrow representing $\Vect{x}$, the tip of this arrow will be at $S(2+3,2+(-1))=S(5,1)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
						                     $A(14,-6)$ as the tail point of an arrow representing $\Vect{x}$, the tip of this arrow will be at $B(17,-7)$
					                   </span>
                     </p>
				              </li>
				              <li>
					                <p>
                        <span>
						                     $U(0,0)$ as the tail point of an arrow representing $\Vect{x}$, the tip of this arrow will be at $V(3,-1)$
					                   </span>
                     </p>
				              </li>
			            </ul>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-685" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An example</span>
                           </p>
                        </info></div></ul></div><br /></div><ul class='chilren'><li><span>addition     </span><a id='glossaryinfo-810' class='msm_infobutton' onmouseover='infoopen(810)'>i</a><div id="dialog-810" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-810' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-808' onmouseover='infoopen(808)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-808' style='display:none;'><div class='pack'><div class='title'>Geometric Interpretation of Vector Addition: Illustration</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>To form the sum of two vectors $\Vect{x}$ and $\Vect{y}$ we concatenate representing arrows. The picture below illustrates this in the case where  $\Vect{x}=(3,1)$, and where  $\Vect{y}=(1,5)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-793" class="hottag" onmouseover="popup(793)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn.gif" height="98.071979434447" width="350"/></a><div id="dialog-793" class="dialogs"><info xmlns="Compositor">
						                     <p>
                              <span>Remember that we can represent a vector as a &#x2018;free floating arrow&#x2019;; i.e. an arrow which we can shift freely in space without changing its length or its direction. Therefore, when given two vectors $\Vect{x}$ and $\Vect{y}$, we can always float them so that the tail of $\Vect{y}$ lies at the tip of $\Vect{x}$. Now the arrow joining the tail of $\Vect{x}$ to the tip of $\Vect{y}$ represents the sum to the two vectors. &#x2013; Why is this so?</span>
                           </p>
						                     <p>
                              <span>If we start from the tail of $\Vect{x}$, we first move $3$ units and then  $1$ unit in the first coordinate direction to get to the tip of $\Vect{y}$. So this is just adding first coordinates. Moreover this same trip has us move $1$ unit and then $-.5$ units in the second coordinate direction. Thus adding coordinates in matching positions corresponds to concatenating arrows as shown.</span>
                           </p>
					                   </info></div></div>	
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Similarly, we obtain the sum of several vectors by forming the concatenation circuit of representing arrows, as in the picture below. If you like, you can watch an animation of this process.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-798" class="hottag" onmouseover="popup(798)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn2.gif" height="244.65174129353" width="350"/></a><div id="dialog-798" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding three vectors, represented by the arrows $\overset{\longrightarrow}{AB}$, $\overset{\longrightarrow}{BC}$, and $\overset{\longrightarrow}{CD}$. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn2.gif" height="244.65174129353" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
				
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Let’s have another example, this time we form the sum of six vectors and obtain the $0$-vector as the final answer:</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-805" class="hottag" onmouseover="popup(805)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn3.gif" height="228.66666666667" width="350"/></a><div id="dialog-805" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding six vectors, and obtain the $0$-vector as the final answer. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn3.gif" height="228.66666666667" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-808" class="dialogs" title="Illustration of vector addition"><info xmlns="Unit">
                           
                           <p>
                              <span>The addition of vectors has a useful geometric interpretation: it corresponds to the concatenation of representing arrows.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>sum     </span><a id='glossaryinfo-812' class='msm_infobutton' onmouseover='infoopen(812)'>i</a><div id="dialog-812" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-812' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-808' onmouseover='infoopen(808)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-808' style='display:none;'><div class='pack'><div class='title'>Geometric Interpretation of Vector Addition: Illustration</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>To form the sum of two vectors $\Vect{x}$ and $\Vect{y}$ we concatenate representing arrows. The picture below illustrates this in the case where  $\Vect{x}=(3,1)$, and where  $\Vect{y}=(1,5)$.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-793" class="hottag" onmouseover="popup(793)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn.gif" height="98.071979434447" width="350"/></a><div id="dialog-793" class="dialogs"><info xmlns="Compositor">
						                     <p>
                              <span>Remember that we can represent a vector as a &#x2018;free floating arrow&#x2019;; i.e. an arrow which we can shift freely in space without changing its length or its direction. Therefore, when given two vectors $\Vect{x}$ and $\Vect{y}$, we can always float them so that the tail of $\Vect{y}$ lies at the tip of $\Vect{x}$. Now the arrow joining the tail of $\Vect{x}$ to the tip of $\Vect{y}$ represents the sum to the two vectors. &#x2013; Why is this so?</span>
                           </p>
						                     <p>
                              <span>If we start from the tail of $\Vect{x}$, we first move $3$ units and then  $1$ unit in the first coordinate direction to get to the tip of $\Vect{y}$. So this is just adding first coordinates. Moreover this same trip has us move $1$ unit and then $-.5$ units in the second coordinate direction. Thus adding coordinates in matching positions corresponds to concatenating arrows as shown.</span>
                           </p>
					                   </info></div></div>	
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Similarly, we obtain the sum of several vectors by forming the concatenation circuit of representing arrows, as in the picture below. If you like, you can watch an animation of this process.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-798" class="hottag" onmouseover="popup(798)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn2.gif" height="244.65174129353" width="350"/></a><div id="dialog-798" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding three vectors, represented by the arrows $\overset{\longrightarrow}{AB}$, $\overset{\longrightarrow}{BC}$, and $\overset{\longrightarrow}{CD}$. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn2.gif" height="244.65174129353" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
				
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Let’s have another example, this time we form the sum of six vectors and obtain the $0$-vector as the final answer:</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'></span><br /><div class='mathcontent'>
<answer.showme.block.body xmlns="Compositor">
			            <p align="center">
                  <span>
				                 <div class="picture"><a id="hottag-805" class="hottag" onmouseover="popup(805)"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Illstrtn3.gif" height="228.66666666667" width="350"/></a><div id="dialog-805" class="dialogs">
<info xmlns="Compositor">
						                     <p>
                              <span>Here we are adding six vectors, and obtain the $0$-vector as the final answer. Below you can watch an animation of this process.</span>
                           </p>
						                     <p align="center">
                              <span>
							                          <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorAdd_Anmtn3.gif" height="228.66666666667" width="350"/></div>
						                        </span>
                           </p>
					                   </info>
</div></div>
			               </span>
               </p>
		          </answer.showme.block.body>
</div><br /></div><br /></div></div><div id="dialog-808" class="dialogs" title="Illustration of vector addition"><info xmlns="Unit">
                           
                           <p>
                              <span>The addition of vectors has a useful geometric interpretation: it corresponds to the concatenation of representing arrows.</span>
                           </p>
                        </info></div></ul></div><br /></div></li><li><span>length     </span><a id='glossaryinfo-1674' class='msm_infobutton' onmouseover='infoopen(1674)'>i</a><div id="dialog-1674" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1674' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-1666' onmouseover='popup(1666)'><span style='cursor:pointer'>Example</span></li><div id="dialog-1666" class="dialogs" title="Example of a Norm Computation"><info xmlns="Unit">
                     
                     <p>
                        <span>The norm of the vector $\Vect{x} = (1,2,2)$ in $\RNr{3}$ is</span>
                     </p>
                     $$\abs{\Vect{x}} = \sqrt{ 1^2 + 2^2 + 2^2 } = 3$$
                  </info></div><li class='defminibutton' id='defminibutton-1668' onmouseover='popup(1668)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1668" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the length of $\Vect{x}$ is obtained by summing up the squares of the components of $\Vect{x}$, and then taking the square root.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>norm     </span><a id='glossaryinfo-1678' class='msm_infobutton' onmouseover='infoopen(1678)'>i</a><div id="dialog-1678" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ its length. It is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1678' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-1666' onmouseover='popup(1666)'><span style='cursor:pointer'>Example</span></li><div id="dialog-1666" class="dialogs" title="Example of a Norm Computation"><info xmlns="Unit">
                     
                     <p>
                        <span>The norm of the vector $\Vect{x} = (1,2,2)$ in $\RNr{3}$ is</span>
                     </p>
                     $$\abs{\Vect{x}} = \sqrt{ 1^2 + 2^2 + 2^2 } = 3$$
                  </info></div><li class='defminibutton' id='defminibutton-1668' onmouseover='popup(1668)'><span style='cursor:pointer'>Comment</span></li><div id="dialog-1668" class="dialogs" title="Comment"><info xmlns="Unit">
                     
                     <p>
                        <span>Thus the length of $\Vect{x}$ is obtained by summing up the squares of the components of $\Vect{x}$, and then taking the square root.</span>
                     </p>
                  </info></div></ul></div><br /></div></li><li><span>translation     </span><a id='glossaryinfo-3089' class='msm_infobutton' onmouseover='infoopen(3089)'>i</a><div id="dialog-3089" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3089' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>velocity     </span></li><li><span>force     </span><a id='glossaryinfo-3177' class='msm_infobutton' onmouseover='infoopen(3177)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3177' style='display:none;'><div class='title'>Vectors Modeling Forces</div><h2> Introduction </h2><p xmlns="Unit">
               <span>When a force acts on an object, it does so in a certain direction and with a certain strength. Thus we can model a force by a vector. The direction in which the force acts corresponds to the direction of the vector, and the magnitude of the force corresponds to the length of the vector.</span>
            </p><div id="dialog-3183" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Place your pointer over an arrow to get answers.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>For example, suppose a vector of length $1$ corresponds to a force of $1000N$. Then the following arrows represent forces as 
			<a id="hottag-3183" class="hottag" onmouseover="popup(3183)"> indicated</a>  .
			</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3186" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceArrows.gif" height="169" width="319" usemap="#ForceArrows"/><map name="ForceArrows"><area id="pic-3188" coords="25,29,121,47" shape="rect" href="#" onmouseover="popup(3188)"><div id="dialog-3188" class="dialogs" title="What does the red vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $4000N$ to the right.</span>
                                 </p>
                              </info></div></area><area id="pic-3190" coords="15,131,25,149,191,77,175,59" shape="poly" href="#" onmouseover="popup(3190)"><div id="dialog-3190" class="dialogs" title="What does the green vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $\sqrt{58} \cdot 1000N$ directed to the upper right.</span>
                                 </p>
                              </info></div></area><area id="pic-3192" coords="189,31,285,105,301,87,209,15" shape="poly" href="#" onmouseover="popup(3192)"><div id="dialog-3192" class="dialogs" title="What does the blue vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $5000N$ directed to the lower right</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>From experiments we learn that several forces acting simultaneously on an object can be consolidated into a single force. Moreover, the consolidated force corresponds to the vector sum of the individual forces. – The picture below illustrates this. Here we have two forces, $F_1$ and $F_2$ acting on an object. The resulting combined force is described by the red vector $F_1 + F_2$.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3196" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceSum.gif" height="173" width="391" usemap="#ForceSum"/><map name="ForceSum"><area id="pic-3198" coords="11,97,27,109,285,41,259,23,21,89,21,91,21,97" shape="poly" href="#" onmouseover="popup(3198)"><div id="dialog-3198" class="dialogs" title="What does the green vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the force vector $F_2$ acting on the object, assumed to be at its tail.</span>
                                 </p>
                              </info></div></area><area id="pic-3200" coords="25,113,121,161,133,143,45,105" shape="poly" href="#" onmouseover="popup(3200)"><div id="dialog-3200" class="dialogs" title="What does the blue vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the force vector $F_1$ acting on the object, assumed to be at its tail.</span>
                                 </p>
                              </info></div></area><area id="pic-3202" coords="369,95,369,77,95,93,67,105" shape="poly" href="#" onmouseover="popup(3202)"><div id="dialog-3202" class="dialogs" title="What does the red vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the single force that results from the combined actions of $F_1$ and $F_2$.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
</div></li></ul></li><li><span>vectors     </span><ul class='chilren'><li><span>parallel     </span><a id='glossaryinfo-876' class='msm_infobutton' onmouseover='infoopen(876)'>i</a><div id="dialog-876" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-876' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-872' onmouseover='infoopen(872)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-872' style='display:none;'><div class='title'>Scalar Multiplication of Vectors - Illustration</div><p xmlns="Unit">
               <span>When we multiply a vector $\mathbf{x}$ by a number (a scalar) $t$, we keep the direction of $\mathbf{x}$ and multiply its length by $t$. If $t$ is positive, this has the effect illustrated below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_2.gif" height="204.43425076453" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we multiply a vector $\mathbf{x}$ by a negative number $t$, we reverse the direction of $\mathbf{x}$, as is illustrated in the picture below.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_3.gif" height="197.98927613941" width="350"/></div>
               </span>
            </p>
<div id="dialog-866" class="dialogs" title="Animation of Scalar Multiplication of a Vector by a Number">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_Anmt.gif" height="130.21505376344" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>Here are a number of scalar multiplications performed on one and the same vector. Click <a id="hottag-866" class="hottag" onmouseover="popup(866)"> here</a>   to animate this example.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/VectorScalarMultiply_1.gif" height="119.45652173913" width="350"/></div>
               </span>
            </p>
</div><div id="dialog-872" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Click for an illustration of parallel vectors.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li><li><span>velocity     </span><ul class='chilren'><li><span>vector     </span></li></ul></li><li><span>velocity vector     </span><a id='glossaryinfo-1133' class='msm_infobutton' onmouseover='infoopen(1133)'>i</a><div id="dialog-1133" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to see the definition of the velocity vector of a linear motion.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1133' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-1131" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘ell of $t$ equals a plus t times v’</span>
                              </p>
                           </info></div><div id="dialog-1135" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘t in R’, which means: $t$ is a number in $\RNr{}$.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <a id="hottag-1131" class="hottag" onmouseover="popup(1131)"> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </a>  , with <a id="hottag-1135" class="hottag" onmouseover="popup(1135)"> 
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /><ul class='defminibuttons'></ul></div><br /></div></li><li><span>volume     </span><ul class='chilren'><li><span>of slanted box     </span><a id='glossaryinfo-10274' class='msm_infobutton' onmouseover='infoopen(10274)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10274' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-10300' onmouseover='infoopen(10300)'><span style='cursor:pointer'>Illustration</span></li><div class='refcontent' id='refcontent-10300' style='display:none;'><div class='title'>Oriented Volume - Illustration</div><p xmlns="Unit">
               <span>To see the difference between ‘volume’ and ‘oriented volume’, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/OrientedVolume.png' height='189.875' width='350'/></div><p xmlns="Unit">
               <span>Here we have</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vol(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vol(\Vect{u},\Vect{v})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr></table><p xmlns="Unit">
               <span>However, taking into account orientations, note that $\omega(\Vect{x},\Vect{y})=+1$, while $\omega(\Vect{u},\Vect{v})=-1$. Therefore</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\OriVol(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$6$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\OriVol(\Vect{u},\Vect{v})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-6$</td></tr></table></div><div id="dialog-10300" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>An illustration of the ‘oriented volume’.</span>
                           </p>
                        </info></div></ul></div><br /></div></li></ul></li></ul></div></div>