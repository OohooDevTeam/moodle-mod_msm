<h3> G L O S S A R Y </h3><ul id="glossaryindex" class="treeview-red"><li><span>$\RNr{}$      </span><a id='glossaryinfo-193' class='msm_infobutton' onmouseover='infoopen(193)'>i</a><div id="dialog-193" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>
                                       $\RNr{}$ denotes the set of all real numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-193' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>We will use the symbol $\RNr{}$ to denote the set of all real numbers.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>$n$-tuple      </span><a id='glossaryinfo-206' class='msm_infobutton' onmouseover='infoopen(206)'>i</a><div id="dialog-206" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An expression of the form $(x_1,\dots ,x_n)$, where $x_1,\dots ,x_n$ are numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-206' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<span> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </span>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>0-matrix      </span><a id='glossaryinfo-4808' class='msm_infobutton' onmouseover='infoopen(4808)'>i</a><div id="dialog-4808" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4808' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>0-transformation      </span><a id='glossaryinfo-15799' class='msm_infobutton' onmouseover='infoopen(15799)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15799' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The $0$-transformation of $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\mathbf{0}\from \RNr{n} \longrightarrow \RNr{m},\quad \mathbf{0}(\Vect{x}) := \Vect{0}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>addition      </span><ul class='chilren'><li><span>matrices      </span><ul class='chilren'><li><span>associativity property      </span><a id='glossaryinfo-5157' class='msm_infobutton' onmouseover='infoopen(5157)'>i</a><div id="dialog-5157" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5157' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutativity      </span><a id='glossaryinfo-5172' class='msm_infobutton' onmouseover='infoopen(5172)'>i</a><div id="dialog-5172" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5172' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>of matrices      </span><a id='glossaryinfo-4883' class='msm_infobutton' onmouseover='infoopen(4883)'>i</a><div id="dialog-4883" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4883' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of vectors      </span><a id='glossaryinfo-792' class='msm_infobutton' onmouseover='infoopen(792)'>i</a><div id="dialog-792" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-792' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>algebraic multiplicity      </span><a id='glossaryinfo-20046' class='msm_infobutton' onmouseover='infoopen(20046)'>i</a><div id="dialog-20046" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20046' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>alternating      </span><ul class='chilren'><li><span>multilinear function      </span><a id='glossaryinfo-9844' class='msm_infobutton' onmouseover='infoopen(9844)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9844' style='display:none;'><div class='title'>Alternating Multilinear Functions</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>This section is more theoretical. It develops the determinant operation as a special case of functions 
			<span> 
                        $F\from M_{nn} \to \RNr{}$
                     </span>  
			which are 
			<a id="20">linear in each column</a>  
			 and have the 
			 <a id="21">alternating property</a>  .</span>
            </p>
<p xmlns="Unit">
               <span>We know that the determinant function $\det\from M_{nn}\to \RNr{}$ has both of these properties. We will see that these two properties ‘multilinear’ and ‘alternating’ alone characterize the determinant operation in the following sense: if $F\from M_{nn}\to \RNr{}$ is alternating and multilinear then there exists a unique number $c$ in $\RNr{}$ such that $F=c\cdot \det$.
		</span>
               
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of alternating multilinear functions</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $F\from M_{nn}\to \RNr{}$ be any function which is linear in each column and alternating. Then $F$ has the following properties:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}=[A_1\ \dots\ X\ \dots\ X\ \dots\ A_n]$, then $F(\Mtrx{A}) =0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $F[A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n] = F[A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$
               </span>
            </p>
         </part.body></li><br /><li>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}= [a_{ij}]$, 
				<span> then</span>  
               </span>
            </p>
            $$F(\Mtrx{A}) = \sum_{r\in \SymGrp{n}} a_{r(1)1}\cdots a_{r(n)n} F[E_{r(1)}\ \dots\ E_{r(n)}]$$
         </part.body>
</li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>There exists a unique number $c$ in $\RNr{}$ such that, for each invertible  $r\from \Set{1,\dots ,n} \to \Set{1,\dots ,n}$,</span>
            </p>
            $$F[E(r(1))\dots E(r(n))] = c\cdot \det [E(r(1))\dots E(r(n))] = c\cdot \sign(r)$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>For each $(n,n)$-matrix $\Mtrx{A}$, $F(\Mtrx{A}) = F(\Mtrx{A}^T)$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Uniqueness of the determinant operation</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $F\from M_{nn}\to \RNr{}$ is alternating and linear in each column, then</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$F$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$F(\IdMtrx{n})\cdot \det$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>property of the determinant operation      </span><a id='glossaryinfo-10323' class='msm_infobutton' onmouseover='infoopen(10323)'>i</a><div id="dialog-10323" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10323' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>angle between two vectors      </span><a id='glossaryinfo-1597' class='msm_infobutton' onmouseover='infoopen(1597)'>i</a><div id="dialog-1597" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The angle between two vectors $\Vect{x}$ and $\Vect{y}$ is denoted $\sphericalangle(\Vect{x},\Vect{y})$. Its cosine can be determined using the norm and dot product operations by</span>
                     </p>
                     $$\cos\sphericalangle(\Vect{x},\Vect{y}) = \frac{\DotPr{ \Vect{x} }{ \Vect{y} }}{| \Vect{x} | | \Vect{y} |}$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1597' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>antisymmetric      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4939' class='msm_infobutton' onmouseover='infoopen(4939)'>i</a><div id="dialog-4939" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4939' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>arrow      </span><a id='glossaryinfo-629' class='msm_infobutton' onmouseover='infoopen(629)'>i</a><div id="dialog-629" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>in $\RNr{n}$, joining point $P$ to point $Q$.</span>
                                 </p>
                                 <p align="center">
                                    <span>Click to see the definition of arrow.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-629' style='display:none;'><br /><div class='def'><span class='deftitle'>Arrow</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An arrow 
					in $\RNr{n}$ is given by listing two points $P$ and $Q$ of $\RNr{n}$ in order. The first point $P$ is called the tail of the arrow. The second point $Q$ is called the tip of the arrow. We write $\Arrw{PQ}$
					to denote the arrow joining $P$ to $Q$.</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>length      </span><a id='glossaryinfo-648' class='msm_infobutton' onmouseover='infoopen(648)'>i</a><div id="dialog-648" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-648' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>associativity      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5199' class='msm_infobutton' onmouseover='infoopen(5199)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5199' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of matrix addition      </span><a id='glossaryinfo-5150' class='msm_infobutton' onmouseover='infoopen(5150)'>i</a><div id="dialog-5150" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5150' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>scalar multiplication of matrices      </span><a id='glossaryinfo-5188' class='msm_infobutton' onmouseover='infoopen(5188)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5188' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>augmented      </span><ul class='chilren'><li><span>coefficient vector      </span><a id='glossaryinfo-3492' class='msm_infobutton' onmouseover='infoopen(3492)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3492' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>basic coordinate vector      </span><a id='glossaryinfo-698' class='msm_infobutton' onmouseover='infoopen(698)'>i</a><div id="dialog-698" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-698' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>basis      </span><a id='glossaryinfo-12614' class='msm_infobutton' onmouseover='infoopen(12614)'>i</a><div id="dialog-12614" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12614' style='display:none;'><br /><div class='def'><span class='deftitle'>Basis</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A 
				<span> basis</span>  
				
				of a subvector space $V$ of $\RNr{n}$ is a collection of vectors $\EuScript{B}$ satisfying:
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ spans $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ is linearly independent.</span>
                        </p>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>ordered      </span><a id='glossaryinfo-14803' class='msm_infobutton' onmouseover='infoopen(14803)'>i</a><div id="dialog-14803" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14803' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div><a id='glossaryinfo-13328' class='msm_infobutton' onmouseover='infoopen(13328)'>i</a><div id="dialog-13328" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... when used to define a coordinate vector.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13328' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>bilinearity      </span><ul class='chilren'><li><span>of dot product      </span><a id='glossaryinfo-1863' class='msm_infobutton' onmouseover='infoopen(1863)'>i</a><div id="dialog-1863" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>The bilinearity property of the dot product asserts that</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1863' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>cartesian product      </span><a id='glossaryinfo-490' class='msm_infobutton' onmouseover='infoopen(490)'>i</a><div id="dialog-490" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>of $\RNr{m}$ and $\RNr{n}$ is $\RNr{m+n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-490' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of   $\RNr{m}$ and $\RNr{n}$
               </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The cartesian product of $\RNr{m}$ and $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\RNr{m}\times \RNr{n}\ :=\ \RNr{m+n},$$
                  <p>
                     <span>i.e. the space of  all $(m+n)$-tuples.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>Cauchy-Schwarz inequality      </span><a id='glossaryinfo-1979' class='msm_infobutton' onmouseover='infoopen(1979)'>i</a><div id="dialog-1979" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The Cauchy-Schwarz inequality asserts that</span>
                     </p>
                     $$| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1979' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>change of coordinates matrix      </span><a id='glossaryinfo-14395' class='msm_infobutton' onmouseover='infoopen(14395)'>i</a><div id="dialog-14395" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14395' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$
<p xmlns="Unit">
               <span>What is the <span> relationship between the coordinate vectors</span>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>of a composition of linear maps      </span><a id='glossaryinfo-14402' class='msm_infobutton' onmouseover='infoopen(14402)'>i</a><div id="dialog-14402" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14402' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>reversal of coordinate change      </span><a id='glossaryinfo-14418' class='msm_infobutton' onmouseover='infoopen(14418)'>i</a><div id="dialog-14418" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{B}\EuScript{C}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14418' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>characteristic      </span><ul class='chilren'><li><span>polynomial of a matrix      </span><a id='glossaryinfo-20017' class='msm_infobutton' onmouseover='infoopen(20017)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-20017' style='display:none;'><br /><div class='def'><span class='deftitle'>Characteristic polynomial</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The determinant of the $(n,n)$-matrix $(\Mtrx{A}-\lambda \IdMtrx{n})$ is a polynomial of degree $n$ in the variable $\lambda$, called the characteristic polynomial of $\Mtrx{A}$.
				
				It is of the form
			</span>
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_n \lambda^n + \cdots a_1\lambda + a_0$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>coefficient      </span><ul class='chilren'><li><span>of a linear equation      </span><a id='glossaryinfo-3273' class='msm_infobutton' onmouseover='infoopen(3273)'>i</a><div id="dialog-3273" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Look up the definition</span>
                        </p>
                     </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3273' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <span> system of linear equations</span>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<span> hyperplane in $\RNr{n}$
                        </span>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="23">intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li><li><span>vector      </span><ul class='chilren'><li><span>augmented      </span><a id='glossaryinfo-3491' class='msm_infobutton' onmouseover='infoopen(3491)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3491' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>in a linear equation      </span><a id='glossaryinfo-3489' class='msm_infobutton' onmouseover='infoopen(3489)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3489' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>cofactor      </span><a id='glossaryinfo-8912' class='msm_infobutton' onmouseover='infoopen(8912)'>i</a><div id="dialog-8912" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-cofactor of a matrix $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8912' style='display:none;'><br /><div class='def'><span class='deftitle'>Cofactor of a matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-cofactor of $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                        </p>
                        $$c_{ij}(\Mtrx{A}) := (-1)^{i+j}\cdot \det(A_{ij})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>colinear      </span><a id='glossaryinfo-2187' class='msm_infobutton' onmouseover='infoopen(2187)'>i</a><div id="dialog-2187" class="dialogs" title="What does ‘colinear’ mean?"><info xmlns="Unit">
                     
                     <p>
                        <span>‘Colinear’ means ‘has the same direction as’.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2187' style='display:none;'><div class='title'>The Projection of a Vector on a Line</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we introduce a construction which appears in many contexts: how to project a vector $\Vect{x}$ onto the line through the origin in the direction of another vector $\Vect{y}$
               </span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/ProjectionVectorLine.png' height='150.390625' width='350'/></div>
<p xmlns="Unit">
               <span>The picture above shows how the vector $\Vect{x}$ gets projected orthogonally onto the line $L$. The result is the vector $\pr_L(\Vect{x})$ which is
   		<span> colinear</span>   with $\Vect{y}$. The following proposition tells us how to compute this projection vector.
			</span>
               
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>column      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4790' class='msm_infobutton' onmouseover='infoopen(4790)'>i</a><div id="dialog-4790" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4790' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>commutativity      </span><ul class='chilren'><li><span>of matrix addition      </span><a id='glossaryinfo-5165' class='msm_infobutton' onmouseover='infoopen(5165)'>i</a><div id="dialog-5165" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5165' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>component      </span><ul class='chilren'><li><span>of a vector orthogonal to another      </span><a id='glossaryinfo-2240' class='msm_infobutton' onmouseover='infoopen(2240)'>i</a><div id="dialog-2240" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The component of a vector $\Vect{x}$ orthogonal to another vector $\Vect{y}$ is</span>
                           </p>
                           $$\Vect{u} = \Vect{x} - \pr_{\Vect{y}}(\Vect{x})$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2240' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>composite      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-7657' class='msm_infobutton' onmouseover='infoopen(7657)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7657' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Composite of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $S\from \RNr{p} \to \RNr{n}$ and $T\from \RNr{n} \to \RNr{m}$ are linear transformations, then their composite 
			</span>
         
      </p>$$(T\Comp S)\from \RNr{p} \longrightarrow \RNr{m},\quad (T\Comp S)(\Vect{x}) = T(S(\Vect{x}))$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(n,p)$-matrix representing $S$, and if $\Mtrx{B}$ is the $(m,n)$-matrix representing $T$, then $\Mtrx{B}\Mtrx{A}$ is the $(m,p)$-matrix which represents $T\Comp S$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>represented by matrix product      </span><a id='glossaryinfo-7657' class='msm_infobutton' onmouseover='infoopen(7657)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7657' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Composite of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $S\from \RNr{p} \to \RNr{n}$ and $T\from \RNr{n} \to \RNr{m}$ are linear transformations, then their composite 
			</span>
         
      </p>$$(T\Comp S)\from \RNr{p} \longrightarrow \RNr{m},\quad (T\Comp S)(\Vect{x}) = T(S(\Vect{x}))$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(n,p)$-matrix representing $S$, and if $\Mtrx{B}$ is the $(m,n)$-matrix representing $T$, then $\Mtrx{B}\Mtrx{A}$ is the $(m,p)$-matrix which represents $T\Comp S$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>composition      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-16572' class='msm_infobutton' onmouseover='infoopen(16572)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16572' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>contraction      </span><a id='glossaryinfo-15828' class='msm_infobutton' onmouseover='infoopen(15828)'>i</a><div id="dialog-15828" class="dialogs" title="What is a contraction?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A contraction is a linear transformation $C$ of $\RNr{n}$ of the form $C(\Vect{x})= s\cdot \Vect{x}$, with $ 0 &lt; s &lt; 1 $ a fixed number.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15828' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-17582' class='msm_infobutton' onmouseover='infoopen(17582)'>i</a><div id="dialog-17582" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17582' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><a id='glossaryinfo-17581' class='msm_infobutton' onmouseover='infoopen(17581)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17581' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li></ul></li><li><span>coordinate      </span><ul class='chilren'><li><span>conversion matrix      </span><a id='glossaryinfo-14391' class='msm_infobutton' onmouseover='infoopen(14391)'>i</a><div id="dialog-14391" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14391' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$
<p xmlns="Unit">
               <span>What is the <span> relationship between the coordinate vectors</span>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>vector      </span><a id='glossaryinfo-13322' class='msm_infobutton' onmouseover='infoopen(13322)'>i</a><div id="dialog-13322" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of the term.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13322' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>coordinate of an $n$-tuple      </span><a id='glossaryinfo-208' class='msm_infobutton' onmouseover='infoopen(208)'>i</a><div id="dialog-208" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Example for $n=3$: $(5,1,2)$ is a $3$-tuple; i.e. it has 3 positions, each of which is occupied by a number. These numbers are the coordinates of the $3$-tuple. Thus the first coordinate is $5$. The second coordinate is $1$. The third coordinate is $2$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-208' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<span> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </span>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>coordinate vector      </span><ul class='chilren'><li><span>basic      </span><a id='glossaryinfo-702' class='msm_infobutton' onmouseover='infoopen(702)'>i</a><div id="dialog-702" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-702' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>Cramer’s rule      </span><a id='glossaryinfo-10976' class='msm_infobutton' onmouseover='infoopen(10976)'>i</a><div id="dialog-10976" class="dialogs" title="Cramer’ rule"><info xmlns="Theorem">
               
               <p>
                  <span>is a formula for finding the solution of  a system of $n$ linear equations in $n$ variables.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10976' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Cramer’ rule</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given the system of $n$ linear equations in $n$ variables below,</span>
      </p>$$
				
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{n1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{n2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$}{\color{red}x_n} &amp; = &amp; c_n \\
\end{array}

			$$<p xmlns="Theorem">
         <span>assume that its coefficient matrix $\Mtrx{A} = [a_{ij}]$ satisfies $\det(\Mtrx{A})\neq 0$. Then, for $1\leq j\leq n$,
			</span>
         
      </p>$$
				
{\color{red} x_j}\ =\ \frac{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$c_1$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$c_n$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; a_{1j} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \vdots &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; a_{nj} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}

			$$<p xmlns="Theorem">
         <span>The matrix in the denominator matrix is $\Mtrx{A}$, and the matrix in the numerator is formed from $\Mtrx{A}$ by replacing its $j$-th column by the augmentation column of the system, $[c_1\ \dots\ c_n]^T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>cross product      </span><a id='glossaryinfo-10539' class='msm_infobutton' onmouseover='infoopen(10539)'>i</a><div id="dialog-10539" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of the operation</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10539' style='display:none;'><br /><div class='def'><span class='deftitle'>Cross product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The cross product of two vectors in $\RNr{3}$
                           </span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x}=(x_1,x_2,x_3)$   and   $\Vect{y}=(y_1,y_2,y_3)$
                           </span>
                        </p>
                        <p>
                           <span>is the following vector of $\RNr{3}$:
					</span>
                           
                           
                        </p>
                        $$
						
\aligned
\CrssPr{ \Vect{x} }{ \Vect{y} }\ &amp;:=\ \left(
\det
\left[
\begin{array}{cc}
x_2 &amp; y_2 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
- \det \left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_2 &amp; y_2
\end{array}
\right]
\right) \\
	&amp;=\ \left( x_2y_3 - x_3y_2 , -(x_1y_3 - x_3y_1) , x_1y_2 - x_2y_1 \right)
\endaligned

					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>determinant      </span><ul class='chilren'><li><span>alternating      </span><a id='glossaryinfo-10645' class='msm_infobutton' onmouseover='infoopen(10645)'>i</a><div id="dialog-10645" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10645' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with matrix multiplication      </span><a id='glossaryinfo-9652' class='msm_infobutton' onmouseover='infoopen(9652)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9652' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>commutes with transposition      </span><a id='glossaryinfo-9446' class='msm_infobutton' onmouseover='infoopen(9446)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9446' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>definition using cofactors      </span><a id='glossaryinfo-8920' class='msm_infobutton' onmouseover='infoopen(8920)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-8920' style='display:none;'><br /><div class='def'><span class='deftitle'>Determinant</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Let $n\geq 1$ be an integer for which determinants of matrices of size $(n,n)$ and smaller have been defined. Then the determinant of a matrix
					</span>
                           
                        </p>
                        $$
						
\Mtrx{A} =
\left[
\begin{array}{cccc}
{\color{red} a_{1,1}} &amp; a_{1,2} &amp; \cdots &amp; a_{1,n+1} \\
{\color{red} a_{2,1}} &amp; a_{2,2} &amp; \cdots &amp; a_{2,n+1} \\
{\color{red} \vdots} &amp; \vdots &amp; \ddots &amp; \vdots \\
{\color{red} a_{n+1,1}} &amp; a_{n+1,2} &amp; \cdots &amp; a_{n+1,n+1}
\end{array}
\right]

					$$
                        <p>
                           <span>of size $(n+1,n+1)$ is given by</span>
                        </p>
                        $$\det(A) := {\color{red} a_{1,1}}\cdot c_{1,1}(\Mtrx{A}) + {\color{red} a_{2,1}}\cdot c_{2,1}(\Mtrx{A}) + \cdots + {\color{red} a_{n+1,1}}\cdot c_{n+1,1}(\Mtrx{A}),$$
                        <p>
                           <span>where $c_{i,1}(\Mtrx{A})$ is the $(i,1)$-cofactor of $\Mtrx{A}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>multilinear      </span><a id='glossaryinfo-9077' class='msm_infobutton' onmouseover='infoopen(9077)'>i</a><div id="dialog-9077" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9077' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>norm property      </span><a id='glossaryinfo-9252' class='msm_infobutton' onmouseover='infoopen(9252)'>i</a><div id="dialog-9252" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9252' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of Van der Monde      </span><a id='glossaryinfo-9599' class='msm_infobutton' onmouseover='infoopen(9599)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9599' style='display:none;'><div class='title'>Further properties of the determinant operation</div>
<p xmlns="Unit">
                     <span>The algebraic properties of the determinant operation have a number of 
				<span> consequences</span>  
				which can simplify the task of computing determinants a lot.</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Computing determinants by row reduction</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the $(n,n)$-matrix  $\Mtrx{A}$ can be row reduced to an upper triangular matrix $\Mtrx{U}$ with diagonal entries $d_1,\dots ,d_n$. If this row reduction used</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>
                  $r$ interchanges of rows; and</span>
            </p>
         </li>
         <li>
            <p>
               <span>the multiplication of rows by (nonzero) numbers $c_1,\dots ,c_k$, then</span>
            </p>
         </li>
      </ul>$$\det(\Mtrx{A}) = (-1)^r\cdot \dfrac{d_1\cdots d_n}{c_1\cdots c_k}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of an inverse matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If the matrix $\Mtrx{A}$ is invertible then</span>
      </p>$$\det(\Mtrx{A}^{-1}) = \dfrac{1}{\det(\Mtrx{A})}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>diagonal      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4815' class='msm_infobutton' onmouseover='infoopen(4815)'>i</a><div id="dialog-4815" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4815' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>diagonalizable matrix      </span><a id='glossaryinfo-20263' class='msm_infobutton' onmouseover='infoopen(20263)'>i</a><div id="dialog-20263" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20263' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>dilation      </span><a id='glossaryinfo-15826' class='msm_infobutton' onmouseover='infoopen(15826)'>i</a><div id="dialog-15826" class="dialogs" title="What is a dilation?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A dilation is a linear transformation $D$ of $\RNr{n}$ of the form $D(\Vect{x})= s\cdot \Vect{x}$, with $ s&gt;0 $ a fixed number.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15826' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-6132' class='msm_infobutton' onmouseover='infoopen(6132)'>i</a><div id="dialog-6132" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6132' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li></ul></li><li><span>dimension      </span><a id='glossaryinfo-12712' class='msm_infobutton' onmouseover='infoopen(12712)'>i</a><div id="dialog-12712" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the dimension of a vector space $V$ as the number of basis vectors in $V$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12712' style='display:none;'><br /><div class='def'><span class='deftitle'>Dimension</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dimension of a subvector space $V$ of $\RNr{n}$ is</span>
                  </p>
                  $$\dim(V):= k\quad \text{if $V$ has a basis of $k$ vectors}$$
                  <p>
                     <span>If $V=\Set{ \Vect{0} }$, we set $\dim(V):=0$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>formula for linear transformations      </span><a id='glossaryinfo-18711' class='msm_infobutton' onmouseover='infoopen(18711)'>i</a><div id="dialog-18711" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{ V }$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-18711' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Dimension formula for linear transformations</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>A linear transformation $L\from V\to W$ satisfies
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{ V }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>direction angle      </span><a id='glossaryinfo-2802' class='msm_infobutton' onmouseover='infoopen(2802)'>i</a><div id="dialog-2802" class="dialogs" title="Direction Angle"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>the angle between a given vector $\mathbf{x}$ in $\RNr{n}$ and one of the coordinate axes.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2802' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>Given a vector $\mathbf{x}$ in $\RNr{n}$, and a number $i$, $1 \leq i \leq n$, the $i$-th direction angle of $\mathbf{x}$ is
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              <span> 
                                    $\omega_i\ :=\ \sphericalangle(\mathbf{e}_i,\mathbf{x})$
                                 </span>  
                           </span>
                        </p>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>distance      </span><ul class='chilren'><li><span>preserving linear transformation      </span><a id='glossaryinfo-8080' class='msm_infobutton' onmouseover='infoopen(8080)'>i</a><div id="dialog-8080" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8080' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>distributivity      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5202' class='msm_infobutton' onmouseover='infoopen(5202)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5202' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>scalar multiplication of matrices      </span><a id='glossaryinfo-5184' class='msm_infobutton' onmouseover='infoopen(5184)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5184' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>domain      </span><ul class='chilren'><li><span>of a function      </span><a id='glossaryinfo-15124' class='msm_infobutton' onmouseover='infoopen(15124)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15124' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>dot product      </span><a id='glossaryinfo-1496' class='msm_infobutton' onmouseover='infoopen(1496)'>i</a><div id="dialog-1496" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The dot product of $\Vect{x} = (x_1,\dots ,x_n)$ and $\Vect{y} = (y_1,\dots ,y_n)$ is </span>
                           </p>
                           $$\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1496' style='display:none;'><br /><div class='def'><span class='deftitle'>Dot Product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dot product of two vectors in $\RNr{n}$,</span>
                     
                     
                  </p>
                  <p align="center">
                     <span>
                        $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{y} = (y_1,\dots ,y_n)$
                     </span>
                  </p>
                  <p>
                     <span>is the number   $\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$
                     </span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>algebraic properties      </span><a id='glossaryinfo-1877' class='msm_infobutton' onmouseover='infoopen(1877)'>i</a><div id="dialog-1877" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating the algebraic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1877' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>binomial identities      </span><a id='glossaryinfo-1934' class='msm_infobutton' onmouseover='infoopen(1934)'>i</a><div id="dialog-1934" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1934' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Binomial Identities of the Dot Product Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$ the following binomial identities hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            $$
					
					\aligned
					\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} + \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } + 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} } \\
					\DotPr{ (\Vect{x} - \Vect{y}) }{ (\Vect{x} - \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } - 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} }
					\endaligned

				$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            $$\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} - \Vect{y}) } = \DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{y} }{ \Vect{y} }$$
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is bilinear      </span><a id='glossaryinfo-1867' class='msm_infobutton' onmouseover='infoopen(1867)'>i</a><div id="dialog-1867" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>That the dot product is bilinear means</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{(\Vect{a} + \Vect{b})}{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{y} }\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{ \Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{ \Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1867' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is symmetry      </span><a id='glossaryinfo-1875' class='msm_infobutton' onmouseover='infoopen(1875)'>i</a><div id="dialog-1875" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is symmetry means that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1875' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>non-degenerate      </span><a id='glossaryinfo-1887' class='msm_infobutton' onmouseover='infoopen(1887)'>i</a><div id="dialog-1887" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is non-degenerate means that</span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1887' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>orthogonality criterion      </span><a id='glossaryinfo-1592' class='msm_infobutton' onmouseover='infoopen(1592)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-1592' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>positive definite      </span><a id='glossaryinfo-1882' class='msm_infobutton' onmouseover='infoopen(1882)'>i</a><div id="dialog-1882" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is positive definite means that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1882' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>relationship to norm      </span><a id='glossaryinfo-1961' class='msm_infobutton' onmouseover='infoopen(1961)'>i</a><div id="dialog-1961" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1961' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>eigenvalue      </span><a id='glossaryinfo-19980' class='msm_infobutton' onmouseover='infoopen(19980)'>i</a><div id="dialog-19980" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19980' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>eigenvector      </span><a id='glossaryinfo-19978' class='msm_infobutton' onmouseover='infoopen(19978)'>i</a><div id="dialog-19978" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19978' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>elementary      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-5542' class='msm_infobutton' onmouseover='infoopen(5542)'>i</a><div id="dialog-5542" class="dialogs" title="elementary matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form</span>
                                 </p>
                                 $$
									
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5542' style='display:none;'><br /><div class='def'><span class='deftitle'>Elementary Matrix</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form
					</span>
                           
                           
                        </p>
                        $$
						
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is a matrix of size $(n,p)$, then forming the matrix product $E_{ij}(t)\cdot \Mtrx{B}$ has the effect of adding $t$ times the $j$-th row of $\Mtrx{B}$ to the $i$-th row of $\Mtrx{B}$. Moreover, for each $t$ in $\RNr{}$, $E_{ij}(t)$ is invertible and   $E_{ij}(t)^{-1} = E_{ij}(-t)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>epimorphic linear transformation      </span><a id='glossaryinfo-18837' class='msm_infobutton' onmouseover='infoopen(18837)'>i</a><div id="dialog-18837" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18837' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>epimorphism      </span><a id='glossaryinfo-18841' class='msm_infobutton' onmouseover='infoopen(18841)'>i</a><div id="dialog-18841" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18841' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>equal $n$tuples      </span><a id='glossaryinfo-263' class='msm_infobutton' onmouseover='infoopen(263)'>i</a><div id="dialog-263" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-263' style='display:none;'><br /><div class='def'><span class='deftitle'>Equal $n$-tuples</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-15147' class='msm_infobutton' onmouseover='infoopen(15147)'>i</a><div id="dialog-15147" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Description of the relationship between functions and equations</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15147' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div><ul class='chilren'><li><span>of hyperspace      </span><a id='glossaryinfo-2362' class='msm_infobutton' onmouseover='infoopen(2362)'>i</a><div id="dialog-2362" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The equation whose solutions form the hyperspace in $\RNr{n}$ perpendicular to the normal vector $\Vect{n} = (a_1,\dots ,a_n)$ is</span>
                                 </p>
                                 $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_1 + \cdots + a_nx_n$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2362' style='display:none;'><div class='title'>Hyperspaces</div><p xmlns="Unit">
                     <span>Let us begin by saying in mathematical terms what a hyperspace is.</span>
                  </p><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /><br /><div class='comment'><span class='commenttitle'>Coordinate version of the Hyperspace Equation</span><br/><div class='mathcontent'><comment.body xmlns="Unit">
                        <p>
                           <span>Let us express the dot product equation $\DotPr{\Vect{x}}{\Vect{n}} = 0$ in terms of the coordinates of $\Vect{x}$ and $\Vect{n}$: if</span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{n} = (a_1,\dots ,a_n)$,
				</span>
                        </p>
                        <p>
                           <span>then</span>
                        </p>
                        $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_n + \cdots + a_n x_n$$
                        <p>
                           <span>This means that $\text{Perp}(\Vect{n})$ consists of the solutions of the linear equation</span>
                        </p>
                        $$a_1x_n + \cdots + a_n x_n = 0$$
                        <p>
                           <span>in the variables $x_1,\dots ,x_n$ with coefficients $a_1,\dots ,a_n$. Conversely, given an equation</span>
                        </p>
                        <p align="center">
                           <span>
                              $a_1x_1+ \cdots + a_nx_n = 0$,   with   $\Vect{n} = (a_1,\dots ,a_n) \neq \Vect{0}$, </span>
                        </p>
                        <p>
                           <span>we know that its solutions form the hyperspace $\text{Perp}(\Vect{n})$.
					</span>
                           
                        </p>
                     </comment.body><br /></div><br /></div><br /></div></li></ul></li><li><span>equivalent      </span><ul class='chilren'><li><span>equations      </span><a id='glossaryinfo-2452' class='msm_infobutton' onmouseover='infoopen(2452)'>i</a><div id="dialog-2452" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept of equivalent equations.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2452' style='display:none;'><div class='title'>Hyperplanes</div>
<p xmlns="Unit">
                     <span>Recall: a hyperplane results from shifting a hyperspace off of the origin. Visual <span> inspection</span>   suggests: The location of a hyperplane $H$ is completely determined by a nonzero vector $\Vect{n}$ which is perpendicular to $H$, and a point $P$ on $H$. Accordingly, we have</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Equation of a Hyperplane</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$ and a point $P$ with position vector $\Vect{p}$, the hyperplane perpendicular to $\Vect{n}$ through $P$ is the set of  all those $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ with</span>
      </p>$$\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br />
<p xmlns="Unit">
                     <span>The vector $\Vect{n}$ is called <span> a normal vector</span>   of the specified hyperplane. An equation for one and the same hyperplane can present itself in various guises:</span>
                  </p>
<br /><div class='comment'><span class='commenttitle'>Alternate appearances of hyperplane equation</span><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>The dot product equation $\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$
                              <span> just differs in appearance</span>   from either one of the two equations below</span>
                        </p>
                        <p align="center">
                           <span>
                              $\DotPr{\Vect{x}}{\Vect{n}} = c$ &#xA0; and &#xA0; $a_1x_1 + \cdots + a_n x_n = c$,</span>
                        </p>
                        <p>
                           <span>where $c:=a_1p_1+\cdots + a_np_n$, $\Vect{x} = (x_1,\dots ,x_n)$, $\Vect{n} = (a_1,\dots ,a_n)$, and $\Vect{p}=(p_1,\dots ,p_n)$. Therefore the solutions of each of these equations forms the same hyperplane as the solutions of any of the other equations.</span>
                        </p>
                        <p>
                           <span>Conversely, if we are given such an equation we can read off a normal vector $\Vect{n} := (a_1,\dots ,a_n)$ to the hyperplane in question. If $a_k\neq 0$, we conclude that the point $P$ with position vector $\Vect{p} := (0,\dots ,0,c/a_k,0,\dots , 0)$ belongs to the hyperplane.</span>
                        </p>
                     </comment.body>
<br /></div><br /></div><br /><br /><div class='comment'><span class='commenttitle'>Equivalent hyperplane equations</span><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>Let $u$ be any nonzero number, and consider the two equations below:</span>
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_1 x_1 + \cdots + a_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$c$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$ua_1x_1 + \cdots ua_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$uc$</td></tr></table>
                        <p>
                           <span>These two equations are not the same. Still, a vector $\Vect{x} = (x_1, \dots ,x_n)$ satisfies one of them exactly when it satisfies the other. Therefore both equations describe the same hyperplane in $\RNr{n}$. In this situation we call the equations equivalent.
					</span>
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>systems of equations      </span><a id='glossaryinfo-3864' class='msm_infobutton' onmouseover='infoopen(3864)'>i</a><div id="dialog-3864" class="dialogs" title="When are two systems of linear equations equivalent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Two systems of linear equations are equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3864' style='display:none;'><br /><div class='def'><span class='deftitle'>Equivalent systems of linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two systems of equations are called equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>function      </span><a id='glossaryinfo-15021' class='msm_infobutton' onmouseover='infoopen(15021)'>i</a><div id="dialog-15021" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>‘Function’ appears here in the introduction to the concept of a linear transformation.</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15021' style='display:none;'><div class='title'>Linear Transformations</div><h2> Introduction </h2>
<p xmlns="Unit">
            <span>In this chapter we are going to develop a concept that is quite familiar at an intuitive level: that of a 
		<span> transformation of space</span>  
		together with objects contained in it. Amongst such transformations we focus upon those which are called 
		&#x2018;<a id="17">linear</a>  &#x2019;.
		Let us consider some examples to see what we mean.
		
	</span>
            
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>Twisting an elastic strip into a 
			<span> M&#xF6;bius strip</span>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="24">Stretching a square into a rectangle</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="25">Rotating a square</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="26">Mirroring an object</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="27">Shearing an object</a>  
                  </span>
               </p>
            </li>
	        </ul>

<p xmlns="Unit">
            <span>To describe the effect of a transformation mathematically, we use the concept of a 
		<span> function</span>  .
		
		
		There is a collection of functions which are particularly nice to work with. These are the 
		<a id="19">linear functions</a>  ,
		also called linear maps, linear homomorphisms, or linear transformations.</span>
            
         </p>

<p xmlns="Unit">
            <span>We find that every linear function can be 
		<span> described by a matrix</span>  
		and, conversely, every matrix describes a linear function. Thus we can leverage our knowledge of matrix algebra in the study of linear transformations.</span>
         </p>
<p xmlns="Unit">
            <span>We then discuss in detail the main examples of linear transformations:</span>
         </p>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>
                     <span> Dilations and contractions</span>   &#xA0; such transformations magnify, respectively shrink, the space $\RNr{n}$.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="26">Rotations</a>   &#xA0; a rotation of $\RNr{2}$ rotates the plane about the origin.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="27">Shear maps</a>   &#xA0; a shear transformation of $\RNr{n}$ turns a cube into a &#x2018;slanted box&#x2019;.
		</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>These three examples of linear transformations are ‘atomic’ in the sense that every linear transformation can be built from them, as we will learn later on.</span>
         </p>
<p xmlns="Unit">
            <span>Next we consider 
		<span> properties</span>  
		enjoyed by linear transformations, but not by arbitrary transformation. For example, such properties help us distinguish transformations which are linear from ones which are not. A section on 
		<a id="24">building new linear transformations</a>  
		from known ones follows.</span>
         </p>

<p xmlns="Unit">
            <span>Of particular interest are those linear transformations whose transformation effect can be reversed: These are the
		<span> invertible linear transformations</span>  .
		Amongst the invertible linear transformations we find a particularly nice collection: The
		<a id="25">distance preserving linear transformations</a>  .
		We encounter those on a daily basis in the form of rotations and reflections.</span>
         </p>
<p xmlns="Unit">
            <span>Linear transformations are also related to systems of linear equations, and this relationship will be explained as well.</span>
         </p></div><a id='glossaryinfo-15020' class='msm_infobutton' onmouseover='infoopen(15020)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15020' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div><ul class='chilren'><li><span>domain      </span><a id='glossaryinfo-15125' class='msm_infobutton' onmouseover='infoopen(15125)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15125' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>target      </span><a id='glossaryinfo-15126' class='msm_infobutton' onmouseover='infoopen(15126)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15126' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>value      </span><a id='glossaryinfo-6205' class='msm_infobutton' onmouseover='infoopen(6205)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6205' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>geometric multiplicity      </span><a id='glossaryinfo-20087' class='msm_infobutton' onmouseover='infoopen(20087)'>i</a><div id="dialog-20087" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20087' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>Gram-Schmidt orthonormalization process      </span><a id='glossaryinfo-14100' class='msm_infobutton' onmouseover='infoopen(14100)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-14100' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Gram-Schmidt orthonormalization</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given an ordered linearly independent set $\EuScript{A}:=(\Vect{a}_1,\dots ,\Vect{a}_r)$ of vectors in $\RNr{n}$, the ordered set of vectors $\EuScript{B}:=(\Vect{v}_1,\dots ,\Vect{v}_r)$ defined below is an ordered ONB of $\span(\EuScript{A})$.
			</span>
         
      </p><table xmlns:default="Theorem" border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14104" class="hottag" onmouseover="popup(14104)">$:=	$</a><div id="dialog-14104" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_1$ is the normalization of $\Vect{a}_1$; i.e. $\Vect{v}_1$ has the same direction as $\Vect{a}_1$, but has length $1$.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_1 }{ \abs{ \Vect{a}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14109" class="hottag" onmouseover="popup(14109)">$:=	$</a><div id="dialog-14109" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_2$ is the component of $\Vect{a}_2$ which is perpendicular to $\Vect{v}_1$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1 }{ \abs{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\vdots$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\qquad \vdots \qquad\qquad \vdots$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14118" class="hottag" onmouseover="popup(14118)">$:=	$</a><div id="dialog-14118" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_r$ is the component of $\Vect{a}_r$ which is perpendicular to each of $\Vect{v}_1$, ... , $\Vect{v}_{r-1}$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} }{ \abs{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} } }$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, $\span\Set{ \Vect{a}_1,\dots ,\Vect{a}_j } = \span\Set{ \Vect{v}_1,\dots ,\Vect{v}_j }$ for each $1\leq j\leq r$ and, if $\Vect{a}_1,\dots ,\Vect{a}_j$ are already orthonormal, then $\Vect{a}_k=\Vect{v}_k$ for each $1\leq k\leq j$.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>homogeneous      </span><ul class='chilren'><li><span>linear equation      </span><a id='glossaryinfo-3275' class='msm_infobutton' onmouseover='infoopen(3275)'>i</a><div id="dialog-3275" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = 0$$
					                   <p>
                           <span>Look up the definition</span>
                        </p>
				                 </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3275' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <span> system of linear equations</span>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<span> hyperplane in $\RNr{n}$
                        </span>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="23">intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li></ul></li><li><span>homogeneous system of linear equations      </span><a id='glossaryinfo-4221' class='msm_infobutton' onmouseover='infoopen(4221)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4221' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>homomorphism      </span><ul class='chilren'><li><span>of vector spaces      </span><a id='glossaryinfo-15306' class='msm_infobutton' onmouseover='infoopen(15306)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15306' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>hyperspace      </span><a id='glossaryinfo-2328' class='msm_infobutton' onmouseover='infoopen(2328)'>i</a><div id="dialog-2328" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The hyperspace in $\RNr{n}$ perpendicular to a nonzero vector $\Vect{n}$  is the set</span>
                                 </p>
                                 <p align="center">
                                    <span>
                                       $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2328' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>identity      </span><ul class='chilren'><li><span>linear transformation of $\RNr{n}$      </span><a id='glossaryinfo-6860' class='msm_infobutton' onmouseover='infoopen(6860)'>i</a><div id="dialog-6860" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6860' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>matrix      </span><a id='glossaryinfo-4822' class='msm_infobutton' onmouseover='infoopen(4822)'>i</a><div id="dialog-4822" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4822' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>image      </span><ul class='chilren'><li><span>of element under a function      </span><a id='glossaryinfo-6206' class='msm_infobutton' onmouseover='infoopen(6206)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6206' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>image of a linear map      </span><a id='glossaryinfo-18625' class='msm_infobutton' onmouseover='infoopen(18625)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18625' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>inconsistent      </span><ul class='chilren'><li><span>system of linear equations      </span><a id='glossaryinfo-3664' class='msm_infobutton' onmouseover='infoopen(3664)'>i</a><div id="dialog-3664" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3664' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>inhomogeneous      </span><ul class='chilren'><li><span>linear equation      </span><a id='glossaryinfo-3277' class='msm_infobutton' onmouseover='infoopen(3277)'>i</a><div id="dialog-3277" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = c$$
					                   <p>
                           <span>with $c \neq 0$. Look up the definition.</span>
                        </p>
				                 </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3277' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <span> system of linear equations</span>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<span> hyperplane in $\RNr{n}$
                        </span>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="23">intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li></ul></li><li><span>inhomogeneous system of linear equations      </span><a id='glossaryinfo-4222' class='msm_infobutton' onmouseover='infoopen(4222)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4222' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>inverse      </span><ul class='chilren'><li><span>of a $(2,2)$-matrix      </span><a id='glossaryinfo-10998' class='msm_infobutton' onmouseover='infoopen(10998)'>i</a><div id="dialog-10998" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10998' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>of a linear transformation      </span><a id='glossaryinfo-16736' class='msm_infobutton' onmouseover='infoopen(16736)'>i</a><div id="dialog-16736" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-16736' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>inversion      </span><a id='glossaryinfo-6889' class='msm_infobutton' onmouseover='infoopen(6889)'>i</a><div id="dialog-6889" class="dialogs" title="What is an inversion?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An inversion is a linear transformation $T$ of $\RNr{n}$ of the form $T(\Vect{x})= -\Vect{x}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6889' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>invertible      </span><ul class='chilren'><li><span>linear transformation      </span><a id='glossaryinfo-18464' class='msm_infobutton' onmouseover='infoopen(18464)'>i</a><div id="dialog-18464" class="dialogs" title="Invertible linear transformation"><info xmlns="Unit">
                           
                           <p>
                              <span>Definition of the concept: A linear map $L\from V\to W$ of subvector spaces of $\RNr{k}$ is invertible, if there exists a linear map $M\from W\to V$ such that</span>
                           </p>
                           $$M\Comp L = \Id{V} \quad\text{and}\quad L\Comp M = \Id{W}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18464' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear map $L\from V\to W$ of subvector spaces of $\RNr{k}$ is called invertible if there exists a linear map $M\from W\to V$ such that
				</span>
                     
                  </p>
                  $$M\Comp L = \Id{V} \quad\text{and}\quad L\Comp M = \Id{W}$$
                  <p>
                     <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-16730' class='msm_infobutton' onmouseover='infoopen(16730)'>i</a><div id="dialog-16730" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div></li><li><span>matrix      </span><a id='glossaryinfo-5344' class='msm_infobutton' onmouseover='infoopen(5344)'>i</a><div id="dialog-5344" class="dialogs" title="Invertible Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>An analysis which motivates the concept of an invertible matrix.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5344' style='display:none;'><div class='title'>Matrix Multiplication: Exceptional Properties</div><p xmlns="Unit">
               <span>Let us recall: So far we have extended the operations of addition and multiplication of numbers to the world of matrices. How about division? i.e. how can we make sense of an expression like this one?
				</span>
               
            </p>$$
					
					\dfrac{
					\left[
					\begin{array}{rr}
					4 &amp; 3 \\
					1 &amp; 0
					\end{array}
					\right] }{
					\left[
					\begin{array}{rr}
					7 &amp; 4 \\
					5 &amp; 3
					\end{array}
					\right]}
					
				$$<p xmlns="Unit">
               <span>To answer this question, let us analyze division by a number to get an idea of how to extend division to the world of matrices: Dividing a number $x$ by another, say $2$, amounts to multiplying $x$  by  $1/2=2^{-1}$. Now, the number $1/2$ is characterized by the property</span>
            </p>$$2\cdot (1/2)\ =\ 1\ (1/2)\cdot 2$$<p xmlns="Unit">
               <span>This is the key: Our goal is to divide an $(n,n)$-matrix $\Mtrx{X}$ by another $(n,n)$-matrix $\Mtrx{A}$. So, if we can find a matrix $\Mtrx{B}$ with</span>
            </p>$$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$<p xmlns="Unit">
               <span>then it makes sense to define $\Mtrx{A}^{-1} := B$. So then we can define</span>
            </p>$$\dfrac{\Mtrx{X}}{\Mtrx{A}}\ :=\ \Mtrx{X}\cdot \Mtrx{B}$$<p xmlns="Unit">
               <span>
                  <b>Alert</b>   Here is a new point which we must really pay attention to: In the world of matrices there are two ways of multiplying $\Mtrx{X}$by $\Mtrx{A}$. Reason:</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  $\Mtrx{B}\Mtrx{X}$ &#xA0; is 
				<span> generally distinct</span>  
				from $\Mtrx{X}\Mtrx{B}$.
			</span>
            </p>
<p xmlns="Unit">
               <span>Accordingly, we must carefully decide whether we want to</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the left; i.e. form the product  $\Mtrx{B}\Mtrx{X}$, or</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the right; i.e. form the product  $\Mtrx{X}\Mtrx{B}$.</span>
                  </p>
               </li>
            </ul></div><a id='glossaryinfo-5396' class='msm_infobutton' onmouseover='infoopen(5396)'>i</a><div id="dialog-5396" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5396' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ of size $(n,n)$ is invertible if there is a matrix $\Mtrx{B}$ such that</span>
                  </p>
                  $$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$
                  <p>
                     <span>In this case, $\Mtrx{B}$ is called the inverse of $\Mtrx{A}$, and is denoted $\Mtrx{A}^{-1}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-17116' class='msm_infobutton' onmouseover='infoopen(17116)'>i</a><div id="dialog-17116" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Context: a distance preserving linear map is invertible</span>
                     </p>
                  </info></div></li></ul></li><li><span>isomorphic linear transformation      </span><a id='glossaryinfo-18843' class='msm_infobutton' onmouseover='infoopen(18843)'>i</a><div id="dialog-18843" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18843' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>isomorphism      </span><a id='glossaryinfo-18847' class='msm_infobutton' onmouseover='infoopen(18847)'>i</a><div id="dialog-18847" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18847' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>kernel      </span><a id='glossaryinfo-17274' class='msm_infobutton' onmouseover='infoopen(17274)'>i</a><div id="dialog-17274" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>`kernel' appears here in the context of linear transformations providing another view toward linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17274' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <span> denoted $T^{-1}(\Vect{y})$
                     </span>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$
<p xmlns="Unit">
               <span>We have 
			<span> seen already</span>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li><li><span>kernel of a linear map      </span><a id='glossaryinfo-18624' class='msm_infobutton' onmouseover='infoopen(18624)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18624' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>kernel of a linear transformation      </span><a id='glossaryinfo-11538' class='msm_infobutton' onmouseover='infoopen(11538)'>i</a><div id="dialog-11538" class="dialogs" title="Kernel"><info xmlns="Unit">
                           
                           <p>
                              <span>The kernel of $L\from V\to W$ is the set of all $\Vect{x}\in V$ with $L(\Vect{x} )=\Vect{0}$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11538' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $V$ and $W$ be subspaces of $\RNr{n}$. The kernel of a linear transformation $L\from V\to W$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Ker{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11542" class="hottag" onmouseover="popup(11542)">$:=	$</a><div id="dialog-11542" class="dialogs" title="How do I read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#xA0;kernel of $L$ is by definition the set of all those $\Vect{x}$ in V such that $L$ of $\Vect{x}$ equals  zero.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st L(\Vect{x}) = \Vect{0} }$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>leading $1$      </span><a id='glossaryinfo-3822' class='msm_infobutton' onmouseover='infoopen(3822)'>i</a><div id="dialog-3822" class="dialogs" title="What is a leading $1$?"><info xmlns="Unit">
                                       
                                       <p>
                                          <span>The concept of ‘leading 1’ occurs within the context of linear equations in row reduced echelon form.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3822' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>left hand      </span><ul class='chilren'><li><span>orientation      </span><a id='glossaryinfo-10117' class='msm_infobutton' onmouseover='infoopen(10117)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10117' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>rule      </span><a id='glossaryinfo-10140' class='msm_infobutton' onmouseover='infoopen(10140)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10140' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>length      </span><ul class='chilren'><li><span>of a vector      </span><a id='glossaryinfo-1668' class='msm_infobutton' onmouseover='infoopen(1668)'>i</a><div id="dialog-1668" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1668' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of an arrow      </span><a id='glossaryinfo-644' class='msm_infobutton' onmouseover='infoopen(644)'>i</a><div id="dialog-644" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-644' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>level set      </span><ul class='chilren'><li><span>of a linear transformation      </span><a id='glossaryinfo-8337' class='msm_infobutton' onmouseover='infoopen(8337)'>i</a><div id="dialog-8337" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8337' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <span> denoted $T^{-1}(\Vect{y})$
                     </span>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$
<p xmlns="Unit">
               <span>We have 
			<span> seen already</span>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li></ul></li><li><span>linear      </span><ul class='chilren'><li><span>combination      </span><a id='glossaryinfo-11715' class='msm_infobutton' onmouseover='infoopen(11715)'>i</a><div id="dialog-11715" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11715' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear combination</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>A linear combination of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $\RNr{n}$ is a vector $\Vect{x}$ of the form
					</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{s}_1 + \cdots + t_r \Vect{s}_r$</td></tr></table>
                        <p>
                           <span>where $t_1,\dots ,t_r$ are numbers in $\RNr{}$.</span>
                        </p>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-5785' class='msm_infobutton' onmouseover='infoopen(5785)'>i</a><div id="dialog-5785" class="dialogs" title="matrix equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5785' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><a id='glossaryinfo-3252' class='msm_infobutton' onmouseover='infoopen(3252)'>i</a><div id="dialog-3252" class="dialogs" title="What is a linear equation?">
<info xmlns="Unit">
                  
				
				              <p>
                     <span>A linear equation is an expression which can be written as</span>
                  </p>
				
				              <p align="center">
                     <span>
                        <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
                     </span>
                  </p>
				
				              <p>
                     <span>Look up the definition.</span>
                  </p>
			            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-3252' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <span> system of linear equations</span>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<span> hyperplane in $\RNr{n}$
                        </span>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="23">intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li><li><span>function      </span><a id='glossaryinfo-6360' class='msm_infobutton' onmouseover='infoopen(6360)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6360' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>map      </span><a id='glossaryinfo-15305' class='msm_infobutton' onmouseover='infoopen(15305)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15305' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>motion      </span><a id='glossaryinfo-1129' class='msm_infobutton' onmouseover='infoopen(1129)'>i</a><div id="dialog-1129" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>A motion of a particle whose location at time $t$ has position vector $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$. – Click to see to the definition.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1129' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <span> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </span>  , with <a id="25">
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>transformation      </span><a id='glossaryinfo-15304' class='msm_infobutton' onmouseover='infoopen(15304)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15304' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>rotation      </span><a id='glossaryinfo-19530' class='msm_infobutton' onmouseover='infoopen(19530)'>i</a><div id="dialog-19530" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19530' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>scaling      </span><a id='glossaryinfo-6882' class='msm_infobutton' onmouseover='infoopen(6882)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6882' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>transformation of $\RNr{n}$      </span><ul class='chilren'><li><span>identity      </span><a id='glossaryinfo-15797' class='msm_infobutton' onmouseover='infoopen(15797)'>i</a><div id="dialog-15797" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15797' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li></ul></li><li><span>linear transformation      </span><a id='glossaryinfo-6032' class='msm_infobutton' onmouseover='infoopen(6032)'>i</a><div id="dialog-6032" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>Appears here in the introduction to the topic of linear transformations.</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6032' style='display:none;'><div class='title'>Linear Transformations</div><h2> Introduction </h2>
<p xmlns="Unit">
            <span>In this chapter we are going to develop a concept that is quite familiar at an intuitive level: that of a 
		<span> transformation of space</span>  
		together with objects contained in it. Amongst such transformations we focus upon those which are called 
		&#x2018;<a id="17">linear</a>  &#x2019;.
		Let us consider some examples to see what we mean.
		
	</span>
            
         </p>

<ul xmlns="Unit">
		          <li>
               <p>
                  <span>Twisting an elastic strip into a 
			<span> M&#xF6;bius strip</span>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="24">Stretching a square into a rectangle</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="25">Rotating a square</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="26">Mirroring an object</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="27">Shearing an object</a>  
                  </span>
               </p>
            </li>
	        </ul>

<p xmlns="Unit">
            <span>To describe the effect of a transformation mathematically, we use the concept of a 
		<span> function</span>  .
		
		
		There is a collection of functions which are particularly nice to work with. These are the 
		<a id="19">linear functions</a>  ,
		also called linear maps, linear homomorphisms, or linear transformations.</span>
            
         </p>

<p xmlns="Unit">
            <span>We find that every linear function can be 
		<span> described by a matrix</span>  
		and, conversely, every matrix describes a linear function. Thus we can leverage our knowledge of matrix algebra in the study of linear transformations.</span>
         </p>
<p xmlns="Unit">
            <span>We then discuss in detail the main examples of linear transformations:</span>
         </p>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>
                     <span> Dilations and contractions</span>   &#xA0; such transformations magnify, respectively shrink, the space $\RNr{n}$.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="26">Rotations</a>   &#xA0; a rotation of $\RNr{2}$ rotates the plane about the origin.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="27">Shear maps</a>   &#xA0; a shear transformation of $\RNr{n}$ turns a cube into a &#x2018;slanted box&#x2019;.
		</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>These three examples of linear transformations are ‘atomic’ in the sense that every linear transformation can be built from them, as we will learn later on.</span>
         </p>
<p xmlns="Unit">
            <span>Next we consider 
		<span> properties</span>  
		enjoyed by linear transformations, but not by arbitrary transformation. For example, such properties help us distinguish transformations which are linear from ones which are not. A section on 
		<a id="24">building new linear transformations</a>  
		from known ones follows.</span>
         </p>

<p xmlns="Unit">
            <span>Of particular interest are those linear transformations whose transformation effect can be reversed: These are the
		<span> invertible linear transformations</span>  .
		Amongst the invertible linear transformations we find a particularly nice collection: The
		<a id="25">distance preserving linear transformations</a>  .
		We encounter those on a daily basis in the form of rotations and reflections.</span>
         </p>
<p xmlns="Unit">
            <span>Linear transformations are also related to systems of linear equations, and this relationship will be explained as well.</span>
         </p></div><ul class='chilren'><li><span>by specifying values on a basis      </span><a id='glossaryinfo-17975' class='msm_infobutton' onmouseover='infoopen(17975)'>i</a><div id="dialog-17975" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Look up the proposition which says that a linear map $f\from V\to W$ is given by specifying is values on a basis of $V$.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17975' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Linear map by values on a basis</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $V$ and $W$ be subspaces of $\RNr{k}$. Given a basis $\EuScript{A}=\Set{ \Vect{a}_1,\dots ,\Vect{a}_n}$ of $V$ and arbitrary vectors $\Vect{z}_1$, ... , $\Vect{z}_n$ in $W$, there is exactly one linear transformation $L\from V\to W$ with
			</span>
         
      </p>$$L(\Vect{a}_1)=\Vect{z}_1\ ,\quad \dots \ ,\quad L(\Vect{a}_n)=\Vect{z}_n$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>distance preserving      </span><a id='glossaryinfo-8082' class='msm_infobutton' onmouseover='infoopen(8082)'>i</a><div id="dialog-8082" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8082' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>epimorphic      </span><a id='glossaryinfo-18839' class='msm_infobutton' onmouseover='infoopen(18839)'>i</a><div id="dialog-18839" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18839' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>invertible      </span><a id='glossaryinfo-7794' class='msm_infobutton' onmouseover='infoopen(7794)'>i</a><div id="dialog-7794" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7794' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>isomorphic      </span><a id='glossaryinfo-18845' class='msm_infobutton' onmouseover='infoopen(18845)'>i</a><div id="dialog-18845" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18845' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphic      </span><a id='glossaryinfo-18833' class='msm_infobutton' onmouseover='infoopen(18833)'>i</a><div id="dialog-18833" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18833' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>orthogonal      </span><a id='glossaryinfo-8088' class='msm_infobutton' onmouseover='infoopen(8088)'>i</a><div id="dialog-8088" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8088' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>scalar product      </span><a id='glossaryinfo-17775' class='msm_infobutton' onmouseover='infoopen(17775)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17775' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>shear map of $\RNr{n}$ parallel to a hyperspace      </span><a id='glossaryinfo-19694' class='msm_infobutton' onmouseover='infoopen(19694)'>i</a><div id="dialog-19694" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19694' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>linear transformations      </span><ul class='chilren'><li><span>composition      </span><a id='glossaryinfo-7650' class='msm_infobutton' onmouseover='infoopen(7650)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7650' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>linearly dependent set      </span><a id='glossaryinfo-12118' class='msm_infobutton' onmouseover='infoopen(12118)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12118' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>linearly independent set      </span><a id='glossaryinfo-12117' class='msm_infobutton' onmouseover='infoopen(12117)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12117' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>Lo Shu-magic square      </span><a id='glossaryinfo-4654' class='msm_infobutton' onmouseover='infoopen(4654)'>i</a><div id="dialog-4654" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>appears here as an early example of organizing numbers in a rectangular shape.</span>
                        </p>
                     </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4654' style='display:none;'><div class='title'>Matrix Algebra</div><h2> Introduction </h2>
<p xmlns="Unit">
            <span>We use the term matrix to refer to any rectangular arrangement of objects.
		
		Here, in linear algebra, we encounter primarily matrices of numbers, that is 
		<span> rectangular arrangement of numbers</span>  . 
		Such an arrangement can serve any one of a vast variety of organizational purposes. For example, when we learned how to solve  
		<a id="16">system of linear equations</a>   we arranged the coefficients of the system in a matrix to facilitate the execution of row operations.
	</span>
            
         </p>
<p xmlns="Unit">
            <span>But matrices can do much more than serve organizational purposes: like vectors, matrices of equal size can be added; it is possible to multiply a matrix by a number; and then there is a new operation: whenever the sizes of two matrices $\Mtrx{A}$ and $\Mtrx{B}$ are compatible, the product $\Mtrx{A}\cdot \Mtrx{B}$ is defined.</span>
         </p><p xmlns="Unit">
            <span>It is possible to embed the system $\RNr{}$ of real numbers in the system of matrices, for example by turning a number $x$ into the matrix $[x]$ consisting of a single entry. Thus the system of all matrices vastly extends the system of real numbers, an extension which is enormously versatile and powerful.</span>
         </p><p xmlns="Unit">
            <span>We will use matrices for a variety of purposes: they will enable us to obtain additional tools to solve systems of linear equations. Further, we will learn how to use matrices to transform space, how to manipulate the location of objects in space, and how alter the shape of objects in space.</span>
         </p><p xmlns="Unit">
            <span>Let us now sketch a few stages of the history of matrices. The benefits of organizing numbers into a rectangular arrangement have been observed quite early. For example</span>
         </p>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>The &#x2018;Lo Shu&#x2019;-<span> magic square</span>  
		of China was recorded around 650 BCE in China.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Also in China, the use of matrices to solve systems of linear equations is documented in Jiu Shang Suan Shu's <i>The Nine Chapters on the Mathematical Art</i>, which originated between 300 BCE and 200 CE.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Magic squares appear in the Arab literature around 700 CE. One can speculate that the became familiar with this concept via links to the ancient Chinese culture when they invaded parts of India's north-west.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>The word ‘matrix’ itself for a rectangular arrangement of numbers was introduced much later in 1848 by J.J. Sylvester,
		
		and the theory of matrices evolved subsequently with many contributors, among them R.W. Hamilton (1805-1865),
		
		H. Grassmann (1809-1877),
		
		A. Cayley (1821-1895),
		
		F.G. Frobenius (1849-1917),
		
		J. von Neumann (1903-1957),
		
		O. Taussky-Todd (1906-1995).
		
	</span>
            
            
            
            
            
            
            
         </p></div></li><li><span>matrix      </span><a id='glossaryinfo-4554' class='msm_infobutton' onmouseover='infoopen(4554)'>i</a><div id="dialog-4554" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>General description as a rectangular arrangement of objects</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4554' style='display:none;'><div class='title'>Matrix Algebra</div><h2> Introduction </h2>
<p xmlns="Unit">
            <span>We use the term matrix to refer to any rectangular arrangement of objects.
		
		Here, in linear algebra, we encounter primarily matrices of numbers, that is 
		<span> rectangular arrangement of numbers</span>  . 
		Such an arrangement can serve any one of a vast variety of organizational purposes. For example, when we learned how to solve  
		<a id="16">system of linear equations</a>   we arranged the coefficients of the system in a matrix to facilitate the execution of row operations.
	</span>
            
         </p>
<p xmlns="Unit">
            <span>But matrices can do much more than serve organizational purposes: like vectors, matrices of equal size can be added; it is possible to multiply a matrix by a number; and then there is a new operation: whenever the sizes of two matrices $\Mtrx{A}$ and $\Mtrx{B}$ are compatible, the product $\Mtrx{A}\cdot \Mtrx{B}$ is defined.</span>
         </p><p xmlns="Unit">
            <span>It is possible to embed the system $\RNr{}$ of real numbers in the system of matrices, for example by turning a number $x$ into the matrix $[x]$ consisting of a single entry. Thus the system of all matrices vastly extends the system of real numbers, an extension which is enormously versatile and powerful.</span>
         </p><p xmlns="Unit">
            <span>We will use matrices for a variety of purposes: they will enable us to obtain additional tools to solve systems of linear equations. Further, we will learn how to use matrices to transform space, how to manipulate the location of objects in space, and how alter the shape of objects in space.</span>
         </p><p xmlns="Unit">
            <span>Let us now sketch a few stages of the history of matrices. The benefits of organizing numbers into a rectangular arrangement have been observed quite early. For example</span>
         </p>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>The &#x2018;Lo Shu&#x2019;-<span> magic square</span>  
		of China was recorded around 650 BCE in China.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Also in China, the use of matrices to solve systems of linear equations is documented in Jiu Shang Suan Shu's <i>The Nine Chapters on the Mathematical Art</i>, which originated between 300 BCE and 200 CE.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Magic squares appear in the Arab literature around 700 CE. One can speculate that the became familiar with this concept via links to the ancient Chinese culture when they invaded parts of India's north-west.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>The word ‘matrix’ itself for a rectangular arrangement of numbers was introduced much later in 1848 by J.J. Sylvester,
		
		and the theory of matrices evolved subsequently with many contributors, among them R.W. Hamilton (1805-1865),
		
		H. Grassmann (1809-1877),
		
		A. Cayley (1821-1895),
		
		F.G. Frobenius (1849-1917),
		
		J. von Neumann (1903-1957),
		
		O. Taussky-Todd (1906-1995).
		
	</span>
            
            
            
            
            
            
            
         </p></div><a id='glossaryinfo-4679' class='msm_infobutton' onmouseover='infoopen(4679)'>i</a><div id="dialog-4679" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of a matrix</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4679' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>
				Let $m,n\geq 1$ be integers. A 
				<span> matrix</span>  
				of size 
				<a id="22">
                              $(m,n)$
                           </a>  
				or an $(m,n)$-matrix is a rectangular arrangement of numbers
			</span>
                     
                  </p>
                  $$
					
					\left[
					\begin{array}{cccccc}
					a_{11} &amp; a_{12} &amp; a_{13} &amp; \cdots &amp; \cdots &amp; a_{1n} \\
					a_{21} &amp; a_{22} &amp; a_{23} &amp; \cdots &amp; \cdots &amp; a_{2n} \\
					\vdots  &amp; \vdots  &amp; \vdots  &amp; \ddots &amp;              &amp; \vdots \\
					\vdots  &amp; \vdots  &amp; \vdots  &amp;             &amp; \ddots  &amp; \vdots \\
					a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \cdots &amp; \cdots &amp; a_{mn}
					\end{array}
					\right]
					
				$$
                  <p>
                     <span>We write $a_{ij}$ for the entry in 
				<a id="23">row</a>  
                        $i$ and 
				<a id="24">column</a>  
                        $j$. This is a number in $\RNr{}$. In more compact notation, the matrix above may be written as $A = [a_{ij}]$, $1\leq i\leq m$ and $1 \leq j \leq n$.
			</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>0-      </span><a id='glossaryinfo-4810' class='msm_infobutton' onmouseover='infoopen(4810)'>i</a><div id="dialog-4810" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4810' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>addition      </span><a id='glossaryinfo-4885' class='msm_infobutton' onmouseover='infoopen(4885)'>i</a><div id="dialog-4885" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4885' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>antisymmetric      </span><a id='glossaryinfo-4941' class='msm_infobutton' onmouseover='infoopen(4941)'>i</a><div id="dialog-4941" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4941' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>diagonal      </span><a id='glossaryinfo-4817' class='msm_infobutton' onmouseover='infoopen(4817)'>i</a><div id="dialog-4817" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4817' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>diagonalizable      </span><a id='glossaryinfo-20275' class='msm_infobutton' onmouseover='infoopen(20275)'>i</a><div id="dialog-20275" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20275' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-5783' class='msm_infobutton' onmouseover='infoopen(5783)'>i</a><div id="dialog-5783" class="dialogs" title="matrix equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5783' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>identity      </span><a id='glossaryinfo-4824' class='msm_infobutton' onmouseover='infoopen(4824)'>i</a><div id="dialog-4824" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4824' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>inverse of a $(2,2)$-matrix      </span><a id='glossaryinfo-11000' class='msm_infobutton' onmouseover='infoopen(11000)'>i</a><div id="dialog-11000" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11000' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>invertible      </span><a id='glossaryinfo-5400' class='msm_infobutton' onmouseover='infoopen(5400)'>i</a><div id="dialog-5400" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5400' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ of size $(n,n)$ is invertible if there is a matrix $\Mtrx{B}$ such that</span>
                  </p>
                  $$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$
                  <p>
                     <span>In this case, $\Mtrx{B}$ is called the inverse of $\Mtrx{A}$, and is denoted $\Mtrx{A}^{-1}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>multiplication      </span><a id='glossaryinfo-4910' class='msm_infobutton' onmouseover='infoopen(4910)'>i</a><div id="dialog-4910" class="dialogs" title="Matrix Multiplication"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4910' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>associative      </span><a id='glossaryinfo-5200' class='msm_infobutton' onmouseover='infoopen(5200)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5200' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>distributive      </span><a id='glossaryinfo-5203' class='msm_infobutton' onmouseover='infoopen(5203)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5203' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>neutral element      </span><a id='glossaryinfo-5206' class='msm_infobutton' onmouseover='infoopen(5206)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5206' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>of a contraction      </span><a id='glossaryinfo-19494' class='msm_infobutton' onmouseover='infoopen(19494)'>i</a><div id="dialog-19494" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19494' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><a id='glossaryinfo-19493' class='msm_infobutton' onmouseover='infoopen(19493)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-19493' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>of a dilation      </span><a id='glossaryinfo-8625' class='msm_infobutton' onmouseover='infoopen(8625)'>i</a><div id="dialog-8625" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8625' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>of one column      </span><a id='glossaryinfo-4792' class='msm_infobutton' onmouseover='infoopen(4792)'>i</a><div id="dialog-4792" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4792' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of one row      </span><a id='glossaryinfo-4785' class='msm_infobutton' onmouseover='infoopen(4785)'>i</a><div id="dialog-4785" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4785' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of upper triangular shape      </span><a id='glossaryinfo-4840' class='msm_infobutton' onmouseover='infoopen(4840)'>i</a><div id="dialog-4840" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is of upper triangular shape if it is square shaped and only entries on or above the diagonal are different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4840' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>orthogonal      </span><a id='glossaryinfo-8212' class='msm_infobutton' onmouseover='infoopen(8212)'>i</a><div id="dialog-8212" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8212' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>power      </span><a id='glossaryinfo-20405' class='msm_infobutton' onmouseover='infoopen(20405)'>i</a><div id="dialog-20405" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>A method of computing powers $\Mtrx{A}^r$ of a diagonalizable matrix $\Mtrx{A}$
                  </span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20405' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Matrix exponentiation</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>For an integer $r\geq 1$ and a diagonalizable matrix $\Mtrx{A}$ with $\Mtrx{D} = \Mtrx{C}^{-1} \Mtrx{A} \Mtrx{C}$ diagonal,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{A}^r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C} \Mtrx{D}^r \Mtrx{C}^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>representing a linear map      </span><a id='glossaryinfo-15612' class='msm_infobutton' onmouseover='infoopen(15612)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15612' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>row rescaling      </span><a id='glossaryinfo-5515' class='msm_infobutton' onmouseover='infoopen(5515)'>i</a><div id="dialog-5515" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5515' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>scalar multiplication      </span><ul class='chilren'><li><span>commutes with matrix multiplication      </span><a id='glossaryinfo-5191' class='msm_infobutton' onmouseover='infoopen(5191)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5191' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>distributes over matrix sums      </span><a id='glossaryinfo-5183' class='msm_infobutton' onmouseover='infoopen(5183)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5183' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is associative      </span><a id='glossaryinfo-5187' class='msm_infobutton' onmouseover='infoopen(5187)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5187' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>scalar product      </span><a id='glossaryinfo-4899' class='msm_infobutton' onmouseover='infoopen(4899)'>i</a><div id="dialog-4899" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4899' style='display:none;'><div class='title'>Matrix Operations</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we explain how to add matrices, how to multiply a matrix by a number, how to multiply two matrices, and what the transpose of a matrix is. The system of all matrices, endowed with these operations, forms a vast and powerful extension of the system of real number $\RNr{}$.</span>
            </p><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Scalar Product of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The (scalar) product of a matrix $A = [a_{ij}]$ by a number $t$ is</span>
                  </p>
                  $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>Addition of matrices and scalar multiplying a matrix by a number probably seem familiar because they behave completely like the corresponding operations on vectors. However, the next operation, multiplying one matrix by another, is new. Please pay particular attention to the size compatibility we require if we want to multiply two matrices.</span>
            </p><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>The transpose operation helps us single out the following special kind of matrix:</span>
            </p><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>square shaped      </span><a id='glossaryinfo-4774' class='msm_infobutton' onmouseover='infoopen(4774)'>i</a><div id="dialog-4774" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A square shaped matrix is one whose number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4774' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><a id='glossaryinfo-4881' class='msm_infobutton' onmouseover='infoopen(4881)'>i</a><div id="dialog-4881" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4881' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>symmetric      </span><a id='glossaryinfo-4937' class='msm_infobutton' onmouseover='infoopen(4937)'>i</a><div id="dialog-4937" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4937' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-20393' class='msm_infobutton' onmouseover='infoopen(20393)'>i</a><div id="dialog-20393" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Appears here in the context of: a symmetric matrix is diagonalizable.</span>
               </p>
            </info></div></li><li><span>transpose      </span><a id='glossaryinfo-4924' class='msm_infobutton' onmouseover='infoopen(4924)'>i</a><div id="dialog-4924" class="dialogs" title="Transpose of a Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4924' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>transposition      </span><ul class='chilren'><li><span>anticommutes with multiplication      </span><a id='glossaryinfo-5250' class='msm_infobutton' onmouseover='infoopen(5250)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5250' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with addition      </span><a id='glossaryinfo-5246' class='msm_infobutton' onmouseover='infoopen(5246)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5246' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with scalar multiplication      </span><a id='glossaryinfo-5248' class='msm_infobutton' onmouseover='infoopen(5248)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5248' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>matrix multiplication      </span><ul class='chilren'><li><span>commutes with determinant      </span><a id='glossaryinfo-9653' class='msm_infobutton' onmouseover='infoopen(9653)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9653' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>minor      </span><a id='glossaryinfo-8901' class='msm_infobutton' onmouseover='infoopen(8901)'>i</a><div id="dialog-8901" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-minor of a matrix $\Mtrx{A}$ is the result of omitting the $i$-th row and the $j$-th column from $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8901' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-minor of $\Mtrx{A}$ is the $(r-1,r-1)$-matrix $\Mtrx{A}_{ij}$ which results from $\Mtrx{A}$ by omitting the $i$-th row and the $j$-th column.</span>
                        </p>
                        $$
						
\Mtrx{A}_{ij} = 
\left[
\begin{array}{cccccc}
a_{11} &amp; \cdots &amp; {\color{red} a_{1j}} &amp; \cdots &amp; \cdots &amp; a_{1r} \\
\vdots &amp; \ddots &amp; {\color{red} \vdots} &amp; &amp; &amp; \vdots \\
\vdots &amp;        &amp; {\color{red} \ddots} &amp;              &amp; &amp; \vdots \\
{\color{red} a_{i1}} &amp; {\color{red} \cdots} &amp; {\color{red} a_{ij}} &amp; {\color{red} \ddots } &amp; {\color{red} \cdots} &amp; {\color{red} a_{ir}} \\
\vdots &amp;  &amp; {\color{red} \vdots} &amp; &amp; \ddots &amp; \vdots \\
a_{r1} &amp; \cdots &amp; {\color{red} a_{rj}} &amp; \cdots &amp; \cdots &amp; a_{rr}
\end{array}
\right]

					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphic linear transformation      </span><a id='glossaryinfo-18831' class='msm_infobutton' onmouseover='infoopen(18831)'>i</a><div id="dialog-18831" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18831' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphism      </span><a id='glossaryinfo-18835' class='msm_infobutton' onmouseover='infoopen(18835)'>i</a><div id="dialog-18835" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18835' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>multilinear      </span><ul class='chilren'><li><span>property of the determinant operation      </span><a id='glossaryinfo-9074' class='msm_infobutton' onmouseover='infoopen(9074)'>i</a><div id="dialog-9074" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9074' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>multiplication      </span><ul class='chilren'><li><span>of a vector by a number      </span><a id='glossaryinfo-838' class='msm_infobutton' onmouseover='infoopen(838)'>i</a><div id="dialog-838" class="dialogs"><info xmlns="Unit">
                                 $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-838' style='display:none;'><br /><div class='def'><span class='deftitle'>Multiplication of a Vector by a Scalar</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a vector $\Vect{x}=(x_1,\dots ,x_n)$ in $\RNr{n}$ by a number $t$ in $\RNr{}$ is
					</span>
                           
                        </p>
                        $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n).$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>multiplicity      </span><ul class='chilren'><li><span>algebraic      </span><a id='glossaryinfo-20048' class='msm_infobutton' onmouseover='infoopen(20048)'>i</a><div id="dialog-20048" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20048' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>geometric      </span><a id='glossaryinfo-20089' class='msm_infobutton' onmouseover='infoopen(20089)'>i</a><div id="dialog-20089" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20089' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>neutral element      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5205' class='msm_infobutton' onmouseover='infoopen(5205)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5205' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>non-degeneracy      </span><ul class='chilren'><li><span>dot product      </span><a id='glossaryinfo-1885' class='msm_infobutton' onmouseover='infoopen(1885)'>i</a><div id="dialog-1885" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the dot product asserts that </span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1885' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>non-degenerate      </span><ul class='chilren'><li><span>norm      </span><a id='glossaryinfo-1487' class='msm_infobutton' onmouseover='infoopen(1487)'>i</a><div id="dialog-1487" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <span> length 1 and the same direction as $\Vect{x}$
                     </span>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>norm      </span><ul class='chilren'><li><span>non-degeneracy      </span><a id='glossaryinfo-1701' class='msm_infobutton' onmouseover='infoopen(1701)'>i</a><div id="dialog-1701" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1701' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <span> length 1 and the same direction as $\Vect{x}$
                     </span>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of a vector      </span><a id='glossaryinfo-1672' class='msm_infobutton' onmouseover='infoopen(1672)'>i</a><div id="dialog-1672" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm or length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1672' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of a vector: properties      </span><a id='glossaryinfo-1479' class='msm_infobutton' onmouseover='infoopen(1479)'>i</a><div id="dialog-1479" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the norm operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1479' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <span> length 1 and the same direction as $\Vect{x}$
                     </span>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>property of the determinant operation      </span><a id='glossaryinfo-10250' class='msm_infobutton' onmouseover='infoopen(10250)'>i</a><div id="dialog-10250" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10250' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>relationship to dot product      </span><a id='glossaryinfo-1588' class='msm_infobutton' onmouseover='infoopen(1588)'>i</a><div id="dialog-1588" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1588' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>normal      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-2330' class='msm_infobutton' onmouseover='infoopen(2330)'>i</a><div id="dialog-2330" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>to a hyperspace in $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2330' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>null space      </span><a id='glossaryinfo-11504' class='msm_infobutton' onmouseover='infoopen(11504)'>i</a><div id="dialog-11504" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11504' style='display:none;'><br /><div class='def'><span class='deftitle'>Null space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The null space of an $(m,n)$-matrix $\Mtrx{A}$ is the collection of all those $\Vect{x}$ in $\RNr{n}$ with $\Mtrx{A}\cdot \Vect{x} = \Vect{0}$. We denote it by $\NllSp{ \Mtrx{A} }$
                     </span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of linear transformations      </span><ul class='chilren'><li><span>sum      </span><a id='glossaryinfo-17719' class='msm_infobutton' onmouseover='infoopen(17719)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17719' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>ordered      </span><ul class='chilren'><li><span>basis      </span><a id='glossaryinfo-13326' class='msm_infobutton' onmouseover='infoopen(13326)'>i</a><div id="dialog-13326" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... when used to define a coordinate vector.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13326' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-14801' class='msm_infobutton' onmouseover='infoopen(14801)'>i</a><div id="dialog-14801" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14801' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div></li></ul></li><li><span>ordered pair      </span><a id='glossaryinfo-105' class='msm_infobutton' onmouseover='infoopen(105)'>i</a><div id="dialog-105" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>another word for $2$-tuple; i.e. an expression of the form $(x,y)$, where $x$ and $y$ are numbers.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-105' style='display:none;'><div class='title'>Visualizing $\RNr{n}$
      </div><p xmlns="Unit">
               <span>If $n$ is one of the integers $1,2,3$, then we may visualize $\RNr{n}$ as follows</span>
            </p>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{}=\RNr{1}$: The set of all <span> 
                        $1$-tuples</span>   forms a line on which one point has been designated to be $0$, and a unit of measurement has been chosen. &#x2013; It is customary to call the line the $x$-<b>axis</b>.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R1_illstrtn.gif" height="50" width="350"/></div>
               </span>
            </p>

<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{2}$: The set of all <span> 
                        $2$-tuples or ordered pairs</span>  
			forms a plane on which one point $\mathbf{0}$ has been designated to be the origin, and two perpendicular lines with a unit of measurement have been chosen. &#x2013; It is customary to draw one of these axes horizontal and call it the $x$-<b>axis</b>. The other line will then appear vertical and will be called the $y$-<b>axis</b>.
		</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R2_illstrtn.gif" height="345.47413793103" width="350"/></div>
               </span>
            </p>

<p xmlns="Unit">
               <span>If we want to give the name $P$ to the point $(2,1)$
                  <span> displayed above</span>  , we write $P(2,1)$ to express that it has coordinates $2$ and $1$.</span>
            </p>

<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{3}$: The set of all <span> 
                        $3$-tuples or ordered triples</span>   can be related to points in the world surrounding us. We pick one point, $\mathbf{0}$, to act as the origin. Then we pick three perpendicular lines with a unit of measurement.. &#x2013; In the picture below,
		</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>the first coordinate axis points toward you. We call it the $x$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> the second coordinate axis goes from left to right. We call the $y$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the third coordinate axis has a vertical direction. We call it the $z$-axis</span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R3_illstrtn.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we want to give the name $Q$ to the point $(3,2,2)$ displayed above, we write $Q(3,2,2)$. To plot it, consider the box in the picture above. Then, starting from the origin,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>move 3 units in the $x$-direction (to arrive a the bottom front left corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $y$-direction (to arrive at the front right bottom corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $z$-direction (to arrive at the blue corner of the box)</span>
                  </p>
               </li>
            </ol>
<p xmlns="Unit">
               <span>You can also see an 
			<span> animation</span>    of this plotting process for several points in $\RNr{3}$.</span>
            </p>
<p xmlns="Unit">
               <span>Note that, in $\RNr{3}$,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>points on the first coordinate axis are given by triples of the form $(x,0,0)$, where $x$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the second coordinate axis are given by triples of the form $(0,y,0)$, where $y$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the third coordinate axis are given by triples of the form $(0,0,z)$, where $z$ is an arbitrary number.</span>
                  </p>
               </li>
            </ol></div></li><li><span>orientation      </span><ul class='chilren'><li><span>1-dimensional      </span><a id='glossaryinfo-10032' class='msm_infobutton' onmouseover='infoopen(10032)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10032' style='display:none;'><div class='title'>1-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Forward&#x2019; and &#x2018;backward&#x2019; on a line are 
				<span> mirrored siblings</span>  .
				An orientation of $\RNr{}$ is given by a choice of one of these two directions. We use a nonzero vector $\Vect{x}=(x)$ to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&gt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the positive orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&lt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the negative orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>2-dimensional      </span><a id='glossaryinfo-10046' class='msm_infobutton' onmouseover='infoopen(10046)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10046' style='display:none;'><div class='title'>2-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Counterclockwise&#x2019; and &#x2018;clockwise&#x2019; motions in the plane are 
				<span> mirrored siblings</span>  .
				An orientation of $\RNr{2}$ is given by a choice of one of these two directions. We use an ordered pair $(\Vect{x},\Vect{y})$ of noncolinear vectors to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the counterclockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the positive orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the clockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the negative orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>3-dimensional      </span><a id='glossaryinfo-10071' class='msm_infobutton' onmouseover='infoopen(10071)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10071' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>left hand      </span><a id='glossaryinfo-10115' class='msm_infobutton' onmouseover='infoopen(10115)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10115' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>of a subspace of $\RNr{k}$      </span><a id='glossaryinfo-14510' class='msm_infobutton' onmouseover='infoopen(14510)'>i</a><div id="dialog-14510" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is given by the choice of an ordered $n$-tuple $\EuScript{B} = (\Vect{b}_1, \dots , \Vect{b}_n)$ of $V$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14510' style='display:none;'><br /><div class='def'><span class='deftitle'>Orientation of a subspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>An orientation of an $n$-dimensional subspace $V$ of $\RNr{k}$ is given by a choice of an ordered basis $\EuScript{B} = (\Vect{b}_1 , \dots , \Vect{b}_n )$ of $V$.
				</span>
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>right hand      </span><a id='glossaryinfo-10114' class='msm_infobutton' onmouseover='infoopen(10114)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10114' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>oriented      </span><ul class='chilren'><li><span>volume      </span><a id='glossaryinfo-10280' class='msm_infobutton' onmouseover='infoopen(10280)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10280' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>orthogonal      </span><ul class='chilren'><li><span>complement      </span><a id='glossaryinfo-11464' class='msm_infobutton' onmouseover='infoopen(11464)'>i</a><div id="dialog-11464" class="dialogs" title="Orthogonal complement"><info xmlns="Unit">
                           
                           <p>
                              <span>The orthogonal complement of a subset $S$ in a sub vector space $V$ of $\RNr{n}$ is the set of those $\Vect{x}$ in $V$ which are perpendicular to every $\Vect{s}$ in $S$.   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11464' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal complement</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal complement of a subset $S$ in a subvector space $V$ of $\RNr{n}$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S^{\bot}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11468" class="hottag" onmouseover="popup(11468)">$:=	$</a><div id="dialog-11468" class="dialogs" title="How do you read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#x2018;S perp is defined to be the set of all those $\Vect{x}$ in $V$ such that $\Vect{x}$ dot $\Vect{s}$ equals 0, for all $\Vect{s}$ in S&#x2019;</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st \DotPr{ \Vect{x} }{ \Vect{s} }=0,\ \ \text{for all $\Vect{s}\in S$} }$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>linear transformation      </span><a id='glossaryinfo-17009' class='msm_infobutton' onmouseover='infoopen(17009)'>i</a><div id="dialog-17009" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17009' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>matrix      </span><a id='glossaryinfo-17133' class='msm_infobutton' onmouseover='infoopen(17133)'>i</a><div id="dialog-17133" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17133' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>projection      </span><a id='glossaryinfo-13750' class='msm_infobutton' onmouseover='infoopen(13750)'>i</a><div id="dialog-13750" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Of a subspace $W$ of $\RNr{n}$ onto a subspace $V$ of $W$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13750' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given subspaces $V\subseteq W$ of $\RNr{n}$, the orthogonal projection of $W$ onto $V$ is
				</span>
                     
                     
                  </p>
                  $$\pr_V\from W \longrightarrow V,\quad \pr_V(\Vect{x}) := (\DotPr{ \Vect{x} }{ \Vect{b}_1 })\Vect{b}_1 + \cdots + (\DotPr{ \Vect{x} }{ \Vect{b}_r })\Vect{b}_r$$
                  <p>
                     <span>where $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ is an arbitrary ONB of $V$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>$\RNr{n}$ onto a hyperspace      </span><a id='glossaryinfo-6970' class='msm_infobutton' onmouseover='infoopen(6970)'>i</a><div id="dialog-6970" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6970' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>projection of a vector along a line      </span><a id='glossaryinfo-2193' class='msm_infobutton' onmouseover='infoopen(2193)'>i</a><div id="dialog-2193" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2193' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>projection of a vector along another      </span><a id='glossaryinfo-2236' class='msm_infobutton' onmouseover='infoopen(2236)'>i</a><div id="dialog-2236" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The orthogonal projection of a vector $\Vect{x}$ along $\Vect{y} \neq \Vect{0}$ is the vector </span>
                           </p>
                           $$\pr_{\Vect{y}}(\Vect{x}) := \dfrac{\Vect{x} \bullet \Vect{y} }{\Vect{y} \bullet \Vect{y} \cdot \Vect{y}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2236' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>reflection      </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace      </span><a id='glossaryinfo-15961' class='msm_infobutton' onmouseover='infoopen(15961)'>i</a><div id="dialog-15961" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15961' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>set of vectors      </span><a id='glossaryinfo-12432' class='msm_infobutton' onmouseover='infoopen(12432)'>i</a><div id="dialog-12432" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12432' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>splitting      </span><a id='glossaryinfo-18515' class='msm_infobutton' onmouseover='infoopen(18515)'>i</a><div id="dialog-18515" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The construction of orthogonal splittings.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18515' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal splitting by orthogonal complement</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>In subspaces $V\subseteq W$ of $\RNr{n}$, the spaces $V$ and $V^{\bot}$ form an orthogonal splitting of $W$. Consequently,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(V) + \dim(V^{\bot})$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>splitting of a subspace      </span><a id='glossaryinfo-13682' class='msm_infobutton' onmouseover='infoopen(13682)'>i</a><div id="dialog-13682" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13682' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <span> 
                                    $W=\span(U\cup V)$
                                 </span>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>orthonormal      </span><ul class='chilren'><li><span>set of vectors      </span><a id='glossaryinfo-12434' class='msm_infobutton' onmouseover='infoopen(12434)'>i</a><div id="dialog-12434" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12434' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>overdetermined      </span><ul class='chilren'><li><span>system of linear equations      </span><a id='glossaryinfo-3675' class='msm_infobutton' onmouseover='infoopen(3675)'>i</a><div id="dialog-3675" class="dialogs" title="When is a system of linear equations overdetermined?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A system of linear equations is called overdetermined if the number of equations exceeds the number of variables and the system has no solution.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3675' style='display:none;'><div class='title'>Three or more equations</div><p xmlns="Unit">
                     <span>No matter how many equations there are in a given system of linear equations, each of the equations will have a corresponding hyperplane of solutions. Therefore, the set of simultaneous solutions of the system consists of the intersection of the solution hyperplanes of the individual equations. For example:</span>
                  </p>
<ul xmlns="Unit">
                     <li>
                        <p>
                           <span>Three linear equations in $2$ two variables will often times have 
					<span> no solution</span>  . In this case we say the system is overdetermined.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Three linear equations in $3$ variables will often times have 
					<a id="25">exactly one solution</a>  .
				</span>
                        </p>
                     </li>
                  </ul>
</div><a id='glossaryinfo-3666' class='msm_infobutton' onmouseover='infoopen(3666)'>i</a><div id="dialog-3666" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3666' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>parallel      </span><ul class='chilren'><li><span>hyperplanes      </span><a id='glossaryinfo-2455' class='msm_infobutton' onmouseover='infoopen(2455)'>i</a><div id="dialog-2455" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2455' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>vectors      </span><a id='glossaryinfo-855' class='msm_infobutton' onmouseover='infoopen(855)'>i</a><div id="dialog-855" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-855' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>point      </span><a id='glossaryinfo-281' class='msm_infobutton' onmouseover='infoopen(281)'>i</a><div id="dialog-281" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An $n$-tuple of $\RNr{n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-281' style='display:none;'><div class='title'>The Space $\RNr{n}$
            </div><br /><div class='def'><span class='deftitle'>The set $\RNr{n}$
                     </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For a positive integer $n$, the space $\RNr{n}$ is the set of all $n$-tuples of numbers; in symbols</span>
                           
                        </p>
                        $$\RNr{n}\ :=\ \Set{(x_1,\dots ,x_n)\st x_1,\dots ,x_n\in \RNr{} }$$
                     </def.body><br /></div><br /></div><br /><p xmlns="Unit">
                     <span>We refer to an $n$-tuple of $\RNr{n}$ as a <b>point</b>.
				 
				This terminology is motivated by the following paragraph on ‘Visualizing $\RNr{n}$. We write $P(x_1,\dots ,x_n)$ to say that a point, named $P$, is given by the $n$-tuple $(x_1,\dots ,x_n)$.</span>
                     
                     
                  </p></div></li><li><span>position vector      </span><a id='glossaryinfo-717' class='msm_infobutton' onmouseover='infoopen(717)'>i</a><div id="dialog-717" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The position vector of a $X$ point in $\RNr{n}$ is represented by the arrow $\Arrow{\Vect{0}}{X}$ joining the origin to $X$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-717' style='display:none;'><div class='title'>
               $n$-Tuples for Points and Vectors</div><p xmlns="Unit">
                     <span>Consider these two expressions</span>
                  </p><p xmlns="Unit" align="center">
                     <span>
                        $X(x_1,\dots ,x_n)$   and  $\Vect{x} = (x_1,\dots ,x_n)$.</span>
                  </p><p xmlns="Unit">
                     <span>In the first expression the $n$-tuple  $(x_1,\dots ,x_n)$ characterizes the location of a point. In the second expression the same $n$-tuple forms a coordinate vector. This ambiguity in notation is firmly entrenched in the literature. Fortunately, we can untangle it nicely if we keep in mind the following dictionary for translating between points and vectors.</span>
                     
                  </p>$$
					
            				\xymatrix@C=15pt{
				*+[F-,]{ \txt{A given point\\$X(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{\txt{yields the vector $\Vect{x}=(x_1,\dots ,x_n)$.\\It is represented by the arrow $\Arrow{\Vect{0}}{X}$.\\We call it the {\bf position vector}\index{position vector} of $X$.}} \\
				*+[F-,]{ \txt{A given vector\\$\Vect{x}=(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{ \txt{yields the point $X(x_1,\dots ,x_n)$.\\It is the tip of the arrow with tail at $\Vect{0}$\\and representing $\Vect{x}$.} }
				}
            	
				$$</div></li><li><span>positive definite      </span><ul class='chilren'><li><span>dot product      </span><a id='glossaryinfo-1880' class='msm_infobutton' onmouseover='infoopen(1880)'>i</a><div id="dialog-1880" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The positive definiteness property of the dot product asserts that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1880' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>preimage      </span><ul class='chilren'><li><span>of a linear transformation      </span><a id='glossaryinfo-8335' class='msm_infobutton' onmouseover='infoopen(8335)'>i</a><div id="dialog-8335" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8335' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <span> denoted $T^{-1}(\Vect{y})$
                     </span>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$
<p xmlns="Unit">
               <span>We have 
			<span> seen already</span>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li><li><span>under a function      </span><a id='glossaryinfo-15153' class='msm_infobutton' onmouseover='infoopen(15153)'>i</a><div id="dialog-15153" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Given a function $f\from X\to Y$ and $y\in Y$, the preimage of $y$ under $f$ consists of all those $x\in X$ such that $f(x)=y$; notation $f^{-1}(y)$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15153' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>product      </span><ul class='chilren'><li><span>of subsets of $\RNr{n}$      </span><a id='glossaryinfo-498' class='msm_infobutton' onmouseover='infoopen(498)'>i</a><div id="dialog-498" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to jump to the definition of ‘product of subsets of $\RNr{n}$’.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-498' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of Sets</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a subset $S$ of $\RNr{m}$ by a subset $T$ of $\RNr{n}$ is the subset $S\times T$ of $\RNr{m+n}$ consisting of all those $(m+n)$-tuples $(x_1,\dots ,x_m\, ,\, y_1,\dots ,y_n)$ with $(x_1,\dots ,x_m)$ in $S$ and $(y_1,\dots ,y_n)$ in $T$.</span>
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of two matrices      </span><a id='glossaryinfo-4908' class='msm_infobutton' onmouseover='infoopen(4908)'>i</a><div id="dialog-4908" class="dialogs" title="product of two matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $B$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4908' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>projection      </span><ul class='chilren'><li><span>$\RNr{n}$ onto a hyperspace      </span><a id='glossaryinfo-19570' class='msm_infobutton' onmouseover='infoopen(19570)'>i</a><div id="dialog-19570" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19570' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of a vector along a line      </span><a id='glossaryinfo-17612' class='msm_infobutton' onmouseover='infoopen(17612)'>i</a><div id="dialog-17612" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17612' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>rank      </span><ul class='chilren'><li><span>formula for matrices      </span><a id='glossaryinfo-18734' class='msm_infobutton' onmouseover='infoopen(18734)'>i</a><div id="dialog-18734" class="dialogs" title="Rank formula for matrices"><info xmlns="Theorem">
               
               $$
							
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18734' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Rank formula</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For a matrix $\Mtrx{A}$ of size $(m,n)$,
			</span>
         
      </p>$$
				
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>of a system of linear equations      </span><a id='glossaryinfo-13085' class='msm_infobutton' onmouseover='infoopen(13085)'>i</a><div id="dialog-13085" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Use of the concept while describing the general solution of such a system.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13085' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Infinitely many solutions - constructive version</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Suppose a system of linear equations with $n$ variables has 
			<span> rank</span>  
            $ r&lt;n $. If its RREF-matrix has no leading 1 in the augmentation column</span>
      </p>$$
				
\begin{array}{ccccccccccccccc|c}
0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_1 } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_2 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_r } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 }
\end{array}
					
			$$<p xmlns="Theorem">
         <span>then this system has infinitely many solutions. Moreover, each of its solutions is of the form</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{d}\ + \ t_1 \Vect{b}_1 + \cdots + t_{n-r} \Vect{b}_{n-r}$</td></tr></table><p xmlns="Theorem">
         <span>Here $t_1,\dots ,t_{n-r}$ are arbitrary numbers; and the vectors $\Vect{d}, \Vect{b}_1,\dots ,\Vect{b}_{n-r}$ of $\RNr{n}$ are constructed from the RREF-matrix as follows.
			</span>
         
      </p><ol xmlns="Theorem">
         <li>
            <p>
               <span>Let $\Mtrx{B} = [ b_{ij} ]$ denote the unaugmented part of the RREF-matrix;</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $u_1,\dots ,u_r$ are the columns of $\Mtrx{B}$ containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $j_1,\dots ,j_{n-r}$ are the columns of $\Mtrx{B}$ not containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $\Vect{d}$ is the vector in $\RNr{n}$ with $d_k$ in position $u_k$ and $0$'s elsewhere.</span>
            </p>
         </li>
         <li>
            <p>
               <span>For $1\leq k\leq n-r$, let $\Vect{b}_k$ in $\RNr{n}$ be the vector which has</span>
            </p>
            <ul>
               <li>
                  <p>
                     <span>a &#x2018;$1$&#x2019; in position $j_k$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the entry $(-b_{i,j_k})$ in position $u_i$;</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>a &#x2018;$0$&#x2019; in each remaining position.</span>
                  </p>
               </li>
            </ul>
         </li>
      </ol></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><a id='glossaryinfo-3824' class='msm_infobutton' onmouseover='infoopen(3824)'>i</a><div id="dialog-3824" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>the definition of the rank of a system of linear equations</span>
                                 </p>
                              </info></div></li></ul></li><li><span>reflection      </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace      </span><a id='glossaryinfo-15977' class='msm_infobutton' onmouseover='infoopen(15977)'>i</a><div id="dialog-15977" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15977' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>representing matrix      </span><ul class='chilren'><li><span>of a linear map      </span><a id='glossaryinfo-6690' class='msm_infobutton' onmouseover='infoopen(6690)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6690' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li></ul></li><li><span>right hand      </span><ul class='chilren'><li><span>orientation      </span><a id='glossaryinfo-10116' class='msm_infobutton' onmouseover='infoopen(10116)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10116' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>rule      </span><a id='glossaryinfo-10139' class='msm_infobutton' onmouseover='infoopen(10139)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10139' style='display:none;'><div class='title'>3-Dimensional Orientation</div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<span> mirrored siblings</span>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<span> middle finger</span>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="27">middle finger</a>  
						with $\Vect{z}$.</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<span> closely related concepts</span>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>rotation      </span><a id='glossaryinfo-19524' class='msm_infobutton' onmouseover='infoopen(19524)'>i</a><div id="dialog-19524" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19524' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>finding axis of rotation      </span><a id='glossaryinfo-20251' class='msm_infobutton' onmouseover='infoopen(20251)'>i</a><div id="dialog-20251" class="dialogs"><info xmlns="Compositor">
						            <p>
                     <span>An application of the theory of eigenvectors and eigenvalues: given a rotation of $\RNr{3}$, find its axis of rotation.</span>
                  </p>
					          </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20251' style='display:none;'><div class='title'>Eigenvectors and Eigenvalues</div><h2> Introduction </h2><p xmlns="Unit">
               <span>In this section we introduce the concepts of eigenvector and eigenvalue. Given an $(n,n)$-matrix we learn how to find its eigenvalues and corresponding eigenvectors.</span>
            </p><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>We turn to the question of finding eigenvectors and eigenvectors of a given $(n,n)$-matrix $\Mtrx{A}$.</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Finding eigenvectors and eigenvalues</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>The $(n,n)$-matrix $\Mtrx{A}$ has an eigenvector with eigenvalue $\lambda$ if and only if </span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(A-\lambda \IdMtrx{n})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Characteristic polynomial</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The determinant of the $(n,n)$-matrix $(\Mtrx{A}-\lambda \IdMtrx{n})$ is a polynomial of degree $n$ in the variable $\lambda$, called the characteristic polynomial of $\Mtrx{A}$.
				
				It is of the form
			</span>
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_n \lambda^n + \cdots a_1\lambda + a_0$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>Next we introduce concepts which help us extract information about $\Mtrx{A}$ from its characteristic polynomial.</span>
            </p><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>Suppose we know all of the roots of the characteristic polynomial of a matrix $\Mtrx{A}$. We then face the task of distilling from this information the transformation properties of $\Mtrx{A}$. For this purpose we need the following concept:</span>
            </p><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of 3-space      </span><a id='glossaryinfo-19082' class='msm_infobutton' onmouseover='infoopen(19082)'>i</a><div id="dialog-19082" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>A section on arbitrary rotations in $\RNr{3}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19082' style='display:none;'><div class='title'>Rotations of 3-Space</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>Here we learn how to find the standard coordinate matrix of a 
			<span> rotation of $\RNr{3}$
                     </span>  
			about an arbitrary axis and through a specified angle. Actually, we need to be a bit more careful here: There are two directions in which we rotate about an axis. So we need a way of distinguishing between these directions. This is accomplished with the following setup.
			</span>
               
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>Orient the axis $\mathbf{L}$ of rotation by a unit vector $\Vect{r}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Align the thumb of your right hand with $\Vect{r}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We say that the rotation is by the Right Hand Rule, if the remaining fingers of your right hand curl around the axis in the direction of the rotation. Else we say that the rotation is by the Left Hand Rule. To find the $(3,3)$-matrix representing such a rotation with respect to standard coordinates, we use the following approach:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Let $\Vect{a}$ be any unit vector which is perpendicular to $\Vect{r}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Set $\Vect{b} := \CrssPr{ \Vect{r} }{ \Vect{a} }$
                     </span>
                  </p>
               </li>
            </ol>
<p xmlns="Unit">
               <span>It follows that the ordered vector triple $\EuScript{B} := (\Vect{a},\Vect{b},\Vect{r})$ is an
			<span> ONB</span>  
			of $\RNr{3}$ representing the 
			<a id="28">RHO</a>  ,
			and with respect to this basis we now describe the rotation.</span>
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Rotation matrix in $\RNr{3}$
   </span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>With the setup described above, the rotation $R$ about the oriented axis $\mathbf{L}$ through the angle $\alpha$ by the RHR is represented by the $(3,3)$-matrix</span>
      </p>$$
				
\Mtrx{A}_{\EuScript{B}\EuScript{B}}\ :=\ 
\left[
\begin{array}{rrr}
\cos \alpha &amp; -\sin \alpha &amp; 0 \\
\sin \alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right]

			$$<p xmlns="Theorem">
         <span>Moreover, the matrix which represents $R$ with respect to standard coordinates is (using $\Mtrx{C}:= [ \Vect{a}\ \Vect{b}\ \Vect{r}]$)</span>
      </p>$$\Mtrx{A} = \Mtrx{A}_{\EuScript{S}\EuScript{S}} = \Mtrx{C} \Mtrx{A}_{\EuScript{B}\EuScript{B}} C^{-1}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The transformation effect of a rotation is reversible, namely by a rotation through the same angle in the opposite direction:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Inverse of rotation in $\RNr{3}$
   </span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A rotation about an axis oriented by the unit vector $\Vect{n}$ through the angle $\alpha$ by the RHR is an isomorphism of $\RNr{3}$. Its inverse is the rotation about the same axis through the angle $\alpha$ by the LHR. It is represented by the matrix</span>
      </p>$$
				
\Mtrx{R}_{\EuScript{B}\EuScript{B}}\ :=\ 
\left[
\begin{array}{rrr}
\cos \alpha &amp; \sin \alpha &amp; 0 \\
-\sin \alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>row      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4783' class='msm_infobutton' onmouseover='infoopen(4783)'>i</a><div id="dialog-4783" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4783' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>reduced echelon form      </span><a id='glossaryinfo-3818' class='msm_infobutton' onmouseover='infoopen(3818)'>i</a><div id="dialog-3818" class="dialogs" title="What is row reduced echelon form?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>
                                       <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm is defined here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3818' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>row rescaling matrix      </span><a id='glossaryinfo-5519' class='msm_infobutton' onmouseover='infoopen(5519)'>i</a><div id="dialog-5519" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5519' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>row space      </span><a id='glossaryinfo-11889' class='msm_infobutton' onmouseover='infoopen(11889)'>i</a><div id="dialog-11889" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>The column space of an $(m,n)$-matrix $\Mtrx{A}$ is the subspace of $\RNr{m}$ spanned by the column vectors of $\Mtrx{A}$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11889' style='display:none;'><br /><div class='def'><span class='deftitle'>Row space / column space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given an $(m,n)$-matrix $\Mtrx{A}$ express it in terms of its row and columns vectors</span>
                        </p>
                        $$
					
\Mtrx{A} =
\left[
\begin{array}{ccc}
a_{11} &amp; \cdots &amp; a_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; \cdots &amp; a_{mn}
\end{array}
\right] = 
\left[
\begin{array}{c}
R_1 \\ \vdots \\ R_m
\end{array}
\right] = 
\left[
\begin{array}{ccc}
C_1 &amp; \dots &amp; C_n
\end{array}
\right]
					
					$$
                        <ul>
                           <li>
                              <p>
                                 <span>The row space of $\Mtrx{A}$ is $\RowSp{\Mtrx{A}} := \span \Set{ R_1,\dots ,R_m }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The column space of $\Mtrx{A}$ is $\ColSp{\Mtrx{A}} := \span \Set{ C_1,\dots ,C_n }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                        </ul>
                     </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-11885' class='msm_infobutton' onmouseover='infoopen(11885)'>i</a><div id="dialog-11885" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>The row space of an $(m,n)$-matrix $\Mtrx{A}$ is the subspace of $\RNr{n}$ spanned by the row vectors of $\Mtrx{A}$.</span>
                                       </p>
                                    </info></div></li><li><span>RREF      </span><a id='glossaryinfo-3820' class='msm_infobutton' onmouseover='infoopen(3820)'>i</a><div id="dialog-3820" class="dialogs" title="What does RREF mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>RREF is the acronym for <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm. Its definition is given here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3820' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>scalar product      </span><ul class='chilren'><li><span>of a linear map by a number      </span><a id='glossaryinfo-16515' class='msm_infobutton' onmouseover='infoopen(16515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16515' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of a linear transformation      </span><ul class='chilren'><li><span>represented by scalar product of matrix      </span><a id='glossaryinfo-7598' class='msm_infobutton' onmouseover='infoopen(7598)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7598' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Scalar product  of a linear map is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L\from \RNr{n} \longrightarrow \RNr{m}$ is a linear transformations and $t\in \RNr{}$ is a number, the scalar product of $L$ by $t$
         </span>
         
      </p>$$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) = t\cdot L(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(m,n)$-matrix representing $L$, then $(t\cdot \Mtrx{A})$ represents $(tL)$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>of a matrix      </span><a id='glossaryinfo-4897' class='msm_infobutton' onmouseover='infoopen(4897)'>i</a><div id="dialog-4897" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4897' style='display:none;'><div class='title'>Matrix Operations</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we explain how to add matrices, how to multiply a matrix by a number, how to multiply two matrices, and what the transpose of a matrix is. The system of all matrices, endowed with these operations, forms a vast and powerful extension of the system of real number $\RNr{}$.</span>
            </p><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Scalar Product of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The (scalar) product of a matrix $A = [a_{ij}]$ by a number $t$ is</span>
                  </p>
                  $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>Addition of matrices and scalar multiplying a matrix by a number probably seem familiar because they behave completely like the corresponding operations on vectors. However, the next operation, multiplying one matrix by another, is new. Please pay particular attention to the size compatibility we require if we want to multiply two matrices.</span>
            </p><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>The transpose operation helps us single out the following special kind of matrix:</span>
            </p><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>scaling      </span><ul class='chilren'><li><span>factor      </span><a id='glossaryinfo-6883' class='msm_infobutton' onmouseover='infoopen(6883)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6883' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>transformation      </span><a id='glossaryinfo-6881' class='msm_infobutton' onmouseover='infoopen(6881)'>i</a><div id="dialog-6881" class="dialogs" title="What is a scaling transformation?"><info xmlns="Unit">
                           
                           <p>
                              <span>A scaling transformation is a linear transformation of $\RNr{n}$ of the form $S(\Vect{x}) = s\cdot \Vect{x}$, with $s\in\RNr{}$ fixed.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6881' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>shear      </span><ul class='chilren'><li><span>transformation of $\RNr{n}$ parallel to a hyperspace      </span><a id='glossaryinfo-7102' class='msm_infobutton' onmouseover='infoopen(7102)'>i</a><div id="dialog-7102" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7102' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>slanted box      </span><a id='glossaryinfo-10256' class='msm_infobutton' onmouseover='infoopen(10256)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10256' style='display:none;'><br /><div class='def'><span class='deftitle'>Slanted box</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{n}$, the slanted box determined by an $n$-tuple of vectors $(\Vect{x}_1,\dots ,\Vect{x}_n)$ is
					</span>
                           
                        </p>
                        $$\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } := \Set{ t_1 \Vect{x}_1+\cdots +t_n \Vect{x}_n \st 0\leq t_1,\dots ,t_n\leq 1 }$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>span      </span><a id='glossaryinfo-11817' class='msm_infobutton' onmouseover='infoopen(11817)'>i</a><div id="dialog-11817" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors in $S$. – Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11817' style='display:none;'><br /><div class='def'><span class='deftitle'>Span</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $S$. – The span of the empty set is, by definition, the vector space consisting of the origin alone.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>splitting      </span><ul class='chilren'><li><span>of a subspace      </span><a id='glossaryinfo-13678' class='msm_infobutton' onmouseover='infoopen(13678)'>i</a><div id="dialog-13678" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13678' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <span> 
                                    $W=\span(U\cup V)$
                                 </span>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>square      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4772' class='msm_infobutton' onmouseover='infoopen(4772)'>i</a><div id="dialog-4772" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4772' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>subspace      </span><a id='glossaryinfo-11417' class='msm_infobutton' onmouseover='infoopen(11417)'>i</a><div id="dialog-11417" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Subspace = subvector space;   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11417' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>subvector space      </span><a id='glossaryinfo-11415' class='msm_infobutton' onmouseover='infoopen(11415)'>i</a><div id="dialog-11415" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11415' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-16459' class='msm_infobutton' onmouseover='infoopen(16459)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16459' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>represented by sum of matrices      </span><a id='glossaryinfo-7542' class='msm_infobutton' onmouseover='infoopen(7542)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7542' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Sum of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L,T\from \RNr{n} \longrightarrow \RNr{m}$ are two linear transformations, then their sum
			</span>
         
      </p>$$(L+T)\from \RNr{n} \longrightarrow \RNr{m},\quad (L+T)(\Vect{x}) = L(\Vect{x}) + T(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Further, if $\Mtrx{A}$ and $\Mtrx{B}$ are the $(m,n)$-matrices representing $L$ and $T$ respectively, then $\Mtrx{A} + \Mtrx{B}$ represents $L+T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>of matrices      </span><a id='glossaryinfo-4879' class='msm_infobutton' onmouseover='infoopen(4879)'>i</a><div id="dialog-4879" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4879' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>symmetric      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4935' class='msm_infobutton' onmouseover='infoopen(4935)'>i</a><div id="dialog-4935" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4935' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>symmetry      </span><ul class='chilren'><li><span>of dot product      </span><a id='glossaryinfo-1873' class='msm_infobutton' onmouseover='infoopen(1873)'>i</a><div id="dialog-1873" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The symmetry property of the dot product asserts that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1873' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>system of linear equations      </span><a id='glossaryinfo-3483' class='msm_infobutton' onmouseover='infoopen(3483)'>i</a><div id="dialog-3483" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>solutions discussed in geometrical terms</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3483' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>homogeneous      </span><a id='glossaryinfo-4223' class='msm_infobutton' onmouseover='infoopen(4223)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4223' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>inconsistent      </span><a id='glossaryinfo-3668' class='msm_infobutton' onmouseover='infoopen(3668)'>i</a><div id="dialog-3668" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3668' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li><li><span>inhomogeneous      </span><a id='glossaryinfo-4224' class='msm_infobutton' onmouseover='infoopen(4224)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4224' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>overdetermined      </span><a id='glossaryinfo-3670' class='msm_infobutton' onmouseover='infoopen(3670)'>i</a><div id="dialog-3670" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3670' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>translation      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-3063' class='msm_infobutton' onmouseover='infoopen(3063)'>i</a><div id="dialog-3063" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3063' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>transposition      </span><ul class='chilren'><li><span>commutes with determinant      </span><a id='glossaryinfo-9447' class='msm_infobutton' onmouseover='infoopen(9447)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9447' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of a matrix      </span><a id='glossaryinfo-4920' class='msm_infobutton' onmouseover='infoopen(4920)'>i</a><div id="dialog-4920" class="dialogs" title="Transpose of a Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4920' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>triangle inequality      </span><a id='glossaryinfo-1974' class='msm_infobutton' onmouseover='infoopen(1974)'>i</a><div id="dialog-1974" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The triangle inequality asserts that, for any two vectors $\Vect{x}$ and $\Vect{y}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1974' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <span> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </span>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>unit      </span><ul class='chilren'><li><span>lattice of $\RNr{2}$      </span><a id='glossaryinfo-15609' class='msm_infobutton' onmouseover='infoopen(15609)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15609' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>square of $\RNr{2}$      </span><a id='glossaryinfo-15606' class='msm_infobutton' onmouseover='infoopen(15606)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15606' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>vector      </span><a id='glossaryinfo-1694' class='msm_infobutton' onmouseover='infoopen(1694)'>i</a><div id="dialog-1694" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>A vector of length $1$; click to see how to compute the unit vector in the direction of a given nonzero vector.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1694' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <span> length 1 and the same direction as $\Vect{x}$
                     </span>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>unitary      </span><ul class='chilren'><li><span>linear transformation      </span><a id='glossaryinfo-8086' class='msm_infobutton' onmouseover='infoopen(8086)'>i</a><div id="dialog-8086" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8086' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>upper triangular matrix      </span><a id='glossaryinfo-4838' class='msm_infobutton' onmouseover='infoopen(4838)'>i</a><div id="dialog-4838" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4838' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>value      </span><ul class='chilren'><li><span>of element under a function      </span><a id='glossaryinfo-15130' class='msm_infobutton' onmouseover='infoopen(15130)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15130' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<span> sets and functions</span>  .
		</span>
            </p>

<p xmlns="Unit">
               <span>Setting up a
			<span> function</span>  
			begins with selecting two 
			<a id="20">sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <span> Transformation of a planar region</span>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="27">Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>Van der Monde determinant      </span><a id='glossaryinfo-9598' class='msm_infobutton' onmouseover='infoopen(9598)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9598' style='display:none;'><div class='title'>Further properties of the determinant operation</div>
<p xmlns="Unit">
                     <span>The algebraic properties of the determinant operation have a number of 
				<span> consequences</span>  
				which can simplify the task of computing determinants a lot.</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Computing determinants by row reduction</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the $(n,n)$-matrix  $\Mtrx{A}$ can be row reduced to an upper triangular matrix $\Mtrx{U}$ with diagonal entries $d_1,\dots ,d_n$. If this row reduction used</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>
                  $r$ interchanges of rows; and</span>
            </p>
         </li>
         <li>
            <p>
               <span>the multiplication of rows by (nonzero) numbers $c_1,\dots ,c_k$, then</span>
            </p>
         </li>
      </ul>$$\det(\Mtrx{A}) = (-1)^r\cdot \dfrac{d_1\cdots d_n}{c_1\cdots c_k}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of an inverse matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If the matrix $\Mtrx{A}$ is invertible then</span>
      </p>$$\det(\Mtrx{A}^{-1}) = \dfrac{1}{\det(\Mtrx{A})}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>vector      </span><a id='glossaryinfo-680' class='msm_infobutton' onmouseover='infoopen(680)'>i</a><div id="dialog-680" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of ‘vector’</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-680' style='display:none;'><br /><div class='def'><span class='deftitle'>Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>The vector represented by an arrow $\Arrw{AB}$ is the collection of all those arrows in $\RNr{n}$ which are equivalent to $\Arrw{AB}$. We write $\Vect{x} = (x_1,\dots ,x_n)$ if, for any of these arrows
					</span>
                           
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\text{(tip coordinates)} - \text{tail coordinates}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr></table>
                     </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>addition      </span><a id='glossaryinfo-788' class='msm_infobutton' onmouseover='infoopen(788)'>i</a><div id="dialog-788" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-788' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>force      </span><a id='glossaryinfo-3181' class='msm_infobutton' onmouseover='infoopen(3181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3181' style='display:none;'><div class='title'>Vectors Modeling Forces</div><h2> Introduction </h2><p xmlns="Unit">
               <span>When a force acts on an object, it does so in a certain direction and with a certain strength. Thus we can model a force by a vector. The direction in which the force acts corresponds to the direction of the vector, and the magnitude of the force corresponds to the length of the vector.</span>
            </p>
<p xmlns="Unit">
               <span>For example, suppose a vector of length $1$ corresponds to a force of $1000N$. Then the following arrows represent forces as 
			<span> indicated</span>  .
			</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceArrows.gif" height="169" width="319"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>From experiments we learn that several forces acting simultaneously on an object can be consolidated into a single force. Moreover, the consolidated force corresponds to the vector sum of the individual forces. – The picture below illustrates this. Here we have two forces, $F_1$ and $F_2$ acting on an object. The resulting combined force is described by the red vector $F_1 + F_2$.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceSum.gif" height="173" width="391"/></div>
               </span>
            </p>
</div></li><li><span>length      </span><a id='glossaryinfo-1670' class='msm_infobutton' onmouseover='infoopen(1670)'>i</a><div id="dialog-1670" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1670' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>norm      </span><a id='glossaryinfo-1674' class='msm_infobutton' onmouseover='infoopen(1674)'>i</a><div id="dialog-1674" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ its length. It is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1674' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><a id='glossaryinfo-790' class='msm_infobutton' onmouseover='infoopen(790)'>i</a><div id="dialog-790" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-790' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>translation      </span><a id='glossaryinfo-3065' class='msm_infobutton' onmouseover='infoopen(3065)'>i</a><div id="dialog-3065" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3065' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>velocity      </span><a id='glossaryinfo-3152' class='msm_infobutton' onmouseover='infoopen(3152)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3152' style='display:none;'><div class='title'>Vectors Modeling Velocities</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>When a particle moves in space, it changes its location at each instant. This change of location is characterized by the direction and the speed of the motion at that instant. Both data combined comprise the velocity at that instant. As velocity is characterized by direction and magnitude, we may represent it by a 
			<span> vector</span>  . The direction of the vector gives the direction of the motion and the length of the vector corresponds to the speed.
		</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Experiments show that superposition of motions corresponds to addition of the corresponding velocity vectors. For example: The motion of a person on a ship relative to a point on shore is superpositioned from</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>The motion of the water relative to the point on shore</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the ship relative to the water surrounding it</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the person relative to the structure of the ship.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>The velocity vector of the moving person relative to a point on shore is the sum of these three velocity vectors.</span>
            </p><p xmlns="Unit">
               <span>Similarly, the motion of an aircraft relative to the ground depends upon the wind which carries the aircraft and the superimposed motion resulting from the aircraft’s own propulsion.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocitySuperposition.gif" height="173" width="441"/></div>
               </span>
            </p>
</div></li></ul></li><li><span>vectors      </span><ul class='chilren'><li><span>parallel      </span><a id='glossaryinfo-857' class='msm_infobutton' onmouseover='infoopen(857)'>i</a><div id="dialog-857" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-857' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>velocity      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-3151' class='msm_infobutton' onmouseover='infoopen(3151)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3151' style='display:none;'><div class='title'>Vectors Modeling Velocities</div><h2> Introduction </h2>
<p xmlns="Unit">
               <span>When a particle moves in space, it changes its location at each instant. This change of location is characterized by the direction and the speed of the motion at that instant. Both data combined comprise the velocity at that instant. As velocity is characterized by direction and magnitude, we may represent it by a 
			<span> vector</span>  . The direction of the vector gives the direction of the motion and the length of the vector corresponds to the speed.
		</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Experiments show that superposition of motions corresponds to addition of the corresponding velocity vectors. For example: The motion of a person on a ship relative to a point on shore is superpositioned from</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>The motion of the water relative to the point on shore</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the ship relative to the water surrounding it</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the person relative to the structure of the ship.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>The velocity vector of the moving person relative to a point on shore is the sum of these three velocity vectors.</span>
            </p><p xmlns="Unit">
               <span>Similarly, the motion of an aircraft relative to the ground depends upon the wind which carries the aircraft and the superimposed motion resulting from the aircraft’s own propulsion.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocitySuperposition.gif" height="173" width="441"/></div>
               </span>
            </p>
</div></li></ul></li><li><span>velocity vector      </span><a id='glossaryinfo-1133' class='msm_infobutton' onmouseover='infoopen(1133)'>i</a><div id="dialog-1133" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to see the definition of the velocity vector of a linear motion.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1133' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <span> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </span>  , with <a id="25">
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>volume      </span><ul class='chilren'><li><span>of slanted box      </span><a id='glossaryinfo-10277' class='msm_infobutton' onmouseover='infoopen(10277)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10277' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li></ul>