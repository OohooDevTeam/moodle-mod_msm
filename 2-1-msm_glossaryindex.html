<div id='glossarypanel' class='panel'><div class='glossarypanelcontent' id='glossarycontent'><h3> G L O S S A R Y </h3><ul id="glossaryindex" class="treeview-red"><li><span>$\RNr{}$      </span><a id='glossaryinfo-193' class='msm_infobutton' onmouseover='infoopen(193)'>i</a><div id="dialog-193" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>
                                       $\RNr{}$ denotes the set of all real numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-193' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>We will use the symbol $\RNr{}$ to denote the set of all real numbers.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>$n$-tuple      </span><a id='glossaryinfo-206' class='msm_infobutton' onmouseover='infoopen(206)'>i</a><div id="dialog-206" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An expression of the form $(x_1,\dots ,x_n)$, where $x_1,\dots ,x_n$ are numbers.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-206' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-204" class="dialogs"><info xmlns="Unit">
                                    <p>
                                       <span>Read this expression as: ‘(n-tuple) x-one, x-two, to , x-n’.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<a id="hottag-204" class="hottag" onmouseover="popup(204)"> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </a>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>0-matrix      </span><a id='glossaryinfo-4808' class='msm_infobutton' onmouseover='infoopen(4808)'>i</a><div id="dialog-4808" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4808' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>0-transformation      </span><a id='glossaryinfo-15798' class='msm_infobutton' onmouseover='infoopen(15798)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15798' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The $0$-transformation of $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\mathbf{0}\from \RNr{n} \longrightarrow \RNr{m},\quad \mathbf{0}(\Vect{x}) := \Vect{0}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>addition      </span><ul class='chilren'><li><span>matrices      </span><ul class='chilren'><li><span>associativity property      </span><a id='glossaryinfo-5157' class='msm_infobutton' onmouseover='infoopen(5157)'>i</a><div id="dialog-5157" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5157' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutativity      </span><a id='glossaryinfo-5172' class='msm_infobutton' onmouseover='infoopen(5172)'>i</a><div id="dialog-5172" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5172' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>of matrices      </span><a id='glossaryinfo-4883' class='msm_infobutton' onmouseover='infoopen(4883)'>i</a><div id="dialog-4883" class="dialogs" title="addition of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4883' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of vectors      </span><a id='glossaryinfo-792' class='msm_infobutton' onmouseover='infoopen(792)'>i</a><div id="dialog-792" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-792' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>algebraic multiplicity      </span><a id='glossaryinfo-20046' class='msm_infobutton' onmouseover='infoopen(20046)'>i</a><div id="dialog-20046" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20046' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>alternating      </span><ul class='chilren'><li><span>multilinear function      </span><a id='glossaryinfo-9816' class='msm_infobutton' onmouseover='infoopen(9816)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9816' style='display:none;'><div class='title'>Alternating Multilinear Functions</div><h2> Introduction </h2><div id="dialog-9820" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>
                              $M_{nn}$ denotes the set of all matrices of size $(n,n)$.</span>
                        </p>
                     </info></div><div id="dialog-9840" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>See details of this property</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-9840' style='display:none;'><div class='title'>The Multilinearity Property of Determinants</div><p xmlns="Unit">
               <span>The determinant operation is linear in each column. What exactly does this mean? Let $1\leq j\leq n$ be an integer. Let's build an $(n,n)$-matrix by placing a fixed column vector in each column position, except for one, say in position $j$. The result is an $(n,n)$-matrix which looks like this:</span>
            </p>$$[A_1\ \dots\ A_{j-1}\ \ -\ \ A_{j+1}\ \dots\ A_n]$$<p xmlns="Unit">
               <span>Allowing the still vacant $j$-th column to be filled by vectors from $\RNr{n}$ yields a function $L\from \RNr{n}\longrightarrow \RNr{}$:</span>
            </p>$$L(X) := \det[A_1\ \dots A_{j-1}\ X\ A_{j+1}\ \dots\ A_n]$$<div id="dialog-9830" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>So $L$ commutes with vector addition and scalar multiplicaiton. Look up the definition of ‘linear transformation’.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-9830' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div>
<p xmlns="Unit">
               <span>To say that the determinant operation is linear in the $j$-th column means that the function $L$ above is 
				<a id="activehottag-9830" class="activehottag" onmouseover="infoopen(9830)"> linear</a>  . To say the determinant operation is multilinear means that this happens for each column $1\leq j\leq n$. In other words, these two identities hold:</span>
            </p>
$$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$$$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$<p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the determinant operation as a whole is linear and, consequently, to assert that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(\Mtrx{A} + \Mtrx{B})$   and   $(\det(\Mtrx{A}) + \det(\Mtrx{B}))$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Warning</b>   It may be tempting to think that the numbers</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $\det(t\cdot \Mtrx{A})$ and $t\cdot \det(\Mtrx{A})$
               </span>
            </p><p xmlns="Unit">
               <span>are the same. This is, in general, <b>not true</b>. Instead, if $\Mtrx{A}$ has size $(n,n)$, we have the identity</span>
            </p>$$\det(t\cdot \Mtrx{A}) = t^n\cdot \det(\Mtrx{A})$$</div><div id="dialog-9842" class="dialogs" title="What does ‘alternating’ mean?"><info xmlns="Unit">
                        
                        <p>
                           <span>If $\Mtrx{A} = [A_1\ \dots\ A_j\ \dots\ A_k\ \dots\ A_n]$ is a $(n,n)$-matrix with columns $A_1,\dots ,A_n$, the alternating property of the determinant operation means that</span>
                        </p>
                        $$\det [A_1\ \dots\ A_j\ \dots\ A_k\ \dots\ A_n] = -\det[A_1\ \dots\ A_k\ \dots\ A_j\ \dots\ A_n]$$
                        <p>
                           <span>Here we have interchanged the columns numbered $j$ and $k$. All other columns remain in their positions. The effect on the determinant is: it changes its sign. Consequently, if we interchange columns of a matrix repeatedly, say $r$ times, then the determinant of the original matrix and the determinant of the final matrix differ by the sign $(-1)^r$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>This section is more theoretical. It develops the determinant operation as a special case of functions 
			<a id="hottag-9820" class="hottag" onmouseover="popup(9820)"> 
                        $F\from M_{nn} \to \RNr{}$
                     </a>  
			which are 
			<a id="activehottag-9840" class="activehottag" onmouseover="infoopen(9840)"> linear in each column</a>  
			 and have the 
			 <a id="hottag-9842" class="hottag" onmouseover="popup(9842)"> alternating property</a>  .</span>
            </p>
<p xmlns="Unit">
               <span>We know that the determinant function $\det\from M_{nn}\to \RNr{}$ has both of these properties. We will see that these two properties ‘multilinear’ and ‘alternating’ alone characterize the determinant operation in the following sense: if $F\from M_{nn}\to \RNr{}$ is alternating and multilinear then there exists a unique number $c$ in $\RNr{}$ such that $F=c\cdot \det$.
		</span>
               
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of alternating multilinear functions</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $F\from M_{nn}\to \RNr{}$ be any function which is linear in each column and alternating. Then $F$ has the following properties:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}=[A_1\ \dots\ X\ \dots\ X\ \dots\ A_n]$, then $F(\Mtrx{A}) =0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $F[A_1\ \dots\ X\ \dots\ Y\ \dots\ A_n] = F[A_1\ \dots\ (X+tY)\ \dots\ Y\ \dots\ A_n]$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-9851" class="dialogs" title="Explanation of the symbols in this formula"><info xmlns="Theorem">
                        
                        <p>
                           <span>
                              $\SymGrp{n}$ denotes the group of all invertible functions from $\Set{ 1,\dots ,n}$ to itself. $E_{j}$ denotes the $(n,1)$-column matrix which has a ‘$1$’ in position $j$ and $0$’s everywhere else.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}= [a_{ij}]$, 
				<a id="hottag-9851" class="hottag" onmouseover="popup(9851)"> then</a>  
               </span>
            </p>
            $$F(\Mtrx{A}) = \sum_{r\in \SymGrp{n}} a_{r(1)1}\cdots a_{r(n)n} F[E_{r(1)}\ \dots\ E_{r(n)}]$$
         </part.body>
</li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>There exists a unique number $c$ in $\RNr{}$ such that, for each invertible  $r\from \Set{1,\dots ,n} \to \Set{1,\dots ,n}$,</span>
            </p>
            $$F[E(r(1))\dots E(r(n))] = c\cdot \det [E(r(1))\dots E(r(n))] = c\cdot \sign(r)$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>For each $(n,n)$-matrix $\Mtrx{A}$, $F(\Mtrx{A}) = F(\Mtrx{A}^T)$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Uniqueness of the determinant operation</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $F\from M_{nn}\to \RNr{}$ is alternating and linear in each column, then</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$F$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$F(\IdMtrx{n})\cdot \det$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>property of the determinant operation      </span><a id='glossaryinfo-10323' class='msm_infobutton' onmouseover='infoopen(10323)'>i</a><div id="dialog-10323" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10323' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>angle between two vectors      </span><a id='glossaryinfo-1597' class='msm_infobutton' onmouseover='infoopen(1597)'>i</a><div id="dialog-1597" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The angle between two vectors $\Vect{x}$ and $\Vect{y}$ is denoted $\sphericalangle(\Vect{x},\Vect{y})$. Its cosine can be determined using the norm and dot product operations by</span>
                     </p>
                     $$\cos\sphericalangle(\Vect{x},\Vect{y}) = \frac{\DotPr{ \Vect{x} }{ \Vect{y} }}{| \Vect{x} | | \Vect{y} |}$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1597' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1599" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1599" class="hottag" onmouseover="popup(1599)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1969' class='msm_infobutton' onmouseover='infoopen(1969)'>i</a><div id="dialog-1969" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The angle between two vectors $\Vect{x}$ and $\Vect{y}$ is denoted $\sphericalangle(\Vect{x},\Vect{y})$. Its cosine can be determined using the norm and dot product operations by</span>
                     </p>
                     $$\cos\sphericalangle(\Vect{x},\Vect{y}) = \frac{\DotPr{ \Vect{x} }{ \Vect{y} }}{| \Vect{x} | | \Vect{y} |}$$
                  </info></div></li><li><span>antisymmetric      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4939' class='msm_infobutton' onmouseover='infoopen(4939)'>i</a><div id="dialog-4939" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4939' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>arrow      </span><a id='glossaryinfo-629' class='msm_infobutton' onmouseover='infoopen(629)'>i</a><div id="dialog-629" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>in $\RNr{n}$, joining point $P$ to point $Q$.</span>
                                 </p>
                                 <p align="center">
                                    <span>Click to see the definition of arrow.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-629' style='display:none;'><br /><div class='def'><span class='deftitle'>Arrow</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An arrow 
					in $\RNr{n}$ is given by listing two points $P$ and $Q$ of $\RNr{n}$ in order. The first point $P$ is called the tail of the arrow. The second point $Q$ is called the tip of the arrow. We write $\Arrw{PQ}$
					to denote the arrow joining $P$ to $Q$.</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>length      </span><a id='glossaryinfo-648' class='msm_infobutton' onmouseover='infoopen(648)'>i</a><div id="dialog-648" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-648' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>associativity      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of matrix addition      </span><a id='glossaryinfo-5150' class='msm_infobutton' onmouseover='infoopen(5150)'>i</a><div id="dialog-5150" class="dialogs" title="Associativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The associativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $(\Mtrx{A} + \Mtrx{B}) + \Mtrx{C}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + (\Mtrx{B} + \Mtrx{C})$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5150' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>scalar multiplication of matrices      </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>augmented      </span><ul class='chilren'><li><span>coefficient vector      </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>basic coordinate vector      </span><a id='glossaryinfo-698' class='msm_infobutton' onmouseover='infoopen(698)'>i</a><div id="dialog-698" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-698' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>basis      </span><a id='glossaryinfo-12614' class='msm_infobutton' onmouseover='infoopen(12614)'>i</a><div id="dialog-12614" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12614' style='display:none;'><br /><div class='def'><span class='deftitle'>Basis</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-12616" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>The plural of ‘basis’ is ‘bases’.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A 
				<a id="hottag-12616" class="hottag" onmouseover="popup(12616)"> basis</a>  
				
				of a subvector space $V$ of $\RNr{n}$ is a collection of vectors $\EuScript{B}$ satisfying:
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ spans $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $\EuScript{B}$ is linearly independent.</span>
                        </p>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>ordered      </span><a id='glossaryinfo-14803' class='msm_infobutton' onmouseover='infoopen(14803)'>i</a><div id="dialog-14803" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14803' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div><a id='glossaryinfo-13328' class='msm_infobutton' onmouseover='infoopen(13328)'>i</a><div id="dialog-13328" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... when used to define a coordinate vector.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13328' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>bilinearity      </span><ul class='chilren'><li><span>of dot product      </span><a id='glossaryinfo-1863' class='msm_infobutton' onmouseover='infoopen(1863)'>i</a><div id="dialog-1863" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>The bilinearity property of the dot product asserts that</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1863' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>cartesian product      </span><a id='glossaryinfo-490' class='msm_infobutton' onmouseover='infoopen(490)'>i</a><div id="dialog-490" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>of $\RNr{m}$ and $\RNr{n}$ is $\RNr{m+n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-490' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of   $\RNr{m}$ and $\RNr{n}$
               </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The cartesian product of $\RNr{m}$ and $\RNr{n}$ is
				</span>
                     
                  </p>
                  $$\RNr{m}\times \RNr{n}\ :=\ \RNr{m+n},$$
                  <p>
                     <span>i.e. the space of  all $(m+n)$-tuples.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>Cauchy-Schwarz inequality      </span><a id='glossaryinfo-1979' class='msm_infobutton' onmouseover='infoopen(1979)'>i</a><div id="dialog-1979" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The Cauchy-Schwarz inequality asserts that</span>
                     </p>
                     $$| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1979' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1607' class='msm_infobutton' onmouseover='infoopen(1607)'>i</a><div id="dialog-1607" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The Cauchy-Schwarz inequality asserts that</span>
                     </p>
                     $$| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$$
                  </info></div></li><li><span>change of coordinates matrix      </span><a id='glossaryinfo-14395' class='msm_infobutton' onmouseover='infoopen(14395)'>i</a><div id="dialog-14395" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14395' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$<div id="dialog-14342" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-14342' style='display:none;'><div class='title'>Change of Coordinates - Illustration</div><p xmlns="Unit">
               <span>To illustrate the essence of ‘change of coordinates’, consider two ordered bases $\EuScript{A} = (\Vect{a}_1,\Vect{a}_2)$ and $\EuScript{B}=(\Vect{b}_1,\Vect{b}_2)$ in $\RNr{2}$. Now, given a vector $\Vect{x}$ in $\RNr{2}$, we may</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{A}:$
                     </span>
                  </p>
                  $$\Vect{x} = u \Vect{a}_1 + v \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{A}} = (u,v)$$
                  <p>
                     <span>The $\EuScript{A}$-coordinates of $\Vect{x}$ are $(u,v)$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{B}:$
                     </span>
                  </p>
                  $$\Vect{x} = s \Vect{b}_1 + t \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{B}} = (s,t)$$
                  <p>
                     <span>The $\EuScript{B}$-coordinates of $\Vect{x}$ are $(s,t)$
                     </span>
                  </p>
               </li>
            </ol><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ChangeBases.png' height='197.4' width='350'/></div><p xmlns="Unit" align="center">
               <span>Here $\Vect{x}_{\EuScript{A}} = \left( \tfrac{3}{2} , \tfrac{5}{2} \right)$
               </span>
            </p><p xmlns="Unit">
               <span>So we arrive at the question: suppose we know the $\EuScript{A}$-coordinates of $\Vect{x}$, what are its $\EuScript{B}$-coordinates? and, vice versa, suppose we know the $\EuScript{B}$-coordinates of $\Vect{x}$, what are its $\EuScript{A}$-coordinates?</span>
            </p><p xmlns="Unit">
               <span>In the section on ‘Change of Coordinates’, we learn that there is a unique matrix $\Mtrx{C}_{\EuScript{B}\EuScript{A}}$, here of size $(2,2)$, with</span>
            </p>$$\Vect{x}_{\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}\cdot \Vect{x}_{\EuScript{A}}$$<p xmlns="Unit">
               <span>Moreover, the matrix which reverses the change from $\EuScript{A}$-coordinates to $\EuScript{B}$-coordinates is</span>
            </p>$$\Mtrx{C}_{\EuScript{A}\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}^{-1}$$</div>
<p xmlns="Unit">
               <span>What is the <a id="activehottag-14342" class="activehottag" onmouseover="infoopen(14342)"> relationship between the coordinate vectors</a>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>of a composition of linear maps      </span><a id='glossaryinfo-14402' class='msm_infobutton' onmouseover='infoopen(14402)'>i</a><div id="dialog-14402" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14402' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>reversal of coordinate change      </span><a id='glossaryinfo-14418' class='msm_infobutton' onmouseover='infoopen(14418)'>i</a><div id="dialog-14418" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Mtrx{C}_{\EuScript{B}\EuScript{C}}$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-14418' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>characteristic      </span><ul class='chilren'><li><span>polynomial of a matrix      </span><a id='glossaryinfo-20016' class='msm_infobutton' onmouseover='infoopen(20016)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-20016' style='display:none;'><br /><div class='def'><span class='deftitle'>Characteristic polynomial</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The determinant of the $(n,n)$-matrix $(\Mtrx{A}-\lambda \IdMtrx{n})$ is a polynomial of degree $n$ in the variable $\lambda$, called the characteristic polynomial of $\Mtrx{A}$.
				
				It is of the form
			</span>
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_n \lambda^n + \cdots a_1\lambda + a_0$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>coefficient      </span><ul class='chilren'><li><span>of a linear equation      </span><a id='glossaryinfo-3273' class='msm_infobutton' onmouseover='infoopen(3273)'>i</a><div id="dialog-3273" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Look up the definition</span>
                        </p>
                     </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3273' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img id="image-3257" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351" usemap="#LinearEq_1Gnrl"/><map name="LinearEq_1Gnrl"><area id="pic-3259" coords="0,2,24,19" shape="rect" href="#" onmouseover="popup(3259)"><div id="dialog-3259" class="dialogs" title="What does $a_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_1$ is the first coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3261" coords="79,2,103,20" shape="rect" href="#" onmouseover="popup(3261)"><div id="dialog-3261" class="dialogs" title="What does $a_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_2$ is the second coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3263" coords="255,2,284,22" shape="rect" href="#" onmouseover="popup(3263)"><div id="dialog-3263" class="dialogs" title="What does $a_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_n$ is the $n$-th coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3265" coords="25,1,47,18" shape="rect" href="#" onmouseover="popup(3265)"><div id="dialog-3265" class="dialogs" title="What does $x_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_1$ is a variable, also called an unknown. It is the first unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3267" coords="104,1,125,19" shape="rect" href="#" onmouseover="popup(3267)"><div id="dialog-3267" class="dialogs" title="What does $x_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_2$ is a variable, also called an unknown. It is the second unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3269" coords="284,0,304,19" shape="rect" href="#" onmouseover="popup(3269)"><div id="dialog-3269" class="dialogs" title="What does $x_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_n$ is a variable, also called an unknown. It is the $n$-th unknown of this linear equation.</span>
                              </p>
			                        </info></div></area></map></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul><div id="dialog-3301" class="dialogs"><info xmlns="Unit">
			
			                     <p>
                           <span>Preview of a System of Linear Equations</span>
                        </p>
		                   </info></div><div class='refcontent' id='refcontent-3301' style='display:none;'><div class='title'>System of Linear Equations – Preview</div><p xmlns="Unit">
               <span>A system of $m$ linear equation in $n$ unknowns looks like this</span>
            </p>$$
				
				\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
				
			$$<p xmlns="Unit">
               <span>Each row in this system is just a single linear equation in $n$ unknowns. Thus each of the symbols</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $a_{ij}$,   $1\leq i\leq m$,   $1\leq j\leq n$,   and   $c_1,\dots ,c_m$
               </span>
            </p><div id="dialog-3287" class="dialogs" title="What exactly does $(i,j)$ refer to?"><info xmlns="Unit">
                        
                        <p>
                           <span>Note that the symbol $a$ has two subscripts:</span>
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>The first subscript, here named $i$ counts the row in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The second subscript, here named $j$ counts the column in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                        </ol>
                     </info></div>
<p xmlns="Unit">
               <span>represents a number which is assumed to be known. Specifically, the number $a_{ij}$ is called the coefficient in position 
			<a id="hottag-3287" class="hottag" onmouseover="popup(3287)"> 
                        $(i,j)$
                     </a>  
			of the system. The symbols $x_1,\dots ,x_n$ represent variables (unknowns), and we are looking for number values</span>
            </p>
$$x_1 = ?,\quad x_2 = ?,\quad \dots \quad x_n = ?$$<p xmlns="Unit">
               <span>such that all of the equations in the given system are simultaneously true.</span>
            </p><p xmlns="Unit">
               <span>An <b>example</b> of a system of two linear equations in $3$ unknowns is:</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
					\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{1}{\color{red}z} &amp; = &amp; 6 \\
\colorbox{lightgreen}{1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{1}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The coefficients of this system are:</span>
            </p>$$
					
					\begin{array}{rclrclrcl}
a_{11} &amp; = &amp; 2 &amp; \quad a_{12} &amp; = &amp; 3 &amp; \quad a_{13} &amp; = &amp; -1 \\
a_{21} &amp; = &amp; 1 &amp; \quad a_{22} &amp; = &amp; 1 &amp; \quad a_{23} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The variables or unknowns of this system are $x,y,z$.  One solution of this system is given by the number assignments</span>
            </p>$$x:= -6,\quad y := 5,\quad z:=1$$<p xmlns="Unit">
               <span>to the unknowns. Indeed, these assignments render both equations simultaneously  true. Let's check it!</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}-6})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}5}} &amp; - &amp; {\color{red}1} &amp; = &amp; 2 \\
{\color{red}-6} &amp; + &amp; {\color{red}5} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}1}} &amp; = &amp; 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We express this by saying that the triple  $(- 6,5,1)$  is a solution of the given system of linear equations. On the other hand, the triple  $(5,2,3)$  is not a solution of this system, because</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}5})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}2}} &amp; - &amp; {\color{red}3} &amp; = &amp; 13\ \neq 2 \\
{\color{red}5} &amp; + &amp; {\color{red}2} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}3}} &amp; = &amp; 13\ \neq 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We will discuss methods for finding all solutions of a system of linear equations. Applying this method to the system at hand we will find that its solutions form a line in $\RNr{3}$. In particular, this system has infinitely many simultaneous solutions.</span>
            </p></div>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <a id="activehottag-3301" class="activehottag" onmouseover="infoopen(3301)"> system of linear equations</a>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>
<div id="dialog-3316" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>Recall an illustration of a hyperplane</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3316' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div><div id="dialog-3331" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A Preview: how to solve a system of linear equations geometrically</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3331' style='display:none;'><div class='title'>Solving a System of Linear Equations Geometrically - Preview</div><p xmlns="Unit">
               <span>The elimination method of Gauß and Jordan transforms a given system of linear equations in one which has the same solutions as the original one but which is so simple that one can read off its solutions right away. – For example, Gauß–Jordan elimination transforms the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \color{red}z &amp; = &amp; 5 \\
\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; {\color{red}y} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}z} &amp; = &amp; 5 \\
\colorbox{lightgreen}{-1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{7}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{-9}{\color{red}z} &amp; = &amp; 5
\end{array}
					
				$$<p xmlns="Unit">
               <span>of 3 equations with 3 unknowns into the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; {\color{red}} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2 \\
 &amp; + &amp; {\color{red}y} &amp; - &amp; {\color{red}1} &amp; = &amp; 1
\end{array}
					
				$$<div id="dialog-3325" class="dialogs" title="What are the steps in the Gauß-Jordan elimination"><info xmlns="Unit">
                        
                        <p>
                           <span>You can learn details about the steps in the Gauß-Jordan elimination in the so named section. Here our goal is merely to explain that the system of linear equations which result from the Gauß_jordan elimination process can be significantly simpler than the original system of linear equations.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>of 2 equations with 3 unknowns. The 
				<a id="hottag-3325" class="hottag" onmouseover="popup(3325)"> steps taken in this process</a>  
				are designed to ensure that both systems have exactly the same solutions.</span>
            </p>
<p xmlns="Unit">
               <span>So, what’s the difference between the first system and second system above? – In the first system it is not easy to see what the solutions are. However, solutions of the second system are easy to read off: For every choice of  $z$ in $\RNr{}$, setting</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $z:= 1+z$   $x := 2-2z$
               </span>
            </p><p xmlns="Unit">
               <span>yields a triple of simultaneous solutions of the system. For example.</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $z:= 0$ yields $y=1$ and $x=2$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= 1$ yields $y=2$ and $x=0$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= -2$ yields $y=-1$ and $x=6$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>As the two systems of linear equations above are equivalent, each of the number triples $(2,1,0)$, $(0,2,1)$, and $(6,-1,-2)$ is also a simultaneous solution of the three equations of the first system.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<a id="activehottag-3316" class="activehottag" onmouseover="infoopen(3316)"> hyperplane in $\RNr{n}$
                        </a>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="activehottag-3331" class="activehottag" onmouseover="infoopen(3331)"> intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li><li><span>vector      </span><ul class='chilren'><li><span>augmented      </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>in a linear equation      </span><a id='glossaryinfo-3487' class='msm_infobutton' onmouseover='infoopen(3487)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>cofactor      </span><a id='glossaryinfo-8912' class='msm_infobutton' onmouseover='infoopen(8912)'>i</a><div id="dialog-8912" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-cofactor of a matrix $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8912' style='display:none;'><br /><div class='def'><span class='deftitle'>Cofactor of a matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-cofactor of $\Mtrx{A}$ is $(-1)^{i+j}$ times the determinant of the $(i,j)$-minor of $\Mtrx{A}$.</span>
                        </p>
                        $$c_{ij}(\Mtrx{A}) := (-1)^{i+j}\cdot \det(A_{ij})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>colinear      </span><a id='glossaryinfo-2187' class='msm_infobutton' onmouseover='infoopen(2187)'>i</a><div id="dialog-2187" class="dialogs" title="What does ‘colinear’ mean?"><info xmlns="Unit">
                     
                     <p>
                        <span>‘Colinear’ means ‘has the same direction as’.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2187' style='display:none;'><div class='title'>The Projection of a Vector on a Line</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we introduce a construction which appears in many contexts: how to project a vector $\Vect{x}$ onto the line through the origin in the direction of another vector $\Vect{y}$
               </span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/ProjectionVectorLine.png' height='150.390625' width='350'/></div><div id="dialog-2189" class="dialogs" title="What does ‘colinear’ mean?"><info xmlns="Unit">
                        
                        <p>
                           <span>‘Colinear’ means ‘has the same direction as’.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The picture above shows how the vector $\Vect{x}$ gets projected orthogonally onto the line $L$. The result is the vector $\pr_L(\Vect{x})$ which is
   		<a id="hottag-2189" class="hottag" onmouseover="popup(2189)"> colinear</a>   with $\Vect{y}$. The following proposition tells us how to compute this projection vector.
			</span>
               
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>column      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4790' class='msm_infobutton' onmouseover='infoopen(4790)'>i</a><div id="dialog-4790" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4790' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>commutativity      </span><ul class='chilren'><li><span>of matrix addition      </span><a id='glossaryinfo-5165' class='msm_infobutton' onmouseover='infoopen(5165)'>i</a><div id="dialog-5165" class="dialogs" title="Commutativity of matrix addition">
<info xmlns="Theorem">
                     
                     <p>
                        <span>The commutativity property of matrix addition is the identity</span>
                     </p>
                     <math.array column="3">
                        <tr rowspan="1">
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{A} + \Mtrx{B}$
                           </td>
                           <td colspan="1" halign="center" valign="middle">
                              $=$
                           </td>
                           <td colspan="2" halign="center" valign="middle">
                              $\Mtrx{B} + \Mtrx{A}$
                           </td>
                        </tr>
                     </math.array>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-5165' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The addition of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(A+B)+C = A + (B+C)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + B = B + A$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>0 is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A + \mathbf{0} = A = \mathbf{0} + A$
               </span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $(-1)\cdot A$ is the additive inverse of $A$
               </span>
            </p>
            <p align="center">
               <span>
                  $A + (-1)\cdot A = \mathbf{0} = (-1)\cdot A + A$
               </span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>component      </span><ul class='chilren'><li><span>of a vector orthogonal to another      </span><a id='glossaryinfo-2240' class='msm_infobutton' onmouseover='infoopen(2240)'>i</a><div id="dialog-2240" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The component of a vector $\Vect{x}$ orthogonal to another vector $\Vect{y}$ is</span>
                           </p>
                           $$\Vect{u} = \Vect{x} - \pr_{\Vect{y}}(\Vect{x})$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2240' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>composite      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-7655' class='msm_infobutton' onmouseover='infoopen(7655)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7655' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Composite of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $S\from \RNr{p} \to \RNr{n}$ and $T\from \RNr{n} \to \RNr{m}$ are linear transformations, then their composite 
			</span>
         
      </p>$$(T\Comp S)\from \RNr{p} \longrightarrow \RNr{m},\quad (T\Comp S)(\Vect{x}) = T(S(\Vect{x}))$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(n,p)$-matrix representing $S$, and if $\Mtrx{B}$ is the $(m,n)$-matrix representing $T$, then $\Mtrx{B}\Mtrx{A}$ is the $(m,p)$-matrix which represents $T\Comp S$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>represented by matrix product      </span><a id='glossaryinfo-7655' class='msm_infobutton' onmouseover='infoopen(7655)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7655' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Composite of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $S\from \RNr{p} \to \RNr{n}$ and $T\from \RNr{n} \to \RNr{m}$ are linear transformations, then their composite 
			</span>
         
      </p>$$(T\Comp S)\from \RNr{p} \longrightarrow \RNr{m},\quad (T\Comp S)(\Vect{x}) = T(S(\Vect{x}))$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(n,p)$-matrix representing $S$, and if $\Mtrx{B}$ is the $(m,n)$-matrix representing $T$, then $\Mtrx{B}\Mtrx{A}$ is the $(m,p)$-matrix which represents $T\Comp S$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>composition      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-16571' class='msm_infobutton' onmouseover='infoopen(16571)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16571' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>contraction      </span><a id='glossaryinfo-15828' class='msm_infobutton' onmouseover='infoopen(15828)'>i</a><div id="dialog-15828" class="dialogs" title="What is a contraction?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A contraction is a linear transformation $C$ of $\RNr{n}$ of the form $C(\Vect{x})= s\cdot \Vect{x}$, with $ 0 &lt; s &lt; 1 $ a fixed number.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15828' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-17582' class='msm_infobutton' onmouseover='infoopen(17582)'>i</a><div id="dialog-17582" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17582' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><a id='glossaryinfo-17566' class='msm_infobutton' onmouseover='infoopen(17566)'>i</a><div id="dialog-17566" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17566' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li></ul></li><li><span>coordinate      </span><ul class='chilren'><li><span>conversion matrix      </span><a id='glossaryinfo-14391' class='msm_infobutton' onmouseover='infoopen(14391)'>i</a><div id="dialog-14391" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Definition of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14391' style='display:none;'><div class='title'>Change of Coordinates</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Suppose we are given two ordered bases for a vector space $W$:</span>
            </p>$$\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r) \quad\text{and}\quad \EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$$<p xmlns="Unit">
               <span>Then a vector $\Vect{x}$ in $W$ can be expressed in exactly one way as a linear combination of $\EuScript{B}$ and of $\EuScript{C}$:</span>
            </p>$$
				
\begin{array}{rcllrcl}
\Vect{x} &amp; = &amp; s_1 \Vect{b}_1 + \cdots + s_r\Vect{b}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{B}} = (s_1,\dots ,s_r) \\
\Vect{x} &amp; = &amp; t_1 \Vect{c}_1 + \cdots + t_r\Vect{c}_r &amp;\quad \text{so} &amp; \Vect{x}_{\EuScript{C}} = (t_1,\dots ,t_r) \\
\end{array}

			$$<div id="dialog-14342" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>See an illustration of this.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-14342' style='display:none;'><div class='title'>Change of Coordinates - Illustration</div><p xmlns="Unit">
               <span>To illustrate the essence of ‘change of coordinates’, consider two ordered bases $\EuScript{A} = (\Vect{a}_1,\Vect{a}_2)$ and $\EuScript{B}=(\Vect{b}_1,\Vect{b}_2)$ in $\RNr{2}$. Now, given a vector $\Vect{x}$ in $\RNr{2}$, we may</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{A}:$
                     </span>
                  </p>
                  $$\Vect{x} = u \Vect{a}_1 + v \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{A}} = (u,v)$$
                  <p>
                     <span>The $\EuScript{A}$-coordinates of $\Vect{x}$ are $(u,v)$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>express $\Vect{x}$ in a unique way as a linear combination of $\EuScript{B}:$
                     </span>
                  </p>
                  $$\Vect{x} = s \Vect{b}_1 + t \Vect{a}_2,\quad \text{and so}\quad \Vect{x}_{\EuScript{B}} = (s,t)$$
                  <p>
                     <span>The $\EuScript{B}$-coordinates of $\Vect{x}$ are $(s,t)$
                     </span>
                  </p>
               </li>
            </ol><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/SubSpace/ims/ChangeBases.png' height='197.4' width='350'/></div><p xmlns="Unit" align="center">
               <span>Here $\Vect{x}_{\EuScript{A}} = \left( \tfrac{3}{2} , \tfrac{5}{2} \right)$
               </span>
            </p><p xmlns="Unit">
               <span>So we arrive at the question: suppose we know the $\EuScript{A}$-coordinates of $\Vect{x}$, what are its $\EuScript{B}$-coordinates? and, vice versa, suppose we know the $\EuScript{B}$-coordinates of $\Vect{x}$, what are its $\EuScript{A}$-coordinates?</span>
            </p><p xmlns="Unit">
               <span>In the section on ‘Change of Coordinates’, we learn that there is a unique matrix $\Mtrx{C}_{\EuScript{B}\EuScript{A}}$, here of size $(2,2)$, with</span>
            </p>$$\Vect{x}_{\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}\cdot \Vect{x}_{\EuScript{A}}$$<p xmlns="Unit">
               <span>Moreover, the matrix which reverses the change from $\EuScript{A}$-coordinates to $\EuScript{B}$-coordinates is</span>
            </p>$$\Mtrx{C}_{\EuScript{A}\EuScript{B}}\ =\ \Mtrx{C}_{\EuScript{B}\EuScript{A}}^{-1}$$</div>
<p xmlns="Unit">
               <span>What is the <a id="activehottag-14342" class="activehottag" onmouseover="infoopen(14342)"> relationship between the coordinate vectors</a>  
                  $\Vect{x}_{\EuScript{B}}$ and $\Vect{x}_{\EuScript{C}}$?</span>
            </p>
<p xmlns="Unit">
               <span>Here we learn that there is a single matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ which handles all conversions from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates via the vector equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Mtrx{C}_{\EuScript{C}\EuScript{B}}\cdot \Vect{x}_{\EuScript{B}}$</td></tr></table><br /><div class='theorem'><span class='theoremtitle'>Change coordinates matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ and $\EuScript{C}=(\Vect{c}_1,\dots ,\Vect{c}_r)$ of a vector space $W$, let</span>
      </p>$$
				
\Mtrx{C}_{\EuScript CB}\ =\ 
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp;  &amp; \uparrow \\
(\Vect{b}_1)_{\EuScript{C}} &amp; (\Vect{b}_2)_{\EuScript{C}} &amp; \cdots &amp; (\Vect{b}_r)_{\EuScript{C}} \\
\downarrow &amp; \downarrow &amp;  &amp; \downarrow
\end{array}\right]


			$$<p xmlns="Theorem">
         <span>Then, for every $\Vect{x}$ in $W$,</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}_{\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{C}\EuScript{B}} \Vect{x}_{\EuScript{B}}$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, the matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ with this property is unique.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The matrix $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$ is called the change of coordinates matrix or the coordinate conversion matrix from  $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates.
		</span>
               
               
               
            </p><p xmlns="Unit">
               <span>Let us now turn to rules which apply to coordinate conversion matrices: Suppose we are given three ordered bases of a subspace $W$ of $\RNr{n}$, say $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$. We then have associated coordinate conversion matrices</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{C}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{C}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{C}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{C}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Mtrx{C}_{\EuScript{D}\EuScript{B}}$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>  to convert from $\EuScript{B}$-coordinates to $\EuScript{D}$-coordinates</span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>The relationship between these matrices is given by the following:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Properties of coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given ordered bases $\EuScript{B}$, $\EuScript{C}$, and $\EuScript{D}$ of a subvector space $W$ of $\RNr{n}$, the associated coordinate conversion matrices are related by
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{B}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{D}\EuScript{C}} \Mtrx{C}_{\EuScript{C}\EuScript{B}}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Reversing coordinate change</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>If $\EuScript{B}$ and $\EuScript{C}$ are ordered bases of a subvector space $W$ of $\RNr{n}$, then
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}_{\EuScript{B}\EuScript{C}}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\left(\Mtrx{C}_{\EuScript{C}\EuScript{B}}\right)^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>vector      </span><a id='glossaryinfo-13322' class='msm_infobutton' onmouseover='infoopen(13322)'>i</a><div id="dialog-13322" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up the definition of the term.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13322' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>coordinate of an $n$-tuple      </span><a id='glossaryinfo-208' class='msm_infobutton' onmouseover='infoopen(208)'>i</a><div id="dialog-208" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Example for $n=3$: $(5,1,2)$ is a $3$-tuple; i.e. it has 3 positions, each of which is occupied by a number. These numbers are the coordinates of the $3$-tuple. Thus the first coordinate is $5$. The second coordinate is $1$. The third coordinate is $2$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-208' style='display:none;'><br /><div class='def'><span class='deftitle'>
                        $n$-tuple of numbers</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-204" class="dialogs"><info xmlns="Unit">
                                    <p>
                                       <span>Read this expression as: ‘(n-tuple) x-one, x-two, to , x-n’.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given an integer $n\geq 1$, an $n$-tuple of numbers
					 is an expression of the form
					<a id="hottag-204" class="hottag" onmouseover="popup(204)"> 
                                    $(x_1,x_2,\dots ,x_n)$
                                 </a>  .</span>
                           
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>The symbol $x_1$ represents a number, called the first coordinate
							
							of the $n$-tuple.</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The symbol $x_2$ represents a number, called the second coordinate of the $n$-tuple.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>In general, if $1\leq i\leq n$ is an integer, then the $i$-th coordinate of $(x_1,\dots ,x_n)$ is the number $x_i$ in the $i$-th position.</span>
                              </p>
                           </li>
                        </ul>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>coordinate vector      </span><ul class='chilren'><li><span>basic      </span><a id='glossaryinfo-702' class='msm_infobutton' onmouseover='infoopen(702)'>i</a><div id="dialog-702" class="dialogs"><info xmlns="Unit">
                                 $$\Vect{e}_i\ :=\ (\overset{i}{\underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0}})$$
                                 <p>
                                    <span>is the $i$-th basic coordinate vector of $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-702' style='display:none;'><br /><div class='def'><span class='deftitle'>Basic coordinate vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For $1\leq i\leq n$, the $i$-th basic coordinate vector of $\RNr{n}$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Vect{e}_i\ :=\ (\overset{i}{ \underset{\leftarrow\hfill n\hfill \rightarrow}{0,\dots ,0,1,0,\dots ,0} })$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>Cramer’s rule      </span><a id='glossaryinfo-10976' class='msm_infobutton' onmouseover='infoopen(10976)'>i</a><div id="dialog-10976" class="dialogs" title="Cramer’ rule"><info xmlns="Theorem">
               
               <p>
                  <span>is a formula for finding the solution of  a system of $n$ linear equations in $n$ variables.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10976' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Cramer’ rule</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given the system of $n$ linear equations in $n$ variables below,</span>
      </p>$$
				
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{n1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{n2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$}{\color{red}x_n} &amp; = &amp; c_n \\
\end{array}

			$$<p xmlns="Theorem">
         <span>assume that its coefficient matrix $\Mtrx{A} = [a_{ij}]$ satisfies $\det(\Mtrx{A})\neq 0$. Then, for $1\leq j\leq n$,
			</span>
         
      </p>$$
				
{\color{red} x_j}\ =\ \frac{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; \colorbox{lightgreen}{$c_1$} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \colorbox{lightgreen}{$\ \vdots\ $} &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; \colorbox{lightgreen}{$c_n$} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}{\text{det}\begin{bmatrix}
a_{11} &amp; \dots &amp; a_{1j-1} &amp; a_{1j} &amp; a_{1j+1} &amp; \dots &amp; a_{1n} \\
\vdots &amp;       &amp; \vdots   &amp; \vdots &amp; \vdots &amp;      &amp; \vdots \\
a_{n1} &amp; \dots &amp; a_{nj-1} &amp; a_{nj} &amp; a_{nj+1} &amp; \dots &amp; a_{nn}
\end{bmatrix}}

			$$<p xmlns="Theorem">
         <span>The matrix in the denominator matrix is $\Mtrx{A}$, and the matrix in the numerator is formed from $\Mtrx{A}$ by replacing its $j$-th column by the augmentation column of the system, $[c_1\ \dots\ c_n]^T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>cross product      </span><a id='glossaryinfo-10539' class='msm_infobutton' onmouseover='infoopen(10539)'>i</a><div id="dialog-10539" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of the operation</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10539' style='display:none;'><br /><div class='def'><span class='deftitle'>Cross product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The cross product of two vectors in $\RNr{3}$
                           </span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x}=(x_1,x_2,x_3)$   and   $\Vect{y}=(y_1,y_2,y_3)$
                           </span>
                        </p>
                        <p>
                           <span>is the following vector of $\RNr{3}$:
					</span>
                           
                           
                        </p>
                        $$
						
\aligned
\CrssPr{ \Vect{x} }{ \Vect{y} }\ &amp;:=\ \left(
\det
\left[
\begin{array}{cc}
x_2 &amp; y_2 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
- \det \left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_3 &amp; y_3
\end{array}
\right]\ ,\ 
\det
\left[
\begin{array}{cc}
x_1 &amp; y_1 \\
x_2 &amp; y_2
\end{array}
\right]
\right) \\
	&amp;=\ \left( x_2y_3 - x_3y_2 , -(x_1y_3 - x_3y_1) , x_1y_2 - x_2y_1 \right)
\endaligned

					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>determinant      </span><ul class='chilren'><li><span>alternating      </span><a id='glossaryinfo-10645' class='msm_infobutton' onmouseover='infoopen(10645)'>i</a><div id="dialog-10645" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Statement and proof of the alternating property</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10645' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with matrix multiplication      </span><a id='glossaryinfo-9650' class='msm_infobutton' onmouseover='infoopen(9650)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9650' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>commutes with transposition      </span><a id='glossaryinfo-9441' class='msm_infobutton' onmouseover='infoopen(9441)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9441' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>definition using cofactors      </span><a id='glossaryinfo-8919' class='msm_infobutton' onmouseover='infoopen(8919)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-8919' style='display:none;'><br /><div class='def'><span class='deftitle'>Determinant</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Let $n\geq 1$ be an integer for which determinants of matrices of size $(n,n)$ and smaller have been defined. Then the determinant of a matrix
					</span>
                           
                        </p>
                        $$
						
\Mtrx{A} =
\left[
\begin{array}{cccc}
{\color{red} a_{1,1}} &amp; a_{1,2} &amp; \cdots &amp; a_{1,n+1} \\
{\color{red} a_{2,1}} &amp; a_{2,2} &amp; \cdots &amp; a_{2,n+1} \\
{\color{red} \vdots} &amp; \vdots &amp; \ddots &amp; \vdots \\
{\color{red} a_{n+1,1}} &amp; a_{n+1,2} &amp; \cdots &amp; a_{n+1,n+1}
\end{array}
\right]

					$$
                        <p>
                           <span>of size $(n+1,n+1)$ is given by</span>
                        </p>
                        $$\det(A) := {\color{red} a_{1,1}}\cdot c_{1,1}(\Mtrx{A}) + {\color{red} a_{2,1}}\cdot c_{2,1}(\Mtrx{A}) + \cdots + {\color{red} a_{n+1,1}}\cdot c_{n+1,1}(\Mtrx{A}),$$
                        <p>
                           <span>where $c_{i,1}(\Mtrx{A})$ is the $(i,1)$-cofactor of $\Mtrx{A}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>multilinear      </span><a id='glossaryinfo-9077' class='msm_infobutton' onmouseover='infoopen(9077)'>i</a><div id="dialog-9077" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9077' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>norm property      </span><a id='glossaryinfo-9252' class='msm_infobutton' onmouseover='infoopen(9252)'>i</a><div id="dialog-9252" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9252' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of Van der Monde      </span><a id='glossaryinfo-9437' class='msm_infobutton' onmouseover='infoopen(9437)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9437' style='display:none;'><div class='title'>Further properties of the determinant operation</div><div id="dialog-9440" class="dialogs" title="Comment"><info xmlns="Unit">
                              
                              <p>
                                 <span>It is possible to prove the statements below directly from the definition of the determinant by cofactor expansion that we gave earlier. However, it is more efficient to derive these statements from the algebraic properties listed above.</span>
                              </p>
                           </info></div>
<p xmlns="Unit">
                     <span>The algebraic properties of the determinant operation have a number of 
				<a id="hottag-9440" class="hottag" onmouseover="popup(9440)"> consequences</a>  
				which can simplify the task of computing determinants a lot.</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Computing determinants by row reduction</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the $(n,n)$-matrix  $\Mtrx{A}$ can be row reduced to an upper triangular matrix $\Mtrx{U}$ with diagonal entries $d_1,\dots ,d_n$. If this row reduction used</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>
                  $r$ interchanges of rows; and</span>
            </p>
         </li>
         <li>
            <p>
               <span>the multiplication of rows by (nonzero) numbers $c_1,\dots ,c_k$, then</span>
            </p>
         </li>
      </ul>$$\det(\Mtrx{A}) = (-1)^r\cdot \dfrac{d_1\cdots d_n}{c_1\cdots c_k}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of an inverse matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If the matrix $\Mtrx{A}$ is invertible then</span>
      </p>$$\det(\Mtrx{A}^{-1}) = \dfrac{1}{\det(\Mtrx{A})}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>diagonal      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4815' class='msm_infobutton' onmouseover='infoopen(4815)'>i</a><div id="dialog-4815" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4815' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>diagonalizable matrix      </span><a id='glossaryinfo-20263' class='msm_infobutton' onmouseover='infoopen(20263)'>i</a><div id="dialog-20263" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20263' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>dilation      </span><a id='glossaryinfo-15826' class='msm_infobutton' onmouseover='infoopen(15826)'>i</a><div id="dialog-15826" class="dialogs" title="What is a dilation?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A dilation is a linear transformation $D$ of $\RNr{n}$ of the form $D(\Vect{x})= s\cdot \Vect{x}$, with $ s&gt;0 $ a fixed number.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15826' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-6132' class='msm_infobutton' onmouseover='infoopen(6132)'>i</a><div id="dialog-6132" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6132' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li></ul></li><li><span>dimension      </span><a id='glossaryinfo-12712' class='msm_infobutton' onmouseover='infoopen(12712)'>i</a><div id="dialog-12712" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the dimension of a vector space $V$ as the number of basis vectors in $V$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12712' style='display:none;'><br /><div class='def'><span class='deftitle'>Dimension</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dimension of a subvector space $V$ of $\RNr{n}$ is</span>
                  </p>
                  $$\dim(V):= k\quad \text{if $V$ has a basis of $k$ vectors}$$
                  <p>
                     <span>If $V=\Set{ \Vect{0} }$, we set $\dim(V):=0$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>formula for linear transformations      </span><a id='glossaryinfo-18711' class='msm_infobutton' onmouseover='infoopen(18711)'>i</a><div id="dialog-18711" class="dialogs">
<info xmlns="Theorem">
               <math.array column="3">
                  <tr rowspan="1">
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{ V }$
                     </td>
                     <td colspan="1" halign="center" valign="middle">
                        $=$
                     </td>
                     <td colspan="2" halign="center" valign="middle">
                        $\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$
                     </td>
                  </tr>
               </math.array>
            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-18711' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Dimension formula for linear transformations</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>A linear transformation $L\from V\to W$ satisfies
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{ V }$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Dim{\Img{ L }}\ +\ \Dim{ \Ker{ L }}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>direction angle      </span><a id='glossaryinfo-2802' class='msm_infobutton' onmouseover='infoopen(2802)'>i</a><div id="dialog-2802" class="dialogs" title="Direction Angle"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>the angle between a given vector $\mathbf{x}$ in $\RNr{n}$ and one of the coordinate axes.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2802' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-2804" class="dialogs" title="Read this as ..."><info xmlns="Unit">
                                    
                                    <p>
                                       <span>‘omega i is defined to be the angle from $\mathbf{e}_i$ and $\mathbf{x}$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                        <p>
                           <span>Given a vector $\mathbf{x}$ in $\RNr{n}$, and a number $i$, $1 \leq i \leq n$, the $i$-th direction angle of $\mathbf{x}$ is
					</span>
                           
                        </p>
                        <p align="center">
                           <span>
                              <a id="hottag-2804" class="hottag" onmouseover="popup(2804)"> 
                                    $\omega_i\ :=\ \sphericalangle(\mathbf{e}_i,\mathbf{x})$
                                 </a>  
                           </span>
                        </p>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>distance      </span><ul class='chilren'><li><span>preserving linear transformation      </span><a id='glossaryinfo-8080' class='msm_infobutton' onmouseover='infoopen(8080)'>i</a><div id="dialog-8080" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8080' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>distributivity      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>scalar multiplication of matrices      </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>domain      </span><ul class='chilren'><li><span>of a function      </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>dot product      </span><a id='glossaryinfo-1496' class='msm_infobutton' onmouseover='infoopen(1496)'>i</a><div id="dialog-1496" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The dot product of $\Vect{x} = (x_1,\dots ,x_n)$ and $\Vect{y} = (y_1,\dots ,y_n)$ is </span>
                           </p>
                           $$\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1496' style='display:none;'><br /><div class='def'><span class='deftitle'>Dot Product</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The dot product of two vectors in $\RNr{n}$,</span>
                     
                     
                  </p>
                  <p align="center">
                     <span>
                        $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{y} = (y_1,\dots ,y_n)$
                     </span>
                  </p>
                  <p>
                     <span>is the number   $\DotPr{ \Vect{x} }{ \Vect{y} } := x_1y_1 + \cdots + x_ny_n$
                     </span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>algebraic properties      </span><a id='glossaryinfo-1877' class='msm_infobutton' onmouseover='infoopen(1877)'>i</a><div id="dialog-1877" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating the algebraic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1877' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>binomial identities      </span><a id='glossaryinfo-1934' class='msm_infobutton' onmouseover='infoopen(1934)'>i</a><div id="dialog-1934" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the dot product operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1934' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Binomial Identities of the Dot Product Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$ the following binomial identities hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            $$
					
					\aligned
					\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} + \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } + 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} } \\
					\DotPr{ (\Vect{x} - \Vect{y}) }{ (\Vect{x} - \Vect{y}) } &amp;= \DotPr{ \Vect{x} }{ \Vect{x} } - 2(\DotPr{ \Vect{x} }{ \Vect{y} }) + \DotPr{ \Vect{y} }{ \Vect{y} }
					\endaligned

				$$
         </part.body></li><br /><li><part.body xmlns="Theorem">
            $$\DotPr{ (\Vect{x} + \Vect{y}) }{ (\Vect{x} - \Vect{y}) } = \DotPr{ \Vect{x} }{ \Vect{x} } - \DotPr{ \Vect{y} }{ \Vect{y} }$$
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is bilinear      </span><a id='glossaryinfo-1867' class='msm_infobutton' onmouseover='infoopen(1867)'>i</a><div id="dialog-1867" class="dialogs">
<info xmlns="Theorem">
                     <p>
                        <span>That the dot product is bilinear means</span>
                     </p>
                     <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{(\Vect{a} + \Vect{b})}{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{y} }\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{ \Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{ \Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
                  </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-1867' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is symmetry      </span><a id='glossaryinfo-1875' class='msm_infobutton' onmouseover='infoopen(1875)'>i</a><div id="dialog-1875" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is symmetry means that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1875' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>non-degenerate      </span><a id='glossaryinfo-1887' class='msm_infobutton' onmouseover='infoopen(1887)'>i</a><div id="dialog-1887" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is non-degenerate means that</span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1887' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>orthogonality criterion      </span><a id='glossaryinfo-1584' class='msm_infobutton' onmouseover='infoopen(1584)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-1584' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1599" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1599" class="hottag" onmouseover="popup(1599)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>positive definite      </span><a id='glossaryinfo-1882' class='msm_infobutton' onmouseover='infoopen(1882)'>i</a><div id="dialog-1882" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>To say that the dot product is positive definite means that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1882' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>relationship to norm      </span><a id='glossaryinfo-1961' class='msm_infobutton' onmouseover='infoopen(1961)'>i</a><div id="dialog-1961" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1961' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1590' class='msm_infobutton' onmouseover='infoopen(1590)'>i</a><div id="dialog-1590" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div></li></ul></li><li><span>eigenvalue      </span><a id='glossaryinfo-19980' class='msm_infobutton' onmouseover='infoopen(19980)'>i</a><div id="dialog-19980" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19980' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>eigenvector      </span><a id='glossaryinfo-19978' class='msm_infobutton' onmouseover='infoopen(19978)'>i</a><div id="dialog-19978" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19978' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>elementary      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-5542' class='msm_infobutton' onmouseover='infoopen(5542)'>i</a><div id="dialog-5542" class="dialogs" title="elementary matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form</span>
                                 </p>
                                 $$
									
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5542' style='display:none;'><br /><div class='def'><span class='deftitle'>Elementary Matrix</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An elementary matrix of size $(n,n)$ of type $(i,j)$, $1\leq i\neq j\leq n$ is of the form
					</span>
                           
                           
                        </p>
                        $$
						
						E_{ij}(t)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; t &amp; \vdots \\
						0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$t$ in position $(i,j)$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is a matrix of size $(n,p)$, then forming the matrix product $E_{ij}(t)\cdot \Mtrx{B}$ has the effect of adding $t$ times the $j$-th row of $\Mtrx{B}$ to the $i$-th row of $\Mtrx{B}$. Moreover, for each $t$ in $\RNr{}$, $E_{ij}(t)$ is invertible and   $E_{ij}(t)^{-1} = E_{ij}(-t)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>epimorphic linear transformation      </span><a id='glossaryinfo-18837' class='msm_infobutton' onmouseover='infoopen(18837)'>i</a><div id="dialog-18837" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18837' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>epimorphism      </span><a id='glossaryinfo-18841' class='msm_infobutton' onmouseover='infoopen(18841)'>i</a><div id="dialog-18841" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18841' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>equal $n$tuples      </span><a id='glossaryinfo-263' class='msm_infobutton' onmouseover='infoopen(263)'>i</a><div id="dialog-263" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-263' style='display:none;'><br /><div class='def'><span class='deftitle'>Equal $n$-tuples</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two $n$-tuples $(x_1,\dots ,x_n)$ and $(y_1,\dots ,y_n)$ are equal if and only if, for each $1\leq k\leq n$, $x_k=y_k$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-15147' class='msm_infobutton' onmouseover='infoopen(15147)'>i</a><div id="dialog-15147" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Description of the relationship between functions and equations</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15147' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div><ul class='chilren'><li><span>of hyperspace      </span><a id='glossaryinfo-2362' class='msm_infobutton' onmouseover='infoopen(2362)'>i</a><div id="dialog-2362" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The equation whose solutions form the hyperspace in $\RNr{n}$ perpendicular to the normal vector $\Vect{n} = (a_1,\dots ,a_n)$ is</span>
                                 </p>
                                 $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_1 + \cdots + a_nx_n$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2362' style='display:none;'><div class='title'>Hyperspaces</div><p xmlns="Unit">
                     <span>Let us begin by saying in mathematical terms what a hyperspace is.</span>
                  </p><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /><br /><div class='comment'><span class='commenttitle'>Coordinate version of the Hyperspace Equation</span><br/><div class='mathcontent'><comment.body xmlns="Unit">
                        <p>
                           <span>Let us express the dot product equation $\DotPr{\Vect{x}}{\Vect{n}} = 0$ in terms of the coordinates of $\Vect{x}$ and $\Vect{n}$: if</span>
                        </p>
                        <p align="center">
                           <span>
                              $\Vect{x} = (x_1,\dots ,x_n)$   and   $\Vect{n} = (a_1,\dots ,a_n)$,
				</span>
                        </p>
                        <p>
                           <span>then</span>
                        </p>
                        $$0 = \DotPr{\Vect{x}}{\Vect{n}} = a_1x_n + \cdots + a_n x_n$$
                        <p>
                           <span>This means that $\text{Perp}(\Vect{n})$ consists of the solutions of the linear equation</span>
                        </p>
                        $$a_1x_n + \cdots + a_n x_n = 0$$
                        <p>
                           <span>in the variables $x_1,\dots ,x_n$ with coefficients $a_1,\dots ,a_n$. Conversely, given an equation</span>
                        </p>
                        <p align="center">
                           <span>
                              $a_1x_1+ \cdots + a_nx_n = 0$,   with   $\Vect{n} = (a_1,\dots ,a_n) \neq \Vect{0}$, </span>
                        </p>
                        <p>
                           <span>we know that its solutions form the hyperspace $\text{Perp}(\Vect{n})$.
					</span>
                           
                        </p>
                     </comment.body><br /></div><br /></div><br /></div></li></ul></li><li><span>equivalent      </span><ul class='chilren'><li><span>equations      </span><a id='glossaryinfo-2452' class='msm_infobutton' onmouseover='infoopen(2452)'>i</a><div id="dialog-2452" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept of equivalent equations.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2452' style='display:none;'><div class='title'>Hyperplanes</div><div id="dialog-2378" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Pictures which assist you with such an inspection.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-2378' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div>
<p xmlns="Unit">
                     <span>Recall: a hyperplane results from shifting a hyperspace off of the origin. Visual <a id="activehottag-2378" class="activehottag" onmouseover="infoopen(2378)"> inspection</a>   suggests: The location of a hyperplane $H$ is completely determined by a nonzero vector $\Vect{n}$ which is perpendicular to $H$, and a point $P$ on $H$. Accordingly, we have</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Equation of a Hyperplane</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$ and a point $P$ with position vector $\Vect{p}$, the hyperplane perpendicular to $\Vect{n}$ through $P$ is the set of  all those $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ with</span>
      </p>$$\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><div id="dialog-2403" class="dialogs" title="Why ‘a’ normal vector and not ‘the’ normal vector"><info xmlns="Unit">
                              
                              <p>
                                 <span>If $\Vect{n}$ is a normal vector of the given hyperplane, then $2\Vect{n}$, $3\Vect{n}$, etc. are also normal vectors of the hyperplane. Therefore, a given hyperplane has many normal vectors (which are all parallel to one another). For this reason we need to speak of a normal vector of a given hyperplane, rather than of the normal vector.</span>
                              </p>
                           </info></div>
<p xmlns="Unit">
                     <span>The vector $\Vect{n}$ is called <a id="hottag-2403" class="hottag" onmouseover="popup(2403)"> a normal vector</a>   of the specified hyperplane. An equation for one and the same hyperplane can present itself in various guises:</span>
                  </p>
<br /><div class='comment'><span class='commenttitle'>Alternate appearances of hyperplane equation</span><br/><div class='mathcontent'><div id="dialog-2415" class="dialogs" title="Why is this so?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>The symbols $a_1,\dots ,a_n$ and $p_1,\dots ,p_n$ represent fixed numbers. So we obtain a constant</span>
                                    </p>
                                    $$c := a_1p_1 + \cdots + a_n p_n$$
                                    <p>
                                       <span>Therefore the equation $\DotPr{(\Vect{x} - \Vect{p})}{ \Vect{n} } = 0$ is equivalent to</span>
                                    </p>
                                    <p align="center">
                                       <span>
                                          $\DotPr{\Vect{x}}{\Vect{n}} = \DotPr{ \Vect{p} }{\Vect{n} } = c$   or   $a_1x_1 + \cdots + a_n x_n = c$
                                       </span>
                                    </p>
                                 </info></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>The dot product equation $\DotPr{ (\Vect{x} - \Vect{p}) }{ \Vect{n} } = 0$
                              <a id="hottag-2415" class="hottag" onmouseover="popup(2415)"> just differs in appearance</a>   from either one of the two equations below</span>
                        </p>
                        <p align="center">
                           <span>
                              $\DotPr{\Vect{x}}{\Vect{n}} = c$ &#xA0; and &#xA0; $a_1x_1 + \cdots + a_n x_n = c$,</span>
                        </p>
                        <p>
                           <span>where $c:=a_1p_1+\cdots + a_np_n$, $\Vect{x} = (x_1,\dots ,x_n)$, $\Vect{n} = (a_1,\dots ,a_n)$, and $\Vect{p}=(p_1,\dots ,p_n)$. Therefore the solutions of each of these equations forms the same hyperplane as the solutions of any of the other equations.</span>
                        </p>
                        <p>
                           <span>Conversely, if we are given such an equation we can read off a normal vector $\Vect{n} := (a_1,\dots ,a_n)$ to the hyperplane in question. If $a_k\neq 0$, we conclude that the point $P$ with position vector $\Vect{p} := (0,\dots ,0,c/a_k,0,\dots , 0)$ belongs to the hyperplane.</span>
                        </p>
                     </comment.body>
<br /></div><br /></div><br /><br /><div class='comment'><span class='commenttitle'>Equivalent hyperplane equations</span><br/><div class='mathcontent'>
<comment.body xmlns="Unit">
                        <p>
                           <span>Let $u$ be any nonzero number, and consider the two equations below:</span>
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_1 x_1 + \cdots + a_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$c$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$ua_1x_1 + \cdots ua_n x_n$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$uc$</td></tr></table>
                        <p>
                           <span>These two equations are not the same. Still, a vector $\Vect{x} = (x_1, \dots ,x_n)$ satisfies one of them exactly when it satisfies the other. Therefore both equations describe the same hyperplane in $\RNr{n}$. In this situation we call the equations equivalent.
					</span>
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>systems of equations      </span><a id='glossaryinfo-3864' class='msm_infobutton' onmouseover='infoopen(3864)'>i</a><div id="dialog-3864" class="dialogs" title="When are two systems of linear equations equivalent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Two systems of linear equations are equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3864' style='display:none;'><br /><div class='def'><span class='deftitle'>Equivalent systems of linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two systems of equations are called equivalent if they have the same solutions; i.e. each solution of one system is also a solution of the other system.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>function      </span><a id='glossaryinfo-15021' class='msm_infobutton' onmouseover='infoopen(15021)'>i</a><div id="dialog-15021" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>‘Function’ appears here in the introduction to the concept of a linear transformation.</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15021' style='display:none;'><div class='title'>Linear Transformations</div><h2> Introduction </h2><div id="dialog-14953" class="dialogs" title="Give me some idea of a ‘transformation’"><info xmlns="Unit">
                     
				
				                 <p>
                        <span>Examples of transformations result when you take a chunk of playdo or soft rubber and bend, twist, stretch, shrink it as you like.</span>
                     </p>
			               </info></div><div id="dialog-14957" class="dialogs" title="What is a linear transformation?"><info xmlns="Unit">
                     
				
				                 <p>
                        <span>Very roughly: a transformation is linear if it transforms lines into lines. – We will give a precise definition of ‘linear transformation’ later on.</span>
                     </p>
			               </info></div>
<p xmlns="Unit">
            <span>In this chapter we are going to develop a concept that is quite familiar at an intuitive level: that of a 
		<a id="hottag-14953" class="hottag" onmouseover="popup(14953)"> transformation of space</a>  
		together with objects contained in it. Amongst such transformations we focus upon those which are called 
		&#x2018;<a id="hottag-14957" class="hottag" onmouseover="popup(14957)"> linear</a>  &#x2019;.
		Let us consider some examples to see what we mean.
		
	</span>
            
         </p>
<div id="dialog-14968" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A picture illustrating the transformation of an elastic strip into a Möbius strip</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-14968' style='display:none;'><div class='title'>Transformation of a Strip into a Möbius Strip</div><p xmlns="Unit">
               <span>The two pictures below show a planar sheet and then the result of deforming it into a twisted band, called a Möbius strip: give</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/MoebiusStrip1.gif" height="279.70711297071" width="350"/></div> &#xA0; <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/MoebiusStrip2.jpg" height="256" width="240"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>This transformation does not transform lines into lines. So it is not linear.</span>
            </p></div><div id="dialog-14975" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the transformation of a square into a rectangle.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-14975' style='display:none;'><div class='title'>Transformation of a Square into a Rectangle</div><p xmlns="Unit">
               <span>The picture below shows a square (left) and then the result of transforming it into a rectangle.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_SquareRectangle.png' height='99.3125' width='350'/></div><p xmlns="Unit">
               <span>This transformation acts on the square by compressing it a bit vertically and stretching it horizontally. In doing so it transforms lines into lines. We will see that it is a linear transformation.</span>
            </p></div><div id="dialog-14982" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the rotation of a square.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-14982' style='display:none;'><div class='title'>Transformation Given by Rotating a Square</div><p xmlns="Unit">
               <span>The picture below shows a square (left) and then the result of rotating it.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_SquareRotate.png' height='162.75' width='350'/></div><p xmlns="Unit">
               <span>This transformation acts on the square by rotating it about its center through approximately 30 degrees. It transforms lines into lines. We will see that it is linear.</span>
            </p></div><div id="dialog-14989" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the transformation of a left hand into a right hand.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-14989' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a right hand being transformed into a left hand by a reflection.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_HandReflection.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>We will see that reflection transformations are linear.</span>
            </p></div><div id="dialog-14996" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating a shear transformation applied to a cube.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-14996' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a cube being transformed by applying a shear transformation.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg' height='262.5' width='350'/></div><p xmlns="Unit">
               <span>We will see that shear transformations are linear.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>Twisting an elastic strip into a 
			<a id="activehottag-14968" class="activehottag" onmouseover="infoopen(14968)"> M&#xF6;bius strip</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-14975" class="activehottag" onmouseover="infoopen(14975)"> Stretching a square into a rectangle</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-14982" class="activehottag" onmouseover="infoopen(14982)"> Rotating a square</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-14989" class="activehottag" onmouseover="infoopen(14989)"> Mirroring an object</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-14996" class="activehottag" onmouseover="infoopen(14996)"> Shearing an object</a>  
                  </span>
               </p>
            </li>
	        </ul>
<div id="dialog-15019" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of how a function describes a transformation.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15019' style='display:none;'><div class='title'>Preview: Function Describes Transformation</div><p xmlns="Unit">
               <span>The concept of a function is properly introduced within the context of set theory. Here we describe in pictorial terms how it may be interpreted as transforming objects.</span>
            </p><p xmlns="Unit">
               <span>In the graphic below the blob $B$ on the left gets transformed into the object $Z$ on the right. In the process, each point of $B$ gets relocated to some point of $Z$. It is this act of relocating points of $B$ to points of $Z$ which is described by a function.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png' height='213.9375' width='350'/></div><p xmlns="Unit">
               <span>Let's now analyze how a function transforms an object. A function $f$ from $B$ to $Z$, denoted $f\from B\to Z$ sends each $x$ of $B$ to some $z$ in $Z$. Note that there must be exactly one $z$ to which $x$ gets transformed. We write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$z$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-15008' class='hottag' onmouseover='popup(15008)'>$=	$</a><div id="dialog-15008" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Read: ‘z equals f of x’</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(x)$</td></tr></table><p xmlns="Unit">
               <span>to express that $f$ transforms $x$ into $z$. Thus $f$ ‘knows’ for each $x$ in $B$ to which point in $Z$ it must be relocated. Accordingly, we think of $f$ as executing the given transformation.</span>
            </p><p xmlns="Unit">
               <span>It is allowed that two or more distinct points of $B$ get transformed into the same point of $Z$. In the graphic above this applies to the points labeled $u_1$ and $u_2$. We therefore have the equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(u_1)$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-15016' class='hottag' onmouseover='popup(15016)'>$=	$</a><div id="dialog-15016" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>To see why we have this equation, recall that $f(u_1)$ is the point of $Z$ into which $u_1$ gets transformed. Similarly, $f(u_2)$ is the point of $Z$ into which $u_2$ gets transformed.</span>
                           </p>
                           <p>
                              <span>Here both of $u_1$ and $u_2$ get transformed into the same point of $Z$. Therefore we have the stated equation.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(u_2)$</td></tr></table></div><div id="dialog-15030" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>Preview description of a linear function</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15030' style='display:none;'><div class='title'>Preview: Linear Function</div><p xmlns="Unit">
               <span>A function $L\from \RNr{n}\to \RNr{m}$ is linear if it satisfies the two properties below</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in \RNr{}$, and $\Vect{x}\in \RNr{n}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>Thus $L$ transforms points of $\RNr{n}$ into points of $\RNr{m}$.</span>
            </p><p xmlns="Unit">
               <span>The first identity asserts that $L$ transforms the vector sum $\Vect{x} + \Vect{y}$ of $\RNr{n}$ into the vector of $\RNr{m}$ obtained by</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>first transforming $\Vect{x}$ so as to obtain $L(\Vect{x})$,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>then transforming $\Vect{y}$ so as to obtain $L(\Vect{y})$,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>finally adding up the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>The second identity implies that $L$ transforms the line of vectors $t\cdot \Vect{x}$ through the origin of $\RNr{n}$ into the line of vectors $t\cdot L(\Vect{x})$ of $\RNr{m}$.</span>
            </p></div>
<p xmlns="Unit">
            <span>To describe the effect of a transformation mathematically, we use the concept of a 
		<a id="activehottag-15019" class="activehottag" onmouseover="infoopen(15019)"> function</a>  .
		
		
		There is a collection of functions which are particularly nice to work with. These are the 
		<a id="activehottag-15030" class="activehottag" onmouseover="infoopen(15030)"> linear functions</a>  ,
		also called linear maps, linear homomorphisms, or linear transformations.</span>
            
         </p>
<div id="dialog-15041" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of the relationship between linear maps and matrices</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15041' style='display:none;'><div class='title'>Preview: Linear Maps and Matrices</div><p xmlns="Unit">
               <span>Linear functions and matrices are intimately related via the following two facts. The first says that every matrix yields a linear function; the second says that every linear function arises in this way.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Theorem</b>    Every matrix $\Mtrx{A}$ of size $(m,n)$ yields a linear transformation $L\from \RNr{n}\to \RNr{m}$ via the identity</span>
            </p>$$L(\Vect{x}) = A\cdot \Vect{x}$$<p xmlns="Unit">
               <span>On the right of this equation we multiply $\Mtrx{A}$ by the column vector $\Vect{x}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Theorem</b>   Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
            </p>$$
					
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
				$$<p xmlns="Unit">
               <span>i.e. the $j$-th column of $\Mtrx{A}$ is the column vector obtained by transforming the $j$-th coordinate vector of $\RNr{n}$ with $L$. Then $L(\Vect{x})=\Mtrx{A}\cdot \Vect{x}$,  for all $\Vect{x}$ in $\RNr{n}$. Moreover, $\Mtrx{A}$,  as defined above, is the only matrix with this property.</span>
            </p></div>
<p xmlns="Unit">
            <span>We find that every linear function can be 
		<a id="activehottag-15041" class="activehottag" onmouseover="infoopen(15041)"> described by a matrix</a>  
		and, conversely, every matrix describes a linear function. Thus we can leverage our knowledge of matrix algebra in the study of linear transformations.</span>
         </p>
<p xmlns="Unit">
            <span>We then discuss in detail the main examples of linear transformations:</span>
         </p><div id="dialog-15061" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a dilation operation</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-15061' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-15070" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a dilation operation</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-15070' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by </span>
            </p>$$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>To understand where this matrix comes from, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Rotation.png' height='167.5625' width='350'/></div><p xmlns="Unit">
               <span>Both $R(\StdBss{1})$ and $R(\StdBss{2})$ result from rotating $\StdBss{1}$ and $\StdBss{2}$ counterclockwise about the origin through the angle $\theta$. So they are vectors of length $1$. Therefore the coordinates of these vectors are as indicated.</span>
            </p></div><div id="dialog-15077" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a shear transformation.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-15077' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a cube being transformed by applying a shear transformation.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg' height='262.5' width='350'/></div><p xmlns="Unit">
               <span>We will see that shear transformations are linear.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>
                     <a id="activehottag-15061" class="activehottag" onmouseover="infoopen(15061)"> Dilations and contractions</a>   &#xA0; such transformations magnify, respectively shrink, the space $\RNr{n}$.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-15070" class="activehottag" onmouseover="infoopen(15070)"> Rotations</a>   &#xA0; a rotation of $\RNr{2}$ rotates the plane about the origin.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-15077" class="activehottag" onmouseover="infoopen(15077)"> Shear maps</a>   &#xA0; a shear transformation of $\RNr{n}$ turns a cube into a &#x2018;slanted box&#x2019;.
		</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>These three examples of linear transformations are ‘atomic’ in the sense that every linear transformation can be built from them, as we will learn later on.</span>
         </p><div id="dialog-15085" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of some properties that are particular to linear transformations.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15085' style='display:none;'><div class='title'>Preview: Properties of Linear Transformations</div><p xmlns="Unit">
               <span>Here are two basic properties which are specific to linear transformations and are not enjoyed by every transformation.</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>A linear transformation $f\from \RNr{n}\to \RNr{m}$ sends the $0$-vector of $\RNr{n}$ to the $0$-vector of $\RNr{m}$; in symbols: $f(\Vect{0}) = \Vect{0}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>A linear transformation $f\from \RNr{n}\to \RNr{m}$ transforms any linear motion in $\RNr{n}$ into a linear motion in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>The first property is frequently helpful in detecting non-linear maps. The second property explains the name "linear transformations".</span>
            </p></div><div id="dialog-15091" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of how to build new linear transformations from suitable given ones.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15091' style='display:none;'><div class='title'>Preview: New Linear Transformations from Given Ones</div><p xmlns="Unit">
               <span>Here we discuss three ways of generating a new linear transformation from given ones</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>The sum of two linear transformations $L,T\from \RNr{n}\to \RNr{m}$ is again linear, and it is given by</span>
                  </p>
                  $$L+T\from \RNr{n} \longrightarrow \RNr{m},\qquad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
               </li>
               <li>
                  <p>
                     <span>The scalar product of a linear transformation $L\from \RNr{n}\to \RNr{m}$ by a number $t\in \RNr{}$ is again linear, and it is given by</span>
                  </p>
                  $$(tL)\from \RNr{n}\longrightarrow \RNr{m},\qquad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
               </li>
               <li>
                  <p>
                     <span>The composition of linear transformations $S$ and $T$ with</span>
                  </p>
                  $$\RNr{p} \overset{L}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                  <p>
                     <span>is again linear, and it is given by</span>
                  </p>
                  $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m},\qquad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
               </li>
            </ol><p xmlns="Unit">
               <span>We will discuss these operations in detail later on.</span>
            </p></div>
<p xmlns="Unit">
            <span>Next we consider 
		<a id="activehottag-15085" class="activehottag" onmouseover="infoopen(15085)"> properties</a>  
		enjoyed by linear transformations, but not by arbitrary transformation. For example, such properties help us distinguish transformations which are linear from ones which are not. A section on 
		<a id="activehottag-15091" class="activehottag" onmouseover="infoopen(15091)"> building new linear transformations</a>  
		from known ones follows.</span>
         </p>
<div id="dialog-15097" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of invertible linear transformations</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15097' style='display:none;'><div class='title'>Preview: New Linear Transformations from Given Ones</div><p xmlns="Unit">
               <span>There are some special linear transformations whose effect on space can be reversed. Here are the definition and most relevant facts:</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        <b>Definition</b>   A linear transformation $L\from \RNr{n} \to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                  </p>
                  $$M\Comp L = \IdMtrx{n} = L\Comp M$$
                  <p>
                     <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If the linear transformation $L\from \RNr{n}\to \RNr{n}$ is invertible, with inverse $M=L^{-1}$, then $M$ is also invertible and</span>
                  </p>
                  $$L = M^{-1} = (L^{-1})^{-1}$$
               </li>
               <li>
                  <p>
                     <span>Let $L\from \RNr{n}\to \RNr{m}$ be a linear transformation represented by the matrix $\Mtrx{A}$ of size $(n,n)$. Then $L$ is invertible if and only if $\Mtrx{A}$ is invertible. Moreover, $L^{-1}$  is represented by the matrix $\Mtrx{A}^{-1}$.</span>
                  </p>
               </li>
            </ol></div><div id="dialog-15102" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of distance preserving linear transformations</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-15102' style='display:none;'><div class='title'>Preview: Distance Preserving Linear Transformations</div><p xmlns="Unit">
               <span>Of particular importance for practical purposes are those linear transformations which preserve all distances. This ensures that size and shape of any object remains unaltered by the transformation. Only its position can change. This is something we take for granted when moving an object from one place to another place in the real world. Here are the main facts.</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        <b>Definition</b>   A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,</span>
                  </p>
                  $$\norm{L(\Vect{x})} = \Vect{x}$$
               </li>
               <li>
                  <p>
                     <span>
                        <b>Proposition</b>   Let $L\from \RNr{n}\to \RNr{n}$ be a linear transformation represented by the matrix $\Mtrx{A}$ of size $(n,n)$. Then $L$ preserves all distances if and only if conditions (i) and (ii) below hold:</span>
                  </p>
                  <ol type="i">
                     <li>
                        <p>
                           <span>Each column vector $A_j$ of $\Mtrx{A}$ has length $1$: $\DotPr{A_j}{A_j} = 1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Any two distinct column vectors of $A$ are perpendicular: whenever $1\leq j\neq k\leq n$, $\DotPr{A_j}{A_k} = 0$.</span>
                        </p>
                     </li>
                  </ol>
               </li>
               <li>
                  <p>
                     <span>
                        <b>Corollary</b>   A linear transformation $L\from \RNr{n}\to \RNr{n}$ preserves distances if and only if the transpose of $\Mtrx{A}$ is also the inverse of $\Mtrx{A}$: $\Mtrx{A}^{-1} = \Mtrx{A}^T$.</span>
                  </p>
               </li>
            </ol></div>
<p xmlns="Unit">
            <span>Of particular interest are those linear transformations whose transformation effect can be reversed: These are the
		<a id="activehottag-15097" class="activehottag" onmouseover="infoopen(15097)"> invertible linear transformations</a>  .
		Amongst the invertible linear transformations we find a particularly nice collection: The
		<a id="activehottag-15102" class="activehottag" onmouseover="infoopen(15102)"> distance preserving linear transformations</a>  .
		We encounter those on a daily basis in the form of rotations and reflections.</span>
         </p>
<p xmlns="Unit">
            <span>Linear transformations are also related to systems of linear equations, and this relationship will be explained as well.</span>
         </p></div><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div><ul class='chilren'><li><span>domain      </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>target      </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li><li><span>value      </span><a id='glossaryinfo-6181' class='msm_infobutton' onmouseover='infoopen(6181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6181' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>geometric multiplicity      </span><a id='glossaryinfo-20087' class='msm_infobutton' onmouseover='infoopen(20087)'>i</a><div id="dialog-20087" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20087' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>Gram-Schmidt orthonormalization process      </span><a id='glossaryinfo-14098' class='msm_infobutton' onmouseover='infoopen(14098)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-14098' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Gram-Schmidt orthonormalization</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given an ordered linearly independent set $\EuScript{A}:=(\Vect{a}_1,\dots ,\Vect{a}_r)$ of vectors in $\RNr{n}$, the ordered set of vectors $\EuScript{B}:=(\Vect{v}_1,\dots ,\Vect{v}_r)$ defined below is an ordered ONB of $\span(\EuScript{A})$.
			</span>
         
      </p><table xmlns:default="Theorem" border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_1$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14104" class="hottag" onmouseover="popup(14104)">$:=	$</a><div id="dialog-14104" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_1$ is the normalization of $\Vect{a}_1$; i.e. $\Vect{v}_1$ has the same direction as $\Vect{a}_1$, but has length $1$.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_1 }{ \abs{ \Vect{a}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_2$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14109" class="hottag" onmouseover="popup(14109)">$:=	$</a><div id="dialog-14109" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_2$ is the component of $\Vect{a}_2$ which is perpendicular to $\Vect{v}_1$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1 }{ \abs{ \Vect{a}_2 - (\DotPr{ \Vect{a}_2 }{ \Vect{v}_1 })\Vect{v}_1} }$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\vdots$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"> </td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\qquad \vdots \qquad\qquad \vdots$</td></tr><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{v}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-14118" class="hottag" onmouseover="popup(14118)">$:=	$</a><div id="dialog-14118" class="dialogs" title=""><default:info xmlns="Theorem">
                     <default:p>
                        <default:span>Thus $\Vect{v}_r$ is the component of $\Vect{a}_r$ which is perpendicular to each of $\Vect{v}_1$, ... , $\Vect{v}_{r-1}$, normalized.</default:span>
                     </default:p>
                  </default:info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dfrac{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} }{ \abs{ \Vect{a}_r - (\DotPr{ \Vect{a}_r }{ \Vect{v}_1 })\Vect{v}_1 - (\DotPr{ \Vect{a}_r }{ \Vect{v}_2 })\Vect{v}_2 - \cdots - (\DotPr{ \Vect{a}_r }{ \Vect{v}_{r-1} })\Vect{v}_{r-1} } }$</td></tr></table><p xmlns="Theorem">
         <span>Moreover, $\span\Set{ \Vect{a}_1,\dots ,\Vect{a}_j } = \span\Set{ \Vect{v}_1,\dots ,\Vect{v}_j }$ for each $1\leq j\leq r$ and, if $\Vect{a}_1,\dots ,\Vect{a}_j$ are already orthonormal, then $\Vect{a}_k=\Vect{v}_k$ for each $1\leq k\leq j$.</span>
      </p></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>homogeneous      </span><ul class='chilren'><li><span>linear equation      </span><a id='glossaryinfo-3275' class='msm_infobutton' onmouseover='infoopen(3275)'>i</a><div id="dialog-3275" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = 0$$
					                   <p>
                           <span>Look up the definition</span>
                        </p>
				                 </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3275' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img id="image-3257" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351" usemap="#LinearEq_1Gnrl"/><map name="LinearEq_1Gnrl"><area id="pic-3259" coords="0,2,24,19" shape="rect" href="#" onmouseover="popup(3259)"><div id="dialog-3259" class="dialogs" title="What does $a_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_1$ is the first coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3261" coords="79,2,103,20" shape="rect" href="#" onmouseover="popup(3261)"><div id="dialog-3261" class="dialogs" title="What does $a_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_2$ is the second coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3263" coords="255,2,284,22" shape="rect" href="#" onmouseover="popup(3263)"><div id="dialog-3263" class="dialogs" title="What does $a_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_n$ is the $n$-th coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3265" coords="25,1,47,18" shape="rect" href="#" onmouseover="popup(3265)"><div id="dialog-3265" class="dialogs" title="What does $x_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_1$ is a variable, also called an unknown. It is the first unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3267" coords="104,1,125,19" shape="rect" href="#" onmouseover="popup(3267)"><div id="dialog-3267" class="dialogs" title="What does $x_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_2$ is a variable, also called an unknown. It is the second unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3269" coords="284,0,304,19" shape="rect" href="#" onmouseover="popup(3269)"><div id="dialog-3269" class="dialogs" title="What does $x_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_n$ is a variable, also called an unknown. It is the $n$-th unknown of this linear equation.</span>
                              </p>
			                        </info></div></area></map></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul><div id="dialog-3301" class="dialogs"><info xmlns="Unit">
			
			                     <p>
                           <span>Preview of a System of Linear Equations</span>
                        </p>
		                   </info></div><div class='refcontent' id='refcontent-3301' style='display:none;'><div class='title'>System of Linear Equations – Preview</div><p xmlns="Unit">
               <span>A system of $m$ linear equation in $n$ unknowns looks like this</span>
            </p>$$
				
				\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
				
			$$<p xmlns="Unit">
               <span>Each row in this system is just a single linear equation in $n$ unknowns. Thus each of the symbols</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $a_{ij}$,   $1\leq i\leq m$,   $1\leq j\leq n$,   and   $c_1,\dots ,c_m$
               </span>
            </p><div id="dialog-3287" class="dialogs" title="What exactly does $(i,j)$ refer to?"><info xmlns="Unit">
                        
                        <p>
                           <span>Note that the symbol $a$ has two subscripts:</span>
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>The first subscript, here named $i$ counts the row in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The second subscript, here named $j$ counts the column in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                        </ol>
                     </info></div>
<p xmlns="Unit">
               <span>represents a number which is assumed to be known. Specifically, the number $a_{ij}$ is called the coefficient in position 
			<a id="hottag-3287" class="hottag" onmouseover="popup(3287)"> 
                        $(i,j)$
                     </a>  
			of the system. The symbols $x_1,\dots ,x_n$ represent variables (unknowns), and we are looking for number values</span>
            </p>
$$x_1 = ?,\quad x_2 = ?,\quad \dots \quad x_n = ?$$<p xmlns="Unit">
               <span>such that all of the equations in the given system are simultaneously true.</span>
            </p><p xmlns="Unit">
               <span>An <b>example</b> of a system of two linear equations in $3$ unknowns is:</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
					\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{1}{\color{red}z} &amp; = &amp; 6 \\
\colorbox{lightgreen}{1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{1}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The coefficients of this system are:</span>
            </p>$$
					
					\begin{array}{rclrclrcl}
a_{11} &amp; = &amp; 2 &amp; \quad a_{12} &amp; = &amp; 3 &amp; \quad a_{13} &amp; = &amp; -1 \\
a_{21} &amp; = &amp; 1 &amp; \quad a_{22} &amp; = &amp; 1 &amp; \quad a_{23} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The variables or unknowns of this system are $x,y,z$.  One solution of this system is given by the number assignments</span>
            </p>$$x:= -6,\quad y := 5,\quad z:=1$$<p xmlns="Unit">
               <span>to the unknowns. Indeed, these assignments render both equations simultaneously  true. Let's check it!</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}-6})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}5}} &amp; - &amp; {\color{red}1} &amp; = &amp; 2 \\
{\color{red}-6} &amp; + &amp; {\color{red}5} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}1}} &amp; = &amp; 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We express this by saying that the triple  $(- 6,5,1)$  is a solution of the given system of linear equations. On the other hand, the triple  $(5,2,3)$  is not a solution of this system, because</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}5})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}2}} &amp; - &amp; {\color{red}3} &amp; = &amp; 13\ \neq 2 \\
{\color{red}5} &amp; + &amp; {\color{red}2} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}3}} &amp; = &amp; 13\ \neq 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We will discuss methods for finding all solutions of a system of linear equations. Applying this method to the system at hand we will find that its solutions form a line in $\RNr{3}$. In particular, this system has infinitely many simultaneous solutions.</span>
            </p></div>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <a id="activehottag-3301" class="activehottag" onmouseover="infoopen(3301)"> system of linear equations</a>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>
<div id="dialog-3316" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>Recall an illustration of a hyperplane</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3316' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div><div id="dialog-3331" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A Preview: how to solve a system of linear equations geometrically</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3331' style='display:none;'><div class='title'>Solving a System of Linear Equations Geometrically - Preview</div><p xmlns="Unit">
               <span>The elimination method of Gauß and Jordan transforms a given system of linear equations in one which has the same solutions as the original one but which is so simple that one can read off its solutions right away. – For example, Gauß–Jordan elimination transforms the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \color{red}z &amp; = &amp; 5 \\
\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; {\color{red}y} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}z} &amp; = &amp; 5 \\
\colorbox{lightgreen}{-1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{7}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{-9}{\color{red}z} &amp; = &amp; 5
\end{array}
					
				$$<p xmlns="Unit">
               <span>of 3 equations with 3 unknowns into the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; {\color{red}} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2 \\
 &amp; + &amp; {\color{red}y} &amp; - &amp; {\color{red}1} &amp; = &amp; 1
\end{array}
					
				$$<div id="dialog-3325" class="dialogs" title="What are the steps in the Gauß-Jordan elimination"><info xmlns="Unit">
                        
                        <p>
                           <span>You can learn details about the steps in the Gauß-Jordan elimination in the so named section. Here our goal is merely to explain that the system of linear equations which result from the Gauß_jordan elimination process can be significantly simpler than the original system of linear equations.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>of 2 equations with 3 unknowns. The 
				<a id="hottag-3325" class="hottag" onmouseover="popup(3325)"> steps taken in this process</a>  
				are designed to ensure that both systems have exactly the same solutions.</span>
            </p>
<p xmlns="Unit">
               <span>So, what’s the difference between the first system and second system above? – In the first system it is not easy to see what the solutions are. However, solutions of the second system are easy to read off: For every choice of  $z$ in $\RNr{}$, setting</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $z:= 1+z$   $x := 2-2z$
               </span>
            </p><p xmlns="Unit">
               <span>yields a triple of simultaneous solutions of the system. For example.</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $z:= 0$ yields $y=1$ and $x=2$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= 1$ yields $y=2$ and $x=0$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= -2$ yields $y=-1$ and $x=6$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>As the two systems of linear equations above are equivalent, each of the number triples $(2,1,0)$, $(0,2,1)$, and $(6,-1,-2)$ is also a simultaneous solution of the three equations of the first system.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<a id="activehottag-3316" class="activehottag" onmouseover="infoopen(3316)"> hyperplane in $\RNr{n}$
                        </a>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="activehottag-3331" class="activehottag" onmouseover="infoopen(3331)"> intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li></ul></li><li><span>homogeneous system of linear equations      </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>homomorphism      </span><ul class='chilren'><li><span>of vector spaces      </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>hyperspace      </span><a id='glossaryinfo-2328' class='msm_infobutton' onmouseover='infoopen(2328)'>i</a><div id="dialog-2328" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The hyperspace in $\RNr{n}$ perpendicular to a nonzero vector $\Vect{n}$  is the set</span>
                                 </p>
                                 <p align="center">
                                    <span>
                                       $\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2328' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>identity      </span><ul class='chilren'><li><span>linear transformation of $\RNr{n}$      </span><a id='glossaryinfo-6860' class='msm_infobutton' onmouseover='infoopen(6860)'>i</a><div id="dialog-6860" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6860' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>matrix      </span><a id='glossaryinfo-4822' class='msm_infobutton' onmouseover='infoopen(4822)'>i</a><div id="dialog-4822" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4822' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>image      </span><ul class='chilren'><li><span>of element under a function      </span><a id='glossaryinfo-6181' class='msm_infobutton' onmouseover='infoopen(6181)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6181' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-6186" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-6185" class="externallink" target="sets" onmouseover="popup(6185)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-6196" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-6196' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-6199" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-6196" class="activehottag" onmouseover="infoopen(6196)"> function</a>  
			begins with selecting two 
			<a id="hottag-6199" class="hottag" onmouseover="popup(6199)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-6215" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6215' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-6221" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-6221' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6215" class="activehottag" onmouseover="infoopen(6215)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-6221" class="activehottag" onmouseover="infoopen(6221)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>image of a linear map      </span><a id='glossaryinfo-18618' class='msm_infobutton' onmouseover='infoopen(18618)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18618' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>inconsistent      </span><ul class='chilren'><li><span>system of linear equations      </span><a id='glossaryinfo-3664' class='msm_infobutton' onmouseover='infoopen(3664)'>i</a><div id="dialog-3664" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3664' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>inhomogeneous      </span><ul class='chilren'><li><span>linear equation      </span><a id='glossaryinfo-3277' class='msm_infobutton' onmouseover='infoopen(3277)'>i</a><div id="dialog-3277" class="dialogs" title="What is a homogeneous linear equation?"><info xmlns="Unit">
                        
					
					                   <p>
                           <span>A homogeneous linear equation can be written in the form</span>
                        </p>
					                   $$a_1x_1 + a_2x_2 + \cdots + a_n x_n = c$$
					                   <p>
                           <span>with $c \neq 0$. Look up the definition.</span>
                        </p>
				                 </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3277' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img id="image-3257" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351" usemap="#LinearEq_1Gnrl"/><map name="LinearEq_1Gnrl"><area id="pic-3259" coords="0,2,24,19" shape="rect" href="#" onmouseover="popup(3259)"><div id="dialog-3259" class="dialogs" title="What does $a_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_1$ is the first coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3261" coords="79,2,103,20" shape="rect" href="#" onmouseover="popup(3261)"><div id="dialog-3261" class="dialogs" title="What does $a_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_2$ is the second coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3263" coords="255,2,284,22" shape="rect" href="#" onmouseover="popup(3263)"><div id="dialog-3263" class="dialogs" title="What does $a_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_n$ is the $n$-th coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3265" coords="25,1,47,18" shape="rect" href="#" onmouseover="popup(3265)"><div id="dialog-3265" class="dialogs" title="What does $x_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_1$ is a variable, also called an unknown. It is the first unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3267" coords="104,1,125,19" shape="rect" href="#" onmouseover="popup(3267)"><div id="dialog-3267" class="dialogs" title="What does $x_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_2$ is a variable, also called an unknown. It is the second unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3269" coords="284,0,304,19" shape="rect" href="#" onmouseover="popup(3269)"><div id="dialog-3269" class="dialogs" title="What does $x_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_n$ is a variable, also called an unknown. It is the $n$-th unknown of this linear equation.</span>
                              </p>
			                        </info></div></area></map></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul><div id="dialog-3301" class="dialogs"><info xmlns="Unit">
			
			                     <p>
                           <span>Preview of a System of Linear Equations</span>
                        </p>
		                   </info></div><div class='refcontent' id='refcontent-3301' style='display:none;'><div class='title'>System of Linear Equations – Preview</div><p xmlns="Unit">
               <span>A system of $m$ linear equation in $n$ unknowns looks like this</span>
            </p>$$
				
				\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
				
			$$<p xmlns="Unit">
               <span>Each row in this system is just a single linear equation in $n$ unknowns. Thus each of the symbols</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $a_{ij}$,   $1\leq i\leq m$,   $1\leq j\leq n$,   and   $c_1,\dots ,c_m$
               </span>
            </p><div id="dialog-3287" class="dialogs" title="What exactly does $(i,j)$ refer to?"><info xmlns="Unit">
                        
                        <p>
                           <span>Note that the symbol $a$ has two subscripts:</span>
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>The first subscript, here named $i$ counts the row in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The second subscript, here named $j$ counts the column in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                        </ol>
                     </info></div>
<p xmlns="Unit">
               <span>represents a number which is assumed to be known. Specifically, the number $a_{ij}$ is called the coefficient in position 
			<a id="hottag-3287" class="hottag" onmouseover="popup(3287)"> 
                        $(i,j)$
                     </a>  
			of the system. The symbols $x_1,\dots ,x_n$ represent variables (unknowns), and we are looking for number values</span>
            </p>
$$x_1 = ?,\quad x_2 = ?,\quad \dots \quad x_n = ?$$<p xmlns="Unit">
               <span>such that all of the equations in the given system are simultaneously true.</span>
            </p><p xmlns="Unit">
               <span>An <b>example</b> of a system of two linear equations in $3$ unknowns is:</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
					\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{1}{\color{red}z} &amp; = &amp; 6 \\
\colorbox{lightgreen}{1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{1}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The coefficients of this system are:</span>
            </p>$$
					
					\begin{array}{rclrclrcl}
a_{11} &amp; = &amp; 2 &amp; \quad a_{12} &amp; = &amp; 3 &amp; \quad a_{13} &amp; = &amp; -1 \\
a_{21} &amp; = &amp; 1 &amp; \quad a_{22} &amp; = &amp; 1 &amp; \quad a_{23} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The variables or unknowns of this system are $x,y,z$.  One solution of this system is given by the number assignments</span>
            </p>$$x:= -6,\quad y := 5,\quad z:=1$$<p xmlns="Unit">
               <span>to the unknowns. Indeed, these assignments render both equations simultaneously  true. Let's check it!</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}-6})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}5}} &amp; - &amp; {\color{red}1} &amp; = &amp; 2 \\
{\color{red}-6} &amp; + &amp; {\color{red}5} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}1}} &amp; = &amp; 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We express this by saying that the triple  $(- 6,5,1)$  is a solution of the given system of linear equations. On the other hand, the triple  $(5,2,3)$  is not a solution of this system, because</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}5})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}2}} &amp; - &amp; {\color{red}3} &amp; = &amp; 13\ \neq 2 \\
{\color{red}5} &amp; + &amp; {\color{red}2} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}3}} &amp; = &amp; 13\ \neq 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We will discuss methods for finding all solutions of a system of linear equations. Applying this method to the system at hand we will find that its solutions form a line in $\RNr{3}$. In particular, this system has infinitely many simultaneous solutions.</span>
            </p></div>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <a id="activehottag-3301" class="activehottag" onmouseover="infoopen(3301)"> system of linear equations</a>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>
<div id="dialog-3316" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>Recall an illustration of a hyperplane</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3316' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div><div id="dialog-3331" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A Preview: how to solve a system of linear equations geometrically</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3331' style='display:none;'><div class='title'>Solving a System of Linear Equations Geometrically - Preview</div><p xmlns="Unit">
               <span>The elimination method of Gauß and Jordan transforms a given system of linear equations in one which has the same solutions as the original one but which is so simple that one can read off its solutions right away. – For example, Gauß–Jordan elimination transforms the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \color{red}z &amp; = &amp; 5 \\
\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; {\color{red}y} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}z} &amp; = &amp; 5 \\
\colorbox{lightgreen}{-1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{7}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{-9}{\color{red}z} &amp; = &amp; 5
\end{array}
					
				$$<p xmlns="Unit">
               <span>of 3 equations with 3 unknowns into the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; {\color{red}} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2 \\
 &amp; + &amp; {\color{red}y} &amp; - &amp; {\color{red}1} &amp; = &amp; 1
\end{array}
					
				$$<div id="dialog-3325" class="dialogs" title="What are the steps in the Gauß-Jordan elimination"><info xmlns="Unit">
                        
                        <p>
                           <span>You can learn details about the steps in the Gauß-Jordan elimination in the so named section. Here our goal is merely to explain that the system of linear equations which result from the Gauß_jordan elimination process can be significantly simpler than the original system of linear equations.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>of 2 equations with 3 unknowns. The 
				<a id="hottag-3325" class="hottag" onmouseover="popup(3325)"> steps taken in this process</a>  
				are designed to ensure that both systems have exactly the same solutions.</span>
            </p>
<p xmlns="Unit">
               <span>So, what’s the difference between the first system and second system above? – In the first system it is not easy to see what the solutions are. However, solutions of the second system are easy to read off: For every choice of  $z$ in $\RNr{}$, setting</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $z:= 1+z$   $x := 2-2z$
               </span>
            </p><p xmlns="Unit">
               <span>yields a triple of simultaneous solutions of the system. For example.</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $z:= 0$ yields $y=1$ and $x=2$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= 1$ yields $y=2$ and $x=0$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= -2$ yields $y=-1$ and $x=6$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>As the two systems of linear equations above are equivalent, each of the number triples $(2,1,0)$, $(0,2,1)$, and $(6,-1,-2)$ is also a simultaneous solution of the three equations of the first system.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<a id="activehottag-3316" class="activehottag" onmouseover="infoopen(3316)"> hyperplane in $\RNr{n}$
                        </a>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="activehottag-3331" class="activehottag" onmouseover="infoopen(3331)"> intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li></ul></li><li><span>inhomogeneous system of linear equations      </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>inverse      </span><ul class='chilren'><li><span>of a $(2,2)$-matrix      </span><a id='glossaryinfo-10998' class='msm_infobutton' onmouseover='infoopen(10998)'>i</a><div id="dialog-10998" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10998' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>of a linear transformation      </span><a id='glossaryinfo-16736' class='msm_infobutton' onmouseover='infoopen(16736)'>i</a><div id="dialog-16736" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-16736' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>inversion      </span><a id='glossaryinfo-6889' class='msm_infobutton' onmouseover='infoopen(6889)'>i</a><div id="dialog-6889" class="dialogs" title="What is an inversion?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An inversion is a linear transformation $T$ of $\RNr{n}$ of the form $T(\Vect{x})= -\Vect{x}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6889' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>invertible      </span><ul class='chilren'><li><span>linear transformation      </span><a id='glossaryinfo-18464' class='msm_infobutton' onmouseover='infoopen(18464)'>i</a><div id="dialog-18464" class="dialogs" title="Invertible linear transformation"><info xmlns="Unit">
                           
                           <p>
                              <span>Definition of the concept: A linear map $L\from V\to W$ of subvector spaces of $\RNr{k}$ is invertible, if there exists a linear map $M\from W\to V$ such that</span>
                           </p>
                           $$M\Comp L = \Id{V} \quad\text{and}\quad L\Comp M = \Id{W}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18464' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear map $L\from V\to W$ of subvector spaces of $\RNr{k}$ is called invertible if there exists a linear map $M\from W\to V$ such that
				</span>
                     
                  </p>
                  $$M\Comp L = \Id{V} \quad\text{and}\quad L\Comp M = \Id{W}$$
                  <p>
                     <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-16730' class='msm_infobutton' onmouseover='infoopen(16730)'>i</a><div id="dialog-16730" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div></li><li><span>matrix      </span><a id='glossaryinfo-5344' class='msm_infobutton' onmouseover='infoopen(5344)'>i</a><div id="dialog-5344" class="dialogs" title="Invertible Matrix"><info xmlns="Unit">
                     
                     <p>
                        <span>An analysis which motivates the concept of an invertible matrix.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5344' style='display:none;'><div class='title'>Matrix Multiplication: Exceptional Properties</div><p xmlns="Unit">
               <span>Let us recall: So far we have extended the operations of addition and multiplication of numbers to the world of matrices. How about division? i.e. how can we make sense of an expression like this one?
				</span>
               
            </p>$$
					
					\dfrac{
					\left[
					\begin{array}{rr}
					4 &amp; 3 \\
					1 &amp; 0
					\end{array}
					\right] }{
					\left[
					\begin{array}{rr}
					7 &amp; 4 \\
					5 &amp; 3
					\end{array}
					\right]}
					
				$$<p xmlns="Unit">
               <span>To answer this question, let us analyze division by a number to get an idea of how to extend division to the world of matrices: Dividing a number $x$ by another, say $2$, amounts to multiplying $x$  by  $1/2=2^{-1}$. Now, the number $1/2$ is characterized by the property</span>
            </p>$$2\cdot (1/2)\ =\ 1\ (1/2)\cdot 2$$<p xmlns="Unit">
               <span>This is the key: Our goal is to divide an $(n,n)$-matrix $\Mtrx{X}$ by another $(n,n)$-matrix $\Mtrx{A}$. So, if we can find a matrix $\Mtrx{B}$ with</span>
            </p>$$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$<p xmlns="Unit">
               <span>then it makes sense to define $\Mtrx{A}^{-1} := B$. So then we can define</span>
            </p>$$\dfrac{\Mtrx{X}}{\Mtrx{A}}\ :=\ \Mtrx{X}\cdot \Mtrx{B}$$<p xmlns="Unit">
               <span>
                  <b>Alert</b>   Here is a new point which we must really pay attention to: In the world of matrices there are two ways of multiplying $\Mtrx{X}$by $\Mtrx{A}$. Reason:</span>
            </p><div id="dialog-5390" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Review an example of this phenomenon.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-5390' style='display:none;'><div class='title'>Matrix Multiplication: Exceptional Properties</div><p xmlns="Unit">
               <span>Most rules for computing with numbers continue to hold when we compute with matrices, but not all: The multiplication of matrices is more delicate because there are two basic exceptions:</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Exception 1</b>   When multiplying two matrices $A$ and $B$, the products $AB$ and $BA$ need not be the same, even if both products are defined. – For example</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$[1\ \ 4\ \ 3] \cdot \left[\begin{array}{r} 5 \\ -2 \\ 7 \end{array}\right]$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$[ 18 ]$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\left[\begin{array}{r} 5 \\ -2 \\ 7 \end{array}\right] \cdot [ 1\ \ 4\ \ 3 ]$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rrr}
					5 &amp; 20 &amp; 15 \\
					-2 &amp; -8 &amp; -6 \\
					7 &amp; 28 &amp; 21
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>In this case the two products don't even have the same size. So they cannot be equal. However, difference in size is not the only possible reason why $AB$ might be different from $BA$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right] \cdot
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					-48 &amp; -36 \\
					64 &amp; 48
					\end{array}\right]
					
				$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					0 &amp; 0 \\
					0 &amp; 0
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>Here $AB$ and $BA$ are both of size $(2,2)$. Still, they are distinct.</span>
            </p><div id="dialog-5380" class="dialogs" title="What is the 0-matrix?"><info xmlns="Unit">
                        
                        <p>
                           <span>A matrix all of whose entries are $0$ is called a $0$-matrix.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Exception 2</b> &#xA0; If $AX$ is the
				<a id="hottag-5380" class="hottag" onmouseover="popup(5380)"> 0-matrix</a>  ,
				it need not be true that at least one of $A$ or $X$ is the 0-matrix.</span>
            </p>
<p xmlns="Unit">
               <span>If $ax=0$ is an equation of numbers, and we know that $a\neq 0$, we conclude immediately that $x=0$. It is very tempting to assume that we can draw the same conclusion when presented with a matrix equation like</span>
            </p>$$AX = \mathbf{0}$$<p xmlns="Unit">
               <span>However, the example below shows that, in this situation, neither $A$ nor $X$ need be $\mathbf{0}$.</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					8 &amp; 6 \\
					4 &amp; 3
					\end{array}\right] \cdot 
					\left[\begin{array}{rr}
					-3 &amp; -6 \\
					4 &amp; 8
					\end{array}\right]
					
				$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$
					
					\left[\begin{array}{rr}
					0 &amp; 0 \\
					0 &amp; 0
					\end{array}\right]
					
				$</td></tr></table><p xmlns="Unit">
               <span>Therefore, a matrix identity like $\Mtrx{A}\Mtrx{X} = \Vect{0}$ by itself does not support the conclusion that $\Mtrx{A}$ or $\Mtrx{X}$ are $\Vect{0}$.</span>
            </p></div>
<p xmlns="Unit" align="center">
               <span>
                  $\Mtrx{B}\Mtrx{X}$ &#xA0; is 
				<a id="activehottag-5390" class="activehottag" onmouseover="infoopen(5390)"> generally distinct</a>  
				from $\Mtrx{X}\Mtrx{B}$.
			</span>
            </p>
<p xmlns="Unit">
               <span>Accordingly, we must carefully decide whether we want to</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the left; i.e. form the product  $\Mtrx{B}\Mtrx{X}$, or</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>divide $\Mtrx{X}$ by $\Mtrx{A}$ on the right; i.e. form the product  $\Mtrx{X}\Mtrx{B}$.</span>
                  </p>
               </li>
            </ul></div><a id='glossaryinfo-5396' class='msm_infobutton' onmouseover='infoopen(5396)'>i</a><div id="dialog-5396" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5396' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ of size $(n,n)$ is invertible if there is a matrix $\Mtrx{B}$ such that</span>
                  </p>
                  $$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$
                  <p>
                     <span>In this case, $\Mtrx{B}$ is called the inverse of $\Mtrx{A}$, and is denoted $\Mtrx{A}^{-1}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-17116' class='msm_infobutton' onmouseover='infoopen(17116)'>i</a><div id="dialog-17116" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>Context: a distance preserving linear map is invertible</span>
                     </p>
                  </info></div></li></ul></li><li><span>isomorphic linear transformation      </span><a id='glossaryinfo-18843' class='msm_infobutton' onmouseover='infoopen(18843)'>i</a><div id="dialog-18843" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18843' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>isomorphism      </span><a id='glossaryinfo-18847' class='msm_infobutton' onmouseover='infoopen(18847)'>i</a><div id="dialog-18847" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18847' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>kernel      </span><a id='glossaryinfo-17274' class='msm_infobutton' onmouseover='infoopen(17274)'>i</a><div id="dialog-17274" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>`kernel' appears here in the context of linear transformations providing another view toward linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17274' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-17256" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-17256" class="hottag" onmouseover="popup(17256)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-17271" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-17271' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-17271" class="activehottag" onmouseover="infoopen(17271)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li><li><span>kernel of a linear map      </span><a id='glossaryinfo-18618' class='msm_infobutton' onmouseover='infoopen(18618)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-18618' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel / image of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $L\from V\to W$ be a linear map of subvector spaces of $\RNr{k}$.</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>The kernel of $L$ is $\ker(L):=\Set{ \Vect{x} \in V \st L(\Vect{x}) = \Vect{0} }$.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>The image of $L$ is
						</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Img{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$:=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{y}\in W \st \Vect{y}=L(\Vect{x})\quad \text{for some \ } \Vect{x}\in V }$</td></tr></table>
                     </li>
                  </ul>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>kernel of a linear transformation      </span><a id='glossaryinfo-11538' class='msm_infobutton' onmouseover='infoopen(11538)'>i</a><div id="dialog-11538" class="dialogs" title="Kernel"><info xmlns="Unit">
                           
                           <p>
                              <span>The kernel of $L\from V\to W$ is the set of all $\Vect{x}\in V$ with $L(\Vect{x} )=\Vect{0}$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11538' style='display:none;'><br /><div class='def'><span class='deftitle'>Kernel of a linear map</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Let $V$ and $W$ be subspaces of $\RNr{n}$. The kernel of a linear transformation $L\from V\to W$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Ker{L}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11542" class="hottag" onmouseover="popup(11542)">$:=	$</a><div id="dialog-11542" class="dialogs" title="How do I read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#xA0;kernel of $L$ is by definition the set of all those $\Vect{x}$ in V such that $L$ of $\Vect{x}$ equals  zero.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st L(\Vect{x}) = \Vect{0} }$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>leading $1$      </span><a id='glossaryinfo-3822' class='msm_infobutton' onmouseover='infoopen(3822)'>i</a><div id="dialog-3822" class="dialogs" title="What is a leading $1$?"><info xmlns="Unit">
                                       
                                       <p>
                                          <span>The concept of ‘leading 1’ occurs within the context of linear equations in row reduced echelon form.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3822' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>left hand      </span><ul class='chilren'><li><span>orientation      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>rule      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>length      </span><ul class='chilren'><li><span>of a vector      </span><a id='glossaryinfo-1668' class='msm_infobutton' onmouseover='infoopen(1668)'>i</a><div id="dialog-1668" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1668' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of an arrow      </span><a id='glossaryinfo-644' class='msm_infobutton' onmouseover='infoopen(644)'>i</a><div id="dialog-644" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The length of an arrow is the distance between its end points. - Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-644' style='display:none;'><br /><div class='def'><span class='deftitle'>Length of an Arrow</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given points $P(x_1,\dots ,x_n)$ and $Q(y_1,\dots ,y_n)$ in $\RNr{n}$, the length of the arrow
					$\Arrow{P}{Q}$ from $P$ to $Q$ is
					</span>
                           
                           
                           
                        </p>
                        $$\Length{\Arrow{P}{Q} }\ :=\ \Dstnc{P}{Q}\ =\ \sqrt{(y_1-x_1)^2+\cdots +(y_n-x_n)^2}.$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>level set      </span><ul class='chilren'><li><span>of a linear transformation      </span><a id='glossaryinfo-8337' class='msm_infobutton' onmouseover='infoopen(8337)'>i</a><div id="dialog-8337" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8337' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-8333" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-8333" class="hottag" onmouseover="popup(8333)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-8348" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-8348' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-8348" class="activehottag" onmouseover="infoopen(8348)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li></ul></li><li><span>linear      </span><ul class='chilren'><li><span>combination      </span><a id='glossaryinfo-11715' class='msm_infobutton' onmouseover='infoopen(11715)'>i</a><div id="dialog-11715" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11715' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear combination</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>A linear combination of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $\RNr{n}$ is a vector $\Vect{x}$ of the form
					</span>
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{s}_1 + \cdots + t_r \Vect{s}_r$</td></tr></table>
                        <p>
                           <span>where $t_1,\dots ,t_r$ are numbers in $\RNr{}$.</span>
                        </p>
                     </def.body>
<br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-5785' class='msm_infobutton' onmouseover='infoopen(5785)'>i</a><div id="dialog-5785" class="dialogs" title="linear equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5785' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><a id='glossaryinfo-3252' class='msm_infobutton' onmouseover='infoopen(3252)'>i</a><div id="dialog-3252" class="dialogs" title="What is a linear equation?">
<info xmlns="Unit">
                  
				
				              <p>
                     <span>A linear equation is an expression which can be written as</span>
                  </p>
				
				              <p align="center">
                     <span>
                        <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351"/></div>
                     </span>
                  </p>
				
				              <p>
                     <span>Look up the definition.</span>
                  </p>
			            </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-3252' style='display:none;'><div class='title'>Linear Equations</div><h2> Introduction </h2><p xmlns="Unit">
            <span>A linear equation in $n$ unknowns is an expression which can be written as
		
	</span>
            
         </p>
<p xmlns="Unit" align="center">
            <span>
               <div class="picture"><img id="image-3257" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/LinearEq_1Gnrl.gif" height="23" width="351" usemap="#LinearEq_1Gnrl"/><map name="LinearEq_1Gnrl"><area id="pic-3259" coords="0,2,24,19" shape="rect" href="#" onmouseover="popup(3259)"><div id="dialog-3259" class="dialogs" title="What does $a_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_1$ is the first coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3261" coords="79,2,103,20" shape="rect" href="#" onmouseover="popup(3261)"><div id="dialog-3261" class="dialogs" title="What does $a_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_2$ is the second coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3263" coords="255,2,284,22" shape="rect" href="#" onmouseover="popup(3263)"><div id="dialog-3263" class="dialogs" title="What does $a_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $a_n$ is the $n$-th coefficient of this linear equation.. It is a number which is given.</span>
                              </p>
			                        </info></div></area><area id="pic-3265" coords="25,1,47,18" shape="rect" href="#" onmouseover="popup(3265)"><div id="dialog-3265" class="dialogs" title="What does $x_1$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_1$ is a variable, also called an unknown. It is the first unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3267" coords="104,1,125,19" shape="rect" href="#" onmouseover="popup(3267)"><div id="dialog-3267" class="dialogs" title="What does $x_2$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_2$ is a variable, also called an unknown. It is the second unknown of this linear equation.</span>
                              </p>
			                        </info></div></area><area id="pic-3269" coords="284,0,304,19" shape="rect" href="#" onmouseover="popup(3269)"><div id="dialog-3269" class="dialogs" title="What does $x_n$ mean"><info xmlns="Unit">
                              
				
				                          <p>
                                 <span>
                                    $x_n$ is a variable, also called an unknown. It is the $n$-th unknown of this linear equation.</span>
                              </p>
			                        </info></div></area></map></div>
	           </span>
         </p>
<p xmlns="Unit">
            <span>We explain the meaning of the symbols in this equation:</span>
         </p><ul xmlns="Unit">
		          <li>
               <p>
                  <span>Each of the symbols $a_1, \dots ,a_n$ represents a number which is considered fixed. They are called the coefficients of the equation.
			
		</span>
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     $c$ on the right represents a number which is also fixed. The equation is called homogeneous if $c=0$, and is called inhomogeneous if $c\neq 0$.
			
			
		</span>
                  
                  
               </p>
            </li>
		          <li>
               <p>
                  <span>The symbol $x_1$ is a variable or an unknown of the equation, as is each of the symbols $x_j$, $1\leq j\leq n$. Our task is to find those number values for each of these variables which render the given equation is true.</span>
               </p>
            </li>
	        </ul><div id="dialog-3301" class="dialogs"><info xmlns="Unit">
			
			                     <p>
                           <span>Preview of a System of Linear Equations</span>
                        </p>
		                   </info></div><div class='refcontent' id='refcontent-3301' style='display:none;'><div class='title'>System of Linear Equations – Preview</div><p xmlns="Unit">
               <span>A system of $m$ linear equation in $n$ unknowns looks like this</span>
            </p>$$
				
				\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
				
			$$<p xmlns="Unit">
               <span>Each row in this system is just a single linear equation in $n$ unknowns. Thus each of the symbols</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $a_{ij}$,   $1\leq i\leq m$,   $1\leq j\leq n$,   and   $c_1,\dots ,c_m$
               </span>
            </p><div id="dialog-3287" class="dialogs" title="What exactly does $(i,j)$ refer to?"><info xmlns="Unit">
                        
                        <p>
                           <span>Note that the symbol $a$ has two subscripts:</span>
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>The first subscript, here named $i$ counts the row in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The second subscript, here named $j$ counts the column in which the coefficient $a_{ij}$ sits.</span>
                              </p>
                           </li>
                        </ol>
                     </info></div>
<p xmlns="Unit">
               <span>represents a number which is assumed to be known. Specifically, the number $a_{ij}$ is called the coefficient in position 
			<a id="hottag-3287" class="hottag" onmouseover="popup(3287)"> 
                        $(i,j)$
                     </a>  
			of the system. The symbols $x_1,\dots ,x_n$ represent variables (unknowns), and we are looking for number values</span>
            </p>
$$x_1 = ?,\quad x_2 = ?,\quad \dots \quad x_n = ?$$<p xmlns="Unit">
               <span>such that all of the equations in the given system are simultaneously true.</span>
            </p><p xmlns="Unit">
               <span>An <b>example</b> of a system of two linear equations in $3$ unknowns is:</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
					\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{1}{\color{red}z} &amp; = &amp; 6 \\
\colorbox{lightgreen}{1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{1}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The coefficients of this system are:</span>
            </p>$$
					
					\begin{array}{rclrclrcl}
a_{11} &amp; = &amp; 2 &amp; \quad a_{12} &amp; = &amp; 3 &amp; \quad a_{13} &amp; = &amp; -1 \\
a_{21} &amp; = &amp; 1 &amp; \quad a_{22} &amp; = &amp; 1 &amp; \quad a_{23} &amp; = &amp; 2
\end{array}
					
				$$<p xmlns="Unit">
               <span>The variables or unknowns of this system are $x,y,z$.  One solution of this system is given by the number assignments</span>
            </p>$$x:= -6,\quad y := 5,\quad z:=1$$<p xmlns="Unit">
               <span>to the unknowns. Indeed, these assignments render both equations simultaneously  true. Let's check it!</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}-6})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}5}} &amp; - &amp; {\color{red}1} &amp; = &amp; 2 \\
{\color{red}-6} &amp; + &amp; {\color{red}5} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}1}} &amp; = &amp; 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We express this by saying that the triple  $(- 6,5,1)$  is a solution of the given system of linear equations. On the other hand, the triple  $(5,2,3)$  is not a solution of this system, because</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
\colorbox{lightgreen}{2}{\cdot({\color{red}5})} &amp; + &amp; \colorbox{lightgreen}{3}{\cdot{\color{red}2}} &amp; - &amp; {\color{red}3} &amp; = &amp; 13\ \neq 2 \\
{\color{red}5} &amp; + &amp; {\color{red}2} &amp; + &amp; \colorbox{lightgreen}{2}{\cdot{\color{red}3}} &amp; = &amp; 13\ \neq 1
\end{array}
					
				$$<p xmlns="Unit">
               <span>We will discuss methods for finding all solutions of a system of linear equations. Applying this method to the system at hand we will find that its solutions form a line in $\RNr{3}$. In particular, this system has infinitely many simultaneous solutions.</span>
            </p></div>
<p xmlns="Unit">
            <span>More generally, we will need to determine simultaneous solutions of a <a id="activehottag-3301" class="activehottag" onmouseover="infoopen(3301)"> system of linear equations</a>  
		in  $n$  unknowns. Fortunately, there are several methods at our disposal to respond to this task. In this chapter we discuss the following:</span>
         </p>
<div id="dialog-3316" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>Recall an illustration of a hyperplane</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3316' style='display:none;'><div class='title'>Hyperplane – Illustration</div><p xmlns="Unit">
               <span>Here we illustrate a hyperplane in $\RNr{2}$ or in $\RNr{3}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{2}$
                  <b>is just a line</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane2D.gif" height="310" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the blue line is the hyperspace which is perpendicular to the green normal vector. The red line $L$ is a hyperplane. It results from parallel translating the blue hyperspace.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>A hyperplane in</b>
                  $\RNr{3}$
                  <b>is just a plane in the usual sense</b>
               </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/DotProduct/ims/HyperPlane3D.gif" height="350" width="300"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>In the picture above, the planes are hyperplanes in 3-space. The tail of the two arrows is supposed to be at the origin. So the lower hyperplane passes through the origin and, hence, is even a hyperspace. In general, we characterize the location of a hyperplane by specifying a vector $\Vect{n}$ (blue) perpendicular to it and by specifying a point on it (the tip of the red arrow). Alternatively, we can think of a hyperplane as being obtained by parallel translating the hyperspace which is perpendicular to $\Vect{n}$ off of the origin by a suitable vector (red).</span>
            </p></div><div id="dialog-3331" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A Preview: how to solve a system of linear equations geometrically</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-3331' style='display:none;'><div class='title'>Solving a System of Linear Equations Geometrically - Preview</div><p xmlns="Unit">
               <span>The elimination method of Gauß and Jordan transforms a given system of linear equations in one which has the same solutions as the original one but which is so simple that one can read off its solutions right away. – For example, Gauß–Jordan elimination transforms the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}y} &amp; - &amp; \color{red}z &amp; = &amp; 5 \\
\colorbox{lightgreen}{2}{\color{red}x} &amp; + &amp; {\color{red}y} &amp; + &amp; \colorbox{lightgreen}{3}{\color{red}z} &amp; = &amp; 5 \\
\colorbox{lightgreen}{-1}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{7}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{-9}{\color{red}z} &amp; = &amp; 5
\end{array}
					
				$$<p xmlns="Unit">
               <span>of 3 equations with 3 unknowns into the system</span>
            </p>$$
					
					\begin{array}{rcrcrcl}
{\color{red}x} &amp; + &amp; {\color{red}} &amp; + &amp; \colorbox{lightgreen}{2}{\color{red}z} &amp; = &amp; 2 \\
 &amp; + &amp; {\color{red}y} &amp; - &amp; {\color{red}1} &amp; = &amp; 1
\end{array}
					
				$$<div id="dialog-3325" class="dialogs" title="What are the steps in the Gauß-Jordan elimination"><info xmlns="Unit">
                        
                        <p>
                           <span>You can learn details about the steps in the Gauß-Jordan elimination in the so named section. Here our goal is merely to explain that the system of linear equations which result from the Gauß_jordan elimination process can be significantly simpler than the original system of linear equations.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>of 2 equations with 3 unknowns. The 
				<a id="hottag-3325" class="hottag" onmouseover="popup(3325)"> steps taken in this process</a>  
				are designed to ensure that both systems have exactly the same solutions.</span>
            </p>
<p xmlns="Unit">
               <span>So, what’s the difference between the first system and second system above? – In the first system it is not easy to see what the solutions are. However, solutions of the second system are easy to read off: For every choice of  $z$ in $\RNr{}$, setting</span>
            </p><p xmlns="Unit" align="center">
               <span>
                  $z:= 1+z$   $x := 2-2z$
               </span>
            </p><p xmlns="Unit">
               <span>yields a triple of simultaneous solutions of the system. For example.</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        $z:= 0$ yields $y=1$ and $x=2$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= 1$ yields $y=2$ and $x=0$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $z:= -2$ yields $y=-1$ and $x=6$
                     </span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>As the two systems of linear equations above are equivalent, each of the number triples $(2,1,0)$, $(0,2,1)$, and $(6,-1,-2)$ is also a simultaneous solution of the three equations of the first system.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>A <b>geometrical method</b>. It uses the fact that the solutions of a single linear equation in $n$ unknowns form a 
			<a id="activehottag-3316" class="activehottag" onmouseover="infoopen(3316)"> hyperplane in $\RNr{n}$
                        </a>  .
			Therefore the simultaneous solutions of $m$ such equations form the 
			<a id="activehottag-3331" class="activehottag" onmouseover="infoopen(3331)"> intersection of the corresponding hyperplanes</a>  . - This method enables us to discuss qualitatively the simultaneous solutions of a system of linear equations.</span>
               </p>
            </li>
		
		          <li>
               <p>
                  <span>The <b>elimination method</b> of Gau&#xDF;
			
			 and Jordan
			
			yields explicitly the solutions of a given system of linear equations. This method is a programmable procedure which transforms a given system of linear equations into simpler and simpler ones. In the end, one is left with a system of linear equations which is so simple that its solutions can be read off immediately.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>Later we will learn a more advanced method for solving certain kinds of systems of linear equations: Cramer’s rule is a formula which is applicable to a system of $n$ linear equations with $n$ unknowns termed non-degenerate. Such a system has always exactly one solution, and Cramer’s rule computes it by a formula involving determinants.</span>
         </p></div></li><li><span>function      </span><a id='glossaryinfo-6359' class='msm_infobutton' onmouseover='infoopen(6359)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6359' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>map      </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>motion      </span><a id='glossaryinfo-1129' class='msm_infobutton' onmouseover='infoopen(1129)'>i</a><div id="dialog-1129" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>A motion of a particle whose location at time $t$ has position vector $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$. – Click to see to the definition.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1129' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-1131" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘ell of $t$ equals a plus t times v’</span>
                              </p>
                           </info></div><div id="dialog-1135" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘t in R’, which means: $t$ is a number in $\RNr{}$.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <a id="hottag-1131" class="hottag" onmouseover="popup(1131)"> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </a>  , with <a id="hottag-1135" class="hottag" onmouseover="popup(1135)"> 
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>transformation      </span><a id='glossaryinfo-15282' class='msm_infobutton' onmouseover='infoopen(15282)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15282' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Transformation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A function $L\from \RNr{n}\to \RNr{m}$ is called linear if it has the two properties below</span>
                        </p>
                        <ul>
                           <li>
                              <p>
                                 <span>
                                    $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                                 </span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>
                                    $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in\RNr{}$, and all $\Vect{x}\in\RNr{n}$.</span>
                              </p>
                           </li>
                        </ul>
                        <p>
                           <span>Alternate terms for linear function include: linear map, linear transformation, homomorphism (of vector spaces).
					</span>
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>rotation      </span><a id='glossaryinfo-19530' class='msm_infobutton' onmouseover='infoopen(19530)'>i</a><div id="dialog-19530" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19530' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>scaling      </span><a id='glossaryinfo-6879' class='msm_infobutton' onmouseover='infoopen(6879)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6879' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>transformation of $\RNr{n}$      </span><ul class='chilren'><li><span>identity      </span><a id='glossaryinfo-15797' class='msm_infobutton' onmouseover='infoopen(15797)'>i</a><div id="dialog-15797" class="dialogs"><info xmlns="Unit">
                           $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15797' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The identity transformation of $\RNr{n}$ is
				</span>
                     
                     
                     
                  </p>
                  $$\IdTrafo{n}\from \RNr{n} \longrightarrow \RNr{n},\quad \IdTrafo{n}(\Vect{x}) := \Vect{x}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li></ul></li><li><span>linear transformation      </span><a id='glossaryinfo-6032' class='msm_infobutton' onmouseover='infoopen(6032)'>i</a><div id="dialog-6032" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>Appears here in the introduction to the topic of linear transformations.</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6032' style='display:none;'><div class='title'>Linear Transformations</div><h2> Introduction </h2><div id="dialog-6030" class="dialogs" title="Give me some idea of a ‘transformation’"><info xmlns="Unit">
                     
				
				                 <p>
                        <span>Examples of transformations result when you take a chunk of playdo or soft rubber and bend, twist, stretch, shrink it as you like.</span>
                     </p>
			               </info></div><div id="dialog-6034" class="dialogs" title="What is a linear transformation?"><info xmlns="Unit">
                     
				
				                 <p>
                        <span>Very roughly: a transformation is linear if it transforms lines into lines. – We will give a precise definition of ‘linear transformation’ later on.</span>
                     </p>
			               </info></div>
<p xmlns="Unit">
            <span>In this chapter we are going to develop a concept that is quite familiar at an intuitive level: that of a 
		<a id="hottag-6030" class="hottag" onmouseover="popup(6030)"> transformation of space</a>  
		together with objects contained in it. Amongst such transformations we focus upon those which are called 
		&#x2018;<a id="hottag-6034" class="hottag" onmouseover="popup(6034)"> linear</a>  &#x2019;.
		Let us consider some examples to see what we mean.
		
	</span>
            
         </p>
<div id="dialog-6045" class="dialogs"><info xmlns="Unit">
					
					                         <p>
                                 <span>A picture illustrating the transformation of an elastic strip into a Möbius strip</span>
                              </p>
				                       </info></div><div class='refcontent' id='refcontent-6045' style='display:none;'><div class='title'>Transformation of a Strip into a Möbius Strip</div><p xmlns="Unit">
               <span>The two pictures below show a planar sheet and then the result of deforming it into a twisted band, called a Möbius strip: give</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/MoebiusStrip1.gif" height="279.70711297071" width="350"/></div> &#xA0; <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/MoebiusStrip2.jpg" height="256" width="240"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>This transformation does not transform lines into lines. So it is not linear.</span>
            </p></div><div id="dialog-6052" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the transformation of a square into a rectangle.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6052' style='display:none;'><div class='title'>Transformation of a Square into a Rectangle</div><p xmlns="Unit">
               <span>The picture below shows a square (left) and then the result of transforming it into a rectangle.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_SquareRectangle.png' height='99.3125' width='350'/></div><p xmlns="Unit">
               <span>This transformation acts on the square by compressing it a bit vertically and stretching it horizontally. In doing so it transforms lines into lines. We will see that it is a linear transformation.</span>
            </p></div><div id="dialog-6059" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the rotation of a square.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6059' style='display:none;'><div class='title'>Transformation Given by Rotating a Square</div><p xmlns="Unit">
               <span>The picture below shows a square (left) and then the result of rotating it.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_SquareRotate.png' height='162.75' width='350'/></div><p xmlns="Unit">
               <span>This transformation acts on the square by rotating it about its center through approximately 30 degrees. It transforms lines into lines. We will see that it is linear.</span>
            </p></div><div id="dialog-6066" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating the transformation of a left hand into a right hand.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6066' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a right hand being transformed into a left hand by a reflection.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_HandReflection.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>We will see that reflection transformations are linear.</span>
            </p></div><div id="dialog-6073" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>A picture illustrating a shear transformation applied to a cube.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6073' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a cube being transformed by applying a shear transformation.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg' height='262.5' width='350'/></div><p xmlns="Unit">
               <span>We will see that shear transformations are linear.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>Twisting an elastic strip into a 
			<a id="activehottag-6045" class="activehottag" onmouseover="infoopen(6045)"> M&#xF6;bius strip</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6052" class="activehottag" onmouseover="infoopen(6052)"> Stretching a square into a rectangle</a>  
		                </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6059" class="activehottag" onmouseover="infoopen(6059)"> Rotating a square</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6066" class="activehottag" onmouseover="infoopen(6066)"> Mirroring an object</a>  
                  </span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6073" class="activehottag" onmouseover="infoopen(6073)"> Shearing an object</a>  
                  </span>
               </p>
            </li>
	        </ul>
<div id="dialog-6096" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of how a function describes a transformation.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6096' style='display:none;'><div class='title'>Preview: Function Describes Transformation</div><p xmlns="Unit">
               <span>The concept of a function is properly introduced within the context of set theory. Here we describe in pictorial terms how it may be interpreted as transforming objects.</span>
            </p><p xmlns="Unit">
               <span>In the graphic below the blob $B$ on the left gets transformed into the object $Z$ on the right. In the process, each point of $B$ gets relocated to some point of $Z$. It is this act of relocating points of $B$ to points of $Z$ which is described by a function.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png' height='213.9375' width='350'/></div><p xmlns="Unit">
               <span>Let's now analyze how a function transforms an object. A function $f$ from $B$ to $Z$, denoted $f\from B\to Z$ sends each $x$ of $B$ to some $z$ in $Z$. Note that there must be exactly one $z$ to which $x$ gets transformed. We write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$z$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-6085' class='hottag' onmouseover='popup(6085)'>$=	$</a><div id="dialog-6085" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>Read: ‘z equals f of x’</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(x)$</td></tr></table><p xmlns="Unit">
               <span>to express that $f$ transforms $x$ into $z$. Thus $f$ ‘knows’ for each $x$ in $B$ to which point in $Z$ it must be relocated. Accordingly, we think of $f$ as executing the given transformation.</span>
            </p><p xmlns="Unit">
               <span>It is allowed that two or more distinct points of $B$ get transformed into the same point of $Z$. In the graphic above this applies to the points labeled $u_1$ and $u_2$. We therefore have the equation</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(u_1)$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'><a id='hottag-6093' class='hottag' onmouseover='popup(6093)'>$=	$</a><div id="dialog-6093" class="dialogs" title=""><info xmlns="Unit">
                           <p>
                              <span>To see why we have this equation, recall that $f(u_1)$ is the point of $Z$ into which $u_1$ gets transformed. Similarly, $f(u_2)$ is the point of $Z$ into which $u_2$ gets transformed.</span>
                           </p>
                           <p>
                              <span>Here both of $u_1$ and $u_2$ get transformed into the same point of $Z$. Therefore we have the stated equation.</span>
                           </p>
                        </info></div></td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$f(u_2)$</td></tr></table></div><div id="dialog-6107" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>Preview description of a linear function</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6107' style='display:none;'><div class='title'>Preview: Linear Function</div><p xmlns="Unit">
               <span>A function $L\from \RNr{n}\to \RNr{m}$ is linear if it satisfies the two properties below</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        $L(\Vect{x}+\Vect{y}) = L(\Vect{x}) + L(\Vect{y})$ for all $\Vect{x},\Vect{y}\in\RNr{n}$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $L(t\cdot \Vect{x}) = t\cdot L(\Vect{x})$ for all $t\in \RNr{}$, and $\Vect{x}\in \RNr{n}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>Thus $L$ transforms points of $\RNr{n}$ into points of $\RNr{m}$.</span>
            </p><p xmlns="Unit">
               <span>The first identity asserts that $L$ transforms the vector sum $\Vect{x} + \Vect{y}$ of $\RNr{n}$ into the vector of $\RNr{m}$ obtained by</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>first transforming $\Vect{x}$ so as to obtain $L(\Vect{x})$,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>then transforming $\Vect{y}$ so as to obtain $L(\Vect{y})$,</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>finally adding up the transformed vectors $L(\Vect{x})$ and $L(\Vect{y})$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>The second identity implies that $L$ transforms the line of vectors $t\cdot \Vect{x}$ through the origin of $\RNr{n}$ into the line of vectors $t\cdot L(\Vect{x})$ of $\RNr{m}$.</span>
            </p></div>
<p xmlns="Unit">
            <span>To describe the effect of a transformation mathematically, we use the concept of a 
		<a id="activehottag-6096" class="activehottag" onmouseover="infoopen(6096)"> function</a>  .
		
		
		There is a collection of functions which are particularly nice to work with. These are the 
		<a id="activehottag-6107" class="activehottag" onmouseover="infoopen(6107)"> linear functions</a>  ,
		also called linear maps, linear homomorphisms, or linear transformations.</span>
            
         </p>
<div id="dialog-6118" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of the relationship between linear maps and matrices</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6118' style='display:none;'><div class='title'>Preview: Linear Maps and Matrices</div><p xmlns="Unit">
               <span>Linear functions and matrices are intimately related via the following two facts. The first says that every matrix yields a linear function; the second says that every linear function arises in this way.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Theorem</b>    Every matrix $\Mtrx{A}$ of size $(m,n)$ yields a linear transformation $L\from \RNr{n}\to \RNr{m}$ via the identity</span>
            </p>$$L(\Vect{x}) = A\cdot \Vect{x}$$<p xmlns="Unit">
               <span>On the right of this equation we multiply $\Mtrx{A}$ by the column vector $\Vect{x}$.</span>
            </p><p xmlns="Unit">
               <span>
                  <b>Theorem</b>   Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
            </p>$$
					
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
				$$<p xmlns="Unit">
               <span>i.e. the $j$-th column of $\Mtrx{A}$ is the column vector obtained by transforming the $j$-th coordinate vector of $\RNr{n}$ with $L$. Then $L(\Vect{x})=\Mtrx{A}\cdot \Vect{x}$,  for all $\Vect{x}$ in $\RNr{n}$. Moreover, $\Mtrx{A}$,  as defined above, is the only matrix with this property.</span>
            </p></div>
<p xmlns="Unit">
            <span>We find that every linear function can be 
		<a id="activehottag-6118" class="activehottag" onmouseover="infoopen(6118)"> described by a matrix</a>  
		and, conversely, every matrix describes a linear function. Thus we can leverage our knowledge of matrix algebra in the study of linear transformations.</span>
         </p>
<p xmlns="Unit">
            <span>We then discuss in detail the main examples of linear transformations:</span>
         </p><div id="dialog-6138" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a dilation operation</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6138' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><div id="dialog-6147" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a dilation operation</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6147' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by </span>
            </p>$$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>To understand where this matrix comes from, consider the picture below</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Rotation.png' height='167.5625' width='350'/></div><p xmlns="Unit">
               <span>Both $R(\StdBss{1})$ and $R(\StdBss{2})$ result from rotating $\StdBss{1}$ and $\StdBss{2}$ counterclockwise about the origin through the angle $\theta$. So they are vectors of length $1$. Therefore the coordinates of these vectors are as indicated.</span>
            </p></div><div id="dialog-6154" class="dialogs"><info xmlns="Unit">
				
				                          <p>
                                 <span>An illustration of a shear transformation.</span>
                              </p>
			                        </info></div><div class='refcontent' id='refcontent-6154' style='display:none;'><div class='title'>Transformation Given by Reflection</div><p xmlns="Unit">
               <span>The picture below shows a cube being transformed by applying a shear transformation.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_Shear3D.jpg' height='262.5' width='350'/></div><p xmlns="Unit">
               <span>We will see that shear transformations are linear.</span>
            </p></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6138" class="activehottag" onmouseover="infoopen(6138)"> Dilations and contractions</a>   &#xA0; such transformations magnify, respectively shrink, the space $\RNr{n}$.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6147" class="activehottag" onmouseover="infoopen(6147)"> Rotations</a>   &#xA0; a rotation of $\RNr{2}$ rotates the plane about the origin.</span>
               </p>
            </li>
		          <li>
               <p>
                  <span>
                     <a id="activehottag-6154" class="activehottag" onmouseover="infoopen(6154)"> Shear maps</a>   &#xA0; a shear transformation of $\RNr{n}$ turns a cube into a &#x2018;slanted box&#x2019;.
		</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>These three examples of linear transformations are ‘atomic’ in the sense that every linear transformation can be built from them, as we will learn later on.</span>
         </p><div id="dialog-6162" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of some properties that are particular to linear transformations.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6162' style='display:none;'><div class='title'>Preview: Properties of Linear Transformations</div><p xmlns="Unit">
               <span>Here are two basic properties which are specific to linear transformations and are not enjoyed by every transformation.</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>A linear transformation $f\from \RNr{n}\to \RNr{m}$ sends the $0$-vector of $\RNr{n}$ to the $0$-vector of $\RNr{m}$; in symbols: $f(\Vect{0}) = \Vect{0}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>A linear transformation $f\from \RNr{n}\to \RNr{m}$ transforms any linear motion in $\RNr{n}$ into a linear motion in $\RNr{m}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>The first property is frequently helpful in detecting non-linear maps. The second property explains the name "linear transformations".</span>
            </p></div><div id="dialog-6168" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of how to build new linear transformations from suitable given ones.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6168' style='display:none;'><div class='title'>Preview: New Linear Transformations from Given Ones</div><p xmlns="Unit">
               <span>Here we discuss three ways of generating a new linear transformation from given ones</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>The sum of two linear transformations $L,T\from \RNr{n}\to \RNr{m}$ is again linear, and it is given by</span>
                  </p>
                  $$L+T\from \RNr{n} \longrightarrow \RNr{m},\qquad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
               </li>
               <li>
                  <p>
                     <span>The scalar product of a linear transformation $L\from \RNr{n}\to \RNr{m}$ by a number $t\in \RNr{}$ is again linear, and it is given by</span>
                  </p>
                  $$(tL)\from \RNr{n}\longrightarrow \RNr{m},\qquad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
               </li>
               <li>
                  <p>
                     <span>The composition of linear transformations $S$ and $T$ with</span>
                  </p>
                  $$\RNr{p} \overset{L}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                  <p>
                     <span>is again linear, and it is given by</span>
                  </p>
                  $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m},\qquad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
               </li>
            </ol><p xmlns="Unit">
               <span>We will discuss these operations in detail later on.</span>
            </p></div>
<p xmlns="Unit">
            <span>Next we consider 
		<a id="activehottag-6162" class="activehottag" onmouseover="infoopen(6162)"> properties</a>  
		enjoyed by linear transformations, but not by arbitrary transformation. For example, such properties help us distinguish transformations which are linear from ones which are not. A section on 
		<a id="activehottag-6168" class="activehottag" onmouseover="infoopen(6168)"> building new linear transformations</a>  
		from known ones follows.</span>
         </p>
<div id="dialog-6174" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of invertible linear transformations</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6174' style='display:none;'><div class='title'>Preview: New Linear Transformations from Given Ones</div><p xmlns="Unit">
               <span>There are some special linear transformations whose effect on space can be reversed. Here are the definition and most relevant facts:</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        <b>Definition</b>   A linear transformation $L\from \RNr{n} \to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                  </p>
                  $$M\Comp L = \IdMtrx{n} = L\Comp M$$
                  <p>
                     <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If the linear transformation $L\from \RNr{n}\to \RNr{n}$ is invertible, with inverse $M=L^{-1}$, then $M$ is also invertible and</span>
                  </p>
                  $$L = M^{-1} = (L^{-1})^{-1}$$
               </li>
               <li>
                  <p>
                     <span>Let $L\from \RNr{n}\to \RNr{m}$ be a linear transformation represented by the matrix $\Mtrx{A}$ of size $(n,n)$. Then $L$ is invertible if and only if $\Mtrx{A}$ is invertible. Moreover, $L^{-1}$  is represented by the matrix $\Mtrx{A}^{-1}$.</span>
                  </p>
               </li>
            </ol></div><div id="dialog-6179" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>A preview of distance preserving linear transformations</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-6179' style='display:none;'><div class='title'>Preview: Distance Preserving Linear Transformations</div><p xmlns="Unit">
               <span>Of particular importance for practical purposes are those linear transformations which preserve all distances. This ensures that size and shape of any object remains unaltered by the transformation. Only its position can change. This is something we take for granted when moving an object from one place to another place in the real world. Here are the main facts.</span>
            </p><ol xmlns="Unit" type="1">
               <li>
                  <p>
                     <span>
                        <b>Definition</b>   A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,</span>
                  </p>
                  $$\norm{L(\Vect{x})} = \Vect{x}$$
               </li>
               <li>
                  <p>
                     <span>
                        <b>Proposition</b>   Let $L\from \RNr{n}\to \RNr{n}$ be a linear transformation represented by the matrix $\Mtrx{A}$ of size $(n,n)$. Then $L$ preserves all distances if and only if conditions (i) and (ii) below hold:</span>
                  </p>
                  <ol type="i">
                     <li>
                        <p>
                           <span>Each column vector $A_j$ of $\Mtrx{A}$ has length $1$: $\DotPr{A_j}{A_j} = 1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Any two distinct column vectors of $A$ are perpendicular: whenever $1\leq j\neq k\leq n$, $\DotPr{A_j}{A_k} = 0$.</span>
                        </p>
                     </li>
                  </ol>
               </li>
               <li>
                  <p>
                     <span>
                        <b>Corollary</b>   A linear transformation $L\from \RNr{n}\to \RNr{n}$ preserves distances if and only if the transpose of $\Mtrx{A}$ is also the inverse of $\Mtrx{A}$: $\Mtrx{A}^{-1} = \Mtrx{A}^T$.</span>
                  </p>
               </li>
            </ol></div>
<p xmlns="Unit">
            <span>Of particular interest are those linear transformations whose transformation effect can be reversed: These are the
		<a id="activehottag-6174" class="activehottag" onmouseover="infoopen(6174)"> invertible linear transformations</a>  .
		Amongst the invertible linear transformations we find a particularly nice collection: The
		<a id="activehottag-6179" class="activehottag" onmouseover="infoopen(6179)"> distance preserving linear transformations</a>  .
		We encounter those on a daily basis in the form of rotations and reflections.</span>
         </p>
<p xmlns="Unit">
            <span>Linear transformations are also related to systems of linear equations, and this relationship will be explained as well.</span>
         </p></div><ul class='chilren'><li><span>by specifying values on a basis      </span><a id='glossaryinfo-17975' class='msm_infobutton' onmouseover='infoopen(17975)'>i</a><div id="dialog-17975" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Look up the proposition which says that a linear map $f\from V\to W$ is given by specifying is values on a basis of $V$.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17975' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Linear map by values on a basis</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $V$ and $W$ be subspaces of $\RNr{k}$. Given a basis $\EuScript{A}=\Set{ \Vect{a}_1,\dots ,\Vect{a}_n}$ of $V$ and arbitrary vectors $\Vect{z}_1$, ... , $\Vect{z}_n$ in $W$, there is exactly one linear transformation $L\from V\to W$ with
			</span>
         
      </p>$$L(\Vect{a}_1)=\Vect{z}_1\ ,\quad \dots \ ,\quad L(\Vect{a}_n)=\Vect{z}_n$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>distance preserving      </span><a id='glossaryinfo-8082' class='msm_infobutton' onmouseover='infoopen(8082)'>i</a><div id="dialog-8082" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the term</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8082' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>epimorphic      </span><a id='glossaryinfo-18839' class='msm_infobutton' onmouseover='infoopen(18839)'>i</a><div id="dialog-18839" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18839' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>invertible      </span><a id='glossaryinfo-7794' class='msm_infobutton' onmouseover='infoopen(7794)'>i</a><div id="dialog-7794" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7794' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A linear transformation $L\from \RNr{n}\to \RNr{n}$ is called invertible if there exists a linear transformation $M\from \RNr{n}\to \RNr{n}$ such that</span>
                        </p>
                        $$M\Comp L = \Id{n} = L\Comp M$$
                        <p>
                           <span>In this case we call $M$ the inverse of $L$ and write $M=L^{-1}$.
					</span>
                           
                           
                           
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-16734' class='msm_infobutton' onmouseover='infoopen(16734)'>i</a><div id="dialog-16734" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The definition of the concept</span>
                                 </p>
                              </info></div></li><li><span>isomorphic      </span><a id='glossaryinfo-18845' class='msm_infobutton' onmouseover='infoopen(18845)'>i</a><div id="dialog-18845" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map $L\from V\to W$ with $\ker(L)=\Set{ \Vect{0} }$ and $\im(L)=W$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18845' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphic      </span><a id='glossaryinfo-18833' class='msm_infobutton' onmouseover='infoopen(18833)'>i</a><div id="dialog-18833" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18833' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>orthogonal      </span><a id='glossaryinfo-8088' class='msm_infobutton' onmouseover='infoopen(8088)'>i</a><div id="dialog-8088" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8088' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>scalar product      </span><a id='glossaryinfo-17771' class='msm_infobutton' onmouseover='infoopen(17771)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17771' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>shear map of $\RNr{n}$ parallel to a hyperspace      </span><a id='glossaryinfo-19694' class='msm_infobutton' onmouseover='infoopen(19694)'>i</a><div id="dialog-19694" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19694' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>linear transformations      </span><ul class='chilren'><li><span>composition      </span><a id='glossaryinfo-7648' class='msm_infobutton' onmouseover='infoopen(7648)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7648' style='display:none;'><br /><div class='def'><span class='deftitle'>Composition of linear maps</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The composition of linear transformations $S$ and $T$ with
					</span>
                           
                           
                        </p>
                        $$\RNr{p} \overset{S}{\longrightarrow} \RNr{n} \overset{T}{\longrightarrow} \RNr{m}$$
                        <p>
                           <span>is given by</span>
                        </p>
                        $$T\Comp S\from \RNr{p} \longrightarrow \RNr{m}, \quad T\Comp S(\Vect{x}) := T(S(\Vect{x}))$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>linearly dependent set      </span><a id='glossaryinfo-12111' class='msm_infobutton' onmouseover='infoopen(12111)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12111' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>linearly independent set      </span><a id='glossaryinfo-12111' class='msm_infobutton' onmouseover='infoopen(12111)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-12111' style='display:none;'><br /><div class='def'><span class='deftitle'>Linearly independent set</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>A set of vectors $S$ in $\RNr{n}$ is called linearly independent if, for any choice of pairwise distinct vectors $\Vect{a}_1,\dots , \Vect{a}_r$ from $S$, the vector equation</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$t_1 \Vect{a}_1 + \cdots + t_r \Vect{a}_r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table>
                  <p>
                     <span>has exactly one solution, namely $t_1=\cdots = t_r=0$. &#x2013; If $S$ fails to be linearly independent, it is called linearly dependent.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>Lo Shu-magic square      </span><a id='glossaryinfo-4654' class='msm_infobutton' onmouseover='infoopen(4654)'>i</a><div id="dialog-4654" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>appears here as an early example of organizing numbers in a rectangular shape.</span>
                        </p>
                     </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4654' style='display:none;'><div class='title'>Matrix Algebra</div><h2> Introduction </h2><div id="dialog-4552" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>An illustration of matrices</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-4552' style='display:none;'><div class='title'>Description of a Matrix</div><p xmlns="Unit">
               <span>A matrix of numbers is a rectangular arrangement of numbers. Here are some examples:</span>
            </p>$$
					
						\left[
						\begin{array}{rrr}
						3 &amp; 1 &amp; -1 \\
						0 &amp; 2 &amp;  5
						\end{array}
						\right]
					
				$$<p xmlns="Unit">
               <span>This is a matrix with $2$ rows and $3$ columns. So we call it a matrix of type $(2,3)$.</span>
            </p>$$
					
						\left[
						\begin{array}{rrrr}
						7 &amp; -4 &amp; 6 &amp; 9 \\
						3 &amp; 0 &amp; 4 &amp; 11 \\
						-3 &amp; -1 &amp; 6 &amp; 9 \\
						2 &amp; 2 &amp; 0 &amp; 4
						\end{array}
						\right]
					
				$$<p xmlns="Unit">
               <span>This is a matrix with $4$ rows and $4$ columns. So we call it a matrix of type $(4,4)$.</span>
            </p><p xmlns="Unit">
               <span>We have already used matrices to record the coefficients of a system of linear equations. For example, the matrices above are the (unaugmented) coefficient matrices of the systems of linear equations below.</span>
            </p>$$
					
					\begin{array}{ccccccc}
\colorbox{lightgreen}{$3$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{$1$}{\color{red}z} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$5$}{\color{red}z} &amp; = &amp; 0
\end{array}
					
				$$$$
					
					\begin{array}{rcccccrcc}
\colorbox{lightgreen}{$7$}{\color{red}r} &amp; - &amp; \colorbox{lightgreen}{$4$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$9$}{\color{red}u} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$3$}{\color{red}r} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$4$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$11$}{\color{red}u} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$-3$}{\color{red}r} &amp; - &amp; \colorbox{lightgreen}{$1$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$9$}{\color{red}u} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$2$}{\color{red}r} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$4$}{\color{red}u} &amp; = &amp; 0 \\
\end{array}
					
				$$</div><div id="dialog-4647" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>Review the section on systems of linear equations and their coefficient matrices.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-4647' style='display:none;'><div class='title'>The Coefficient Matrix of a System of Linear Equations</div><h2> Introduction </h2><div id="dialog-4560" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>RREF = <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>Form</b>
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>We are now going to learn how to work with systems of linear equations more economically. Observe that, when reducing a system of linear equations to 
			<a id="hottag-4560" class="hottag" onmouseover="popup(4560)"> RREF</a>  ,
			we really only manipulate its coefficients, not its variables. So, by carrying the variables along all the time we just do a lot of unnecessary work. &#x2013; How can we do better?</span>
            </p>
<p xmlns="Unit">
               <span>We save ourselves a lot of work by extracting from the system its coefficients and writing them in a rectangle whose rows and columns resemble the original system. Thus we obtain the (augmented) coefficient matrix of the given system of linear equations. Now the operations on equations in a system translate into operations on rows in the associated augmented coefficient matrix. The details follow.</span>
            </p><br /><div class='def'><span class='deftitle'>Coefficient Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Given a system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_1 } \\
\colorbox{lightgreen}{$a_{21}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_2 } \\
%
\vdots &amp;  &amp; \vdots &amp;  &amp; \ddots &amp; &amp; &amp; \vdots &amp; &amp; {\color{blue} \vdots } \\
\vdots &amp;  &amp; \vdots &amp;  &amp;  &amp; \ddots &amp; &amp;  \vdots &amp; &amp; {\color{blue} \vdots } \\
\colorbox{lightgreen}{$a_{m1}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
				$$
                  <p>
                     <span>its augmented coefficient matrix, and its coefficient matrix are the rectangular arrangements of numbers below</span>
                  </p>
                  <table class="mathtable" border="3" cellpadding="1" style="width:100% !important;"><tr>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>Augmented Coefficient Matrix</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>Coefficient Matrix</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style="border-width:3px !important;">
                           $$
								
\begin{array}{cccccc}
\colorbox{lightgreen}{$a_{11} $} &amp; \colorbox{lightgreen}{$a_{12}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{1n}$} &amp; {\color{blue} c_1 } \\
\colorbox{lightgreen}{$a_{21} $} &amp; \colorbox{lightgreen}{$a_{22}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{2n}$} &amp; {\color{blue} c_2 } \\
\vdots &amp; \vdots &amp; \ddots &amp; &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp; \vdots &amp; &amp; \ddots &amp; \vdots &amp; {\color{blue} \vdots } \\
\colorbox{lightgreen}{$a_{m1} $} &amp; \colorbox{lightgreen}{$a_{m2}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{mn}$} &amp; {\color{blue} c_m }
\end{array}
						
							$$
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>&#xA0;&#xA0;</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           $$
								
\begin{array}{ccccc}
\colorbox{lightgreen}{$a_{11} $} &amp; \colorbox{lightgreen}{$a_{12}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{1n}$} \\
\colorbox{lightgreen}{$a_{21} $} &amp; \colorbox{lightgreen}{$a_{22}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{2n}$} \\
\vdots &amp; \vdots &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; \vdots &amp; &amp; \ddots &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1} $} &amp; \colorbox{lightgreen}{$a_{m2}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{mn}$} 
\end{array}
						
							$$
                        </td>
                     </tr></table>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4568' onmouseover='infoopen(4568)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4568' style='display:none;'><div class='pack'><div class='title'>An Example of a Coefficient Matrix</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the coefficient matrix and the augmented coefficient matrix of the system of linear equations</span>
         </p>
			
			      $$
					
\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$0$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$-1$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} z} &amp; = &amp; {\color{blue} 1 } \\
\colorbox{lightgreen}{$3$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$-9$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$3$}{\color{red} z} &amp; = &amp; {\color{blue} 9 } \\
\colorbox{lightgreen}{$3$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$8$}{\color{red} z} &amp; = &amp; {\color{blue} 14 } \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The augmented coefficient matrix is</span>
               </p>
			            $$
					
A\ =\
\left[\begin{array}{rrrr|r}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; {\color{blue} 1 } \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; {\color{blue} 9 } \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; {\color{blue} 14 }
\end{array}
\right]
					
				$$
			
			            <p>
                  <span>The coefficient matrix is</span>
               </p>
			            $$
					
A\ =\
\left[\begin{array}{rrrr}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$}  \\
\end{array}
\right]
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4568" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a coefficient matrix</span>
                     </p>
                  </info></div></ul></div><br /><p xmlns="Unit">
               <span>To find the solutions of a system of linear equations, we turn its augmented coefficient matrix into a matrix in RREF. To this end we apply row operations to the augmented coefficient matrix which correspond to operations on the rows of a system of linear equations. Here is the dictionary which translates between these two settings.</span>
            </p><table class='mathtable' border='2' cellpadding='0' style='width:100% !important;'><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>
                           <b>System Operation</b>
                        </span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>
                           <b>Matrix Operation</b>
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Interchanging of two equations</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Interchanging of two rows</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Multiplying an equation by a nonzero number</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Multiplying a row by a nonzero number</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Adding a multiple of one equation to another</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Adding a multiple of one row to another</span>
                     </p>
                  </td>
               </tr></table><div id="dialog-4576" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An example to illustrate how this works</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-4576' style='display:none;'><div class='pack'><div class='title'>Row Reduction with Coefficient Matrix - Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the solutions of the system of linear equations below by extracting its augmented coefficient matrix and transforming it to RREF.</span>
         </p>
			      $$
					
					\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$-1$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}z} &amp; = &amp; 1 \\
%
\colorbox{lightgreen}{$3$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$-9$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$3$}{\color{red}z} &amp; = &amp; 9 \\
%
\colorbox{lightgreen}{$3$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$8$}{\color{red}z} &amp; = &amp; 14 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The augmented coefficient matrix of the given system of linear equations is.</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|r}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; 9 \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14
\end{array}
					
				$$
			
			            <p>
                  <span>The part on the left of the vertical bar is the coefficient matrix. The part on the right is the augmented part, also called the augmentation vector. To find the solutions of the given system of linear equations, we reduce the augmented coefficient matrix to RREF. We begin by interchanging the first two rows:</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; 9 &amp; {\color{red} :3} \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14 &amp;
\end{array}
					
				$$
			
			            <p>
                  <span>Dividing the first row by $3$ yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14 &amp; {\color{red} -3\cdot R_1}
\end{array}
					
				$$
			
			            <p>
                  <span>Subtracting $3$ times the first row from the third yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$10$} &amp; \colorbox{lightgreen}{$-5$} &amp; \colorbox{lightgreen}{$5$} &amp; 5 &amp; {\color{red} (-5)\cdot R_2}
\end{array}
					
				$$
			
			            <p>
                  <span>Subtracting $5$ times the second row from the third yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; {\color{red} :2}\\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>Dividing the second row by $2$ yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  {\color{red} +3\cdot R_2 }\\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-1/2$} &amp; \colorbox{lightgreen}{$1/2$} &amp; 1/2 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>Adding $3$ times row 2 to row $1$ yields.</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1/2$} &amp; \colorbox{lightgreen}{$5/2$} &amp; 9/2 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-1/2$} &amp; \colorbox{lightgreen}{$1/2$} &amp; 1/2 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>The matrix above is in Row Reduced Echelon Form. This tells us that the original system of linear equations is equivalent to the system.</span>
               </p>
			
			            $$
					
					\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$1$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1/2$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$5/2$}{\color{red}z} &amp; = &amp; 9/2 \\
%
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$-1/2$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$1/2$}{\color{red}z} &amp; = &amp; 1/2 \\
%
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$0$}{\color{red}z} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			            <p>
                  <span>Thus we see that its solutions are obtained by choosing freely number values for $y$ and $z$ and then solving for the variables tied to leading $1$:</span>
               </p>
			
			            $$
					
					\aligned
x\ &amp;=\ \dfrac{1}{2}\ +\ \dfrac{1}{2}\, y\ -\ \dfrac{1}{2}\, z \\
w\ &amp;=\ \dfrac{9}{2}\ -\ \dfrac{1}{2}\, y\ -\ \dfrac{5}{2}\, z
\endaligned
					
				$$
			
			            <p>
                  <span>Consequently, the solutions of this system of linear equations are vectors of the form</span>
               </p>
			
			            $$
					
\begin{array}{l}
\left( \dfrac{9}{2}\, -\, \dfrac{1}{2}\, y\, -\, \dfrac{5}{2}\, z , \dfrac{1}{2}\, +\, \dfrac{1}{2}\, y\, -\, \dfrac{1}{2}\, z , y , z \right) = \\
\tfrac{1}{2}\cdot (9,1,0,0) + y\cdot (-\tfrac{1}{2},\tfrac{1}{2},1,0) + z\cdot (-\tfrac{5}{2},-\tfrac{1}{2},0,1)
\end{array}
					
				$$
			
			            <p>
                  <span>where $y$ and $z$ are arbitrary real numbers. So we see that the solutions of the given system of linear equations are spanned by the vectors $(-\tfrac{1}{2},\tfrac{1}{2},1,0)$ and $(-\tfrac{5}{2},-\tfrac{1}{2},0,1)$ and is shifted by the vector $(\tfrac{9}{2},\tfrac{1}{2},0,0)$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div>
<p xmlns="Unit">
               <span>Thus we can save ourselves quite a bit of 
			<a id="activehottag-4576" class="activehottag" onmouseover="infoopen(4576)"> writing effort</a>  
			by working with the augmented coefficient matrix instead of the full system of linear equations.</span>
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Shape of an RREF cofficient matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An augmented coefficient matrix in RREF has the following form</span>
      </p>$$
				
\begin{array}{ccccccccccccccc|c}
0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_1 } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_2 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_r } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} * } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 }
\end{array}
				
			$$<p xmlns="Theorem">
         <span>The ${*}$ in the augmentation column of the $(r+1)$-st row is either a $0$ or a $1$. If it is a $1$, then $d_1=\cdots =d_r=0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The rank of a system of linear equations is the number of leading $1$’s in the RREF of its non-augmented coefficient matrix.</span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4586' onmouseover='infoopen(4586)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4586' style='display:none;'><div class='pack'><div class='title'>The rank of a system of linear equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the rank of the system of linear equations</span>
         </p>
			      $$
					
\begin{array}{rcrcrcr}
x &amp; + &amp; 3y &amp; &amp; &amp; = &amp; 4 \\
  &amp;   &amp;    &amp; &amp; z &amp; = &amp; -1
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The coefficient matrix of this system of linear equations is</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
{\color{red} 1} &amp; 3 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; {\color{red} 1} &amp; -1
\end{array}
					
				$$
			            <p>
                  <span>The non-augmented coefficient matrix has two leading 1’s. Therefore the rank of this system of linear equations is $2$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose a system of linear equations has a coefficient matrix which row reduces to </span>
         </p>
			      $$
					
\begin{array}{rrrrrr|r}
1 &amp; 3 &amp; 0 &amp; 0 &amp; 7 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 5 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 5
\end{array}
					
				$$
			      <p>
            <span>Find the rank of the system.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Indeed, the given matrix is already in RREF. Let us identify its leading 1’s:</span>
               </p>
			            $$
					
\begin{array}{rrrrrr|r}
{\color{red} 1} &amp; 3 &amp; 0 &amp; 0 &amp; 7 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; {\color{red} 1} &amp; 0 &amp; 5 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; {\color{red} 1} &amp; 1 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; {\color{red} 1} &amp; 5
\end{array}
					
				$$
			            <p>
                  <span>So the non-augmented part of the row reduced coefficient matrix contains 4 leading 1’s. Therefore the rank of this system of linear equations is 4.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4586" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of the rank of a system of linear equations</span>
                     </p>
                  </info></div></ul></div><br /></div>
<p xmlns="Unit">
            <span>We use the term matrix to refer to any rectangular arrangement of objects.
		
		Here, in linear algebra, we encounter primarily matrices of numbers, that is 
		<a id="activehottag-4552" class="activehottag" onmouseover="infoopen(4552)"> rectangular arrangement of numbers</a>  . 
		Such an arrangement can serve any one of a vast variety of organizational purposes. For example, when we learned how to solve  
		<a id="activehottag-4647" class="activehottag" onmouseover="infoopen(4647)"> system of linear equations</a>   we arranged the coefficients of the system in a matrix to facilitate the execution of row operations.
	</span>
            
         </p>
<p xmlns="Unit">
            <span>But matrices can do much more than serve organizational purposes: like vectors, matrices of equal size can be added; it is possible to multiply a matrix by a number; and then there is a new operation: whenever the sizes of two matrices $\Mtrx{A}$ and $\Mtrx{B}$ are compatible, the product $\Mtrx{A}\cdot \Mtrx{B}$ is defined.</span>
         </p><p xmlns="Unit">
            <span>It is possible to embed the system $\RNr{}$ of real numbers in the system of matrices, for example by turning a number $x$ into the matrix $[x]$ consisting of a single entry. Thus the system of all matrices vastly extends the system of real numbers, an extension which is enormously versatile and powerful.</span>
         </p><p xmlns="Unit">
            <span>We will use matrices for a variety of purposes: they will enable us to obtain additional tools to solve systems of linear equations. Further, we will learn how to use matrices to transform space, how to manipulate the location of objects in space, and how alter the shape of objects in space.</span>
         </p><p xmlns="Unit">
            <span>Let us now sketch a few stages of the history of matrices. The benefits of organizing numbers into a rectangular arrangement have been observed quite early. For example</span>
         </p><div id="dialog-4658" class="dialogs" title="The Lo Shu-magic square"><info xmlns="Unit">
                           
				
				                       <p>
                              <span>In  today's language, the Lo Shu-magic square is a matrix of size $(3,3)$ with the ‘magical’ property that the sum of the numbers in any one row, column, or diagonal all equal the same number. For example, the matrix below is a Lo Shu-magic square whose row-, column-, and diagonal sums all equal $15$.</span>
                           </p>
				                       $$
						
						\left[
						\begin{array}{ccc}
						2 &amp; 7 &amp; 6 \\
						9 &amp; 5 &amp; 1 \\
						4 &amp; 3 &amp; 8
						\end{array}
						\right]
						
					$$
			                     </info></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>The &#x2018;Lo Shu&#x2019;-<a id="hottag-4658" class="hottag" onmouseover="popup(4658)"> magic square</a>  
		of China was recorded around 650 BCE in China.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Also in China, the use of matrices to solve systems of linear equations is documented in Jiu Shang Suan Shu's <i>The Nine Chapters on the Mathematical Art</i>, which originated between 300 BCE and 200 CE.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Magic squares appear in the Arab literature around 700 CE. One can speculate that the became familiar with this concept via links to the ancient Chinese culture when they invaded parts of India's north-west.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>The word ‘matrix’ itself for a rectangular arrangement of numbers was introduced much later in 1848 by J.J. Sylvester,
		
		and the theory of matrices evolved subsequently with many contributors, among them R.W. Hamilton (1805-1865),
		
		H. Grassmann (1809-1877),
		
		A. Cayley (1821-1895),
		
		F.G. Frobenius (1849-1917),
		
		J. von Neumann (1903-1957),
		
		O. Taussky-Todd (1906-1995).
		
	</span>
            
            
            
            
            
            
            
         </p></div></li><li><span>matrix      </span><a id='glossaryinfo-4554' class='msm_infobutton' onmouseover='infoopen(4554)'>i</a><div id="dialog-4554" class="dialogs"><info xmlns="Unit">
                  <p>
                     <span>General description as a rectangular arrangement of objects</span>
                  </p>
               </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4554' style='display:none;'><div class='title'>Matrix Algebra</div><h2> Introduction </h2><div id="dialog-4552" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>An illustration of matrices</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-4552' style='display:none;'><div class='title'>Description of a Matrix</div><p xmlns="Unit">
               <span>A matrix of numbers is a rectangular arrangement of numbers. Here are some examples:</span>
            </p>$$
					
						\left[
						\begin{array}{rrr}
						3 &amp; 1 &amp; -1 \\
						0 &amp; 2 &amp;  5
						\end{array}
						\right]
					
				$$<p xmlns="Unit">
               <span>This is a matrix with $2$ rows and $3$ columns. So we call it a matrix of type $(2,3)$.</span>
            </p>$$
					
						\left[
						\begin{array}{rrrr}
						7 &amp; -4 &amp; 6 &amp; 9 \\
						3 &amp; 0 &amp; 4 &amp; 11 \\
						-3 &amp; -1 &amp; 6 &amp; 9 \\
						2 &amp; 2 &amp; 0 &amp; 4
						\end{array}
						\right]
					
				$$<p xmlns="Unit">
               <span>This is a matrix with $4$ rows and $4$ columns. So we call it a matrix of type $(4,4)$.</span>
            </p><p xmlns="Unit">
               <span>We have already used matrices to record the coefficients of a system of linear equations. For example, the matrices above are the (unaugmented) coefficient matrices of the systems of linear equations below.</span>
            </p>$$
					
					\begin{array}{ccccccc}
\colorbox{lightgreen}{$3$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}y} &amp; - &amp; \colorbox{lightgreen}{$1$}{\color{red}z} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$5$}{\color{red}z} &amp; = &amp; 0
\end{array}
					
				$$$$
					
					\begin{array}{rcccccrcc}
\colorbox{lightgreen}{$7$}{\color{red}r} &amp; - &amp; \colorbox{lightgreen}{$4$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$9$}{\color{red}u} &amp; = &amp; 0 \\
%
\colorbox{lightgreen}{$3$}{\color{red}r} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$4$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$11$}{\color{red}u} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$-3$}{\color{red}r} &amp; - &amp; \colorbox{lightgreen}{$1$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$9$}{\color{red}u} &amp; = &amp; 0 \\
\colorbox{lightgreen}{$2$}{\color{red}r} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}s} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}t} &amp; + &amp; \colorbox{lightgreen}{$4$}{\color{red}u} &amp; = &amp; 0 \\
\end{array}
					
				$$</div><div id="dialog-4647" class="dialogs"><info xmlns="Unit">
				
				                    <p>
                           <span>Review the section on systems of linear equations and their coefficient matrices.</span>
                        </p>
			                  </info></div><div class='refcontent' id='refcontent-4647' style='display:none;'><div class='title'>The Coefficient Matrix of a System of Linear Equations</div><h2> Introduction </h2><div id="dialog-4560" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>RREF = <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>Form</b>
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>We are now going to learn how to work with systems of linear equations more economically. Observe that, when reducing a system of linear equations to 
			<a id="hottag-4560" class="hottag" onmouseover="popup(4560)"> RREF</a>  ,
			we really only manipulate its coefficients, not its variables. So, by carrying the variables along all the time we just do a lot of unnecessary work. &#x2013; How can we do better?</span>
            </p>
<p xmlns="Unit">
               <span>We save ourselves a lot of work by extracting from the system its coefficients and writing them in a rectangle whose rows and columns resemble the original system. Thus we obtain the (augmented) coefficient matrix of the given system of linear equations. Now the operations on equations in a system translate into operations on rows in the associated augmented coefficient matrix. The details follow.</span>
            </p><br /><div class='def'><span class='deftitle'>Coefficient Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>Given a system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_1 } \\
\colorbox{lightgreen}{$a_{21}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_2 } \\
%
\vdots &amp;  &amp; \vdots &amp;  &amp; \ddots &amp; &amp; &amp; \vdots &amp; &amp; {\color{blue} \vdots } \\
\vdots &amp;  &amp; \vdots &amp;  &amp;  &amp; \ddots &amp; &amp;  \vdots &amp; &amp; {\color{blue} \vdots } \\
\colorbox{lightgreen}{$a_{m1}$} {\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$} {\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$} {\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
				$$
                  <p>
                     <span>its augmented coefficient matrix, and its coefficient matrix are the rectangular arrangements of numbers below</span>
                  </p>
                  <table class="mathtable" border="3" cellpadding="1" style="width:100% !important;"><tr>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>Augmented Coefficient Matrix</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>Coefficient Matrix</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style="border-width:3px !important;">
                           $$
								
\begin{array}{cccccc}
\colorbox{lightgreen}{$a_{11} $} &amp; \colorbox{lightgreen}{$a_{12}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{1n}$} &amp; {\color{blue} c_1 } \\
\colorbox{lightgreen}{$a_{21} $} &amp; \colorbox{lightgreen}{$a_{22}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{2n}$} &amp; {\color{blue} c_2 } \\
\vdots &amp; \vdots &amp; \ddots &amp; &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp; \vdots &amp; &amp; \ddots &amp; \vdots &amp; {\color{blue} \vdots } \\
\colorbox{lightgreen}{$a_{m1} $} &amp; \colorbox{lightgreen}{$a_{m2}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{mn}$} &amp; {\color{blue} c_m }
\end{array}
						
							$$
                        </td>
                        <td style="border-width:3px !important;">
                           <p>
                              <span>&#xA0;&#xA0;</span>
                           </p>
                        </td>
                        <td style="border-width:3px !important;">
                           $$
								
\begin{array}{ccccc}
\colorbox{lightgreen}{$a_{11} $} &amp; \colorbox{lightgreen}{$a_{12}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{1n}$} \\
\colorbox{lightgreen}{$a_{21} $} &amp; \colorbox{lightgreen}{$a_{22}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{2n}$} \\
\vdots &amp; \vdots &amp; \ddots &amp; &amp; \vdots \\
\vdots &amp; \vdots &amp; &amp; \ddots &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1} $} &amp; \colorbox{lightgreen}{$a_{m2}$} &amp; \cdots &amp; \cdots &amp; \colorbox{lightgreen}{$a_{mn}$} 
\end{array}
						
							$$
                        </td>
                     </tr></table>
               </def.body>
<br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4568' onmouseover='infoopen(4568)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4568' style='display:none;'><div class='pack'><div class='title'>An Example of a Coefficient Matrix</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the coefficient matrix and the augmented coefficient matrix of the system of linear equations</span>
         </p>
			
			      $$
					
\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$0$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$-1$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} z} &amp; = &amp; {\color{blue} 1 } \\
\colorbox{lightgreen}{$3$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$-9$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$3$}{\color{red} z} &amp; = &amp; {\color{blue} 9 } \\
\colorbox{lightgreen}{$3$}{\color{red} w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$8$}{\color{red} z} &amp; = &amp; {\color{blue} 14 } \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The augmented coefficient matrix is</span>
               </p>
			            $$
					
A\ =\
\left[\begin{array}{rrrr|r}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; {\color{blue} 1 } \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; {\color{blue} 9 } \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; {\color{blue} 14 }
\end{array}
\right]
					
				$$
			
			            <p>
                  <span>The coefficient matrix is</span>
               </p>
			            $$
					
A\ =\
\left[\begin{array}{rrrr}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} \\
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$}  \\
\end{array}
\right]
					
				$$
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4568" class="dialogs" title=""><info xmlns="Unit">
                     <p>
                        <span>An example of a coefficient matrix</span>
                     </p>
                  </info></div></ul></div><br /><p xmlns="Unit">
               <span>To find the solutions of a system of linear equations, we turn its augmented coefficient matrix into a matrix in RREF. To this end we apply row operations to the augmented coefficient matrix which correspond to operations on the rows of a system of linear equations. Here is the dictionary which translates between these two settings.</span>
            </p><table class='mathtable' border='2' cellpadding='0' style='width:100% !important;'><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>
                           <b>System Operation</b>
                        </span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>
                           <b>Matrix Operation</b>
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Interchanging of two equations</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Interchanging of two rows</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Multiplying an equation by a nonzero number</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Multiplying a row by a nonzero number</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Adding a multiple of one equation to another</span>
                     </p>
                  </td>
                  <td style='border-width:2px !important;'>
                     <p>
                        <span>Adding a multiple of one row to another</span>
                     </p>
                  </td>
               </tr></table><div id="dialog-4576" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An example to illustrate how this works</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-4576' style='display:none;'><div class='pack'><div class='title'>Row Reduction with Coefficient Matrix - Example</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the solutions of the system of linear equations below by extracting its augmented coefficient matrix and transforming it to RREF.</span>
         </p>
			      $$
					
					\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$2$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$-1$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}z} &amp; = &amp; 1 \\
%
\colorbox{lightgreen}{$3$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$-9$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$6$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$3$}{\color{red}z} &amp; = &amp; 9 \\
%
\colorbox{lightgreen}{$3$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$8$}{\color{red}z} &amp; = &amp; 14 \\
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The augmented coefficient matrix of the given system of linear equations is.</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|r}
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; 9 \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14
\end{array}
					
				$$
			
			            <p>
                  <span>The part on the left of the vertical bar is the coefficient matrix. The part on the right is the augmented part, also called the augmentation vector. To find the solutions of the given system of linear equations, we reduce the augmented coefficient matrix to RREF. We begin by interchanging the first two rows:</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$-9$} &amp; \colorbox{lightgreen}{$6$} &amp; \colorbox{lightgreen}{$3$} &amp; 9 &amp; {\color{red} :3} \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14 &amp;
\end{array}
					
				$$
			
			            <p>
                  <span>Dividing the first row by $3$ yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$3$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$8$} &amp; 14 &amp; {\color{red} -3\cdot R_1}
\end{array}
					
				$$
			
			            <p>
                  <span>Subtracting $3$ times the first row from the third yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$10$} &amp; \colorbox{lightgreen}{$-5$} &amp; \colorbox{lightgreen}{$5$} &amp; 5 &amp; {\color{red} (-5)\cdot R_2}
\end{array}
					
				$$
			
			            <p>
                  <span>Subtracting $5$ times the second row from the third yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$-1$} &amp; \colorbox{lightgreen}{$1$} &amp; 1 &amp; {\color{red} :2}\\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>Dividing the second row by $2$ yields</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-3$} &amp; \colorbox{lightgreen}{$2$} &amp; \colorbox{lightgreen}{$1$} &amp; 3 &amp;  {\color{red} +3\cdot R_2 }\\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-1/2$} &amp; \colorbox{lightgreen}{$1/2$} &amp; 1/2 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>Adding $3$ times row 2 to row $1$ yields.</span>
               </p>
			
			            $$
					
					\begin{array}{rrrr|rr}
\colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1/2$} &amp; \colorbox{lightgreen}{$5/2$} &amp; 9/2 &amp;  \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$1$} &amp; \colorbox{lightgreen}{$-1/2$} &amp; \colorbox{lightgreen}{$1/2$} &amp; 1/2 &amp; \\
%
\colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; \colorbox{lightgreen}{$0$} &amp; 0 &amp; 
\end{array}
					
				$$
			
			            <p>
                  <span>The matrix above is in Row Reduced Echelon Form. This tells us that the original system of linear equations is equivalent to the system.</span>
               </p>
			
			            $$
					
					\begin{array}{rcrcrcrcr}
\colorbox{lightgreen}{$1$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$1/2$}{\color{red}y} &amp; + &amp; \colorbox{lightgreen}{$5/2$}{\color{red}z} &amp; = &amp; 9/2 \\
%
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$1$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$-1/2$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$1/2$}{\color{red}z} &amp; = &amp; 1/2 \\
%
\colorbox{lightgreen}{$0$}{\color{red}w} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}x} &amp; + &amp; \colorbox{lightgreen}{$0$}{\color{red}y} &amp;  + &amp; \colorbox{lightgreen}{$0$}{\color{red}z} &amp; = &amp; 0 \\
\end{array}
					
				$$
			
			            <p>
                  <span>Thus we see that its solutions are obtained by choosing freely number values for $y$ and $z$ and then solving for the variables tied to leading $1$:</span>
               </p>
			
			            $$
					
					\aligned
x\ &amp;=\ \dfrac{1}{2}\ +\ \dfrac{1}{2}\, y\ -\ \dfrac{1}{2}\, z \\
w\ &amp;=\ \dfrac{9}{2}\ -\ \dfrac{1}{2}\, y\ -\ \dfrac{5}{2}\, z
\endaligned
					
				$$
			
			            <p>
                  <span>Consequently, the solutions of this system of linear equations are vectors of the form</span>
               </p>
			
			            $$
					
\begin{array}{l}
\left( \dfrac{9}{2}\, -\, \dfrac{1}{2}\, y\, -\, \dfrac{5}{2}\, z , \dfrac{1}{2}\, +\, \dfrac{1}{2}\, y\, -\, \dfrac{1}{2}\, z , y , z \right) = \\
\tfrac{1}{2}\cdot (9,1,0,0) + y\cdot (-\tfrac{1}{2},\tfrac{1}{2},1,0) + z\cdot (-\tfrac{5}{2},-\tfrac{1}{2},0,1)
\end{array}
					
				$$
			
			            <p>
                  <span>where $y$ and $z$ are arbitrary real numbers. So we see that the solutions of the given system of linear equations are spanned by the vectors $(-\tfrac{1}{2},\tfrac{1}{2},1,0)$ and $(-\tfrac{5}{2},-\tfrac{1}{2},0,1)$ and is shifted by the vector $(\tfrac{9}{2},\tfrac{1}{2},0,0)$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div>
<p xmlns="Unit">
               <span>Thus we can save ourselves quite a bit of 
			<a id="activehottag-4576" class="activehottag" onmouseover="infoopen(4576)"> writing effort</a>  
			by working with the augmented coefficient matrix instead of the full system of linear equations.</span>
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Shape of an RREF cofficient matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An augmented coefficient matrix in RREF has the following form</span>
      </p>$$
				
\begin{array}{ccccccccccccccc|c}
0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_1 } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_2 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_r } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} * } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 }
\end{array}
				
			$$<p xmlns="Theorem">
         <span>The ${*}$ in the augmentation column of the $(r+1)$-st row is either a $0$ or a $1$. If it is a $1$, then $d_1=\cdots =d_r=0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The rank of a system of linear equations is the number of leading $1$’s in the RREF of its non-augmented coefficient matrix.</span>
                  </p>
               </def.body><br /></div><br /><ul class='defminibuttons'><li class='defminibutton' id='defminibutton-4586' onmouseover='infoopen(4586)'><span style='cursor:pointer'>Example</span></li><div class='refcontent' id='refcontent-4586' style='display:none;'><div class='pack'><div class='title'>The rank of a system of linear equations</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Find the rank of the system of linear equations</span>
         </p>
			      $$
					
\begin{array}{rcrcrcr}
x &amp; + &amp; 3y &amp; &amp; &amp; = &amp; 4 \\
  &amp;   &amp;    &amp; &amp; z &amp; = &amp; -1
\end{array}
					
				$$
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>The coefficient matrix of this system of linear equations is</span>
               </p>
			            $$
					
\begin{array}{rrr|r}
{\color{red} 1} &amp; 3 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; {\color{red} 1} &amp; -1
\end{array}
					
				$$
			            <p>
                  <span>The non-augmented coefficient matrix has two leading 1’s. Therefore the rank of this system of linear equations is $2$.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'><statement.showme xmlns="Compositor">
			      <p>
            <span>Suppose a system of linear equations has a coefficient matrix which row reduces to </span>
         </p>
			      $$
					
\begin{array}{rrrrrr|r}
1 &amp; 3 &amp; 0 &amp; 0 &amp; 7 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 5 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 5
\end{array}
					
				$$
			      <p>
            <span>Find the rank of the system.</span>
         </p>
		    </statement.showme></div><br /></div><br /><br /><div class='answershowme'><span class='answershowmetitle'></span><span class='answershowmetype'>Solution</span><br /><div class='mathcontent'><answer.showme.block.body xmlns="Compositor">
			            <p>
                  <span>Indeed, the given matrix is already in RREF. Let us identify its leading 1’s:</span>
               </p>
			            $$
					
\begin{array}{rrrrrr|r}
{\color{red} 1} &amp; 3 &amp; 0 &amp; 0 &amp; 7 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; {\color{red} 1} &amp; 0 &amp; 5 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; {\color{red} 1} &amp; 1 &amp; 0 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; {\color{red} 1} &amp; 5
\end{array}
					
				$$
			            <p>
                  <span>So the non-augmented part of the row reduced coefficient matrix contains 4 leading 1’s. Therefore the rank of this system of linear equations is 4.</span>
               </p>
		          </answer.showme.block.body></div><br /></div><br /></div></div><div id="dialog-4586" class="dialogs" title="Example"><info xmlns="Unit">
                     
                     <p>
                        <span>Examples of the rank of a system of linear equations</span>
                     </p>
                  </info></div></ul></div><br /></div>
<p xmlns="Unit">
            <span>We use the term matrix to refer to any rectangular arrangement of objects.
		
		Here, in linear algebra, we encounter primarily matrices of numbers, that is 
		<a id="activehottag-4552" class="activehottag" onmouseover="infoopen(4552)"> rectangular arrangement of numbers</a>  . 
		Such an arrangement can serve any one of a vast variety of organizational purposes. For example, when we learned how to solve  
		<a id="activehottag-4647" class="activehottag" onmouseover="infoopen(4647)"> system of linear equations</a>   we arranged the coefficients of the system in a matrix to facilitate the execution of row operations.
	</span>
            
         </p>
<p xmlns="Unit">
            <span>But matrices can do much more than serve organizational purposes: like vectors, matrices of equal size can be added; it is possible to multiply a matrix by a number; and then there is a new operation: whenever the sizes of two matrices $\Mtrx{A}$ and $\Mtrx{B}$ are compatible, the product $\Mtrx{A}\cdot \Mtrx{B}$ is defined.</span>
         </p><p xmlns="Unit">
            <span>It is possible to embed the system $\RNr{}$ of real numbers in the system of matrices, for example by turning a number $x$ into the matrix $[x]$ consisting of a single entry. Thus the system of all matrices vastly extends the system of real numbers, an extension which is enormously versatile and powerful.</span>
         </p><p xmlns="Unit">
            <span>We will use matrices for a variety of purposes: they will enable us to obtain additional tools to solve systems of linear equations. Further, we will learn how to use matrices to transform space, how to manipulate the location of objects in space, and how alter the shape of objects in space.</span>
         </p><p xmlns="Unit">
            <span>Let us now sketch a few stages of the history of matrices. The benefits of organizing numbers into a rectangular arrangement have been observed quite early. For example</span>
         </p><div id="dialog-4658" class="dialogs" title="The Lo Shu-magic square"><info xmlns="Unit">
                           
				
				                       <p>
                              <span>In  today's language, the Lo Shu-magic square is a matrix of size $(3,3)$ with the ‘magical’ property that the sum of the numbers in any one row, column, or diagonal all equal the same number. For example, the matrix below is a Lo Shu-magic square whose row-, column-, and diagonal sums all equal $15$.</span>
                           </p>
				                       $$
						
						\left[
						\begin{array}{ccc}
						2 &amp; 7 &amp; 6 \\
						9 &amp; 5 &amp; 1 \\
						4 &amp; 3 &amp; 8
						\end{array}
						\right]
						
					$$
			                     </info></div>
<ul xmlns="Unit">
		          <li>
               <p>
                  <span>The &#x2018;Lo Shu&#x2019;-<a id="hottag-4658" class="hottag" onmouseover="popup(4658)"> magic square</a>  
		of China was recorded around 650 BCE in China.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Also in China, the use of matrices to solve systems of linear equations is documented in Jiu Shang Suan Shu's <i>The Nine Chapters on the Mathematical Art</i>, which originated between 300 BCE and 200 CE.
			
		</span>
                  
               </p>
            </li>
		
		          <li>
               <p>
                  <span>Magic squares appear in the Arab literature around 700 CE. One can speculate that the became familiar with this concept via links to the ancient Chinese culture when they invaded parts of India's north-west.</span>
               </p>
            </li>
	        </ul>
<p xmlns="Unit">
            <span>The word ‘matrix’ itself for a rectangular arrangement of numbers was introduced much later in 1848 by J.J. Sylvester,
		
		and the theory of matrices evolved subsequently with many contributors, among them R.W. Hamilton (1805-1865),
		
		H. Grassmann (1809-1877),
		
		A. Cayley (1821-1895),
		
		F.G. Frobenius (1849-1917),
		
		J. von Neumann (1903-1957),
		
		O. Taussky-Todd (1906-1995).
		
	</span>
            
            
            
            
            
            
            
         </p></div><a id='glossaryinfo-4679' class='msm_infobutton' onmouseover='infoopen(4679)'>i</a><div id="dialog-4679" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of a matrix</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4679' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-4681" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>The plural of matrix is ‘matrices’.</span>
                              </p>
                           </info></div><div id="dialog-4683" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>
							Thus $m$ counts the number of  in the matrix, while $n$ counts the number of columns in the matrix.
						</span>
                              </p>
                           </info></div><div id="dialog-4685" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>A row in a matrix is a horizontal line of its entries</span>
                              </p>
                           </info></div><div id="dialog-4687" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>A column in a matrix is a vertical line of its entries.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>
				Let $m,n\geq 1$ be integers. A 
				<a id="hottag-4681" class="hottag" onmouseover="popup(4681)"> matrix</a>  
				of size 
				<a id="hottag-4683" class="hottag" onmouseover="popup(4683)"> 
                              $(m,n)$
                           </a>  
				or an $(m,n)$-matrix is a rectangular arrangement of numbers
			</span>
                     
                  </p>
                  $$
					
					\left[
					\begin{array}{cccccc}
					a_{11} &amp; a_{12} &amp; a_{13} &amp; \cdots &amp; \cdots &amp; a_{1n} \\
					a_{21} &amp; a_{22} &amp; a_{23} &amp; \cdots &amp; \cdots &amp; a_{2n} \\
					\vdots  &amp; \vdots  &amp; \vdots  &amp; \ddots &amp;              &amp; \vdots \\
					\vdots  &amp; \vdots  &amp; \vdots  &amp;             &amp; \ddots  &amp; \vdots \\
					a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \cdots &amp; \cdots &amp; a_{mn}
					\end{array}
					\right]
					
				$$
                  <p>
                     <span>We write $a_{ij}$ for the entry in 
				<a id="hottag-4685" class="hottag" onmouseover="popup(4685)"> row</a>  
                        $i$ and 
				<a id="hottag-4687" class="hottag" onmouseover="popup(4687)"> column</a>  
                        $j$. This is a number in $\RNr{}$. In more compact notation, the matrix above may be written as $A = [a_{ij}]$, $1\leq i\leq m$ and $1 \leq j \leq n$.
			</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>0-      </span><a id='glossaryinfo-4810' class='msm_infobutton' onmouseover='infoopen(4810)'>i</a><div id="dialog-4810" class="dialogs" title="0-Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4810' style='display:none;'><br /><div class='def'><span class='deftitle'>0-Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For any size $(m,n)$, the $0$-matrix has only $0$'s as entries.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>addition      </span><a id='glossaryinfo-4885' class='msm_infobutton' onmouseover='infoopen(4885)'>i</a><div id="dialog-4885" class="dialogs" title="matrix addition"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4885' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>antisymmetric      </span><a id='glossaryinfo-4941' class='msm_infobutton' onmouseover='infoopen(4941)'>i</a><div id="dialog-4941" class="dialogs" title="Antisymmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is antisymmetric if   $\Mtrx{A} = -\Mtrx{A}^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4941' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>diagonal      </span><a id='glossaryinfo-4817' class='msm_infobutton' onmouseover='infoopen(4817)'>i</a><div id="dialog-4817" class="dialogs" title="Diagonal Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4817' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonal Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A diagonal matrix is square shaped and only diagonal entries $a_{ii}$ are allowed to be distinct from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>diagonalizable      </span><a id='glossaryinfo-20275' class='msm_infobutton' onmouseover='infoopen(20275)'>i</a><div id="dialog-20275" class="dialogs" title="Diagonalizable matrix">
<info xmlns="Unit">
                           
                           <p>
                              <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that</span>
                           </p>
                           <math.array column="3">
                              <tr rowspan="1">
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{D}$
                                 </td>
                                 <td colspan="1" halign="center" valign="middle">
                                    $=$
                                 </td>
                                 <td colspan="2" halign="center" valign="middle">
                                    $\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$
                                 </td>
                              </tr>
                           </math.array>
                           <p>
                              <span>is a diagonal matrix.</span>
                           </p>
                        </info>
</div><div class='glossaryrefcontent' id='glossaryrefcontent-20275' style='display:none;'><br /><div class='def'><span class='deftitle'>Diagonalizable matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An $(n,n)$-matrix $\Mtrx{A}$ is called diagonalizable if there exists and invertible matrix $\Mtrx{C}$ such that
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{D}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C}^{-1}\cdot \Mtrx{A} \Mtrx{C}$</td></tr></table>
                  <p>
                     <span>is a diagonal matrix.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>equation      </span><a id='glossaryinfo-5783' class='msm_infobutton' onmouseover='infoopen(5783)'>i</a><div id="dialog-5783" class="dialogs" title="matrix equation"><info xmlns="Theorem">
               
               <p>
                  <span>On the relationship between matrix equations and linear equations</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5783' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>identity      </span><a id='glossaryinfo-4824' class='msm_infobutton' onmouseover='infoopen(4824)'>i</a><div id="dialog-4824" class="dialogs" title="Identity Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The $(n,n)$-identity matrix $\IdMtrx{n}$is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4824' style='display:none;'><br /><div class='def'><span class='deftitle'>Identity Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $(n,n)$-identity matrix is the square matrix with $n$ rows and $n$ columns whose diagonal entries are all equal to $1$, and all other entries are equal to $0$. We write $\IdMtrx{n}$ for this matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>inverse of a $(2,2)$-matrix      </span><a id='glossaryinfo-11000' class='msm_infobutton' onmouseover='infoopen(11000)'>i</a><div id="dialog-11000" class="dialogs" title="Inverse of a $(2,2)$-matrix"><info xmlns="Theorem">
               
               <p>
                  <span>An invertible $(2,2)$-matrix</span>
               </p>
               $$
							
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11000' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Inverse of a (2,2)-matrix</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>An invertible $(2,2)$-matrix
			</span>
         
         
      </p>$$
				
\Mtrx{A} = 
\left[
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right]\quad \text{has}\quad
\Mtrx{A}^{-1} = \dfrac{1}{\det(\Mtrx{A})}
\left[
\begin{array}{rr}
d &amp; -b \\
-c &amp; a
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>invertible      </span><a id='glossaryinfo-5400' class='msm_infobutton' onmouseover='infoopen(5400)'>i</a><div id="dialog-5400" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5400' style='display:none;'><br /><div class='def'><span class='deftitle'>Invertible Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ of size $(n,n)$ is invertible if there is a matrix $\Mtrx{B}$ such that</span>
                  </p>
                  $$\Mtrx{A}\Mtrx{B}\ =\ \IdMtrx{n}\ =\ \Mtrx{B}\Mtrx{A}$$
                  <p>
                     <span>In this case, $\Mtrx{B}$ is called the inverse of $\Mtrx{A}$, and is denoted $\Mtrx{A}^{-1}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>multiplication      </span><a id='glossaryinfo-4910' class='msm_infobutton' onmouseover='infoopen(4910)'>i</a><div id="dialog-4910" class="dialogs" title="Matrix Multiplication"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4910' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>associative      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>distributive      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>neutral element      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>of a contraction      </span><a id='glossaryinfo-19494' class='msm_infobutton' onmouseover='infoopen(19494)'>i</a><div id="dialog-19494" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19494' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>The contraction transformations of $\RNr{n}$ are given by</span>
            </p>$$C\from \RNr{n} \longrightarrow \RNr{n},\quad C(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ 0 &lt; s &lt; 1 $ is a fixed number. – Why is it called a ‘contraction transformation’? – $C$ is called a contraction transformation because it shrinks or contracts each distance and, therefore, each object in $\RNr{n}$ by the factor $s$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Contraction.png' height='162.3125' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $C$, we note that $C$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$C(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $C$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div><a id='glossaryinfo-17580' class='msm_infobutton' onmouseover='infoopen(17580)'>i</a><div id="dialog-17580" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the contraction of $\RNr{n}$ with factor $ 0 &lt; s &lt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17580' style='display:none;'><div class='title'>The Inversion Transformation</div><p xmlns="Unit">
               <span>The inversion transformation of $\RNr{n}$ is given by</span>
            </p>$$T\from \RNr{n} \longrightarrow \RNr{n},\quad T(\Vect{x}) := (-1)\cdot\Vect{x}$$<p xmlns="Unit">
               <span>Why is it called ‘inversion transformation’? – $T$ is called inversion transformation because it inverts each vector. The effect of this transformation on objects is also described as ‘reflection about the origin’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Inversion.png' height='199.0625' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $T$, we note that $T$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$T(\StdBss{j}) = - \StdBss{j} = (0,\dots ,0,-1,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $T$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{rrrr}
-1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; -1 &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; -1
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the inversion of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
T\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y) = (-x,-y) = 
\left[
\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; -1
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>of a dilation      </span><a id='glossaryinfo-8625' class='msm_infobutton' onmouseover='infoopen(8625)'>i</a><div id="dialog-8625" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>The matrix representing the dilation of $\RNr{n}$ with factor $ s &gt; 1 $ is represented by the matrix $s\cdot \IdMtrx{n}$; i.e. $s$ times the identity matrix of size $(n,n)$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8625' style='display:none;'><div class='title'>The Dilation Transformations</div><p xmlns="Unit">
               <span>The dilation transformations of $\RNr{n}$ are given by</span>
            </p>$$D\from \RNr{n} \longrightarrow \RNr{n},\quad D(\Vect{x}) := s\cdot\Vect{x}$$<p xmlns="Unit">
               <span>where $ s &gt; 1 $ is a fixed number. Thus $D$ magnifies or dilates each vector and, therefore, each object in $\RNr{n}$ by the factor $s$ – hence the name ‘dilation transformation’.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Dilation.png' height='147' width='350'/></div><p xmlns="Unit">
               <span>To find the matrix representing $D$, we note that $D$ transforms the basic vector $\StdBss{j}$ into
				</span>
               
               
            </p>$$D(\StdBss{j}) = s\cdot \StdBss{j} = (0,\dots ,0,s,0,\dots ,0)$$<p xmlns="Unit">
               <span>Therefore $D$ is represented by the matrix of size $(n,n)$
               </span>
            </p>$$
					
s\cdot \IdMtrx{n} = 
\left[
\begin{array}{cccc}
s &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; s &amp;             &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; s
\end{array}
\right]
					
				$$<p xmlns="Unit">
               <span>For example, the dilation of $\RNr{2}$ in the picture above is</span>
            </p>$$
					
D\from \RNr{2} \longrightarrow \RNr{2},\qquad D(x,y)=\tfrac{3}{2}\cdot (x,y) = 
\left[
\begin{array}{cc}
\tfrac{3}{2} &amp; 0 \\
0 &amp; \tfrac{3}{2}
\end{array}
\right] \left[ \begin{array}{c} x \\ y \end{array} \right]
					
				$$</div></li><li><span>of one column      </span><a id='glossaryinfo-4792' class='msm_infobutton' onmouseover='infoopen(4792)'>i</a><div id="dialog-4792" class="dialogs" title="Column Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(m,1)$ is called a column matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4792' style='display:none;'><br /><div class='def'><span class='deftitle'>Column Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(m,1)$ is called a column matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of one row      </span><a id='glossaryinfo-4785' class='msm_infobutton' onmouseover='infoopen(4785)'>i</a><div id="dialog-4785" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4785' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of upper triangular shape      </span><a id='glossaryinfo-4840' class='msm_infobutton' onmouseover='infoopen(4840)'>i</a><div id="dialog-4840" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is of upper triangular shape if it is square shaped and only entries on or above the diagonal are different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4840' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>orthogonal      </span><a id='glossaryinfo-8212' class='msm_infobutton' onmouseover='infoopen(8212)'>i</a><div id="dialog-8212" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8212' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>power      </span><a id='glossaryinfo-20405' class='msm_infobutton' onmouseover='infoopen(20405)'>i</a><div id="dialog-20405" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>A method of computing powers $\Mtrx{A}^r$ of a diagonalizable matrix $\Mtrx{A}$
                  </span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20405' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Matrix exponentiation</span><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>For an integer $r\geq 1$ and a diagonalizable matrix $\Mtrx{A}$ with $\Mtrx{D} = \Mtrx{C}^{-1} \Mtrx{A} \Mtrx{C}$ diagonal,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{A}^r$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Mtrx{C} \Mtrx{D}^r \Mtrx{C}^{-1}$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>representing a linear map      </span><a id='glossaryinfo-15515' class='msm_infobutton' onmouseover='infoopen(15515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15515' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>row rescaling      </span><a id='glossaryinfo-5515' class='msm_infobutton' onmouseover='infoopen(5515)'>i</a><div id="dialog-5515" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5515' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>scalar multiplication      </span><ul class='chilren'><li><span>commutes with matrix multiplication      </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>distributes over matrix sums      </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>is associative      </span><a id='glossaryinfo-5180' class='msm_infobutton' onmouseover='infoopen(5180)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5180' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Distributes over a matrix sum</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The scalar multiplication of a matrix by a number has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Distributes over a matrix sum</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (A + B) = t\cdot A\ +\ t\cdot B$
               </span>
               
               
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Scalar sum distributes over matrices: $(s+t)\cdot A = s\cdot A + t\cdot A$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of scalars multiplies associatively</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(st)\cdot A = s\cdot (tA)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Product of matrices multiplies associatively into a scalar</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot (AB) = (tA)B$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Left and right multiplication by a scalar are equal</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $t\cdot A = A \cdot t$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>scalar product      </span><a id='glossaryinfo-4899' class='msm_infobutton' onmouseover='infoopen(4899)'>i</a><div id="dialog-4899" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4899' style='display:none;'><div class='title'>Matrix Operations</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we explain how to add matrices, how to multiply a matrix by a number, how to multiply two matrices, and what the transpose of a matrix is. The system of all matrices, endowed with these operations, forms a vast and powerful extension of the system of real number $\RNr{}$.</span>
            </p><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Scalar Product of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The (scalar) product of a matrix $A = [a_{ij}]$ by a number $t$ is</span>
                  </p>
                  $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>Addition of matrices and scalar multiplying a matrix by a number probably seem familiar because they behave completely like the corresponding operations on vectors. However, the next operation, multiplying one matrix by another, is new. Please pay particular attention to the size compatibility we require if we want to multiply two matrices.</span>
            </p><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>The transpose operation helps us single out the following special kind of matrix:</span>
            </p><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>square shaped      </span><a id='glossaryinfo-4774' class='msm_infobutton' onmouseover='infoopen(4774)'>i</a><div id="dialog-4774" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A square shaped matrix is one whose number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4774' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><a id='glossaryinfo-4881' class='msm_infobutton' onmouseover='infoopen(4881)'>i</a><div id="dialog-4881" class="dialogs" title="matrix sum"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4881' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>symmetric      </span><a id='glossaryinfo-4937' class='msm_infobutton' onmouseover='infoopen(4937)'>i</a><div id="dialog-4937" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4937' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-20393' class='msm_infobutton' onmouseover='infoopen(20393)'>i</a><div id="dialog-20393" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Appears here in the context of: a symmetric matrix is diagonalizable.</span>
               </p>
            </info></div></li><li><span>transpose      </span><a id='glossaryinfo-4924' class='msm_infobutton' onmouseover='infoopen(4924)'>i</a><div id="dialog-4924" class="dialogs" title="Matrix Transpose"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4924' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>transposition      </span><ul class='chilren'><li><span>anticommutes with multiplication      </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with addition      </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>commutes with scalar multiplication      </span><a id='glossaryinfo-5242' class='msm_infobutton' onmouseover='infoopen(5242)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5242' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Transposition is its own inverse</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The transposition operation on matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Transposition is its own inverse</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}^T)^T = \Mtrx{A}$
               </span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with addition of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A} + \Mtrx{B})^T = \Mtrx{A}^T + \Mtrx{B}^T$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalar multiplication of matrices</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(t\cdot \Mtrx{A})^T = t\cdot (\Mtrx{A}^T)$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Anticommutes with multiplication</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(\Mtrx{A}\Mtrx{B})^T = \Mtrx{B}^T \Mtrx{A}^T$
               </span>
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li></ul></li><li><span>matrix multiplication      </span><ul class='chilren'><li><span>commutes with determinant      </span><a id='glossaryinfo-9650' class='msm_infobutton' onmouseover='infoopen(9650)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9650' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>minor      </span><a id='glossaryinfo-8901' class='msm_infobutton' onmouseover='infoopen(8901)'>i</a><div id="dialog-8901" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The $(i,j)$-minor of a matrix $\Mtrx{A}$ is the result of omitting the $i$-th row and the $j$-th column from $\Mtrx{A}$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8901' style='display:none;'><br /><div class='def'><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a matrix $\Mtrx{A}$ of size $(r,r)$ and a position $(i,j)$ within $\Mtrx{A}$,
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>
                              $i,j$ with $1\leq i\leq r$, $1\leq j\leq r$,</span>
                        </p>
                        <p>
                           <span>the $(i,j)$-minor of $\Mtrx{A}$ is the $(r-1,r-1)$-matrix $\Mtrx{A}_{ij}$ which results from $\Mtrx{A}$ by omitting the $i$-th row and the $j$-th column.</span>
                        </p>
                        $$
						
\Mtrx{A}_{ij} = 
\left[
\begin{array}{cccccc}
a_{11} &amp; \cdots &amp; {\color{red} a_{1j}} &amp; \cdots &amp; \cdots &amp; a_{1r} \\
\vdots &amp; \ddots &amp; {\color{red} \vdots} &amp; &amp; &amp; \vdots \\
\vdots &amp;        &amp; {\color{red} \ddots} &amp;              &amp; &amp; \vdots \\
{\color{red} a_{i1}} &amp; {\color{red} \cdots} &amp; {\color{red} a_{ij}} &amp; {\color{red} \ddots } &amp; {\color{red} \cdots} &amp; {\color{red} a_{ir}} \\
\vdots &amp;  &amp; {\color{red} \vdots} &amp; &amp; \ddots &amp; \vdots \\
a_{r1} &amp; \cdots &amp; {\color{red} a_{rj}} &amp; \cdots &amp; \cdots &amp; a_{rr}
\end{array}
\right]

					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphic linear transformation      </span><a id='glossaryinfo-18831' class='msm_infobutton' onmouseover='infoopen(18831)'>i</a><div id="dialog-18831" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18831' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>monomorphism      </span><a id='glossaryinfo-18835' class='msm_infobutton' onmouseover='infoopen(18835)'>i</a><div id="dialog-18835" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>A linear map whose kernel consists only of the $\Vect{0}$-vector</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18835' style='display:none;'><br /><div class='def'><span class='deftitle'>Monomorphism, Epimorphism, Isomorphism</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from V\to W$ is called</span>
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>
                              <i>Monomorphic</i> or a <i>monomorphism</i> if $\ker(L)$ consists only of the $\Vect{0}$-vector.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Epimorphic</i> or an <i>epimorphism</i> if $\im(L)=W$.
					</span>
                           
                           
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <i>Isomorphic</i> or an <i>isomorphism</i> if $L$ is both a monomorphism and an epimorphism.
					</span>
                           
                           
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>multilinear      </span><ul class='chilren'><li><span>property of the determinant operation      </span><a id='glossaryinfo-9074' class='msm_infobutton' onmouseover='infoopen(9074)'>i</a><div id="dialog-9074" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Statement and proof of the multilinearity property</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-9074' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: Multilinearity properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Additivity in each column</span><part.body xmlns="Theorem">
            <p>
               <span>If $A_1,\dots ,A_n$, $X,Y$ denote column vectors, then</span>
            </p>
            $$
					
\det[A_1 \cdots {\color{red}(X+Y)} \cdots  A_n] = \det[A_1 \cdots {\color{red} X} \cdots \ A_n]\ + \det[A_1 \cdots {\color{red} Y} \cdots  A_n]

				$$
            <p>
               <span>Here all of $X$, $Y$, and $(X+Y)$ appear in the same column.</span>
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Commutes with scalars in each column</span><part.body xmlns="Theorem">
            <p>
               <span>For $t$ in $\RNr{}$,</span>
            </p>
            $$
					
\det[A_1\ \dots\ ({\color{red} t}\cdot X)\ \dots \ A_n] = {\color{red} t}\cdot \det[A_1\ \dots\ X\ \dots\ A_n]

				$$
            <p>
               <span>for $1\leq j\leq n$.</span>
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>multiplication      </span><ul class='chilren'><li><span>of a vector by a number      </span><a id='glossaryinfo-838' class='msm_infobutton' onmouseover='infoopen(838)'>i</a><div id="dialog-838" class="dialogs"><info xmlns="Unit">
                                 $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-838' style='display:none;'><br /><div class='def'><span class='deftitle'>Multiplication of a Vector by a Scalar</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a vector $\Vect{x}=(x_1,\dots ,x_n)$ in $\RNr{n}$ by a number $t$ in $\RNr{}$ is
					</span>
                           
                        </p>
                        $$t\cdot \Vect{x}\ =\ t\cdot (x_1,\dots ,x_n)\ :=\ (tx_1,\dots ,tx_n).$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>multiplicity      </span><ul class='chilren'><li><span>algebraic      </span><a id='glossaryinfo-20048' class='msm_infobutton' onmouseover='infoopen(20048)'>i</a><div id="dialog-20048" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20048' style='display:none;'><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>geometric      </span><a id='glossaryinfo-20089' class='msm_infobutton' onmouseover='infoopen(20089)'>i</a><div id="dialog-20089" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... of an eigenvalue. Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20089' style='display:none;'><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>neutral element      </span><ul class='chilren'><li><span>matrix multiplication      </span><a id='glossaryinfo-5196' class='msm_infobutton' onmouseover='infoopen(5196)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-5196' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Associativity</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The multiplication of matrices has the following properties</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Associativity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $(AB)C = A(BC)$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Distributivity</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $A ( B + C) = AB + AC$   $(B + C)D = BD + CD$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Identity matrix is neutral element</span><part.body xmlns="Theorem">
            <p>
               <span>If $\Mtrx{A}$ has size $(m,n)$, then   $\IdMtrx{m}A = A\IdMtrx{n}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>non-degeneracy      </span><ul class='chilren'><li><span>dot product      </span><a id='glossaryinfo-1885' class='msm_infobutton' onmouseover='infoopen(1885)'>i</a><div id="dialog-1885" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the dot product asserts that </span>
                     </p>
                     <p align="center">
                        <span>
                           $\DotPr{ \Vect{x} }{ \Vect{x} } = 0$ if and only if $\Vect{x} = \Vect{0}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1885' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>non-degenerate      </span><ul class='chilren'><li><span>norm      </span><a id='glossaryinfo-1487' class='msm_infobutton' onmouseover='infoopen(1487)'>i</a><div id="dialog-1487" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1487' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1484" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1484" class="hottag" onmouseover="popup(1484)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1699' class='msm_infobutton' onmouseover='infoopen(1699)'>i</a><div id="dialog-1699" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div></li></ul></li><li><span>norm      </span><ul class='chilren'><li><span>non-degeneracy      </span><a id='glossaryinfo-1701' class='msm_infobutton' onmouseover='infoopen(1701)'>i</a><div id="dialog-1701" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1701' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1696" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1696" class="hottag" onmouseover="popup(1696)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1489' class='msm_infobutton' onmouseover='infoopen(1489)'>i</a><div id="dialog-1489" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The non-degeneracy property of the norm operation asserts that, for a vector $\Vect{x}$, $|\Vect{x}| = 0$ if and only if $\Vect{x}$ is the zero vector. – Click to see why it is true.</span>
                     </p>
                  </info></div></li><li><span>of a vector      </span><a id='glossaryinfo-1672' class='msm_infobutton' onmouseover='infoopen(1672)'>i</a><div id="dialog-1672" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm or length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1672' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of a vector: properties      </span><a id='glossaryinfo-1479' class='msm_infobutton' onmouseover='infoopen(1479)'>i</a><div id="dialog-1479" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the norm operation</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1479' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1484" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1484" class="hottag" onmouseover="popup(1484)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1691' class='msm_infobutton' onmouseover='infoopen(1691)'>i</a><div id="dialog-1691" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Click for the proposition formulating basic properties of the norm operation</span>
               </p>
            </info></div></li><li><span>property of the determinant operation      </span><a id='glossaryinfo-10250' class='msm_infobutton' onmouseover='infoopen(10250)'>i</a><div id="dialog-10250" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm property of the determinant says that $\det(\IdMtrx{n})=1$. This is stated and proved here</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-10250' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: alternating and normalizing</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>The determinant operation on $(n,n)$-matrices has the following properties.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>alternating</span><part.body xmlns="Theorem">
            <p>
               <span>interchanging two distinct columns reverses the sign of the determinant.
				</span>
               
               
            </p>
            $$\det [A_1\ \dots\ {\color{blue} A_j}\ \dots\ {\color{red} A_k}\ \dots\ A_n] = -\det[A_1\ \dots\ {\color{red} A_k}\ \dots\ {\color{blue} A_j}\ \dots\ A_n]$$
         </part.body></li><br /><li><span class='parttheoremtitle'>normalizing property</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\det(\IdMtrx{n}) = 1$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>relationship to dot product      </span><a id='glossaryinfo-1588' class='msm_infobutton' onmouseover='infoopen(1588)'>i</a><div id="dialog-1588" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1588' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1599" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1599" class="hottag" onmouseover="popup(1599)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1959' class='msm_infobutton' onmouseover='infoopen(1959)'>i</a><div id="dialog-1959" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The norm and dot product operations are related by the identity</span>
                     </p>
                     $$\DotPr{\Vect{x}}{\Vect{x}} = | \Vect{x} |^2$$
                  </info></div></li></ul></li><li><span>normal      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-2330' class='msm_infobutton' onmouseover='infoopen(2330)'>i</a><div id="dialog-2330" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>to a hyperspace in $\RNr{n}$
                                    </span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2330' style='display:none;'><br /><div class='def'><span class='deftitle'>Hyperspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given a nonzero vector $\Vect{n}$ in $\RNr{n}$, the hyperspace perpendicular to $\Vect{n}$ is the set</span>
                        </p>
                        $$\text{Perp}(\Vect{n}) := \Set{ \Vect{x} \in \RNr{n} \st \DotPr{\Vect{x}}{\Vect{n}} = 0}$$
                        <p>
                           <span>The vector $\Vect{n}$ is called a normal vector of $\text{Perp}(\Vect{n})$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>null space      </span><a id='glossaryinfo-11504' class='msm_infobutton' onmouseover='infoopen(11504)'>i</a><div id="dialog-11504" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11504' style='display:none;'><br /><div class='def'><span class='deftitle'>Null space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The null space of an $(m,n)$-matrix $\Mtrx{A}$ is the collection of all those $\Vect{x}$ in $\RNr{n}$ with $\Mtrx{A}\cdot \Vect{x} = \Vect{0}$. We denote it by $\NllSp{ \Mtrx{A} }$
                     </span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of linear transformations      </span><ul class='chilren'><li><span>sum      </span><a id='glossaryinfo-17715' class='msm_infobutton' onmouseover='infoopen(17715)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-17715' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>ordered      </span><ul class='chilren'><li><span>basis      </span><a id='glossaryinfo-13326' class='msm_infobutton' onmouseover='infoopen(13326)'>i</a><div id="dialog-13326" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>... when used to define a coordinate vector.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13326' style='display:none;'><br /><div class='def'><span class='deftitle'>Coordinate vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given an ordered basis $\EuScript{B} = (\Vect{b}_1,\dots , \Vect{b}_m)$ of a subvector space $V$ of  $\RNr{n}$, the coordinate vector of $\Vect{x}$ in $V$ with respect to $\EuScript{B}$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$\Vect{x}_{\EuScript{B}} = (t_1,\dots ,t_m)\quad \text{if}\quad \Vect{x} = t_1 \Vect{b}_1+\cdots + t_m \Vect{b}_m$$
               </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-14801' class='msm_infobutton' onmouseover='infoopen(14801)'>i</a><div id="dialog-14801" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Explanation of the concept</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14801' style='display:none;'><div class='title'>Explanation: Coordinate Vector</div><p xmlns="Unit">
               <span>What is the meaning of ‘$\EuScript{B} = (\Vect{b}_1,\dots ,\Vect{b_m})$ is an ordered basis? – This statement provides two pieces of information, namely:
			</span>
               
               
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The vectors $\Vect{b}_1$, ... , $\Vect{b}_m$ form a basis of $V$, and</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>These vectors have been arranged into an ordered sequence. Consequently</span>
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>Amongst the basis vectors, there is a 1-st vector, given here by $\Vect{b}_1$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 2-nd vector, given here by $\Vect{b}_2$
                           </span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Then there is a 3-rd vector, given here by $\Vect{b}_3$, etc.</span>
                        </p>
                     </li>
                  </ol>
               </li>
            </ol><p xmlns="Unit">
               <span/>
            </p><p xmlns="Unit">
               <span>Why does ‘coordinate vector’ make sense?</span>
            </p><p xmlns="Unit">
               <span>The notion of ‘coordinate vector’ relies on the fact that every vector $\Vect{x}$ in $V$ can be expressed in exactly one way as a linear combination of the vectors in $\EuScript{B}$:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$t_1 \Vect{b}_1 + \cdots + t_m \Vect{b}_m$</td></tr></table><p xmlns="Unit">
               <span>In other words: the numbers $t_1,\dots ,t_m$ are unique. So we may take them as the entries of a vector in $\RNr{m}$, namely $(t_1,\dots ,t_m)$:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>The 1-st coordinate $t_1$ is the coefficient of the basis vector $\Vect{b}_1$ which was designated the 1-st vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 2-nd coordinate $t_2$ is the coefficient of the basis vector $\Vect{b}_2$ which was designated the 2-nd vector in the basis $\EuScript{B}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The 3-rd coordinate $t_3$ is the coefficient of the basis vector $\Vect{b}_3$ which was designated the 3-rd vector in the basis $\EuScript{B}$; etc.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We emphasize that the numbers $t_1, \dots ,t_m$ depend completely upon the choice of the basis $\EuScript{B}$ and the ordering given to the vectors in $\EuScript{B}$. To record this dependence, we write</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{B}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_1,\dots ,t_m)$</td></tr></table><p xmlns="Unit">
               <span>
                  <b>Example</b>   Suppose we use the vectors in $\EuScript{B}$ to make the new ordered basis $\EuScript{C} = (t_m, \dots ,t_1)$; so we kept the vectors but reversed their ordering. Then</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\Vect{x}_{\EuScript{C}}$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$(t_m,\dots ,t_1)$</td></tr></table></div></li></ul></li><li><span>ordered pair      </span><a id='glossaryinfo-105' class='msm_infobutton' onmouseover='infoopen(105)'>i</a><div id="dialog-105" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>another word for $2$-tuple; i.e. an expression of the form $(x,y)$, where $x$ and $y$ are numbers.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-105' style='display:none;'><div class='title'>Visualizing $\RNr{n}$
      </div><p xmlns="Unit">
               <span>If $n$ is one of the integers $1,2,3$, then we may visualize $\RNr{n}$ as follows</span>
            </p><div id="dialog-99" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. a single number $x$ between brackets: $(x)$
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{}=\RNr{1}$: The set of all <a id="hottag-99" class="hottag" onmouseover="popup(99)"> 
                        $1$-tuples</a>   forms a line on which one point has been designated to be $0$, and a unit of measurement has been chosen. &#x2013; It is customary to call the line the $x$-<b>axis</b>.
		</span>
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R1_illstrtn.gif" height="50" width="350"/></div>
               </span>
            </p>
<div id="dialog-107" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. two number $x$ and $y$ between brackets: $(x,y)$. Such $2$-tuples are also called <b>ordered pairs</b>.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{2}$: The set of all <a id="hottag-107" class="hottag" onmouseover="popup(107)"> 
                        $2$-tuples or ordered pairs</a>  
			forms a plane on which one point $\mathbf{0}$ has been designated to be the origin, and two perpendicular lines with a unit of measurement have been chosen. &#x2013; It is customary to draw one of these axes horizontal and call it the $x$-<b>axis</b>. The other line will then appear vertical and will be called the $y$-<b>axis</b>.
		</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R2_illstrtn.gif" height="345.47413793103" width="350"/></div>
               </span>
            </p>
<div id="dialog-113" class="dialogs" title="Animation of relating ordered pairs to points in the plane">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnCrdnts2_anm.gif" height="223.33333333333" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>If we want to give the name $P$ to the point $(2,1)$
                  <a id="hottag-113" class="hottag" onmouseover="popup(113)"> displayed above</a>  , we write $P(2,1)$ to express that it has coordinates $2$ and $1$.</span>
            </p>
<div id="dialog-118" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>i.e. three numbers $x,y,z$ between brackets: $(x,y,z)$
                           </span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>
                  <b>Visualizing</b>
                  $\RNr{3}$: The set of all <a id="hottag-118" class="hottag" onmouseover="popup(118)"> 
                        $3$-tuples or ordered triples</a>   can be related to points in the world surrounding us. We pick one point, $\mathbf{0}$, to act as the origin. Then we pick three perpendicular lines with a unit of measurement.. &#x2013; In the picture below,
		</span>
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>the first coordinate axis points toward you. We call it the $x$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> the second coordinate axis goes from left to right. We call the $y$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the third coordinate axis has a vertical direction. We call it the $z$-axis</span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/R3_illstrtn.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>If we want to give the name $Q$ to the point $(3,2,2)$ displayed above, we write $Q(3,2,2)$. To plot it, consider the box in the picture above. Then, starting from the origin,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>move 3 units in the $x$-direction (to arrive a the bottom front left corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $y$-direction (to arrive at the front right bottom corner of the box),</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>from there move 2 units parallel to the $z$-direction (to arrive at the blue corner of the box)</span>
                  </p>
               </li>
            </ol><div id="dialog-127" class="dialogs" title="Animation of plotting ordered triples in a 3D-coordinate system.">
<info xmlns="Unit">
                        
                        <p align="center">
                           <span>
                              <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Rn/ims/CrtsnCrdnts3_anm.gif" height="250.6976744186" width="350"/></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>You can also see an 
			<a id="hottag-127" class="hottag" onmouseover="popup(127)"> animation</a>    of this plotting process for several points in $\RNr{3}$.</span>
            </p>
<p xmlns="Unit">
               <span>Note that, in $\RNr{3}$,</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>points on the first coordinate axis are given by triples of the form $(x,0,0)$, where $x$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the second coordinate axis are given by triples of the form $(0,y,0)$, where $y$ is an arbitrary number.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>points on the third coordinate axis are given by triples of the form $(0,0,z)$, where $z$ is an arbitrary number.</span>
                  </p>
               </li>
            </ol></div></li><li><span>orientation      </span><ul class='chilren'><li><span>1-dimensional      </span><a id='glossaryinfo-10030' class='msm_infobutton' onmouseover='infoopen(10030)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10030' style='display:none;'><div class='title'>1-Dimensional Orientation</div><div id="dialog-10042" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10042' style='display:none;'><div class='title'>1-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Forward’ and ‘backward’ on a line are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation1.png' height='35.4375' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{}$ is given by a choice of one of these two directions. Thus a nonzero vector $\Vect{x}=(x)$ represents an orientation $\omega(\Vect{x})$ of  $\RNr{}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $ x&gt;0 $
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Vect{x}$ represents the positive orientation of $\RNr{}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $ x&lt;0 $
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\Vect{x}$ represents the negative orientation of $\RNr{}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, $\Vect{x}=(2)$ below represents the positive orientation of $\RNr{}$. We express this by writing $\omega(\Vect{x}) = +1$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the pair $\Vect{v}=(-3)$ represents the negative orientation of $\RNr{}$. We express this by writing $\omega(\Vect{v}) = -1$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Forward&#x2019; and &#x2018;backward&#x2019; on a line are 
				<a id="activehottag-10042" class="activehottag" onmouseover="infoopen(10042)"> mirrored siblings</a>  .
				An orientation of $\RNr{}$ is given by a choice of one of these two directions. We use a nonzero vector $\Vect{x}=(x)$ to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&gt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the positive orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $ x&lt;0 $
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\Vect{x}$ represents the negative orientation of $\RNr{}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>2-dimensional      </span><a id='glossaryinfo-10044' class='msm_infobutton' onmouseover='infoopen(10044)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10044' style='display:none;'><div class='title'>2-Dimensional Orientation</div><div id="dialog-10067" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10067' style='display:none;'><div class='title'>2-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Counterclockwise’ and ‘clockwise’ motions in the plane are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2.png' height='188.125' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{2}$ is given by a choice of one of these two directions. Any pair $(\Vect{x},\Vect{y})$ of noncolinear vectors represents an orientation $\omega(\Vect{x},\Vect{y})$ of  $\RNr{2}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the counterclockwise direction</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y})$ represents the positive orientation of $\RNr{2}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the clockwise direction</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y})$ represents the negative orientation of $\RNr{2}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the pair $(\Vect{x},\Vect{y})$ below represents the positive or counterclockwise orientation of $\RNr{2}$. We express this by writing $\omega(\Vect{x},\Vect{y}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2CClockwise.png' height='178.0625' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the pair $(\Vect{x},\Vect{y})$ below represents the negative or clockwise orientation of $\RNr{2}$. We express this by writing $\omega(\Vect{x},\Vect{y}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/Orientation2Clockwise.png' height='206.5' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging vectors in a pair of vectors reverses orientation</b>
               </span>
            </p><p xmlns="Unit">
               <span>Start with a pair of vectors $(\Vect{x},\Vect{y})$ representing a given orientation. Then interchange the vectors so as to obtain a new pair of ordered vectors: $(\Vect{y},\Vect{x})$. This new pair also represents an orientation of $\RNr{2}$. However, this time the shorter of the two arcs from $\Vect{y}$ to $\Vect{x}$ is the same as the shorter of the two arcs from $\Vect{x}$ to $\Vect{y}$, just in the opposite direction. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x})$</td></tr></table></div>
<p xmlns="Unit">
                     <span>&#x2018;Counterclockwise&#x2019; and &#x2018;clockwise&#x2019; motions in the plane are 
				<a id="activehottag-10067" class="activehottag" onmouseover="infoopen(10067)"> mirrored siblings</a>  .
				An orientation of $\RNr{2}$ is given by a choice of one of these two directions. We use an ordered pair $(\Vect{x},\Vect{y})$ of noncolinear vectors to represent these directions. We adopt the convention that
				</span>
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the counterclockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the positive orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>The lesser of the two angles from $\Vect{x}$ to $\Vect{y}$ occurs in the clockwise direction</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y})$ represents the negative orientation of $\RNr{2}$
                              </span>
                           </p>
                        </td>
                     </tr></table></div></li><li><span>3-dimensional      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>left hand      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>of a subspace of $\RNr{k}$      </span><a id='glossaryinfo-14510' class='msm_infobutton' onmouseover='infoopen(14510)'>i</a><div id="dialog-14510" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is given by the choice of an ordered $n$-tuple $\EuScript{B} = (\Vect{b}_1, \dots , \Vect{b}_n)$ of $V$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-14510' style='display:none;'><br /><div class='def'><span class='deftitle'>Orientation of a subspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>An orientation of an $n$-dimensional subspace $V$ of $\RNr{k}$ is given by a choice of an ordered basis $\EuScript{B} = (\Vect{b}_1 , \dots , \Vect{b}_n )$ of $V$.
				</span>
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>right hand      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>oriented      </span><ul class='chilren'><li><span>volume      </span><a id='glossaryinfo-10274' class='msm_infobutton' onmouseover='infoopen(10274)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10274' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>orthogonal      </span><ul class='chilren'><li><span>complement      </span><a id='glossaryinfo-11464' class='msm_infobutton' onmouseover='infoopen(11464)'>i</a><div id="dialog-11464" class="dialogs" title="Orthogonal complement"><info xmlns="Unit">
                           
                           <p>
                              <span>The orthogonal complement of a subset $S$ in a sub vector space $V$ of $\RNr{n}$ is the set of those $\Vect{x}$ in $V$ which are perpendicular to every $\Vect{s}$ in $S$.   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11464' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal complement</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal complement of a subset $S$ in a subvector space $V$ of $\RNr{n}$ is
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$S^{\bot}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-11468" class="hottag" onmouseover="popup(11468)">$:=	$</a><div id="dialog-11468" class="dialogs" title="How do you read this?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>Read this as: &#x2018;S perp is defined to be the set of all those $\Vect{x}$ in $V$ such that $\Vect{x}$ dot $\Vect{s}$ equals 0, for all $\Vect{s}$ in S&#x2019;</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Set{ \Vect{x}\in V \st \DotPr{ \Vect{x} }{ \Vect{s} }=0,\ \ \text{for all $\Vect{s}\in S$} }$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>linear transformation      </span><a id='glossaryinfo-17009' class='msm_infobutton' onmouseover='infoopen(17009)'>i</a><div id="dialog-17009" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17009' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>matrix      </span><a id='glossaryinfo-17133' class='msm_infobutton' onmouseover='infoopen(17133)'>i</a><div id="dialog-17133" class="dialogs" title="What is an orthogonal matrix?"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $\Mtrx{A}$ is called orthogonal if $\Mtrx{A}\Mtrx{A}^T = \IdMtrx{}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17133' style='display:none;'><br /><div class='def'><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is called orthogonal if its column vectors have length $1$ and are mutually orthogonal.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>projection      </span><a id='glossaryinfo-13750' class='msm_infobutton' onmouseover='infoopen(13750)'>i</a><div id="dialog-13750" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Of a subspace $W$ of $\RNr{n}$ onto a subspace $V$ of $W$. – Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13750' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Given subspaces $V\subseteq W$ of $\RNr{n}$, the orthogonal projection of $W$ onto $V$ is
				</span>
                     
                     
                  </p>
                  $$\pr_V\from W \longrightarrow V,\quad \pr_V(\Vect{x}) := (\DotPr{ \Vect{x} }{ \Vect{b}_1 })\Vect{b}_1 + \cdots + (\DotPr{ \Vect{x} }{ \Vect{b}_r })\Vect{b}_r$$
                  <p>
                     <span>where $\EuScript{B}=(\Vect{b}_1,\dots ,\Vect{b}_r)$ is an arbitrary ONB of $V$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>$\RNr{n}$ onto a hyperspace      </span><a id='glossaryinfo-6970' class='msm_infobutton' onmouseover='infoopen(6970)'>i</a><div id="dialog-6970" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6970' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>projection of a vector along a line      </span><a id='glossaryinfo-2193' class='msm_infobutton' onmouseover='infoopen(2193)'>i</a><div id="dialog-2193" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2193' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>projection of a vector along another      </span><a id='glossaryinfo-2236' class='msm_infobutton' onmouseover='infoopen(2236)'>i</a><div id="dialog-2236" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The orthogonal projection of a vector $\Vect{x}$ along $\Vect{y} \neq \Vect{0}$ is the vector </span>
                           </p>
                           $$\pr_{\Vect{y}}(\Vect{x}) := \dfrac{\Vect{x} \bullet \Vect{y} }{\Vect{y} \bullet \Vect{y} \cdot \Vect{y}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2236' style='display:none;'><br /><div class='def'><span class='deftype'>Notation</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>We sometimes write $\pr_{\Vect{y}}(\Vect{x})$ for $\pr_{L}(\Vect{x})$, and call it the orthogonal projection of $\Vect{x}$ along $\Vect{y}$.
			 The vector $\Vect{u} = \Vect{x} - \pr_{\Vect{y}} (\Vect{x})$ is called the component of $\Vect{x}$ orthogonal to $\Vect{y}$.
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>reflection      </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace      </span><a id='glossaryinfo-15961' class='msm_infobutton' onmouseover='infoopen(15961)'>i</a><div id="dialog-15961" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15961' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>set of vectors      </span><a id='glossaryinfo-12432' class='msm_infobutton' onmouseover='infoopen(12432)'>i</a><div id="dialog-12432" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12432' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>splitting      </span><a id='glossaryinfo-18515' class='msm_infobutton' onmouseover='infoopen(18515)'>i</a><div id="dialog-18515" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The construction of orthogonal splittings.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18515' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal splitting by orthogonal complement</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>In subspaces $V\subseteq W$ of $\RNr{n}$, the spaces $V$ and $V^{\bot}$ form an orthogonal splitting of $W$. Consequently,
			</span>
         
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(W)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\dim(V) + \dim(V^{\bot})$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>splitting of a subspace      </span><a id='glossaryinfo-13682' class='msm_infobutton' onmouseover='infoopen(13682)'>i</a><div id="dialog-13682" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13682' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-13676" class="dialogs" title="What does this notation mean?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>
                                          $U\cup V$ is the union of the sets $U$ and $V$; i.e. a vector belongs to $U\cup V$ if it belongs to $U$ or to $V$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <a id="hottag-13676" class="hottag" onmouseover="popup(13676)"> 
                                    $W=\span(U\cup V)$
                                 </a>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>orthonormal      </span><ul class='chilren'><li><span>set of vectors      </span><a id='glossaryinfo-12434' class='msm_infobutton' onmouseover='infoopen(12434)'>i</a><div id="dialog-12434" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-12434' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal / Orthonormal Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A set $S$ of nonzero vectors is called orthgonal if</span>
                  </p>
                  $$\DotPr{ \Vect{x} }{ \Vect{y} } = 0\quad \text{for all}\quad \Vect{x}\neq \Vect{y}\in S$$
                  <p>
                     <span>The set $S$ is called orthonormal if it is orthogonal and, in addition, $\abs{ \Vect{x} } = 1$, for each $\Vect{x}$ in $S$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>overdetermined      </span><ul class='chilren'><li><span>system of linear equations      </span><a id='glossaryinfo-3675' class='msm_infobutton' onmouseover='infoopen(3675)'>i</a><div id="dialog-3675" class="dialogs" title="When is a system of linear equations overdetermined?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A system of linear equations is called overdetermined if the number of equations exceeds the number of variables and the system has no solution.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3675' style='display:none;'><div class='title'>Three or more equations</div><p xmlns="Unit">
                     <span>No matter how many equations there are in a given system of linear equations, each of the equations will have a corresponding hyperplane of solutions. Therefore, the set of simultaneous solutions of the system consists of the intersection of the solution hyperplanes of the individual equations. For example:</span>
                  </p><div id="dialog-3685" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Illustration of an overdetermined system of linear equations</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-3685' style='display:none;'><div class='title'>An Overdetermined System of Equations – Illustration</div><p xmlns="Unit">
               <span>The picture below shows the lines of solution of three linear equations in two variables.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/ThreeEqnsR2Overdetermined.gif" height="318" width="434"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>Each of these 3 lines is the solution set of a linear equation in two unknowns. These three lines have no point in common. Therefore the set of simultaneous solutions of the three equations is empty.</span>
            </p><p xmlns="Unit">
               <span>When dealing with 3 equations in 2 variables, how ‘often’ does this happen? – Observe: shifting or rotating any of these solution lines a little will not qualitative change the picture  in the sense there is still no point common to all three lines.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, start from a situation where all three lines pass through a common point. It is then possible to displace two of these lines by a suitable tiny amount so that they have no point in common. (Try this!) So this situation where three lines in the plane have a point in common is a ‘rare’ and special case.</span>
            </p></div><div id="dialog-3693" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Illustration of the solutions of a certain system of 3 linear equations in three unknowns</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-3693' style='display:none;'><div class='title'>A System with Unique Solution – Illustration</div><p xmlns="Unit">
               <span>The picture below shows the planes of solutions in $\RNr{3}$ of three linear equations in three variables.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearEqs/ims/ThreeEqnsR3Generic.gif" height="333" width="390"/></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>Each of these 3 planes is the solution plane of a linear equation in three unknowns. There is exactly on point which lies on all three planes. Therefore this point is the unique simultaneous solution of the given system of linear equations.</span>
            </p></div>
<ul xmlns="Unit">
                     <li>
                        <p>
                           <span>Three linear equations in $2$ two variables will often times have 
					<a id="activehottag-3685" class="activehottag" onmouseover="infoopen(3685)"> no solution</a>  . In this case we say the system is overdetermined.
					</span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>Three linear equations in $3$ variables will often times have 
					<a id="activehottag-3693" class="activehottag" onmouseover="infoopen(3693)"> exactly one solution</a>  .
				</span>
                        </p>
                     </li>
                  </ul>
</div><a id='glossaryinfo-3666' class='msm_infobutton' onmouseover='infoopen(3666)'>i</a><div id="dialog-3666" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3666' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>parallel      </span><ul class='chilren'><li><span>hyperplanes      </span><a id='glossaryinfo-2455' class='msm_infobutton' onmouseover='infoopen(2455)'>i</a><div id="dialog-2455" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-2455' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel hyperplanes</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Two hyperplanes in $\RNr{n}$ are called parallel if they have parallel normal vectors.
				</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>vectors      </span><a id='glossaryinfo-855' class='msm_infobutton' onmouseover='infoopen(855)'>i</a><div id="dialog-855" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-855' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>point      </span><a id='glossaryinfo-281' class='msm_infobutton' onmouseover='infoopen(281)'>i</a><div id="dialog-281" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An $n$-tuple of $\RNr{n}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-281' style='display:none;'><div class='title'>The Space $\RNr{n}$
            </div><br /><div class='def'><span class='deftitle'>The set $\RNr{n}$
                     </span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>For a positive integer $n$, the space $\RNr{n}$ is the set of all $n$-tuples of numbers; in symbols</span>
                           
                        </p>
                        $$\RNr{n}\ :=\ \Set{(x_1,\dots ,x_n)\st x_1,\dots ,x_n\in \RNr{} }$$
                     </def.body><br /></div><br /></div><br /><p xmlns="Unit">
                     <span>We refer to an $n$-tuple of $\RNr{n}$ as a <b>point</b>.
				 
				This terminology is motivated by the following paragraph on ‘Visualizing $\RNr{n}$. We write $P(x_1,\dots ,x_n)$ to say that a point, named $P$, is given by the $n$-tuple $(x_1,\dots ,x_n)$.</span>
                     
                     
                  </p></div></li><li><span>position vector      </span><a id='glossaryinfo-717' class='msm_infobutton' onmouseover='infoopen(717)'>i</a><div id="dialog-717" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The position vector of a $X$ point in $\RNr{n}$ is represented by the arrow $\Arrow{\Vect{0}}{X}$ joining the origin to $X$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-717' style='display:none;'><div class='title'>
               $n$-Tuples for Points and Vectors</div><p xmlns="Unit">
                     <span>Consider these two expressions</span>
                  </p><p xmlns="Unit" align="center">
                     <span>
                        $X(x_1,\dots ,x_n)$   and  $\Vect{x} = (x_1,\dots ,x_n)$.</span>
                  </p><p xmlns="Unit">
                     <span>In the first expression the $n$-tuple  $(x_1,\dots ,x_n)$ characterizes the location of a point. In the second expression the same $n$-tuple forms a coordinate vector. This ambiguity in notation is firmly entrenched in the literature. Fortunately, we can untangle it nicely if we keep in mind the following dictionary for translating between points and vectors.</span>
                     
                  </p>$$
					
            				\xymatrix@C=15pt{
				*+[F-,]{ \txt{A given point\\$X(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{\txt{yields the vector $\Vect{x}=(x_1,\dots ,x_n)$.\\It is represented by the arrow $\Arrow{\Vect{0}}{X}$.\\We call it the {\bf position vector}\index{position vector} of $X$.}} \\
				*+[F-,]{ \txt{A given vector\\$\Vect{x}=(x_1,\dots ,x_n)$} } \ar[rr] &amp; &amp;
				*+[F-,]{ \txt{yields the point $X(x_1,\dots ,x_n)$.\\It is the tip of the arrow with tail at $\Vect{0}$\\and representing $\Vect{x}$.} }
				}
            	
				$$</div></li><li><span>positive definite      </span><ul class='chilren'><li><span>dot product      </span><a id='glossaryinfo-1880' class='msm_infobutton' onmouseover='infoopen(1880)'>i</a><div id="dialog-1880" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The positive definiteness property of the dot product asserts that $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1880' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>preimage      </span><ul class='chilren'><li><span>of a linear transformation      </span><a id='glossaryinfo-8335' class='msm_infobutton' onmouseover='infoopen(8335)'>i</a><div id="dialog-8335" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Discussed here in the context of linear transformations and linear equations.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8335' style='display:none;'><div class='title'>Linear Equations and Linear Transformations</div><p xmlns="Unit">
               <span>We can also use linear transformations to gain an alternate view of linear equations. To explain this, consider a linear transformation $T\from \RNr{n}\to \RNr{m}$. Given $\Vect{y}$ in $\RNr{m}$, we ask: which $\Vect{x}$ in $\RNr{n}$ get transformed into $\Vect{y}$? In other words: which $\Vect{x}$ satisfy the equation</span>
            </p>$$T( \Vect{x} ) = \Vect{y}?$$<div id="dialog-8333" class="dialogs" title="Careful here!"><info xmlns="Unit">
                        
                        <p>
                           <span>
                              $T^{-1}(\Vect{y})$ is notation for a set of points in $\RNr{n}$. We do not assume here that $T$ is an invertible function.</span>
                        </p>
                        <p>
                           <span>On the other hand, if $T$ happens to be invertible the set $T^{-1}(\Vect{y})$ consists of a single point, and this point is the value of the function $T^{-1}$ at $\Vect{y}$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>The collection of such $\Vect{x}$ form the preimage, or the level set, of $\Vect{y}$ under $T$ and is <a id="hottag-8333" class="hottag" onmouseover="popup(8333)"> denoted $T^{-1}(\Vect{y})$
                     </a>  .
			</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Finding the solutions of the equation $T(\Vect{x}) = \Vect{y}$ amounts to finding the solutions of a linear equation. To see this, represent $T$ by an $(m,n)$-matrix $\Mtrx{A}$. Then we have $T(\Vect{x}) = \Mtrx{A}\cdot \Vect{x}$, for every $\Vect{x}$ in $\RNr{n}$. Therefore,
		</span>
            </p>$$T(\Vect{x}) = \Vect{y}\quad \text{ if and only if } \quad A\cdot \Vect{x} = \Vect{y}$$<div id="dialog-8348" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Look up this fact.</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-8348' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the coefficient matrix $\Mtrx{A}$ of the system of $n$ linear equations in $n$ variables
			</span>
         
         
      </p>$$
				
\begin{array}{rcccrcr}
\colorbox{lightgreen}{$a_{11}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$} {\color{red} x_n} &amp; = &amp; c_1 \\
\vdots\ \ \ &amp; &amp; &amp; &amp; \vdots\ \ \ &amp; &amp; \vdots\ \ \\
\colorbox{lightgreen}{$a_{n1}$} {\color{red} x_1} &amp; + &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{nn}$} {\color{red} x_n} &amp; = &amp; c_n
\end{array}
				
			$$<p xmlns="Theorem">
         <span>is invertible. Then this system has the unique solution</span>
      </p>$$
				
{\color{red}\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}}\ =\
A^{-1} \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix}
				
			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div>
<p xmlns="Unit">
               <span>We have 
			<a id="activehottag-8348" class="activehottag" onmouseover="infoopen(8348)"> seen already</a>  
			 that the matrix equation on the right corresponds to a system of $m$ linear equations in $n$ variables.</span>
            </p>
<p xmlns="Unit">
               <span>We will see later, that the preimage of  $\Vect{y}=\Vect{0}$ under $T$ plays a special role. It therefore has its own name: it is called the kernel of  $T$.
			</span>
               
            </p></div></li><li><span>under a function      </span><a id='glossaryinfo-15153' class='msm_infobutton' onmouseover='infoopen(15153)'>i</a><div id="dialog-15153" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>Given a function $f\from X\to Y$ and $y\in Y$, the preimage of $y$ under $f$ consists of all those $x\in X$ such that $f(x)=y$; notation $f^{-1}(y)$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15153' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>product      </span><ul class='chilren'><li><span>of subsets of $\RNr{n}$      </span><a id='glossaryinfo-498' class='msm_infobutton' onmouseover='infoopen(498)'>i</a><div id="dialog-498" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to jump to the definition of ‘product of subsets of $\RNr{n}$’.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-498' style='display:none;'><br /><div class='def'><span class='deftitle'>Product of Sets</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a subset $S$ of $\RNr{m}$ by a subset $T$ of $\RNr{n}$ is the subset $S\times T$ of $\RNr{m+n}$ consisting of all those $(m+n)$-tuples $(x_1,\dots ,x_m\, ,\, y_1,\dots ,y_n)$ with $(x_1,\dots ,x_m)$ in $S$ and $(y_1,\dots ,y_n)$ in $T$.</span>
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of two matrices      </span><a id='glossaryinfo-4908' class='msm_infobutton' onmouseover='infoopen(4908)'>i</a><div id="dialog-4908" class="dialogs" title="product of two matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by</span>
                           </p>
                           $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                           <p>
                              <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $B$:</span>
                           </p>
                           $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4908' style='display:none;'><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>projection      </span><ul class='chilren'><li><span>$\RNr{n}$ onto a hyperspace      </span><a id='glossaryinfo-19570' class='msm_infobutton' onmouseover='infoopen(19570)'>i</a><div id="dialog-19570" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal projection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19570' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Projection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal projection of $\RNr{n}$ onto the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$P\from \RNr{n} \longrightarrow \RNr{n},\quad P(\Vect{x}) = \Vect{x}\ -\ \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>of a vector along a line      </span><a id='glossaryinfo-17612' class='msm_infobutton' onmouseover='infoopen(17612)'>i</a><div id="dialog-17612" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>The projection of a vector $\Vect{x}$ onto the line $L$ in the direction of the nonzero vector $\Vect{y}$ is the vector</span>
               </p>
               $$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-17612' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Orthogonal Projection of a Vector on a Line</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Let $\Vect{x}$ be an arbitrary vector of $\RNr{n}$, and let $L$ be the line through the origin in the direction of a nonzero vector $\Vect{y}$. Then the orthogonal projection of $\Vect{x}$ onto $L$ is the vector
 			</span>
         
         
         
      </p>$$\pr_L(\Vect{x}) = \dfrac{ \DotPr{\Vect{x}}{\Vect{y}} }{ \DotPr{\Vect{y}}{\Vect{y}} } \cdot \Vect{y}$$<p xmlns="Theorem">
         <span>Moreover, $\Vect{y}$ is perpendicular to $\Vect{x} - \pr_{L}(\Vect{x})$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>rank      </span><ul class='chilren'><li><span>formula for matrices      </span><a id='glossaryinfo-18734' class='msm_infobutton' onmouseover='infoopen(18734)'>i</a><div id="dialog-18734" class="dialogs" title="Rank formula for matrices"><info xmlns="Theorem">
               
               $$
							
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

						$$
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-18734' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Rank formula</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For a matrix $\Mtrx{A}$ of size $(m,n)$,
			</span>
         
      </p>$$
				
\begin{array}{rcl}
n &amp; = &amp; \Rnk{ \Mtrx{ A } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \RowSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } } \\
  &amp; = &amp; \Dim{ \ColSp{ \Mtrx{ A } } } + \Dim{ \NllSp{ \Mtrx{ A } } }
\end{array}

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>of a system of linear equations      </span><a id='glossaryinfo-13085' class='msm_infobutton' onmouseover='infoopen(13085)'>i</a><div id="dialog-13085" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>Use of the concept while describing the general solution of such a system.</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13085' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Infinitely many solutions - constructive version</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><div id="dialog-13092" class="dialogs"><info xmlns="Theorem">
                  <p>
                     <span>Recall: the rank of a system of linear equations is the number of leading $1$'s in the non-augmented part of its RREF-matrix</span>
                  </p>
               </info></div>
<statement.theorem><p xmlns="Theorem">
         <span>Suppose a system of linear equations with $n$ variables has 
			<a id="hottag-13092" class="hottag" onmouseover="popup(13092)"> rank</a>  
            $ r&lt;n $. If its RREF-matrix has no leading 1 in the augmentation column</span>
      </p>$$
				
\begin{array}{ccccccccccccccc|c}
0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_1 } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; 0 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_2 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 &amp; * &amp; \cdots &amp; * &amp; {\color{blue} d_r } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 } \\
\vdots &amp;   &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp;   &amp; \vdots &amp; &amp;     &amp; \vdots &amp; {\color{blue} \vdots } \\
0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; {\color{blue} 0 }
\end{array}
					
			$$<p xmlns="Theorem">
         <span>then this system has infinitely many solutions. Moreover, each of its solutions is of the form</span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{x}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\Vect{d}\ + \ t_1 \Vect{b}_1 + \cdots + t_{n-r} \Vect{b}_{n-r}$</td></tr></table><p xmlns="Theorem">
         <span>Here $t_1,\dots ,t_{n-r}$ are arbitrary numbers; and the vectors $\Vect{d}, \Vect{b}_1,\dots ,\Vect{b}_{n-r}$ of $\RNr{n}$ are constructed from the RREF-matrix as follows.
			</span>
         
      </p><ol xmlns="Theorem">
         <li>
            <p>
               <span>Let $\Mtrx{B} = [ b_{ij} ]$ denote the unaugmented part of the RREF-matrix;</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $u_1,\dots ,u_r$ are the columns of $\Mtrx{B}$ containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $j_1,\dots ,j_{n-r}$ are the columns of $\Mtrx{B}$ not containing a leading $1$.</span>
            </p>
         </li>
         <li>
            <p>
               <span>
                  $\Vect{d}$ is the vector in $\RNr{n}$ with $d_k$ in position $u_k$ and $0$'s elsewhere.</span>
            </p>
         </li>
         <li>
            <p>
               <span>For $1\leq k\leq n-r$, let $\Vect{b}_k$ in $\RNr{n}$ be the vector which has</span>
            </p>
            <ul>
               <li>
                  <p>
                     <span>a &#x2018;$1$&#x2019; in position $j_k$
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>the entry $(-b_{i,j_k})$ in position $u_i$;</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>a &#x2018;$0$&#x2019; in each remaining position.</span>
                  </p>
               </li>
            </ul>
         </li>
      </ol></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><a id='glossaryinfo-3824' class='msm_infobutton' onmouseover='infoopen(3824)'>i</a><div id="dialog-3824" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>the definition of the rank of a system of linear equations</span>
                                 </p>
                              </info></div></li></ul></li><li><span>reflection      </span><ul class='chilren'><li><span>$\RNr{n}$ about a hyperspace      </span><a id='glossaryinfo-15977' class='msm_infobutton' onmouseover='infoopen(15977)'>i</a><div id="dialog-15977" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of orthogonal reflection</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-15977' style='display:none;'><br /><div class='def'><span class='deftitle'>Orthogonal Reflection</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The orthogonal reflection of $\RNr{n}$ about the hyperspace perpendicular to the nonzero vector $\Vect{c}$ is given by
				</span>
                     
                     
                  </p>
                  $$M\from \RNr{n} \longrightarrow \RNr{n},\quad M(\Vect{x}) = \Vect{x}\ -\ 2\cdot \dfrac{\DotPr{\Vect{x}}{\Vect{c}}}{\DotPr{\Vect{c}}{\Vect{c}}} \cdot \Vect{c}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>representing matrix      </span><ul class='chilren'><li><span>of a linear map      </span><a id='glossaryinfo-6592' class='msm_infobutton' onmouseover='infoopen(6592)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6592' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li></ul></li><li><span>right hand      </span><ul class='chilren'><li><span>orientation      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li><li><span>rule      </span><a id='glossaryinfo-10069' class='msm_infobutton' onmouseover='infoopen(10069)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10069' style='display:none;'><div class='title'>3-Dimensional Orientation</div><div id="dialog-10113" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Details on this</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-10113' style='display:none;'><div class='title'>3-Dimensional Orientation</div><p xmlns="Unit">
               <span>‘Right hand’ and ‘left hand’ in 3-space are mirrored siblings.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/LeftHandRightHand.jpg' height='233.625' width='350'/></div><p xmlns="Unit">
               <span>An orientation of $\RNr{3}$ is given by a choice of one of these two hands. Any triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors represents an orientation $\omega(\Vect{x},\Vect{y},\Vect{z})$ of  $\RNr{3}$ as follows:</span>
            </p><table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>If</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>we find</span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>and say</span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10080" class="hottag" onmouseover="popup(10080)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10080" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr><tr>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                        </span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10082" class="hottag" onmouseover="popup(10082)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10082" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Without harming your hand</span>
                                 </p>
                              </info></div></span>
                     </p>
                  </td>
                  <td style='border-width:3px !important;'>
                     <p>
                        <span>
                           $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                        </span>
                     </p>
                  </td>
               </tr></table><p xmlns="Unit">
               <span>For example, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the positive or right hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationRightHand.gif' height='248.5' width='350'/></div><p xmlns="Unit">
               <span>On the other hand, the triple $(\Vect{x},\Vect{y},\Vect{z})$ below represents the negative or left hand orientation of $\RNr{3}$. We express this by writing $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$.</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/3OrientationLeftHand.gif' height='229.85074626866' width='350'/></div><p xmlns="Unit">
               <span>
                  <b>Interchanging a pair of vectors reverses orientation</b>   Now start with a triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ representing a given orientation. Then interchange a pair amongst these vectors:  e.g. $(\Vect{y},\Vect{x},\Vect{z})$. This new triple determines an orientation of $\RNr{3}$ which is opposite to the orientation given by $(\Vect{x},\Vect{y},\Vect{z})$. Therefore:</span>
            </p><table border='0' class='matharray'><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{x},\Vect{y},\Vect{z})$</td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{y},\Vect{x},\Vect{z})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{z},\Vect{x},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{x},\Vect{z},\Vect{y})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$\omega(\Vect{y},\Vect{z},\Vect{x})$</td></tr><tr class='matharrayrow' align='center'><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'> </td><td class='matharraycell' colspan='1' rowspan='1' align='center' valign='middle'>$=$</td><td class='matharraycell' colspan='2' rowspan='1' align='center' valign='middle'>$-\omega(\Vect{z},\Vect{y},\Vect{x})$</td></tr></table><p xmlns="Unit">
               <span>In this computation, the identity $\omega(\Vect{x},\Vect{y},\Vect{z}) = \omega(\Vect{z},\Vect{x},\Vect{y})$ means that the triple of vectors $(\Vect{x},\Vect{y},\Vect{z})$ represents the same orientation as the triple of vectors $(\Vect{z},\Vect{x},\Vect{y})$.</span>
            </p><p xmlns="Unit">
               <span>On the other hand, the identity $\omega(\Vect{y},\Vect{z},\Vect{x}) = -\omega(\Vect{x},\Vect{z},\Vect{y})$ means that the respective triples of vectors represent opposite orientations of $\RNr{3}$.</span>
            </p></div>
<p xmlns="Unit">
                     <span>&#x2018;Right hand&#x2019; and &#x2018;left hand&#x2019; in $\RNr{3}$ are 
				<a id="activehottag-10113" class="activehottag" onmouseover="infoopen(10113)"> mirrored siblings</a>  . 
				An orientation of $\RNr{3}$ is given by a choice of one of these two hands. We use an ordered triple $(\Vect{x},\Vect{y},\Vect{z})$ of noncoplanar vectors to represent such a choice, and adopt the convention that
				</span>
                     
                     
                     
                     
                     
                  </p>
<table class='mathtable' border='3' cellpadding='2' style='width:100% !important;'><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>If</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>we find</span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>and say</span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = +1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your right hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10120" class="hottag" onmouseover="popup(10120)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10120" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the positive orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr><tr>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $\omega(\Vect{x},\Vect{y},\Vect{z}) = -1$
                              </span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>It is possible to align your left hand's thumb with $\Vect{x}$, its index finger with $\Vect{y}$, and its 
						<a id="hottag-10122" class="hottag" onmouseover="popup(10122)"> middle finger</a>  
						with $\Vect{z}$.<div id="dialog-10122" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Without harming your hand</span>
                                       </p>
                                    </info></div></span>
                           </p>
                        </td>
                        <td style='border-width:3px !important;'>
                           <p>
                              <span>
                                 $(\Vect{x},\Vect{y},\Vect{z})$ represents the negative orientation of $\RNr{3}$
                              </span>
                           </p>
                        </td>
                     </tr></table><br /><div class='comment'><br/><div class='mathcontent'><div id="dialog-10138" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>Details on this</span>
                                       </p>
                                    </info></div><div class='refcontent' id='refcontent-10138' style='display:none;'><div class='title'>3-Dimensional Orientation and Rotations</div><p xmlns="Unit">
               <span>The right hand orientation is closely related to what is called rotation about an oriented axis according to the right hand rule. </span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Determinants/ims/RightHandRule.jpg" height="262.5" width="350"/></div>
               </span>
            </p>
<div id="dialog-10132" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>A torus looks like the surface of a donut or an inner tube</span>
                        </p>
                     </info></div><div id="dialog-10135" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>View an animation of this rotation. You need to have an animation player capable of using the avi-file format.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>In the picture above the 
				<a id="hottag-10132" class="hottag" onmouseover="popup(10132)"> toroidal</a>  
				object above 
					<a href="http://webmath.math.ualberta.ca/~gepe/LinearAlgebraRn/Determinants/ims/RightHandRule.avi" id="hottag-10134" class="externallink" target="new" onmouseover="popup(10134)"> rotates</a>  
				in the direction of the arrows near "FCM". To identify this rotation as one according to the right hand rule we note: The axis of rotation is oriented by the displayed vector, call it $\Vect{z}$. Upon aligning the thumb of your right hand with $\Vect{z}$, your curled fingers point in the direction of the rotation.</span>
            </p>
<p xmlns="Unit">
               <span>The relationship between a "rotation according to the right hand rule" and the "right hand orientation" is obtained as follows.</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Choose any nonzero vector $\Vect{x}$ perpendicular to $\Vect{z}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Let $\Vect{y}$ be the result of rotating $\Vect{y}$ through the angle of $\pi/2$ according to the right hand rule.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Then the triple $(\Vect{x},\Vect{y},\Vect{z})$ represents the right hand orientation of $\RNr{3}$.</span>
                  </p>
               </li>
            </ol></div>
<comment.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{3}$, orientation and rotation about an oriented axis according to the right/left hand rule are 
					<a id="activehottag-10138" class="activehottag" onmouseover="infoopen(10138)"> closely related concepts</a>  .
				</span>
                           
                           
                        </p>
                     </comment.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>rotation      </span><a id='glossaryinfo-19524' class='msm_infobutton' onmouseover='infoopen(19524)'>i</a><div id="dialog-19524" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the linear transformation of $\RNr{2}$ which describes a rotation.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19524' style='display:none;'><br /><div class='def'><span class='deftitle'>Rotation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The counterclockwise rotation of $\RNr{2}$ about the origin through the angle $\theta$ is given by 
				</span>
                     
                     
                     
                  </p>
                  $$
					
R_{\theta}\from \RNr{2} \longrightarrow \RNr{2},\quad R_{\theta}(x,y) = 
\left[
\begin{array}{rr}
\cos\theta &amp; -\sin\theta \\
\sin\theta &amp; \cos\theta
\end{array}
\right]
\left[
\begin{array}{r} x \\ y \end{array}
\right]
					
				$$
               </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>finding axis of rotation      </span><a id='glossaryinfo-20251' class='msm_infobutton' onmouseover='infoopen(20251)'>i</a><div id="dialog-20251" class="dialogs"><info xmlns="Compositor">
						            <p>
                     <span>An application of the theory of eigenvectors and eigenvalues: given a rotation of $\RNr{3}$, find its axis of rotation.</span>
                  </p>
					          </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-20251' style='display:none;'><div class='title'>Eigenvectors and Eigenvalues</div><h2> Introduction </h2><p xmlns="Unit">
               <span>In this section we introduce the concepts of eigenvector and eigenvalue. Given an $(n,n)$-matrix we learn how to find its eigenvalues and corresponding eigenvectors.</span>
            </p><br /><div class='def'><span class='deftitle'>Eigenvector / Eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvector of an $(n,n)$-matrix $\Mtrx{A}$ is a nonzero vector $\Vect{v}$ in $\RNr{n}$ such that</span>
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$A \Vect{v}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle"><a id="hottag-19974" class="hottag" onmouseover="popup(19974)">$=	$</a><div id="dialog-19974" class="dialogs" title="What does this equation mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This equation asserts that $\Mtrx{A}$ transforms $\Vect{v}$ by rescaling it by the factor $\lambda$. Thus the vectors $\Vect{v}$ and $\Mtrx{A}\Vect{v}$ lie on the same line.</span>
                                 </p>
                              </info></div></td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\lambda \Vect{v}\quad \text{for some $\lambda$ in $\RNr{}$}$</td></tr></table>
                  <p>
                     <span>The number $\lambda$ is called the eigenvalue of $\Mtrx{A}$ corresponding to $\Vect{v}$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>We turn to the question of finding eigenvectors and eigenvectors of a given $(n,n)$-matrix $\Mtrx{A}$.</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Finding eigenvectors and eigenvalues</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>The $(n,n)$-matrix $\Mtrx{A}$ has an eigenvector with eigenvalue $\lambda$ if and only if </span>
      </p><table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\det(A-\lambda \IdMtrx{n})$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$0$</td></tr></table></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Characteristic polynomial</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>The determinant of the $(n,n)$-matrix $(\Mtrx{A}-\lambda \IdMtrx{n})$ is a polynomial of degree $n$ in the variable $\lambda$, called the characteristic polynomial of $\Mtrx{A}$.
				
				It is of the form
			</span>
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$a_n \lambda^n + \cdots a_1\lambda + a_0$</td></tr></table>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>Next we introduce concepts which help us extract information about $\Mtrx{A}$ from its characteristic polynomial.</span>
            </p><br /><div class='def'><span class='deftitle'>Algebraic multiplicity of an eigenvalue</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                  <p>
                     <span>An eigenvalue $t$ of a matrix $\Mtrx{A}$ is said to have algebraic multiplicity $a$ if the characteristic polynomial $p(\lambda)$ can be written as
				</span>
                     
                     
                  </p>
                  <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$p(\lambda)$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(\lambda-t)^a \cdot q(\lambda)$</td></tr></table>
                  <p>
                     <span>and $q(t)\neq 0$.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /><p xmlns="Unit">
               <span>Suppose we know all of the roots of the characteristic polynomial of a matrix $\Mtrx{A}$. We then face the task of distilling from this information the transformation properties of $\Mtrx{A}$. For this purpose we need the following concept:</span>
            </p><br /><div class='def'><span class='deftitle'>Eigenspace</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>Let $\Mtrx{A}$ be an $(n,n)$-matrix with eigenvalue $\lambda_k$. The eigenspace of $\Mtrx{A}$ corresponding to $\lambda_k$ is the nullspace of the matrix $(\Mtrx{A}-\lambda_k\IdMtrx{n})$. The geometric multiplicity of $\lambda_k$ is the dimension of $\NllSp{\Mtrx{A}-\lambda_k\IdMtrx{n}}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>of 3-space      </span><a id='glossaryinfo-19082' class='msm_infobutton' onmouseover='infoopen(19082)'>i</a><div id="dialog-19082" class="dialogs"><info xmlns="Unit">
                     <p>
                        <span>A section on arbitrary rotations in $\RNr{3}$
                        </span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-19082' style='display:none;'><div class='title'>Rotations of 3-Space</div><h2> Introduction </h2><div id="dialog-19095" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>An illustration of a rotation of $\RNr{3}$
                              </span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-19095' style='display:none;'><div class='title'>Rotation of 3-Space - Illustration</div><p xmlns="Unit">
               <span>How do we describe the rotation of space about an arbitrary axis in $\RNr{3}$?</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafosII/ims/RotationGeneral.jpg' height='262.5' width='350'/></div><p xmlns="Unit">
               <span>Our strategy is to reduce a rotation about an arbitrary axis through the angle $\alpha$ to a rotation about a coordinate axis:</span>
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>Introduce an ordered orthonormal coordinate system $\EuScript{B}=(\Vect{a},\Vect{b},\Vect{n})$ such that the axis of rotation has the direction of the basis vector $\Vect{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Using $\EuScript{B}$-coordinates, we describe the given rotation as if it were a rotation of $\RNr{3}$ about the $z$-axis.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Vect{a}$ gets transformed into $\cos\alpha \Vect{a} + \sin\theta \Vect{b}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Vect{b}$ gets transformed into $-\sin\alpha \Vect{a} +\cos\theta \Vect{b}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        $\Vect{n}$ gets transformed into $\Vect{n}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>In $\EuScript{B}$-coordinates this rotation is therefore represented by</span>
                  </p>
                  $$
							
\Mtrx{A}_{\EuScript{B}\EuScript{B}}\ =\ 
\left[
\begin{array}{rrr}
\cos \alpha &amp; -\sin\alpha &amp; 0 \\
\sin\alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right]

						$$
               </li>
               <li>
                  <p>
                     <span>Let $\Mtrx{C}_{\EuScript{B}\EuScript{S}}$ denote the matrix which converts from standard coordinates to  $\EuScript{B}$-coordinates. Then the matrix describing the given rotation in standard coordinates is</span>
                  </p>
                  <math.array column="3">
                     <tr rowspan="1">
                        <td colspan="2" halign="center" valign="middle">
                           $\Mtrx{R}_{\EuScript{S}\EuScript{S}}$
                        </td>
                        <td colspan="1" halign="center" valign="middle">
                           $=$
                        </td>
                        <td colspan="2" halign="center" valign="middle">
                           $\Mtrx{C}_{\EuScript{S}\EuScript{B}} \Mtrx{R}_{\EuScript{B}\EuScript{B}} \Mtrx{C}_{\EuScript{B} \EuScript{S}}$
                        </td>
                     </tr>
                  </math.array>
               </li>
            </ol>
</div>
<p xmlns="Unit">
               <span>Here we learn how to find the standard coordinate matrix of a 
			<a id="activehottag-19095" class="activehottag" onmouseover="infoopen(19095)"> rotation of $\RNr{3}$
                     </a>  
			about an arbitrary axis and through a specified angle. Actually, we need to be a bit more careful here: There are two directions in which we rotate about an axis. So we need a way of distinguishing between these directions. This is accomplished with the following setup.
			</span>
               
            </p>
<ol xmlns="Unit">
               <li>
                  <p>
                     <span>Orient the axis $\mathbf{L}$ of rotation by a unit vector $\Vect{r}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Align the thumb of your right hand with $\Vect{r}$.</span>
                  </p>
               </li>
            </ol><p xmlns="Unit">
               <span>We say that the rotation is by the Right Hand Rule, if the remaining fingers of your right hand curl around the axis in the direction of the rotation. Else we say that the rotation is by the Left Hand Rule. To find the $(3,3)$-matrix representing such a rotation with respect to standard coordinates, we use the following approach:</span>
            </p><ol xmlns="Unit">
               <li>
                  <p>
                     <span>Let $\Vect{a}$ be any unit vector which is perpendicular to $\Vect{r}$.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>Set $\Vect{b} := \CrssPr{ \Vect{r} }{ \Vect{a} }$
                     </span>
                  </p>
               </li>
            </ol><div id="dialog-19101" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>ONB = Orthonormal Basis</span>
                        </p>
                     </info></div><div id="dialog-19103" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>RHO = Right Hand Orientation</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>It follows that the ordered vector triple $\EuScript{B} := (\Vect{a},\Vect{b},\Vect{r})$ is an
			<a id="hottag-19101" class="hottag" onmouseover="popup(19101)"> ONB</a>  
			of $\RNr{3}$ representing the 
			<a id="hottag-19103" class="hottag" onmouseover="popup(19103)"> RHO</a>  ,
			and with respect to this basis we now describe the rotation.</span>
            </p>
<br /><div class='theorem'><span class='theoremtitle'>Rotation matrix in $\RNr{3}$
   </span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>With the setup described above, the rotation $R$ about the oriented axis $\mathbf{L}$ through the angle $\alpha$ by the RHR is represented by the $(3,3)$-matrix</span>
      </p>$$
				
\Mtrx{A}_{\EuScript{B}\EuScript{B}}\ :=\ 
\left[
\begin{array}{rrr}
\cos \alpha &amp; -\sin \alpha &amp; 0 \\
\sin \alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right]

			$$<p xmlns="Theorem">
         <span>Moreover, the matrix which represents $R$ with respect to standard coordinates is (using $\Mtrx{C}:= [ \Vect{a}\ \Vect{b}\ \Vect{r}]$)</span>
      </p>$$\Mtrx{A} = \Mtrx{A}_{\EuScript{S}\EuScript{S}} = \Mtrx{C} \Mtrx{A}_{\EuScript{B}\EuScript{B}} C^{-1}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
               <span>The transformation effect of a rotation is reversible, namely by a rotation through the same angle in the opposite direction:</span>
            </p><br /><div class='theorem'><span class='theoremtitle'>Inverse of rotation in $\RNr{3}$
   </span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A rotation about an axis oriented by the unit vector $\Vect{n}$ through the angle $\alpha$ by the RHR is an isomorphism of $\RNr{3}$. Its inverse is the rotation about the same axis through the angle $\alpha$ by the LHR. It is represented by the matrix</span>
      </p>$$
				
\Mtrx{R}_{\EuScript{B}\EuScript{B}}\ :=\ 
\left[
\begin{array}{rrr}
\cos \alpha &amp; \sin \alpha &amp; 0 \\
-\sin \alpha &amp; \cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{array}
\right]

			$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>row      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4783' class='msm_infobutton' onmouseover='infoopen(4783)'>i</a><div id="dialog-4783" class="dialogs" title="Row Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix of size $(1,n)$ is called a row matrix.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4783' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix of size $(1,n)$ is called a row matrix.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>reduced echelon form      </span><a id='glossaryinfo-3818' class='msm_infobutton' onmouseover='infoopen(3818)'>i</a><div id="dialog-3818" class="dialogs" title="What is row reduced echelon form?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>
                                       <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm is defined here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3818' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>row rescaling matrix      </span><a id='glossaryinfo-5519' class='msm_infobutton' onmouseover='infoopen(5519)'>i</a><div id="dialog-5519" class="dialogs" title="matrix - row rescaling"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>The row rescaling matrix of size $(n,n)$, which multiplies the $u$-th row by the number $s$ is</span>
                                 </p>
                                 $$
									
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
								$$
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-5519' style='display:none;'><br /><div class='def'><span class='deftitle'>Row Rescaling Matrices</span><span class='deftype'>Terminology</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The $u$-th row rescaling matrix of size $(n,n)$ is
					</span>
                           
                           
                           
                        </p>
                        $$
						
						D_u(s)\ :=\ \begin{bmatrix}
						1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\
						\vdots &amp; \ddots &amp; \vdots &amp; &amp; \vdots \\
						0 &amp; \cdots &amp; s &amp; \cdots &amp; 0 \\
						\vdots &amp; &amp; \vdots &amp; \ddots &amp; \vdots \\
						0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1
						\end{bmatrix}\qquad \text{$s$ in row $u$}
						
					$$
                        <p>
                           <span>If $\Mtrx{B}$ is of size $(n,p)$, then the matrix product $D_{u}(s)\cdot \Mtrx{B}$ has the effect of multiplying the $u$-th row of $\Mtrx{B}$ by $s$. If $s\neq 0$, then $D_{u}(s)$ is invertible and   $D_{u}(s)^{-1} = D_{u}(1/s)$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>row space      </span><a id='glossaryinfo-11889' class='msm_infobutton' onmouseover='infoopen(11889)'>i</a><div id="dialog-11889" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>The column space of an $(m,n)$-matrix $\Mtrx{A}$ is the subspace of $\RNr{m}$ spanned by the column vectors of $\Mtrx{A}$.</span>
                                       </p>
                                    </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11889' style='display:none;'><br /><div class='def'><span class='deftitle'>Row space / column space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given an $(m,n)$-matrix $\Mtrx{A}$ express it in terms of its row and columns vectors</span>
                        </p>
                        $$
					
\Mtrx{A} =
\left[
\begin{array}{ccc}
a_{11} &amp; \cdots &amp; a_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; \cdots &amp; a_{mn}
\end{array}
\right] = 
\left[
\begin{array}{c}
R_1 \\ \vdots \\ R_m
\end{array}
\right] = 
\left[
\begin{array}{ccc}
C_1 &amp; \dots &amp; C_n
\end{array}
\right]
					
					$$
                        <ul>
                           <li>
                              <p>
                                 <span>The row space of $\Mtrx{A}$ is $\RowSp{\Mtrx{A}} := \span \Set{ R_1,\dots ,R_m }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The column space of $\Mtrx{A}$ is $\ColSp{\Mtrx{A}} := \span \Set{ C_1,\dots ,C_n }$.
						</span>
                                 
                                 
                              </p>
                           </li>
                        </ul>
                     </def.body><br /></div><br /></div><br /></div><a id='glossaryinfo-11885' class='msm_infobutton' onmouseover='infoopen(11885)'>i</a><div id="dialog-11885" class="dialogs"><info xmlns="Unit">
                                       <p>
                                          <span>The row space of an $(m,n)$-matrix $\Mtrx{A}$ is the subspace of $\RNr{n}$ spanned by the row vectors of $\Mtrx{A}$.</span>
                                       </p>
                                    </info></div></li><li><span>RREF      </span><a id='glossaryinfo-3820' class='msm_infobutton' onmouseover='infoopen(3820)'>i</a><div id="dialog-3820" class="dialogs" title="What does RREF mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>RREF is the acronym for <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm. Its definition is given here.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3820' style='display:none;'><br /><div class='def'><span class='deftitle'>Reduced Row Echelon Form / Rank</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A system of linear equations</span>
                        </p>
                        $$
						
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
						
					$$
                        <p>
                           <span>is in <b>R</b>ow <b>R</b>educed <b>E</b>chelon <b>F</b>orm (RREF) if the coefficients $a_{ij}$ satisfy the following four conditions.
					</span>
                           
                           
                        </p>
                        <ol>
                           <li>
                              <p>
                                 <span>For a given row, either all coefficients are $0$, or the first non-zero coefficient from the left is a ‘$1$’, called the leading $1$ of the row.
						</span>
                                 
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>The leading $1$ of any row occurs further to the right than the leading $1$’s of higher rows.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>Above and below any leading $1$, all coefficients are $0$.</span>
                              </p>
                           </li>
                           <li>
                              <p>
                                 <span>If all coefficients in a row are $0$, then this row is below any row containing a leading $1$.</span>
                              </p>
                           </li>
                        </ol>
                        <p>
                           <span>The rank of a system of linear equations in RREF is the number of its leading $1$’s among the numbers $a_{ij}$.
					</span>
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>scalar product      </span><ul class='chilren'><li><span>of a linear map by a number      </span><a id='glossaryinfo-16514' class='msm_infobutton' onmouseover='infoopen(16514)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16514' style='display:none;'><br /><div class='def'><span class='deftitle'>Scalar product of a linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The scalar product of a linear function $L\from \RNr{n} \to \RNr{m}$ by a number $t\in \RNr{}$ is
					</span>
                           
                           
                        </p>
                        $$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) := t\cdot L(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>of a linear transformation      </span><ul class='chilren'><li><span>represented by scalar product of matrix      </span><a id='glossaryinfo-7596' class='msm_infobutton' onmouseover='infoopen(7596)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7596' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Scalar product  of a linear map is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L\from \RNr{n} \longrightarrow \RNr{m}$ is a linear transformations and $t\in \RNr{}$ is a number, the scalar product of $L$ by $t$
         </span>
         
      </p>$$(tL)\from \RNr{n} \longrightarrow \RNr{m},\quad (tL)(\Vect{x}) = t\cdot L(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Moreover, if $\Mtrx{A}$ is the $(m,n)$-matrix representing $L$, then $(t\cdot \Mtrx{A})$ represents $(tL)$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>of a matrix      </span><a id='glossaryinfo-4897' class='msm_infobutton' onmouseover='infoopen(4897)'>i</a><div id="dialog-4897" class="dialogs" title="scalar product of a matrix"><info xmlns="Unit">
                              
                              <p>
                                 <span>For every number $t$ and every matrix $A$, the scalar product $t\cdot A$ is</span>
                              </p>
                              $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
                           </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4897' style='display:none;'><div class='title'>Matrix Operations</div><h2> Introduction </h2><p xmlns="Unit">
               <span>Here we explain how to add matrices, how to multiply a matrix by a number, how to multiply two matrices, and what the transpose of a matrix is. The system of all matrices, endowed with these operations, forms a vast and powerful extension of the system of real number $\RNr{}$.</span>
            </p><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Scalar Product of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The (scalar) product of a matrix $A = [a_{ij}]$ by a number $t$ is</span>
                  </p>
                  $$t\cdot A\ :=\ [t\cdot a_{ij}]$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>Addition of matrices and scalar multiplying a matrix by a number probably seem familiar because they behave completely like the corresponding operations on vectors. However, the next operation, multiplying one matrix by another, is new. Please pay particular attention to the size compatibility we require if we want to multiply two matrices.</span>
            </p><br /><div class='def'><span class='deftitle'>Matrix Multiplication</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The product of a matrix $\Mtrx{A} = [a_{ij}]$ of size $(m,n)$ by a matrix $\Mtrx{B} = [b_{jk}]$ of size $(n,p)$ is the matrix if size $(m,p)$ given by
				</span>
                     
                     
                  </p>
                  $$\Mtrx{A}\cdot \Mtrx{B}\ :=\ [c_{ik}]$$
                  <p>
                     <span>where $c_{ik}$ is the dot product of the $i$-th row of $\Mtrx{A}$ by the $k$-th column of $\Mtrx{B}$:</span>
                  </p>
                  $$c_{ik}\ :=\ a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in}b_{nk}$$
               </def.body><br /></div><br /></div><br /><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /><p xmlns="Unit">
               <span>The transpose operation helps us single out the following special kind of matrix:</span>
            </p><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>scaling      </span><ul class='chilren'><li><span>factor      </span><a id='glossaryinfo-6879' class='msm_infobutton' onmouseover='infoopen(6879)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-6879' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li><li><span>transformation      </span><a id='glossaryinfo-6881' class='msm_infobutton' onmouseover='infoopen(6881)'>i</a><div id="dialog-6881" class="dialogs" title="What is a scaling transformation?"><info xmlns="Unit">
                           
                           <p>
                              <span>A scaling transformation is a linear transformation of $\RNr{n}$ of the form $S(\Vect{x}) = s\cdot \Vect{x}$, with $s\in\RNr{}$ fixed.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-6881' style='display:none;'><br /><div class='def'><span class='deftitle'>Scaling Transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A scaling transformation of $\RNr{n}$ is of the form
				</span>
                     
                     
                  </p>
                  $$S\from\RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = s\cdot \Vect{x}$$
                  <p>
                     <span>Here ‘$s$’ is a fixed number which is called the scaling factor.
				
				Depending on the value of $s$, the scaling map $S$ is called
			</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>a <i>dilation</i> if $ s&gt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>a <i>contraction</i> if $ 0&lt; s &lt; 1 $
                           </span>
                           
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>an <i>inversion</i> if $ s = -1 $
                           </span>
                           
                        </p>
                     </li>
                  </ul>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>shear      </span><ul class='chilren'><li><span>transformation of $\RNr{n}$ parallel to a hyperspace      </span><a id='glossaryinfo-7102' class='msm_infobutton' onmouseover='infoopen(7102)'>i</a><div id="dialog-7102" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Lookup the definition of shear transformation</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-7102' style='display:none;'><br /><div class='def'><span class='deftitle'>Shear Transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The shear map of $\RNr{n}$ with respect to the unit vector $\Vect{n}$, and with shear vector $\Vect{s}\bot \Vect{n}$ is given by
				</span>
                     
                     
                  </p>
                  $$S\from \RNr{n} \longrightarrow \RNr{n},\quad S(\Vect{x}) = \Vect{x} + (\DotPr{ \Vect{x} }{ \Vect{n} })\cdot \Vect{s}$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>slanted box      </span><a id='glossaryinfo-10255' class='msm_infobutton' onmouseover='infoopen(10255)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10255' style='display:none;'><br /><div class='def'><span class='deftitle'>Slanted box</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>In $\RNr{n}$, the slanted box determined by an $n$-tuple of vectors $(\Vect{x}_1,\dots ,\Vect{x}_n)$ is
					</span>
                           
                        </p>
                        $$\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } := \Set{ t_1 \Vect{x}_1+\cdots +t_n \Vect{x}_n \st 0\leq t_1,\dots ,t_n\leq 1 }$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>span      </span><a id='glossaryinfo-11817' class='msm_infobutton' onmouseover='infoopen(11817)'>i</a><div id="dialog-11817" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors in $S$. – Definition of the concept.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11817' style='display:none;'><br /><div class='def'><span class='deftitle'>Span</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The span of a set of vectors $S$ in $\RNr{n}$ is $\span(S)$, the collection of all linear combinations of vectors $\Vect{s}_1$, ... , $\Vect{s}_r$ in $S$. – The span of the empty set is, by definition, the vector space consisting of the origin alone.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>splitting      </span><ul class='chilren'><li><span>of a subspace      </span><a id='glossaryinfo-13678' class='msm_infobutton' onmouseover='infoopen(13678)'>i</a><div id="dialog-13678" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-13678' style='display:none;'><br /><div class='def'><span class='deftitle'>(Orthogonal) Splitting</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-13676" class="dialogs" title="What does this notation mean?"><info xmlns="Unit">
                                    
                                    <p>
                                       <span>
                                          $U\cup V$ is the union of the sets $U$ and $V$; i.e. a vector belongs to $U\cup V$ if it belongs to $U$ or to $V$.</span>
                                    </p>
                                 </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>A splitting of a subspace $W$ of $\RNr{n}$ is given by two subspaces $U$ and $V$ of $W$ satisfying
				</span>
                     
                  </p>
                  <ul>
                     <li>
                        <p>
                           <span>If $\Vect{w}$ in $W$ belongs to both $U$ and $V$, then $\Vect{w}=\Vect{0}$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              <a id="hottag-13676" class="hottag" onmouseover="popup(13676)"> 
                                    $W=\span(U\cup V)$
                                 </a>  
                           </span>
                           
                        </p>
                     </li>
                  </ul>
                  <p>
                     <span>In this case we write $W=U\dotplus V$. Such a splitting of $W$ is called orthogonal if $\DotPr{ \Vect{u} }{ \Vect{v} } = 0$ for each $\Vect{u}$ in $U$ and each $\Vect{v}$ in $V$.
				</span>
                     
                     
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li></ul></li><li><span>square      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4772' class='msm_infobutton' onmouseover='infoopen(4772)'>i</a><div id="dialog-4772" class="dialogs" title="Square Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4772' style='display:none;'><br /><div class='def'><span class='deftitle'>Square Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A matrix is square shaped if the number of its rows equals the number of its columns; i.e. if it is of size $(n,n)$ for some $n\geq 1$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>subspace      </span><a id='glossaryinfo-11417' class='msm_infobutton' onmouseover='infoopen(11417)'>i</a><div id="dialog-11417" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Subspace = subvector space;   Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11417' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>subvector space      </span><a id='glossaryinfo-11415' class='msm_infobutton' onmouseover='infoopen(11415)'>i</a><div id="dialog-11415" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Definition of the concept.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-11415' style='display:none;'><br /><div class='def'><span class='deftitle'>Subvector space</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A subvector space, or subspace, of $\RNr{n}$ is a subset $V$ of $\RNr{n}$ with the following properties
				</span>
                     
                     
                  </p>
                  <ol>
                     <li>
                        <p>
                           <span>The $\Vect{0}$-vector belongs to $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under vector addition; that is, if $\Vect{x}$ and $\Vect{y}$ are in $V$, then $\Vect{x}+\Vect{y}$ is also in $V$.</span>
                        </p>
                     </li>
                     <li>
                        <p>
                           <span>
                              $V$ is closed under scalar multiplication; that is, if $\Vect{x}$ is in $V$ and $t$ is a number in $\RNr{}$, then $t \Vect{x}$ is in $V$.</span>
                        </p>
                     </li>
                  </ol>
                  <p>
                     <span>If $V,W$ are subvector spaces of $\RNr{n}$, we say that $V$ is a subvector space of $W$ if $V$ is contained in $W$.</span>
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><ul class='chilren'><li><span>of linear transformations      </span><a id='glossaryinfo-16458' class='msm_infobutton' onmouseover='infoopen(16458)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-16458' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of linear transformations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of two linear transformations $L,T\from \RNr{n} \longrightarrow \RNr{m}$ is
					</span>
                           
                           
                        </p>
                        $$(L+T)\from \RNr{n} \longrightarrow \RNr{m}, \quad (L+T)(\Vect{x}) := L(\Vect{x}) + T(\Vect{x})$$
                     </def.body><br /></div><br /></div><br /></div><ul class='chilren'><li><span>represented by sum of matrices      </span><a id='glossaryinfo-7540' class='msm_infobutton' onmouseover='infoopen(7540)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-7540' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Sum of linear maps is linear</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If $L,T\from \RNr{n} \longrightarrow \RNr{m}$ are two linear transformations, then their sum
			</span>
         
      </p>$$(L+T)\from \RNr{n} \longrightarrow \RNr{m},\quad (L+T)(\Vect{x}) = L(\Vect{x}) + T(\Vect{x})$$<p xmlns="Theorem">
         <span>is again linear. Further, if $\Mtrx{A}$ and $\Mtrx{B}$ are the $(m,n)$-matrices representing $L$ and $T$ respectively, then $\Mtrx{A} + \Mtrx{B}$ represents $L+T$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li></ul></li><li><span>of matrices      </span><a id='glossaryinfo-4879' class='msm_infobutton' onmouseover='infoopen(4879)'>i</a><div id="dialog-4879" class="dialogs" title="sum of matrices"><info xmlns="Unit">
                           
                           <p>
                              <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is</span>
                           </p>
                           $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4879' style='display:none;'><br /><div class='def'><span class='deftitle'>Sum of two Matrices</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The sum of two matrices $A = [a_{ij}]$ and $B=[b_{ij}]$ of size $(m,n)$ is
				</span>
                     
                     
                     
                     
                  </p>
                  $$A\ +\ B\ :=\ [a_{ij} + b_{ij}]$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>symmetric      </span><ul class='chilren'><li><span>matrix      </span><a id='glossaryinfo-4935' class='msm_infobutton' onmouseover='infoopen(4935)'>i</a><div id="dialog-4935" class="dialogs" title="Symmetric Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>A matrix $A$ is said to be symmetric if   $A = A^T$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4935' style='display:none;'><br /><div class='def'><span class='deftitle'>(Anti-)Symmetric Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A matrix $\Mtrx{A}$ is said to be symmetric if   $\Mtrx{A} = \Mtrx{A}^T$. It is called antisymmetric if $\Mtrx{A} = - \Mtrx{A}^T$
                     </span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>symmetry      </span><ul class='chilren'><li><span>of dot product      </span><a id='glossaryinfo-1873' class='msm_infobutton' onmouseover='infoopen(1873)'>i</a><div id="dialog-1873" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The symmetry property of the dot product asserts that</span>
                     </p>
                     $$\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$$
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1873' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x},\Vect{y},\Vect{a},\Vect{b}$ in $\RNr{n}$ and any number $t$ in $\RNr{}$, the following hold:
      	</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Bilinearity</span>
<part.body xmlns="Theorem">
            <p>
               <span/>
               
               
            </p>
            <table class="mathtable" border="0" cellpadding="0" style="width:100% !important;"><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (\Vect{a} + \Vect{b})}{\Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{\Vect{a} }{ \Vect{y}}\ +\ \DotPr{\Vect{b} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{(\Vect{x} + \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $=$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ \Vect{x} }\ +\ \DotPr{\Vect{a} }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                        </tr><tr>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ (t\cdot \Vect{a}) }{ \Vect{y} }$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $= t\cdot (\DotPr{\Vect{a} }{ \Vect{y} }) =$
                                 </span>
                              </p>
                           </td>
                           <td style="border-width:0px !important;">
                              <p>
                                 <span>
                                    $\DotPr{ \Vect{a} }{ (t \cdot \Vect{y}) }$
                                 </span>
                              </p>
                           </td>
                        </tr></table>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Symmetry</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{a} }{ \Vect{x} } = \DotPr{ \Vect{x} }{ \Vect{a} }$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Positive definite</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } \geq 0$ for all $\Vect{x}$ in $\RNr{n}$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Non-degeneracy</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} }$ if and only if $\Vect{x} = \Vect{0}$
               </span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li></ul></li><li><span>system of linear equations      </span><a id='glossaryinfo-3483' class='msm_infobutton' onmouseover='infoopen(3483)'>i</a><div id="dialog-3483" class="dialogs"><info xmlns="Theorem">
               <p>
                  <span>solutions discussed in geometrical terms</span>
               </p>
            </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3483' style='display:none;'><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div><ul class='chilren'><li><span>homogeneous      </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>inconsistent      </span><a id='glossaryinfo-3668' class='msm_infobutton' onmouseover='infoopen(3668)'>i</a><div id="dialog-3668" class="dialogs" title="What is an inconsistent system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An inconsistent system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3668' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li><li><span>inhomogeneous      </span><a id='glossaryinfo-4220' class='msm_infobutton' onmouseover='infoopen(4220)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-4220' style='display:none;'><br /><div class='def'><span class='deftitle'>(In-)Homogeneous System of Linear equations</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A system of linear equations</span>
                  </p>
                  $$
					
\begin{array}{cccccccccc}
\colorbox{lightgreen}{$a_{11}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red}x_n} &amp; = &amp; c_1 \\
\colorbox{lightgreen}{$a_{21}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red}x_n} &amp; = &amp; c_2 \\
\vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
\vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
\colorbox{lightgreen}{$a_{m1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red}x_n} &amp; = &amp; c_m \\
\end{array}
						
				$$
                  <p>
                     <span>is called homogeneous if $c_1=c_2=\cdots =c_n=0$. Else it is called inhomogeneous.
				</span>
                     
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>overdetermined      </span><a id='glossaryinfo-3670' class='msm_infobutton' onmouseover='infoopen(3670)'>i</a><div id="dialog-3670" class="dialogs" title="What is an overdetermined system of linear equations"><info xmlns="Unit">
                           
                           <p>
                              <span>An overdetermined system of linear equations is one which has no solution.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3670' style='display:none;'><div class='title'>Solutions of Several Linear Equations</div><br /><div class='theorem'><span class='theoremtype'>Theorem</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given a system of $m$ linear equations in $n$ unknowns
			</span>
         
      </p>$$
				
							\begin{array}{rcccccccccc}
							(E_1)\qquad &amp; \colorbox{lightgreen}{$a_{11}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{12}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{1n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_1} \\
							(E_2)\qquad &amp; \colorbox{lightgreen}{$a_{21}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{22}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{2n}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_2} \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; \ddots &amp; &amp; + &amp; \vdots &amp; &amp; \vdots \\
							\vdots\qquad &amp; \vdots &amp; + &amp; \vdots &amp; + &amp; &amp; \ddots &amp; + &amp; \vdots &amp; &amp; \vdots \\
							(E_m)\qquad &amp; \colorbox{lightgreen}{$a_{m1}$}{\color{red} x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{m2}$}{\color{red} x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{mn}$}{\color{red} x_n} &amp; = &amp; {\color{blue} c_m} \\
\end{array}
							
			$$<p xmlns="Theorem">
         <span>let $H_i$ denote the hyperplane in $\RNr{n}$ formed by the solutions of the equation $E_i$. Then the simultaneous solutions of equations $E_1,\dots ,E_n$ consists of all those points in $\RNr{n}$ which belong to each of the hyperplanes $H_1,\dots ,H_n$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>So we know now that finding simultaneous solutions of linear equations corresponds geometrically to forming the intersection of hyperplanes associated to the individual equations. Let us discuss what can happen when forming the intersection of two such equations. We will then illustrate our findings in $\RNr{2}$ and $\RNr{3}$.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Simultaneous solutions of two linear equations</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'>
<statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in $n$ variables</span>
      </p>$$
				
						\begin{array}{rcrccccrcl}
\colorbox{lightgreen}{$a_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$a_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$a_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_{1}$}{\color{red}x_1} &amp; + &amp; \colorbox{lightgreen}{$b_{2}$}{\color{red}x_2} &amp; + &amp; \cdots &amp; \cdots &amp; + &amp; \colorbox{lightgreen}{$b_{n}$}{\color{red}x_n} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>form the coefficient vectors $\Vect{n}_1$, $\Vect{n}_2$, and the augmented coefficient vectors $\Vect{N}_1$ given by
			</span>
         
         
         
      </p><table class="mathtable" border="1" cellpadding="2" style="width:100% !important;"><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,\dots ,a_n)$}$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\colorbox{lightgreen}{$\Vect{n}_2 := (b_1,\dots ,b_n)$}$
                  </span>
               </p>
            </td>
         </tr><tr>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,\dots ,a_n$},{\color{blue} c})$
                  </span>
               </p>
            </td>
            <td style="border-width:1px !important;">
               <p>
                  <span>
                     $\Vect{N}_2 := (\colorbox{lightgreen}{$b_1,\dots ,b_n$},{\color{blue} d})$
                  </span>
               </p>
            </td>
         </tr></table><p xmlns="Theorem">
         <span>If $\Vect{n}_1,\Vect{n}_2\neq \Vect{0}$ the following hold:</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>If $n=2$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have exactly  one common solution.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $n\geq 3$, and if $\colorbox{lightgreen}{$\Vect{n}_1$}$ and $\colorbox{lightgreen}{$\Vect{n}_2$}$ are not parallel, then the given equations have infinitely many common solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{n}_1$ and $\Vect{n}_2$ are parallel but $\mathbf{N}_1$ and $\mathbf{N}_2$ are not parallel, the given equations have no simultaneous solutions.</span>
            </p>
         </li>
         <li>
            <p>
               <span>If $\Vect{N}_1$ and $\Vect{N}_2$ are parallel, one of the equations is redundant, and the solutions hyperplane of one equation also forms the simultaneous solution set of both equations.</span>
            </p>
         </li>
      </ul></statement.theorem>
<ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now interpret in detail what this proposition says in dimensions 2 and 3. We begin with the situation where the coefficient vectors are not parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>2 equations, 2 variables, non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in exactly one point, and this point is the unique simultaneous solution of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>2 equations, 3 variables non parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1$ and $\Vect{n}_2$ are not parallel then these lines intersect in a line, and this line consists of all simultaneous solutions of the given system.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>Let us now turn to the situation where the coefficient vectors of the equations are parallel.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in two variables $x$ and $y$
         </span>
      </p>$$
				
						\begin{array}{rcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; = &amp; {\color{blue} d} \\
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a line in $\RNr{2}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq tc$ then these lines are parallel and distinct. So they have no point in common and, therefore, this system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = tc$ then these two lines are the same. This means that each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Two linear equations, parallel coefficients</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given two linear equations in three variables $x,y,z$
         </span>
      </p>$$
				
						\begin{array}{rcrcrcl}
\colorbox{lightgreen}{$a_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$a_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$a_3$}{\color{red} z} &amp; = &amp; {\color{blue} c} \\
\colorbox{lightgreen}{$b_1$}{\color{red} x} &amp; + &amp; \colorbox{lightgreen}{$b_2$}{\color{red} y} &amp; + &amp; \colorbox{lightgreen}{$b_3$}{\color{red} z} &amp; = &amp; {\color{blue} d}
						\end{array}
					
			$$<p xmlns="Theorem">
         <span>the coefficient vectors are</span>
      </p>$$\colorbox{lightgreen}{$\Vect{n}_1 := (a_1,a_2,a_3)$}\quad \text{and}\quad \colorbox{lightgreen}{$\Vect{n}_2 := (b_1,b_2,b_3)$}$$<p xmlns="Theorem">
         <span>While the augmented coefficient vectors are</span>
      </p>$$\Vect{N}_1 := (\colorbox{lightgreen}{$a_1,a_2,a_3$},{\color{blue} c})\quad \text{and}\quad \Vect{N}_2 := (\colorbox{lightgreen}{$b_1,b_2,b_3$},{\color{blue} d})$$<p xmlns="Theorem">
         <span>The solutions of each equation form a plane in $\RNr{3}$. If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d\neq t\cdot c$ these planes are parallel and distinct. So they have no point in common. Therefore the given system of linear equations has no simultaneous solution.</span>
      </p><p xmlns="Theorem">
         <span>If $\Vect{n}_1 = t\cdot \Vect{n}_2$ and $d = t\cdot c$ these planes are the same. So each solution of one equation is also a solution of the other: the two equations are said to be equivalent.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>If the solution set of the given system of equations is empty, we say that the system of equations is inconsistent
					
					or overdetermined.
					
					or overdetermined.
					</span>
                     
                     
                     
                     
                  </p></div></li></ul></li><li><span>translation      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-3063' class='msm_infobutton' onmouseover='infoopen(3063)'>i</a><div id="dialog-3063" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3063' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>transposition      </span><ul class='chilren'><li><span>commutes with determinant      </span><a id='glossaryinfo-9441' class='msm_infobutton' onmouseover='infoopen(9441)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9441' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div></li><li><span>of a matrix      </span><a id='glossaryinfo-4920' class='msm_infobutton' onmouseover='infoopen(4920)'>i</a><div id="dialog-4920" class="dialogs" title="Transpose of a Matrix"><info xmlns="Unit">
                           
                           <p>
                              <span>The transpose of a matrix</span>
                           </p>
                           $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                           <p>
                              <span>is the matrix</span>
                           </p>
                           $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4920' style='display:none;'><br /><div class='def'><span class='deftitle'>Transpose of a Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The transpose of a matrix
				</span>
                     
                     
                     
                  </p>
                  $$A\ =\ [a_{ij}],\qquad 1\leq i\leq m,\ \ 1\leq j\leq n$$
                  <p>
                     <span>is the matrix</span>
                  </p>
                  $$A^T\ :=\ [a_{ji}],\qquad 1\leq j\leq n,\ \ 1\leq i\leq m$$
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>triangle inequality      </span><a id='glossaryinfo-1974' class='msm_infobutton' onmouseover='infoopen(1974)'>i</a><div id="dialog-1974" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The triangle inequality asserts that, for any two vectors $\Vect{x}$ and $\Vect{y}$.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1974' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Geometric Properties of Norm and Dot Product</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$ and $\Vect{y}$ in $\RNr{n}$, the following hold:</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><span class='parttheoremtitle'>Relationship between dot product and norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{ \Vect{x} }{ \Vect{x} } = | \Vect{x} |^2$
               </span>
               
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Orthogonality criterion</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\DotPr{\Vect{x}}{\Vect{y}} = 0$ if and only if $\Vect{x}$ is perpendicular to $\Vect{y}$.
				</span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Angle between two vectors</span><div id="dialog-1971" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>
                              $\sphericalangle(\Vect{x},\Vect{y})$ denotes the angle between the vectors $\Vect{x}$ and $\Vect{y}$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>
                  <a id="hottag-1971" class="hottag" onmouseover="popup(1971)"> 
                        $\DotPr{\Vect{x}}{\Vect{y}} = \Abs{ \Vect{x} } \Abs{ \Vect{y} }\cdot \cos \sphericalangle(\Vect{x},\Vect{y})$
                     </a>  , provided $\Vect{x}$ and $\Vect{y}$ have positive length.
				</span>
               
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Triangle inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $\Abs{\Vect{x} + \Vect{y}} \leq \Abs{\Vect{x}} + \Abs{\Vect{y}}$
               </span>
               
            </p>
         </part.body></li><br /><li><span class='parttheoremtitle'>Cauchy-Schwarz inequality</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $| \DotPr{\Vect{x}}{\Vect{y}} | \leq | \Vect{x} | | \Vect{y} |$. </span>
               
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1602' class='msm_infobutton' onmouseover='infoopen(1602)'>i</a><div id="dialog-1602" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>The triangle inequality asserts that, for any two vectors $\Vect{x}$ and $\Vect{y}$.</span>
                     </p>
                  </info></div></li><li><span>unit      </span><ul class='chilren'><li><span>lattice of $\RNr{2}$      </span><a id='glossaryinfo-15515' class='msm_infobutton' onmouseover='infoopen(15515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15515' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>square of $\RNr{2}$      </span><a id='glossaryinfo-15515' class='msm_infobutton' onmouseover='infoopen(15515)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15515' style='display:none;'><div class='title'>Every Linear Map Comes from a Matrix</div><p xmlns="Unit">
                     <span>We just learned that matrices provide a convenient source for linear transformations. But can we obtain every linear transformation in this way? The answer to this question is: ‘Yes!’, and the following theorem tells us how to find the matrix describing a given linear transformation.</span>
                  </p><br /><div class='theorem'><span class='theoremtitle'>Given Linear map, Find Matrix</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Given an arbitrary linear transformation $L\from \RNr{n}\to \RNr{m}$, form the matrix</span>
      </p>$$
				
A\ :=\
\left[\begin{array}{cccc}
\uparrow &amp; \uparrow &amp; \cdots &amp; \uparrow \\
L(\StdBss{1}) &amp; L(\StdBss{2}) &amp; \cdots &amp; L(\StdBss{n}) \\
\downarrow &amp; \downarrow &amp; \cdots &amp; \downarrow
\end{array}\right]
					
			$$<p xmlns="Theorem">
         <span>Then $L(\Vect{x}) = \Mtrx{A}\Vect{x}$, for all $\Vect{x}$ in $\RNr{n}$. Moreover $\Mtrx{A}$, so defined, is the only matrix with this property. </span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><p xmlns="Unit">
                     <span>In the context of the theorem above, we say that the matrix $\Mtrx{A}$ represents $L$.
				</span>
                     
                     
                  </p></div></li><li><span>vector      </span><a id='glossaryinfo-1694' class='msm_infobutton' onmouseover='infoopen(1694)'>i</a><div id="dialog-1694" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>A vector of length $1$; click to see how to compute the unit vector in the direction of a given nonzero vector.</span>
                     </p>
                  </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1694' style='display:none;'><br /><div class='theorem'><span class='theoremtitle'>Algebraic Properties of the Norm Operation</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For vectors $\Vect{x}$, and $\Vect{y}$, and numbers $t$ in $\RNr{}$ the following hold:</span>
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>
                  $|t\cdot \Vect{x}| = |t|\cdot |\Vect{x}|$
               </span>
            </p>
         </part.body></li><br /><li><div id="dialog-1696" class="dialogs"><info xmlns="Theorem">
                        <p>
                           <span>Note how $\Vect{u}$ is built: Start with the vector $\Vect{x}$. It has length $|\Vect{x}|$. Then divide $\Vect{x}$ by its length. So you get a vector of length $1$.</span>
                        </p>
                     </info></div>
<part.body xmlns="Theorem">
            <p>
               <span>If $\Vect{x}\neq \Vect{0}$, the vector $\Vect{u} := \tfrac{\Vect{x}}{|\Vect{x}|}$ has <a id="hottag-1696" class="hottag" onmouseover="popup(1696)"> length 1 and the same direction as $\Vect{x}$
                     </a>  ; we call $\Vect{u}$ the unit vector in the direction of  $\Vect{x}$.</span>
               
            </p>
         </part.body>
</li><br /><li><span class='parttheoremtitle'>Non degeneracy of norm</span><part.body xmlns="Theorem">
            <p>
               <span>
                  $|\Vect{x}| = 0$   if and only if   $\Vect{x} = \Vect{0}$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /></div><a id='glossaryinfo-1482' class='msm_infobutton' onmouseover='infoopen(1482)'>i</a><div id="dialog-1482" class="dialogs"><info xmlns="Theorem">
                     <p>
                        <span>A vector of length $1$; click to see how to compute the unit vector in the direction of a given nonzero vector.</span>
                     </p>
                  </info></div></li></ul></li><li><span>unitary      </span><ul class='chilren'><li><span>linear transformation      </span><a id='glossaryinfo-8086' class='msm_infobutton' onmouseover='infoopen(8086)'>i</a><div id="dialog-8086" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>is an alternate term for ‘distance preserving linear transformation’</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-8086' style='display:none;'><br /><div class='def'><span class='deftitle'>Distance preserving linear transformation</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A linear transformation $L\from \RNr{n} \to \RNr{n}$ is said to preserve distances if, for all $\Vect{x}$ in $\RNr{n}$,
				</span>
                     
                     
                  </p>
                  $$\abs{L(\Vect{x})} = \abs{\Vect{x}}$$
                  <p>
                     <span>Other terms in use for ‘distance preserving linear transformation’ include ‘orthogonal transformation’ or ‘unitary transformation’
				</span>
                     
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>upper triangular matrix      </span><a id='glossaryinfo-4838' class='msm_infobutton' onmouseover='infoopen(4838)'>i</a><div id="dialog-4838" class="dialogs" title="Upper Triangular Matrix"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-4838' style='display:none;'><br /><div class='def'><span class='deftitle'>Upper Triangular Matrix</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>An upper triangular matrix is square shaped and only entries on or above the diagonal are allowed to be different from $0$.
					</span>
                           
                           
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li><li><span>value      </span><ul class='chilren'><li><span>of element under a function      </span><a id='glossaryinfo-15104' class='msm_infobutton' onmouseover='infoopen(15104)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-15104' style='display:none;'><div class='title'>Functions - A Rapid Introduction</div><h2> Introduction </h2><div id="dialog-15109" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Link to an online book on sets and functions.</span>
                           </p>
                        </info></div>
<p xmlns="Unit">
               <span>To make this introduction to linear algebra somewhat self contained, we include here a rapid introduction to the notions of
			<a href="http://webmath.facsci.ualberta.ca:8080/cocoon/fcm/Content/SetsNaive/Sets.xml" id="hottag-15108" class="externallink" target="sets" onmouseover="popup(15108)"> sets and functions</a>  .
		</span>
            </p>
<div id="dialog-15119" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Comment on the concept of a function</span>
                           </p>
                        </info></div><div class='refcontent' id='refcontent-15119' style='display:none;'><div class='title'>The Contraction Transformations</div><p xmlns="Unit">
               <span>It is very likely that you have already come in contact with the concept of a function. For example, within the context of calculus, you might have gotten used thinking of a function as a curve in a 2D-coordinate system like this one:</span>
            </p><div class='picture'><img class='mathimage' src='http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/FunctionGraph.png' height='343.63636363636' width='350'/></div><p xmlns="Unit">
               <span>Here the domain $X$ of the function is an interval of the horizontal axis, and the target $Y$ is $\RNr{}$. The curve in the graphic consists of all points $(x,y)$ in $\RNr{2}$ with $x$ in $X$ and $y=f(x)$.</span>
            </p><p xmlns="Unit">
               <span>Let us understand clearly that the curve in the graphic does not depict the transformation described by $f$. Rather, the curve is called the ‘graph’ of $f$.</span>
            </p><p xmlns="Unit">
               <span>For most of our present purposes the graph is not the appropriate object to associate to a function. Therefore it is necessary to take the concept of a function in its original form and then learn how to use it to transforms space.</span>
            </p></div><div id="dialog-15122" class="dialogs" title="Quick description of a set"><info xmlns="Unit">
                        
                        <p>
                           <span>A set is any collection $U$ of objects, even objects of your thought or imagination are allowed. The objects in $U$ are called the elements of $U$. We write $u\in U$ to say that $u$ is an element of $U$.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>Setting up a
			<a id="activehottag-15119" class="activehottag" onmouseover="infoopen(15119)"> function</a>  
			begins with selecting two 
			<a id="hottag-15122" class="hottag" onmouseover="popup(15122)"> sets</a>  
               </span>
               
            </p>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>A set $X$, called the domain of the function
				</span>
                     
                     
                  </p>
               </li>
               <li>
                  <p>
                     <span>A set $Y$, called the target of the function
				</span>
                     
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>A function $f$ from $X$ to $Y$, denoted $f\from X\to Y$, associates to each element $x$ in $X$ some element of $Y$. This element must be unique and is denoted $f(x)$. Names for it include: the ‘value’ of $f$ at $x$, the ‘function value’ of $f$ at $x$, or the ‘image of $x$ under $f$ ’.
			</span>
               
               
               
            </p><p xmlns="Unit">
               <span>It is possible that two or more distinct elements of $X$ get sent to the same element of $Y$. In other words, it is possible that, for $x\neq x'$ in $X$, $f(x) = f(x')$. - Here are some examples.</span>
            </p><div id="dialog-15138" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a planar region being transformed, and the transformation sends several points of $X$ to the same point of $Y$.</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15138' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Planar Region</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the image below the potato shaped region $X$ on the left gets transformed into the collar shaped object on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_NonLinear.png" height="213.9375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>
                     $X$ serves as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The entire background serves as the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The collar shapened object on the right represents the result of transforming the domain. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from X\to Y$ transforms $X$ into the image of $f$; i.e. the collar shaped object on the right. In the process the blue dot on the left, marked $x$, gets transformed into the blue dot, marked $f(x)$ on the right. Both of the red dots on the left, marked $u_1$ and $u_2$, get transformed into a single point. This is expressed by the identity</span>
         </p>
			
			      $$f(u_1) = f(u_2)$$
			
			      <p>
            <span>For each point of the domain $X$ the function $f$ tells us into which precise location in the target $Y$ it gets transformed.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div><div id="dialog-15144" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>An example of a line segment being transformed into a curve</span>
                                 </p>
                              </info></div><div class='refcontent' id='refcontent-15144' style='display:none;'><div class='pack'><div class='title'>Example: Transformation of a Line Segment</div><br /><div class='showme'><span class='showmetitle'></span><span class='showmetype'>Example</span><br /><div class='mathcontent'>
<statement.showme xmlns="Compositor">
			      <p>
            <span>In the picture below the line segment $[a,b]$ on the left gets transformed into the red curve on the right.</span>
         </p>
			
			      <div class="picture"><img class="mathimage" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/LinearTrafos/ims/Trafo_LineSegment.png" height="207.375" width="350"/></div>
			
			
			      <p>
            <span>To fit this intuitive process into the mathematical formalism of functions, we do the following:</span>
         </p>
			
			      <ul>
				        <li>
               <p>
                  <span>We take the interval $[a,b]$ in $\RNr{}$ as the domain of the transforming function $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The plane $\RNr{2}$ on the right is the target of $f$.</span>
               </p>
            </li>
				        <li>
               <p>
                  <span>The curve on the right is the transformed line segment. This is also called the image of $f$.</span>
               </p>
            </li>
			      </ul>
			
			      <p>
            <span>The function $f\from [a,b]\to \RNr{2}$ transforms $[a,b]$ into the curve on the right. Note that the image of $f$ need not be equal to the target $\RNr{2}$. Note also that the end point $a$ of $[a,b]$ gets transformed into the end point $f(a)$ of the curve on the right, and that the end point $b$ of $[a,b]$ gets transformed into the end point $f(b)$ of the curve.</span>
         </p>
		    </statement.showme>
</div><br /></div><br /><br /></div></div>
<ul xmlns="Unit">
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15138" class="activehottag" onmouseover="infoopen(15138)"> Transformation of a planar region</a>  
                     </span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>
                        <a id="activehottag-15144" class="activehottag" onmouseover="infoopen(15144)"> Transformation of a line segment</a>  
                     </span>
                  </p>
               </li>
            </ul>
<p xmlns="Unit">
               <span>
                  <b>Functions and equations</b>   We just learned that a function $f\from X\to Y$ can transform several distinct elements of $X$ into the same element $y\in Y$. Therefore it makes sense to ask: What is the total collection of elements of $X$ which get sent to a given $y$ in $Y$? or, in symbols, what are the solutions of the equation below?
			</span>
               
            </p>$$f(x) = y$$<p xmlns="Unit">
               <span>Thus functions provide a general tool to formulate equations. The solutions of the equation above form the ‘preimage of $y$ under $f$’. It is denoted $f^{-1}(y)$ and consists of all those $x$ in $X$ which satisfy the equation $f(x)=y$.
			</span>
               
               
            </p><p xmlns="Unit">
               <span>There remains the question: How do we solve such equations? In general, this task can be quite challenging. At this point we can indicate the following:</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>If $f$ is a linear function, we will see that the equation above is equivalent to a system of linear equations, and so we know how to solve them.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span> If $f$ is differentiable, we can feed our knowledge of solving linear equations into the framework of differential calculus and obtain qualitative answers. These answers include the ‘inverse function theorem’ or its corollary the ‘implicit function theorem’.</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>If $f$ is a polynomial, i.e. a relatively ‘simple’ function, efforts to describe all of its solutions continue to provide ongoing research challenges, and is the primary goal of the subject of Algebraic Geometry. </span>
                  </p>
               </li>
            </ul></div></li></ul></li><li><span>Van der Monde determinant      </span><a id='glossaryinfo-9437' class='msm_infobutton' onmouseover='infoopen(9437)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-9437' style='display:none;'><div class='title'>Further properties of the determinant operation</div><div id="dialog-9440" class="dialogs" title="Comment"><info xmlns="Unit">
                              
                              <p>
                                 <span>It is possible to prove the statements below directly from the definition of the determinant by cofactor expansion that we gave earlier. However, it is more efficient to derive these statements from the algebraic properties listed above.</span>
                              </p>
                           </info></div>
<p xmlns="Unit">
                     <span>The algebraic properties of the determinant operation have a number of 
				<a id="hottag-9440" class="hottag" onmouseover="popup(9440)"> consequences</a>  
				which can simplify the task of computing determinants a lot.</span>
                  </p>
<br /><div class='theorem'><span class='theoremtitle'>Determinant: additional properties</span><span class='theoremtype'>Proposition</span><br/><div class='mathcontent'><statement.theorem></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'><li><part.body xmlns="Theorem">
            <p>
               <span>Whenever two columns of a matrix $\Mtrx{A}$ are equal, then $\det(\Mtrx{A}) = 0$.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>Adding a multiple of one column to another column leaves the determinant unchanged.</span>
            </p>
         </part.body></li><br /><li><part.body xmlns="Theorem">
            <p>
               <span>The determinant commutes with transposition: $\det(\Mtrx{A}) = \det(\Mtrx{A}^T)$.
				</span>
               
               
            </p>
         </part.body></li><br /></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Computing determinants by row reduction</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>Suppose the $(n,n)$-matrix  $\Mtrx{A}$ can be row reduced to an upper triangular matrix $\Mtrx{U}$ with diagonal entries $d_1,\dots ,d_n$. If this row reduction used</span>
      </p><ul xmlns="Theorem">
         <li>
            <p>
               <span>
                  $r$ interchanges of rows; and</span>
            </p>
         </li>
         <li>
            <p>
               <span>the multiplication of rows by (nonzero) numbers $c_1,\dots ,c_k$, then</span>
            </p>
         </li>
      </ul>$$\det(\Mtrx{A}) = (-1)^r\cdot \dfrac{d_1\cdots d_n}{c_1\cdots c_k}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant tests invertibility of a matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>A square matrix $\Mtrx{A}$ is invertible exactly when $\det(\Mtrx{A}) \neq 0$.</span>
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of a product</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>For $(n,n)$-matrices $\Mtrx{A}$ and $\Mtrx{B}$, $\det(\Mtrx{A}\cdot \Mtrx{B}) = \det(\Mtrx{A})\cdot \det(\Mtrx{B})$.
			</span>
         
         
      </p></statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /><br /><div class='theorem'><span class='theoremtitle'>Determinant of an inverse matrix</span><span class='theoremtype'>Corollary</span><br/><div class='mathcontent'><statement.theorem><p xmlns="Theorem">
         <span>If the matrix $\Mtrx{A}$ is invertible then</span>
      </p>$$\det(\Mtrx{A}^{-1}) = \dfrac{1}{\det(\Mtrx{A})}$$</statement.theorem><ol class='parttheorem' style='list-style-type:lower-roman;'></ol></div><br /></div><br /></div></li><li><span>vector      </span><a id='glossaryinfo-680' class='msm_infobutton' onmouseover='infoopen(680)'>i</a><div id="dialog-680" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>definition of ‘vector’</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-680' style='display:none;'><br /><div class='def'><span class='deftitle'>Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'>
<def.body xmlns="Unit">
                        <p>
                           <span>The vector represented by an arrow $\Arrw{AB}$ is the collection of all those arrows in $\RNr{n}$ which are equivalent to $\Arrw{AB}$. We write $\Vect{x} = (x_1,\dots ,x_n)$ if, for any of these arrows
					</span>
                           
                           
                        </p>
                        <table border="0" class="matharray"><tr class="matharrayrow" align="center"><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$\text{(tip coordinates)} - \text{tail coordinates}$</td><td class="matharraycell" colspan="1" rowspan="1" align="center" valign="middle">$=$</td><td class="matharraycell" colspan="2" rowspan="1" align="center" valign="middle">$(x_1,\dots ,x_n)$</td></tr></table>
                     </def.body>
<br /></div><br /></div><br /></div><ul class='chilren'><li><span>addition      </span><a id='glossaryinfo-788' class='msm_infobutton' onmouseover='infoopen(788)'>i</a><div id="dialog-788" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-788' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>force      </span><a id='glossaryinfo-3177' class='msm_infobutton' onmouseover='infoopen(3177)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3177' style='display:none;'><div class='title'>Vectors Modeling Forces</div><h2> Introduction </h2><p xmlns="Unit">
               <span>When a force acts on an object, it does so in a certain direction and with a certain strength. Thus we can model a force by a vector. The direction in which the force acts corresponds to the direction of the vector, and the magnitude of the force corresponds to the length of the vector.</span>
            </p><div id="dialog-3183" class="dialogs"><info xmlns="Unit">
                        <p>
                           <span>Place your pointer over an arrow to get answers.</span>
                        </p>
                     </info></div>
<p xmlns="Unit">
               <span>For example, suppose a vector of length $1$ corresponds to a force of $1000N$. Then the following arrows represent forces as 
			<a id="hottag-3183" class="hottag" onmouseover="popup(3183)"> indicated</a>  .
			</span>
               
            </p>

<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3186" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceArrows.gif" height="169" width="319" usemap="#ForceArrows"/><map name="ForceArrows"><area id="pic-3188" coords="25,29,121,47" shape="rect" href="#" onmouseover="popup(3188)"><div id="dialog-3188" class="dialogs" title="What does the red vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $4000N$ to the right.</span>
                                 </p>
                              </info></div></area><area id="pic-3190" coords="15,131,25,149,191,77,175,59" shape="poly" href="#" onmouseover="popup(3190)"><div id="dialog-3190" class="dialogs" title="What does the green vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $\sqrt{58} \cdot 1000N$ directed to the upper right.</span>
                                 </p>
                              </info></div></area><area id="pic-3192" coords="189,31,285,105,301,87,209,15" shape="poly" href="#" onmouseover="popup(3192)"><div id="dialog-3192" class="dialogs" title="What does the blue vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents a force of $5000N$ directed to the lower right</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
<p xmlns="Unit">
               <span>From experiments we learn that several forces acting simultaneously on an object can be consolidated into a single force. Moreover, the consolidated force corresponds to the vector sum of the individual forces. – The picture below illustrates this. Here we have two forces, $F_1$ and $F_2$ acting on an object. The resulting combined force is described by the red vector $F_1 + F_2$.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3196" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/ForceSum.gif" height="173" width="391" usemap="#ForceSum"/><map name="ForceSum"><area id="pic-3198" coords="11,97,27,109,285,41,259,23,21,89,21,91,21,97" shape="poly" href="#" onmouseover="popup(3198)"><div id="dialog-3198" class="dialogs" title="What does the green vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the force vector $F_2$ acting on the object, assumed to be at its tail.</span>
                                 </p>
                              </info></div></area><area id="pic-3200" coords="25,113,121,161,133,143,45,105" shape="poly" href="#" onmouseover="popup(3200)"><div id="dialog-3200" class="dialogs" title="What does the blue vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the force vector $F_1$ acting on the object, assumed to be at its tail.</span>
                                 </p>
                              </info></div></area><area id="pic-3202" coords="369,95,369,77,95,93,67,105" shape="poly" href="#" onmouseover="popup(3202)"><div id="dialog-3202" class="dialogs" title="What does the red vector represent?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the single force that results from the combined actions of $F_1$ and $F_2$.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
</div></li><li><span>length      </span><a id='glossaryinfo-1670' class='msm_infobutton' onmouseover='infoopen(1670)'>i</a><div id="dialog-1670" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The length of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1670' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>norm      </span><a id='glossaryinfo-1674' class='msm_infobutton' onmouseover='infoopen(1674)'>i</a><div id="dialog-1674" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>The norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ its length. It is given by</span>
                           </p>
                           $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
                           <p>
                              <span>Click to jump to the section where it is defined.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1674' style='display:none;'><br /><div class='def'><span class='deftitle'>Norm of a Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>The length or norm of a vector $\Vect{x} = (x_1,\dots ,x_n)$ in $\RNr{n}$ is given by </span>
                     
                     
                     
                     
                     
                  </p>
                  $$|\Vect{x}| := \sqrt{x_{1}^{2} + \cdots + x_{n}^{2}}$$
               </def.body><br /></div><br /></div><br /></div></li><li><span>sum      </span><a id='glossaryinfo-790' class='msm_infobutton' onmouseover='infoopen(790)'>i</a><div id="dialog-790" class="dialogs"><info xmlns="Unit">
                                 $$(x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n)\ :=\ (x_1+y_1,\, \dots\, ,x_n+y_n)$$
                                 <p>
                                    <span>Click to jump to the definition</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-790' style='display:none;'><br /><div class='def'><span class='deftitle'>Addition of Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>The sum of vectors $\Vect{x}=(x_1,\dots ,x_n)$ and $\Vect{y}=(y_1,\dots ,y_n)$ in $\RNr{n}$ is </span>
                           
                           
                           
                        </p>
                        $$
						
						\aligned
						\Vect{x}\ +\ \Vect{y}\ =\ (x_1,\dots ,x_n)\ +\ (y_1,\dots ,y_n) \\
						:=\ (x_1+y_1,\, \dots\, ,x_n+y_n)
						\endaligned
						
					$$
                     </def.body><br /></div><br /></div><br /></div></li><li><span>translation      </span><a id='glossaryinfo-3065' class='msm_infobutton' onmouseover='infoopen(3065)'>i</a><div id="dialog-3065" class="dialogs" title="Translation Vector"><info xmlns="Unit">
                           
                           <p>
                              <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-3065' style='display:none;'><br /><div class='def'><span class='deftitle'>Translation Vector</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                  <p>
                     <span>A translation vector is a vector $\mathbf{t}$ in $\RNr{n}$ which is used to describe the shifting operation in $\RNr{n}$ whose effect on a vector $\mathbf{x}$ is to send it to $\mathbf{t} + \mathbf{x}$.
				</span>
                     
                     
                  </p>
               </def.body><br /></div><br /></div><br /></div></li><li><span>velocity      </span><a id='glossaryinfo-3138' class='msm_infobutton' onmouseover='infoopen(3138)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3138' style='display:none;'><div class='title'>Vectors Modeling Velocities</div><h2> Introduction </h2><div id="dialog-3142" class="dialogs" title="Illustration of Vectors representing Velocities">
<info xmlns="Unit">
                        
                        <p>
                           <span>For example, suppose a vector of length 1 corresponds to the speed of 20km/h. Then the following arrows represent velocities as indicated.</span>
                        </p>
                        <p align="center">
                           <span>
                              <div class="picture"><img id="image-3144" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocityVector02.gif" height="169" width="319" usemap="#VelocityVector02"/><map name="VelocityVector02"><area id="pic-3146" coords="21,24,119,48" shape="rect" href="#" onmouseover="popup(3146)"><div id="dialog-3146" class="dialogs" title="What does the red arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represents a velocity of 80km/h to the right</span>
                                             </p>
                                          </info></div></area><area id="pic-3148" coords="17,130,29,152,187,78,175,60,19,124" shape="poly" href="#" onmouseover="popup(3148)"><div id="dialog-3148" class="dialogs" title="What does the green arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represents the velocity of $\sqrt{58}\cdot 20km/h$ towords the upper right</span>
                                             </p>
                                          </info></div></area><area id="pic-3150" coords="191,32,283,104,301,86,207,20" shape="poly" href="#" onmouseover="popup(3150)"><div id="dialog-3150" class="dialogs" title="What does the blue arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represent the velocity of 100km/h towards the lower left.</span>
                                             </p>
                                          </info></div></area></map></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>When a particle moves in space, it changes its location at each instant. This change of location is characterized by the direction and the speed of the motion at that instant. Both data combined comprise the velocity at that instant. As velocity is characterized by direction and magnitude, we may represent it by a 
			<a id="hottag-3142" class="hottag" onmouseover="popup(3142)"> vector</a>  . The direction of the vector gives the direction of the motion and the length of the vector corresponds to the speed.
		</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Experiments show that superposition of motions corresponds to addition of the corresponding velocity vectors. For example: The motion of a person on a ship relative to a point on shore is superpositioned from</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>The motion of the water relative to the point on shore</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the ship relative to the water surrounding it</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the person relative to the structure of the ship.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>The velocity vector of the moving person relative to a point on shore is the sum of these three velocity vectors.</span>
            </p><p xmlns="Unit">
               <span>Similarly, the motion of an aircraft relative to the ground depends upon the wind which carries the aircraft and the superimposed motion resulting from the aircraft’s own propulsion.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3159" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocitySuperposition.gif" height="173" width="441" usemap="#VelocitySuperposition"/><map name="VelocitySuperposition"><area id="pic-3161" coords="217,39,417,53" shape="rect" href="#" onmouseover="popup(3161)"><div id="dialog-3161" class="dialogs" title="What does the blue arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the aircraft relative to the surrounding air.</span>
                                 </p>
                              </info></div></area><area id="pic-3163" coords="135,115,155,111,219,39,193,35" shape="poly" href="#" onmouseover="popup(3163)"><div id="dialog-3163" class="dialogs" title="What does the green arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the air relative to the ground.</span>
                                 </p>
                              </info></div></area><area id="pic-3165" coords="157,113,161,121,425,47,369,51,159,107" shape="poly" href="#" onmouseover="popup(3165)"><div id="dialog-3165" class="dialogs" title="What does the red arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the aircraft relative to the ground.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
</div></li></ul></li><li><span>vectors      </span><ul class='chilren'><li><span>parallel      </span><a id='glossaryinfo-857' class='msm_infobutton' onmouseover='infoopen(857)'>i</a><div id="dialog-857" class="dialogs"><info xmlns="Unit">
                                 <p>
                                    <span>Definition of the concept</span>
                                 </p>
                              </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-857' style='display:none;'><br /><div class='def'><span class='deftitle'>Parallel Vectors</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>A vector $\Vect{y}$ is parallel to a nonzero vector $\Vect{x}$ if
					</span>
                           
                           
                        </p>
                        <p align="center">
                           <span>there exists a number $t$ with $\Vect{y} = t\cdot \Vect{x}$.</span>
                        </p>
                     </def.body><br /></div><br /></div><br /></div></li></ul></li><li><span>velocity      </span><ul class='chilren'><li><span>vector      </span><a id='glossaryinfo-3138' class='msm_infobutton' onmouseover='infoopen(3138)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-3138' style='display:none;'><div class='title'>Vectors Modeling Velocities</div><h2> Introduction </h2><div id="dialog-3142" class="dialogs" title="Illustration of Vectors representing Velocities">
<info xmlns="Unit">
                        
                        <p>
                           <span>For example, suppose a vector of length 1 corresponds to the speed of 20km/h. Then the following arrows represent velocities as indicated.</span>
                        </p>
                        <p align="center">
                           <span>
                              <div class="picture"><img id="image-3144" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocityVector02.gif" height="169" width="319" usemap="#VelocityVector02"/><map name="VelocityVector02"><area id="pic-3146" coords="21,24,119,48" shape="rect" href="#" onmouseover="popup(3146)"><div id="dialog-3146" class="dialogs" title="What does the red arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represents a velocity of 80km/h to the right</span>
                                             </p>
                                          </info></div></area><area id="pic-3148" coords="17,130,29,152,187,78,175,60,19,124" shape="poly" href="#" onmouseover="popup(3148)"><div id="dialog-3148" class="dialogs" title="What does the green arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represents the velocity of $\sqrt{58}\cdot 20km/h$ towords the upper right</span>
                                             </p>
                                          </info></div></area><area id="pic-3150" coords="191,32,283,104,301,86,207,20" shape="poly" href="#" onmouseover="popup(3150)"><div id="dialog-3150" class="dialogs" title="What does the blue arrow mean?"><info xmlns="Unit">
                                             
                                             <p>
                                                <span>This vector represent the velocity of 100km/h towards the lower left.</span>
                                             </p>
                                          </info></div></area></map></div>
                           </span>
                        </p>
                     </info>
</div>
<p xmlns="Unit">
               <span>When a particle moves in space, it changes its location at each instant. This change of location is characterized by the direction and the speed of the motion at that instant. Both data combined comprise the velocity at that instant. As velocity is characterized by direction and magnitude, we may represent it by a 
			<a id="hottag-3142" class="hottag" onmouseover="popup(3142)"> vector</a>  . The direction of the vector gives the direction of the motion and the length of the vector corresponds to the speed.
		</span>
               
               
            </p>
<p xmlns="Unit">
               <span>Experiments show that superposition of motions corresponds to addition of the corresponding velocity vectors. For example: The motion of a person on a ship relative to a point on shore is superpositioned from</span>
            </p><ul xmlns="Unit">
               <li>
                  <p>
                     <span>The motion of the water relative to the point on shore</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the ship relative to the water surrounding it</span>
                  </p>
               </li>
               <li>
                  <p>
                     <span>The motion of the person relative to the structure of the ship.</span>
                  </p>
               </li>
            </ul><p xmlns="Unit">
               <span>The velocity vector of the moving person relative to a point on shore is the sum of these three velocity vectors.</span>
            </p><p xmlns="Unit">
               <span>Similarly, the motion of an aircraft relative to the ground depends upon the wind which carries the aircraft and the superimposed motion resulting from the aircraft’s own propulsion.</span>
            </p>
<p xmlns="Unit" align="center">
               <span>
                  <div class="picture"><img id="image-3159" class="mathimagemap" src="http://localhost/moodle/mod/msm/newxml/LinearAlgebraRn/Modeling/ims/VelocitySuperposition.gif" height="173" width="441" usemap="#VelocitySuperposition"/><map name="VelocitySuperposition"><area id="pic-3161" coords="217,39,417,53" shape="rect" href="#" onmouseover="popup(3161)"><div id="dialog-3161" class="dialogs" title="What does the blue arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the aircraft relative to the surrounding air.</span>
                                 </p>
                              </info></div></area><area id="pic-3163" coords="135,115,155,111,219,39,193,35" shape="poly" href="#" onmouseover="popup(3163)"><div id="dialog-3163" class="dialogs" title="What does the green arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the air relative to the ground.</span>
                                 </p>
                              </info></div></area><area id="pic-3165" coords="157,113,161,121,425,47,369,51,159,107" shape="poly" href="#" onmouseover="popup(3165)"><div id="dialog-3165" class="dialogs" title="What does the red arrow mean?"><info xmlns="Unit">
                                 
                                 <p>
                                    <span>This vector represents the velocity of the aircraft relative to the ground.</span>
                                 </p>
                              </info></div></area></map></div>
               </span>
            </p>
</div></li></ul></li><li><span>velocity vector      </span><a id='glossaryinfo-1133' class='msm_infobutton' onmouseover='infoopen(1133)'>i</a><div id="dialog-1133" class="dialogs"><info xmlns="Unit">
                           <p>
                              <span>Click to see the definition of the velocity vector of a linear motion.</span>
                           </p>
                        </info></div><div class='glossaryrefcontent' id='glossaryrefcontent-1133' style='display:none;'><br /><div class='def'><span class='deftitle'>Linear Motion</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><div id="dialog-1131" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘ell of $t$ equals a plus t times v’</span>
                              </p>
                           </info></div><div id="dialog-1135" class="dialogs"><info xmlns="Unit">
                              <p>
                                 <span>Read this as: ‘t in R’, which means: $t$ is a number in $\RNr{}$.</span>
                              </p>
                           </info></div>
<def.body xmlns="Unit">
                  <p>
                     <span>The linear motion through $\mathbf{a}$ with velocity vector $\mathbf{v}$ is given by</span>
                  </p>
                  <p align="center">
                     <span>
                        <a id="hottag-1131" class="hottag" onmouseover="popup(1131)"> 
                              $\mathbf{l}(t)\ =\ \mathbf{a} + t\cdot \mathbf{v}$
                           </a>  , with <a id="hottag-1135" class="hottag" onmouseover="popup(1135)"> 
                              $t\in \RNr{}$
                           </a>  
                     </span>
                     
                     
                  </p>
                  <p>
                     <span>The variable $t$ is called the time parameter for the motion, and the above equation is the parametric equation for the given linear motion.</span>
                  </p>
               </def.body>
<br /></div><br /></div><br /></div></li><li><span>volume      </span><ul class='chilren'><li><span>of slanted box      </span><a id='glossaryinfo-10274' class='msm_infobutton' onmouseover='infoopen(10274)'>i</a><div class='glossaryrefcontent' id='glossaryrefcontent-10274' style='display:none;'><br /><div class='def'><span class='deftitle'>Volume and oriented volume</span><span class='deftype'>Definition</span><br/><div class='mathcontent'><def.body xmlns="Unit">
                        <p>
                           <span>Given vectors $\Vect{x}_1,\dots ,\Vect{x}_n$ in $\RNr{n}$,</span>
                        </p>
                        $$\Vol(\Vect{x}_1,\dots ,\Vect{x}_n) := \Vol (\SltdBox{ \Vect{x}_1,\dots ,\Vect{x}_n } )$$
                        <p>
                           <span>is the volume of the slanted box in $\RNr{n}$ spanned by the vectors $\Vect{x}_1,\dots ,\Vect{x}_n$.
					
					The oriented volume of this box is
					</span>
                           
                           
                           
                           
                        </p>
                        $$\OriVol(\Vect{x}_1,\dots ,\Vect{x}_n) := \omega(\Vect{x}_1,\dots \Vect{x}_n)\cdot \Vol(\Vect{x}_1,\dots ,\Vect{x}_n)$$
                     </def.body><br /></div><br /></div><br /></div></li></ul></li></ul></div></div>